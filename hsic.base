0001-color-testing.patch:+			base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
0001-color-testing.patch:+				printk("r_rr: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("r_gg: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("r_bb: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("g_rr: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("g_gg: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("g_bb: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("b_rr: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("b_gg: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+				printk("b_bb: %d\n", SDE_REG_READ(&ctx->hw,
0001-color-testing.patch:+			printk("coeffs->c: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_C_OFF));
0001-color-testing.patch:+			printk("coeffs->r: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_R_OFF));
0001-color-testing.patch:+			printk("coeffs->g: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_G_OFF));
0001-color-testing.patch:+			printk("coeffs->b: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_B_OFF));
0001-color-testing.patch:+			printk("coeffs->rg: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RG_OFF));
0001-color-testing.patch:+			printk("coeffs->rb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RB_OFF));
0001-color-testing.patch:+			printk("coeffs->gb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_GB_OFF));
0001-color-testing.patch:+			printk("coeffs->rgb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RGB_OFF));
0001-color-testing.patch:+	printk("PCC_EN: %d\n", SDE_REG_READ(&ctx->hw, ctx->cap->sblk->pcc.base));
0001-color-testing.patch:+			base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+				SDE_REG_WRITE(&ctx->hw,
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, 255);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, red);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, green);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, blue);
0001-color-testing.patch:+		/*SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, red);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, green);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, blue);
0001-color-testing.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, 100);*/
0001-color-testing.patch:+	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
arch/ia64/kernel/perfmon_itanium.h:	is_loaded = ctx->ctx_state == PFM_CTX_LOADED || ctx->ctx_state == PFM_CTX_MASKED;
arch/ia64/kernel/perfmon_itanium.h:	if (cnum == 13 && is_loaded && ((*val & 0x1) == 0UL) && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon_itanium.h:	if (cnum == 11 && is_loaded && ((*val >> 28)& 0x1) == 0 && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon.c:	return ctx->ctx_pmds[i].val + (ia64_get_pmd(i) & pmu_conf->ovfl_val);
arch/ia64/kernel/perfmon.c:	ctx->ctx_pmds[i].val = val  & ~ovfl_val;
arch/ia64/kernel/perfmon.c:	next = (ctx->ctx_msgq_tail+1) % PFM_MAX_MSGS;
arch/ia64/kernel/perfmon.c:	DPRINT(("ctx_fd=%p head=%d tail=%d\n", ctx, ctx->ctx_msgq_head, ctx->ctx_msgq_tail));
arch/ia64/kernel/perfmon.c:	if (next == ctx->ctx_msgq_head) return NULL;
arch/ia64/kernel/perfmon.c: 	idx = 	ctx->ctx_msgq_tail;
arch/ia64/kernel/perfmon.c:	ctx->ctx_msgq_tail = next;
arch/ia64/kernel/perfmon.c:	DPRINT(("ctx=%p head=%d tail=%d msg=%d\n", ctx, ctx->ctx_msgq_head, ctx->ctx_msgq_tail, idx));
arch/ia64/kernel/perfmon.c:	return ctx->ctx_msgq+idx;
arch/ia64/kernel/perfmon.c:	DPRINT(("ctx=%p head=%d tail=%d\n", ctx, ctx->ctx_msgq_head, ctx->ctx_msgq_tail));
arch/ia64/kernel/perfmon.c:	msg = ctx->ctx_msgq+ctx->ctx_msgq_head;
arch/ia64/kernel/perfmon.c:	ctx->ctx_msgq_head = (ctx->ctx_msgq_head+1) % PFM_MAX_MSGS;
arch/ia64/kernel/perfmon.c:	DPRINT(("ctx=%p head=%d tail=%d type=%d\n", ctx, ctx->ctx_msgq_head, ctx->ctx_msgq_tail, msg->pfm_gen_msg.msg_type));
arch/ia64/kernel/perfmon.c:	ctx->ctx_msgq_head = ctx->ctx_msgq_tail = 0;
arch/ia64/kernel/perfmon.c:		spin_lock_init(&ctx->ctx_lock);
arch/ia64/kernel/perfmon.c:		ctx->ctx_state = PFM_CTX_UNLOADED;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_block       = (ctx_flags & PFM_FL_NOTIFY_BLOCK) ? 1 : 0;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_system      = (ctx_flags & PFM_FL_SYSTEM_WIDE) ? 1: 0;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_no_msg      = (ctx_flags & PFM_FL_OVFL_NO_MSG) ? 1: 0;
arch/ia64/kernel/perfmon.c:		 * ctx->ctx_fl_excl_idle   = (ctx_flags & PFM_FL_EXCL_IDLE) ? 1: 0;
arch/ia64/kernel/perfmon.c:		init_completion(&ctx->ctx_restart_done);
arch/ia64/kernel/perfmon.c:		ctx->ctx_last_activation = PFM_INVALID_ACTIVATION;
arch/ia64/kernel/perfmon.c:		ctx->ctx_msgq_head = ctx->ctx_msgq_tail = 0;
arch/ia64/kernel/perfmon.c:		init_waitqueue_head(&ctx->ctx_msgq_wait);
arch/ia64/kernel/perfmon.c:		init_waitqueue_head(&ctx->ctx_zombieq);
arch/ia64/kernel/perfmon.c:	 * As a consequence to this call, the ctx->th_pmds[] array
arch/ia64/kernel/perfmon.c:	mask = ctx->ctx_used_pmds[0];
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val += (val & ovfl_mask);
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val = val;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val,
arch/ia64/kernel/perfmon.c:	mask = ctx->ctx_used_monitors[0] >> PMU_FIRST_COUNTER;
arch/ia64/kernel/perfmon.c:		ia64_set_pmc(i, ctx->th_pmcs[i] & ~0xfUL);
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[i] &= ~0xfUL;
arch/ia64/kernel/perfmon.c:		DPRINT_ovfl(("pmc[%d]=0x%lx\n", i, ctx->th_pmcs[i]));
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_state != PFM_CTX_MASKED) {
arch/ia64/kernel/perfmon.c:			task_pid_nr(task), task_pid_nr(current), ctx->ctx_state);
arch/ia64/kernel/perfmon.c:	mask = ctx->ctx_used_pmds[0];
arch/ia64/kernel/perfmon.c:			val = ctx->ctx_pmds[i].val & ovfl_mask;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val &= ~ovfl_mask;
arch/ia64/kernel/perfmon.c:			val = ctx->ctx_pmds[i].val;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val,
arch/ia64/kernel/perfmon.c:	mask = ctx->ctx_used_monitors[0] >> PMU_FIRST_COUNTER;
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[i] = ctx->ctx_pmcs[i];
arch/ia64/kernel/perfmon.c:		ia64_set_pmc(i, ctx->th_pmcs[i]);
arch/ia64/kernel/perfmon.c:					task_pid_nr(task), i, ctx->th_pmcs[i]));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:		pfm_restore_ibrs(ctx->ctx_ibrs, pmu_conf->num_ibrs);
arch/ia64/kernel/perfmon.c:		pfm_restore_dbrs(ctx->ctx_dbrs, pmu_conf->num_dbrs);
arch/ia64/kernel/perfmon.c:	unsigned long mask = ctx->ctx_all_pmds[0];
arch/ia64/kernel/perfmon.c:		val = ctx->ctx_pmds[i].val;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val = val & ~ovfl_val;
arch/ia64/kernel/perfmon.c:		ctx->th_pmds[i] = val;
arch/ia64/kernel/perfmon.c:			ctx->th_pmds[i],
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[i].val));
arch/ia64/kernel/perfmon.c:	unsigned long mask = ctx->ctx_all_pmcs[0];
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[i] = ctx->ctx_pmcs[i];
arch/ia64/kernel/perfmon.c:		DPRINT(("pmc[%d]=0x%lx\n", i, ctx->th_pmcs[i]));
arch/ia64/kernel/perfmon.c:		if (ctx && ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_smpl_hdr == NULL) goto invalid_free;
arch/ia64/kernel/perfmon.c:	fmt = ctx->ctx_buf_fmt;
arch/ia64/kernel/perfmon.c:		ctx->ctx_smpl_hdr,
arch/ia64/kernel/perfmon.c:		ctx->ctx_smpl_size,
arch/ia64/kernel/perfmon.c:		ctx->ctx_smpl_vaddr));
arch/ia64/kernel/perfmon.c:	pfm_rvfree(ctx->ctx_smpl_hdr, ctx->ctx_smpl_size);
arch/ia64/kernel/perfmon.c:	ctx->ctx_smpl_hdr  = NULL;
arch/ia64/kernel/perfmon.c:	ctx->ctx_smpl_size = 0UL;
arch/ia64/kernel/perfmon.c:  	add_wait_queue(&ctx->ctx_msgq_wait, &wait);
arch/ia64/kernel/perfmon.c:		DPRINT(("head=%d tail=%d\n", ctx->ctx_msgq_head, ctx->ctx_msgq_tail));
arch/ia64/kernel/perfmon.c:	remove_wait_queue(&ctx->ctx_msgq_wait, &wait);
arch/ia64/kernel/perfmon.c:	DPRINT(("pfm_poll ctx_fd=%d before poll_wait\n", ctx->ctx_fd));
arch/ia64/kernel/perfmon.c:	poll_wait(filp, &ctx->ctx_msgq_wait, wait);
arch/ia64/kernel/perfmon.c:	DPRINT(("pfm_poll ctx_fd=%d mask=0x%x\n", ctx->ctx_fd, mask));
arch/ia64/kernel/perfmon.c:	ret = fasync_helper (fd, filp, on, &ctx->ctx_async_queue);
arch/ia64/kernel/perfmon.c:		ctx->ctx_async_queue, ret));
arch/ia64/kernel/perfmon.c:		ctx->ctx_async_queue, ret));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:			ctx->ctx_cpu,
arch/ia64/kernel/perfmon.c:	if (owner != ctx->ctx_task) {
arch/ia64/kernel/perfmon.c:			task_pid_nr(owner), task_pid_nr(ctx->ctx_task));
arch/ia64/kernel/perfmon.c:	DPRINT(("on CPU%d forcing system wide stop for [%d]\n", smp_processor_id(), task_pid_nr(ctx->ctx_task)));
arch/ia64/kernel/perfmon.c:	DPRINT(("calling CPU%d for cleanup\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:	ret = smp_call_function_single(ctx->ctx_cpu, pfm_syswide_force_stop, ctx, 1);
arch/ia64/kernel/perfmon.c:	DPRINT(("called CPU%d for cleanup ret=%d\n", ctx->ctx_cpu, ret));
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:		if (is_system && ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:			DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:			DPRINT(("ctx_state=%d\n", ctx->ctx_state));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_smpl_vaddr && current->mm) {
arch/ia64/kernel/perfmon.c:		smpl_buf_vaddr = ctx->ctx_smpl_vaddr;
arch/ia64/kernel/perfmon.c:		smpl_buf_size  = ctx->ctx_smpl_size;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_going_zombie = 1;
arch/ia64/kernel/perfmon.c:		complete(&ctx->ctx_restart_done);
arch/ia64/kernel/perfmon.c:  		add_wait_queue(&ctx->ctx_zombieq, &wait);
arch/ia64/kernel/perfmon.c:		remove_wait_queue(&ctx->ctx_zombieq, &wait);
arch/ia64/kernel/perfmon.c:		ctx->ctx_state = PFM_CTX_ZOMBIE;
arch/ia64/kernel/perfmon.c:	state = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_smpl_hdr) {
arch/ia64/kernel/perfmon.c:		smpl_buf_addr = ctx->ctx_smpl_hdr;
arch/ia64/kernel/perfmon.c:		smpl_buf_size = ctx->ctx_smpl_size;
arch/ia64/kernel/perfmon.c:		ctx->ctx_smpl_hdr = NULL;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_is_sampling = 0;
arch/ia64/kernel/perfmon.c:	if (smpl_buf_addr) pfm_exit_smpl_buffer(ctx->ctx_buf_fmt);
arch/ia64/kernel/perfmon.c:		pfm_unreserve_session(ctx, ctx->ctx_fl_system , ctx->ctx_cpu);
arch/ia64/kernel/perfmon.c:	ctx->ctx_smpl_hdr   = smpl_buf;
arch/ia64/kernel/perfmon.c:	ctx->ctx_smpl_size  = size; /* aligned size */
arch/ia64/kernel/perfmon.c:	DPRINT(("aligned size=%ld, hdr=%p mapped @0x%lx\n", size, ctx->ctx_smpl_hdr, vma->vm_start));
arch/ia64/kernel/perfmon.c:	ctx->ctx_smpl_vaddr = (void *)vma->vm_start;
arch/ia64/kernel/perfmon.c:	ctx->ctx_buf_fmt = fmt;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_is_sampling = 1; /* assume record() is defined */
arch/ia64/kernel/perfmon.c:	ret = pfm_buf_fmt_init(fmt, task, ctx->ctx_smpl_hdr, ctx_flags, cpu, fmt_arg);
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmcs[i] = PMC_DFL_VAL(i);
arch/ia64/kernel/perfmon.c:		DPRINT(("pmc[%d]=0x%lx\n", i, ctx->ctx_pmcs[i]));
arch/ia64/kernel/perfmon.c:	ctx->ctx_all_pmcs[0] = pmu_conf->impl_pmcs[0] & ~0x1;
arch/ia64/kernel/perfmon.c:	ctx->ctx_all_pmds[0] = pmu_conf->impl_pmds[0];
arch/ia64/kernel/perfmon.c:	DPRINT(("<%d> all_pmcs=0x%lx all_pmds=0x%lx\n", ctx->ctx_fd, ctx->ctx_all_pmcs[0],ctx->ctx_all_pmds[0]));
arch/ia64/kernel/perfmon.c:	ctx->ctx_used_ibrs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	ctx->ctx_used_dbrs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	req->ctx_fd = ctx->ctx_fd = fd;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_system,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_block,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_excl_idle,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_no_msg,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fd));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_buf_fmt) {
arch/ia64/kernel/perfmon.c:		pfm_buf_fmt_exit(ctx->ctx_buf_fmt, current, NULL, regs);
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[i].val = val = pfm_new_counter_value(ctx->ctx_pmds+ i, is_long_reset);
arch/ia64/kernel/perfmon.c:		reset_others        |= ctx->ctx_pmds[i].reset_pmds[0];
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[i].val = val = pfm_new_counter_value(ctx->ctx_pmds + i, is_long_reset);
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_state == PFM_CTX_MASKED) {
arch/ia64/kernel/perfmon.c:		val           = pfm_new_counter_value(ctx->ctx_pmds+ i, is_long_reset);
arch/ia64/kernel/perfmon.c:		reset_others |= ctx->ctx_pmds[i].reset_pmds[0];
arch/ia64/kernel/perfmon.c:		val = pfm_new_counter_value(ctx->ctx_pmds + i, is_long_reset);
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	task      = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:		if (is_system && ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:			DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].flags = flags;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].reset_pmds[0] = reset_pmds;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].smpl_pmds[0]  = smpl_pmds;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].eventid       = req->reg_smpl_eventid;
arch/ia64/kernel/perfmon.c:			if (state == PFM_CTX_MASKED) ctx->ctx_ovfl_regs[0] &= ~1UL << cnum;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmcs[cnum] = value;
arch/ia64/kernel/perfmon.c:			if (is_system == 0) ctx->th_pmcs[cnum] = value;
arch/ia64/kernel/perfmon.c:				ctx->ctx_reload_pmcs[0] |= 1UL << cnum;
arch/ia64/kernel/perfmon.c:			  ctx->ctx_all_pmcs[0],
arch/ia64/kernel/perfmon.c:			  ctx->ctx_used_pmds[0],
arch/ia64/kernel/perfmon.c:			  ctx->ctx_pmds[cnum].eventid,
arch/ia64/kernel/perfmon.c:			  ctx->ctx_reload_pmcs[0],
arch/ia64/kernel/perfmon.c:			  ctx->ctx_used_monitors[0],
arch/ia64/kernel/perfmon.c:			  ctx->ctx_ovfl_regs[0]));
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	task      = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:		if (unlikely(is_system && ctx->ctx_cpu != smp_processor_id())) {
arch/ia64/kernel/perfmon.c:			DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].lval = value;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[cnum].long_reset  = req->reg_long_reset;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[cnum].short_reset = req->reg_short_reset;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[cnum].seed = req->reg_random_seed;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[cnum].mask = req->reg_random_mask;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[cnum].val  = value;
arch/ia64/kernel/perfmon.c:			ctx->ctx_ovfl_regs[0] &= ~1UL << cnum;
arch/ia64/kernel/perfmon.c:			if (is_system == 0) ctx->th_pmds[cnum] = hw_value;
arch/ia64/kernel/perfmon.c:				ctx->ctx_reload_pmds[0] |= 1UL << cnum;
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].val,
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].short_reset,
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].long_reset,
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].seed,
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].mask,
arch/ia64/kernel/perfmon.c:			ctx->ctx_used_pmds[0],
arch/ia64/kernel/perfmon.c:			ctx->ctx_pmds[cnum].reset_pmds[0],
arch/ia64/kernel/perfmon.c:			ctx->ctx_reload_pmds[0],
arch/ia64/kernel/perfmon.c:			ctx->ctx_all_pmds[0],
arch/ia64/kernel/perfmon.c:			ctx->ctx_ovfl_regs[0]));
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	task      = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:		if (unlikely(is_system && ctx->ctx_cpu != smp_processor_id())) {
arch/ia64/kernel/perfmon.c:			DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:		sval        = ctx->ctx_pmds[cnum].val;
arch/ia64/kernel/perfmon.c:		lval        = ctx->ctx_pmds[cnum].lval;
arch/ia64/kernel/perfmon.c:			val = is_loaded ? ctx->th_pmds[cnum] : 0UL;
arch/ia64/kernel/perfmon.c:			ret = (*rd_func)(ctx->ctx_task, ctx, cnum, &v, regs);
arch/ia64/kernel/perfmon.c:	if (task != current && ctx->ctx_fl_system == 0) return -EBUSY;
arch/ia64/kernel/perfmon.c:	if (task != current && ctx->ctx_fl_system == 0) return -EBUSY;
arch/ia64/kernel/perfmon.c:	if (ctx && ctx->ctx_fl_using_dbreg == 1) return -1;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	fmt       = ctx->ctx_buf_fmt;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	if (is_system && ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:		DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:		fmt = ctx->ctx_buf_fmt;
arch/ia64/kernel/perfmon.c:			ctx->ctx_ovfl_regs[0]));
arch/ia64/kernel/perfmon.c:			prefetch(ctx->ctx_smpl_hdr);
arch/ia64/kernel/perfmon.c:				ret = pfm_buf_fmt_restart_active(fmt, task, &rst_ctrl, ctx->ctx_smpl_hdr, regs);
arch/ia64/kernel/perfmon.c:				ret = pfm_buf_fmt_restart(fmt, task, &rst_ctrl, ctx->ctx_smpl_hdr, regs);
arch/ia64/kernel/perfmon.c:				pfm_reset_regs(ctx, ctx->ctx_ovfl_regs, PFM_PMD_LONG_RESET);
arch/ia64/kernel/perfmon.c:		ctx->ctx_ovfl_regs[0] = 0UL;
arch/ia64/kernel/perfmon.c:		ctx->ctx_state = PFM_CTX_LOADED;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_can_restart = 0;
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_fl_can_restart == 0) return -EINVAL;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_can_restart = 0;
arch/ia64/kernel/perfmon.c:		complete(&ctx->ctx_restart_done);
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_trap_reason = PFM_TRAP_REASON_RESET;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	task      = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:		if (unlikely(is_system && ctx->ctx_cpu != smp_processor_id())) {
arch/ia64/kernel/perfmon.c:			DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:	first_time = ctx->ctx_fl_using_dbreg == 0;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_using_dbreg = 1;
arch/ia64/kernel/perfmon.c:			ctx->ctx_ibrs[rnum] = dbreg.val;
arch/ia64/kernel/perfmon.c:				rnum, dbreg.val, ctx->ctx_used_ibrs[0], is_loaded, can_access_pmu));
arch/ia64/kernel/perfmon.c:			ctx->ctx_dbrs[rnum] = dbreg.val;
arch/ia64/kernel/perfmon.c:				rnum, dbreg.val, ctx->ctx_used_dbrs[0], is_loaded, can_access_pmu));
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_fl_system) {
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_using_dbreg = 0;
arch/ia64/kernel/perfmon.c:	if (task != current && ctx->ctx_fl_system == 0) return -EBUSY;
arch/ia64/kernel/perfmon.c:	if (task != current && ctx->ctx_fl_system == 0) return -EBUSY;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	if (is_system && ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:		DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:		ctx->ctx_saved_psr_up = 0;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	if (is_system && ctx->ctx_cpu != smp_processor_id()) {
arch/ia64/kernel/perfmon.c:		DPRINT(("should be running on CPU%d\n", ctx->ctx_cpu));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_task == current) {
arch/ia64/kernel/perfmon.c:		tregs = task_pt_regs(ctx->ctx_task);
arch/ia64/kernel/perfmon.c:		ctx->ctx_saved_psr_up = IA64_PSR_UP;
arch/ia64/kernel/perfmon.c:	state     = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:			ctx->ctx_state));
arch/ia64/kernel/perfmon.c:	DPRINT(("load_pid [%d] using_dbreg=%d\n", req->load_pid, ctx->ctx_fl_using_dbreg));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:	the_cpu = ctx->ctx_cpu = smp_processor_id();
arch/ia64/kernel/perfmon.c:	ctx->ctx_state = PFM_CTX_LOADED;
arch/ia64/kernel/perfmon.c:	ctx->ctx_task = task;
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_fl_excl_idle) PFM_CPUINFO_SET(PFM_CPUINFO_EXCL_IDLE);
arch/ia64/kernel/perfmon.c:	pmcs_source = ctx->th_pmcs;
arch/ia64/kernel/perfmon.c:	pmds_source = ctx->th_pmds;
arch/ia64/kernel/perfmon.c:		pfm_restore_pmds(pmds_source, ctx->ctx_all_pmds[0]);
arch/ia64/kernel/perfmon.c:		pfm_restore_pmcs(pmcs_source, ctx->ctx_all_pmcs[0]);
arch/ia64/kernel/perfmon.c:		ctx->ctx_reload_pmcs[0] = 0UL;
arch/ia64/kernel/perfmon.c:		ctx->ctx_reload_pmds[0] = 0UL;
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:			pfm_restore_ibrs(ctx->ctx_ibrs, pmu_conf->num_ibrs);
arch/ia64/kernel/perfmon.c:			pfm_restore_dbrs(ctx->ctx_dbrs, pmu_conf->num_dbrs);
arch/ia64/kernel/perfmon.c:		ctx->ctx_last_activation = PFM_INVALID_ACTIVATION;
arch/ia64/kernel/perfmon.c:		ctx->ctx_saved_psr_up = 0UL;
arch/ia64/kernel/perfmon.c:	if (ret) pfm_unreserve_session(ctx, ctx->ctx_fl_system, the_cpu);
arch/ia64/kernel/perfmon.c:				ctx->ctx_state = PFM_CTX_UNLOADED;
arch/ia64/kernel/perfmon.c:				ctx->ctx_task  = NULL;
arch/ia64/kernel/perfmon.c:	DPRINT(("ctx_state=%d task [%d]\n", ctx->ctx_state, task ? task_pid_nr(task) : -1));
arch/ia64/kernel/perfmon.c:	prev_state = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	is_system  = ctx->ctx_fl_system;
arch/ia64/kernel/perfmon.c:	ctx->ctx_state = PFM_CTX_UNLOADED;
arch/ia64/kernel/perfmon.c:			pfm_unreserve_session(ctx, 1 , ctx->ctx_cpu);
arch/ia64/kernel/perfmon.c:		ctx->ctx_task = NULL;
arch/ia64/kernel/perfmon.c:		pfm_unreserve_session(ctx, 0 , ctx->ctx_cpu);
arch/ia64/kernel/perfmon.c:	ctx->ctx_last_activation = PFM_INVALID_ACTIVATION;
arch/ia64/kernel/perfmon.c:	ctx->ctx_task             = NULL;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_trap_reason  = PFM_TRAP_REASON_NONE;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_can_restart  = 0;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_going_zombie = 0;
arch/ia64/kernel/perfmon.c:	DPRINT(("state=%d task [%d]\n", ctx->ctx_state, task_pid_nr(task)));
arch/ia64/kernel/perfmon.c:	state = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	state = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:	task  = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:		DPRINT(("context %d no task, state=%d\n", ctx->ctx_fd, state));
arch/ia64/kernel/perfmon.c:		ctx->ctx_fd,
arch/ia64/kernel/perfmon.c:	if (task == current || ctx->ctx_fl_system) return 0;
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_state != old_state) {
arch/ia64/kernel/perfmon.c:			DPRINT(("old_state=%d new_state=%d\n", old_state, ctx->ctx_state));
arch/ia64/kernel/perfmon.c:	prefetch(&ctx->ctx_state);
arch/ia64/kernel/perfmon.c:	pfm_buffer_fmt_t *fmt = ctx->ctx_buf_fmt;
arch/ia64/kernel/perfmon.c:	state = ctx->ctx_state;
arch/ia64/kernel/perfmon.c:			ret = pfm_buf_fmt_restart_active(fmt, current, &rst_ctrl, ctx->ctx_smpl_hdr, regs);
arch/ia64/kernel/perfmon.c:			ret = pfm_buf_fmt_restart(fmt, current, &rst_ctrl, ctx->ctx_smpl_hdr, regs);
arch/ia64/kernel/perfmon.c:			if (ctx->ctx_state == PFM_CTX_MASKED) pfm_restore_monitoring(current);
arch/ia64/kernel/perfmon.c:		ctx->ctx_state = PFM_CTX_LOADED;
arch/ia64/kernel/perfmon.c:	wake_up_interruptible(&ctx->ctx_zombieq);
arch/ia64/kernel/perfmon.c:	reason = ctx->ctx_fl_trap_reason;
arch/ia64/kernel/perfmon.c:	ctx->ctx_fl_trap_reason = PFM_TRAP_REASON_NONE;
arch/ia64/kernel/perfmon.c:	ovfl_regs = ctx->ctx_ovfl_regs[0];
arch/ia64/kernel/perfmon.c:	DPRINT(("reason=%d state=%d\n", reason, ctx->ctx_state));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_going_zombie || ctx->ctx_state == PFM_CTX_ZOMBIE)
arch/ia64/kernel/perfmon.c:	ret = wait_for_completion_interruptible(&ctx->ctx_restart_done);
arch/ia64/kernel/perfmon.c:	ovfl_regs = ctx->ctx_ovfl_regs[0];
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_going_zombie) {
arch/ia64/kernel/perfmon.c:	ctx->ctx_ovfl_regs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_state == PFM_CTX_ZOMBIE) {
arch/ia64/kernel/perfmon.c:	if (msg) wake_up_interruptible(&ctx->ctx_msgq_wait);
arch/ia64/kernel/perfmon.c:	kill_fasync (&ctx->ctx_async_queue, SIGIO, POLL_IN);
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_no_msg == 0) {
arch/ia64/kernel/perfmon.c:		msg->pfm_ovfl_msg.msg_ctx_fd       = ctx->ctx_fd;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_no_msg,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fd,
arch/ia64/kernel/perfmon.c:	msg->pfm_end_msg.msg_ctx_fd  = ctx->ctx_fd;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_no_msg,
arch/ia64/kernel/perfmon.c:		ctx->ctx_fd));
arch/ia64/kernel/perfmon.c:	if (unlikely(ctx->ctx_state == PFM_CTX_ZOMBIE)) goto stop_monitoring;
arch/ia64/kernel/perfmon.c:			ctx->ctx_used_pmds[0]));
arch/ia64/kernel/perfmon.c:		old_val              = new_val = ctx->ctx_pmds[i].val;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[i].val = new_val;
arch/ia64/kernel/perfmon.c:		ovfl_arg = &ctx->ctx_ovfl_arg;
arch/ia64/kernel/perfmon.c:		prefetch(ctx->ctx_smpl_hdr);
arch/ia64/kernel/perfmon.c:			ovfl_arg->smpl_pmds[0]  = smpl_pmds = ctx->ctx_pmds[i].smpl_pmds[0];
arch/ia64/kernel/perfmon.c:			ovfl_arg->pmd_value      = ctx->ctx_pmds[i].val;
arch/ia64/kernel/perfmon.c:			ovfl_arg->pmd_last_reset = ctx->ctx_pmds[i].lval;
arch/ia64/kernel/perfmon.c:			ovfl_arg->pmd_eventid    = ctx->ctx_pmds[i].eventid;
arch/ia64/kernel/perfmon.c:			ret = (*ctx->ctx_buf_fmt->fmt_handler)(task, ctx->ctx_smpl_hdr, ovfl_arg, regs, tstamp);
arch/ia64/kernel/perfmon.c:		ctx->ctx_ovfl_regs[0] = ovfl_pmds;
arch/ia64/kernel/perfmon.c:			ctx->ctx_fl_trap_reason = PFM_TRAP_REASON_BLOCK;
arch/ia64/kernel/perfmon.c:			ctx->ctx_fl_trap_reason,
arch/ia64/kernel/perfmon.c:		ctx->ctx_state = PFM_CTX_MASKED;
arch/ia64/kernel/perfmon.c:		ctx->ctx_fl_can_restart = 1;
arch/ia64/kernel/perfmon.c:		if (ctx->ctx_fl_system == 0 && (task->thread.flags & IA64_THREAD_PM_VALID) == 0) 
arch/ia64/kernel/perfmon.c:	struct task_struct *task = ctx->ctx_task;
arch/ia64/kernel/perfmon.c:					task_pid_nr(ctx->ctx_task)));
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_state == PFM_CTX_ZOMBIE) {
arch/ia64/kernel/perfmon.c:		BUG_ON(ctx->ctx_smpl_hdr);
arch/ia64/kernel/perfmon.c:	ctx->ctx_saved_psr_up = psr & IA64_PSR_UP;
arch/ia64/kernel/perfmon.c:	pfm_save_pmds(ctx->th_pmds, ctx->ctx_used_pmds[0]);
arch/ia64/kernel/perfmon.c:	ctx->th_pmcs[0] = ia64_get_pmc(0);
arch/ia64/kernel/perfmon.c:	if (ctx->th_pmcs[0] & ~0x1UL) pfm_unfreeze_pmu();
arch/ia64/kernel/perfmon.c:	ctx->ctx_saved_psr_up = psr & IA64_PSR_UP;
arch/ia64/kernel/perfmon.c:	pfm_save_pmds(ctx->th_pmds, ctx->ctx_used_pmds[0]);
arch/ia64/kernel/perfmon.c:	ctx->th_pmcs[0] = ia64_get_pmc(0);
arch/ia64/kernel/perfmon.c:	if (ctx->th_pmcs[0] & ~0x1UL) pfm_unfreeze_pmu();
arch/ia64/kernel/perfmon.c:	if (unlikely(ctx->ctx_state == PFM_CTX_ZOMBIE)) {
arch/ia64/kernel/perfmon.c:		BUG_ON(ctx->ctx_smpl_hdr);
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:		pfm_restore_ibrs(ctx->ctx_ibrs, pmu_conf->num_ibrs);
arch/ia64/kernel/perfmon.c:		pfm_restore_dbrs(ctx->ctx_dbrs, pmu_conf->num_dbrs);
arch/ia64/kernel/perfmon.c:	psr_up = ctx->ctx_saved_psr_up;
arch/ia64/kernel/perfmon.c:	if (GET_LAST_CPU(ctx) == smp_processor_id() && ctx->ctx_last_activation == GET_ACTIVATION()) {
arch/ia64/kernel/perfmon.c:		pmc_mask = ctx->ctx_reload_pmcs[0];
arch/ia64/kernel/perfmon.c:		pmd_mask = ctx->ctx_reload_pmds[0];
arch/ia64/kernel/perfmon.c:		pmd_mask = pfm_sysctl.fastctxsw ?  ctx->ctx_used_pmds[0] : ctx->ctx_all_pmds[0];
arch/ia64/kernel/perfmon.c:		pmc_mask = ctx->ctx_all_pmcs[0];
arch/ia64/kernel/perfmon.c:	if (pmd_mask) pfm_restore_pmds(ctx->th_pmds, pmd_mask);
arch/ia64/kernel/perfmon.c:	if (pmc_mask) pfm_restore_pmcs(ctx->th_pmcs, pmc_mask);
arch/ia64/kernel/perfmon.c:	if (unlikely(PMC0_HAS_OVFL(ctx->th_pmcs[0]))) {
arch/ia64/kernel/perfmon.c:		ia64_set_pmc(0, ctx->th_pmcs[0]);
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	ctx->ctx_reload_pmcs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	ctx->ctx_reload_pmds[0] = 0UL;
arch/ia64/kernel/perfmon.c:	if (ctx->ctx_fl_using_dbreg) {
arch/ia64/kernel/perfmon.c:		pfm_restore_ibrs(ctx->ctx_ibrs, pmu_conf->num_ibrs);
arch/ia64/kernel/perfmon.c:		pfm_restore_dbrs(ctx->ctx_dbrs, pmu_conf->num_dbrs);
arch/ia64/kernel/perfmon.c:	psr_up = ctx->ctx_saved_psr_up;
arch/ia64/kernel/perfmon.c:	pmd_mask = pfm_sysctl.fastctxsw ?  ctx->ctx_used_pmds[0] : ctx->ctx_all_pmds[0];
arch/ia64/kernel/perfmon.c:	pmc_mask = ctx->ctx_all_pmcs[0];
arch/ia64/kernel/perfmon.c:	pfm_restore_pmds(ctx->th_pmds, pmd_mask);
arch/ia64/kernel/perfmon.c:	pfm_restore_pmcs(ctx->th_pmcs, pmc_mask);
arch/ia64/kernel/perfmon.c:	if (unlikely(PMC0_HAS_OVFL(ctx->th_pmcs[0]))) {
arch/ia64/kernel/perfmon.c:		ia64_set_pmc(0, ctx->th_pmcs[0]);
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[0] = 0UL;
arch/ia64/kernel/perfmon.c:	is_self = ctx->ctx_task == task ? 1 : 0;
arch/ia64/kernel/perfmon.c:	can_access_pmu = (GET_PMU_OWNER() == task) || (ctx->ctx_fl_system && ctx->ctx_cpu == smp_processor_id());
arch/ia64/kernel/perfmon.c:		pmc0 = ctx->th_pmcs[0];
arch/ia64/kernel/perfmon.c:		ctx->th_pmcs[0] = 0;
arch/ia64/kernel/perfmon.c:	mask2 = ctx->ctx_used_pmds[0];
arch/ia64/kernel/perfmon.c:		val = pmd_val = can_access_pmu ? ia64_get_pmd(i) : ctx->th_pmds[i];
arch/ia64/kernel/perfmon.c:				ctx->ctx_pmds[i].val,
arch/ia64/kernel/perfmon.c:			val = ctx->ctx_pmds[i].val + (val & ovfl_val);
arch/ia64/kernel/perfmon.c:		if (is_self) ctx->th_pmds[i] = pmd_val;
arch/ia64/kernel/perfmon.c:		ctx->ctx_pmds[i].val = val;
arch/ia64/kernel/perfmon.c:		printk("->CPU%d pmc[%d]=0x%lx thread_pmc[%d]=0x%lx\n", this_cpu, i, ia64_get_pmc(i), i, ctx->th_pmcs[i]);
arch/ia64/kernel/perfmon.c:		printk("->CPU%d pmd[%d]=0x%lx thread_pmd[%d]=0x%lx\n", this_cpu, i, ia64_get_pmd(i), i, ctx->th_pmds[i]);
arch/ia64/kernel/perfmon.c:				ctx->ctx_state,
arch/ia64/kernel/perfmon.c:				ctx->ctx_smpl_vaddr,
arch/ia64/kernel/perfmon.c:				ctx->ctx_smpl_hdr,
arch/ia64/kernel/perfmon.c:				ctx->ctx_msgq_head,
arch/ia64/kernel/perfmon.c:				ctx->ctx_msgq_tail,
arch/ia64/kernel/perfmon.c:				ctx->ctx_saved_psr_up);
arch/ia64/kernel/perfmon_montecito.h:	is_loaded = ctx->ctx_state == PFM_CTX_LOADED || ctx->ctx_state == PFM_CTX_MASKED;
arch/ia64/kernel/perfmon_montecito.h:	DPRINT(("cnum=%u val=0x%lx, using_dbreg=%d loaded=%d\n", cnum, tmpval, ctx->ctx_fl_using_dbreg, is_loaded));
arch/ia64/kernel/perfmon_montecito.h:	    && (tmpval & 0x1e00000000000UL) && (tmpval & 0x18181818UL) != 0x18181818UL && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon_montecito.h:	if (cnum == 38 && is_loaded && ((tmpval & 0x492UL) != 0x492UL) && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon_montecito.h:			  val38 = ctx->ctx_pmcs[38];
arch/ia64/kernel/perfmon_montecito.h:			  val41 = ctx->ctx_pmcs[41];
arch/ia64/kernel/perfmon_montecito.h:			  val32 = ctx->ctx_pmcs[32];
arch/ia64/kernel/perfmon_montecito.h:			  val41 = ctx->ctx_pmcs[41];
arch/ia64/kernel/perfmon_montecito.h:			  val32 = ctx->ctx_pmcs[32];
arch/ia64/kernel/perfmon_montecito.h:			  val38 = ctx->ctx_pmcs[38];
arch/ia64/kernel/perfmon_mckinley.h:	is_loaded = ctx->ctx_state == PFM_CTX_LOADED || ctx->ctx_state == PFM_CTX_MASKED;
arch/ia64/kernel/perfmon_mckinley.h:	DPRINT(("cnum=%u val=0x%lx, using_dbreg=%d loaded=%d\n", cnum, *val, ctx->ctx_fl_using_dbreg, is_loaded));
arch/ia64/kernel/perfmon_mckinley.h:	    && (*val & 0x1e00000000000UL) && (*val & 0x18181818UL) != 0x18181818UL && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon_mckinley.h:	if (cnum == 14 && is_loaded && ((*val & 0x2222UL) != 0x2222UL) && ctx->ctx_fl_using_dbreg == 0) {
arch/ia64/kernel/perfmon_mckinley.h:			 val13 = ctx->ctx_pmcs[13];
arch/ia64/kernel/perfmon_mckinley.h:			 val14 = ctx->ctx_pmcs[14];
arch/ia64/kernel/perfmon_mckinley.h:		case 13: val8  = ctx->ctx_pmcs[8];
arch/ia64/kernel/perfmon_mckinley.h:			 val14 = ctx->ctx_pmcs[14];
arch/ia64/kernel/perfmon_mckinley.h:		case 14: val8  = ctx->ctx_pmcs[8];
arch/ia64/kernel/perfmon_mckinley.h:			 val13 = ctx->ctx_pmcs[13];
arch/x86/kernel/cpu/microcode/core.c:	ctx->err = microcode_ops->collect_cpu_info(smp_processor_id(),
arch/x86/kernel/cpu/microcode/core.c:						   ctx->cpu_sig);
arch/x86/kernel/cpu/microcode/core.c:	ctx->err = microcode_ops->apply_microcode(smp_processor_id());
arch/x86/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/x86/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/x86/purgatory/sha256.c:	sctx->state[0] = SHA256_H0;
arch/x86/purgatory/sha256.c:	sctx->state[1] = SHA256_H1;
arch/x86/purgatory/sha256.c:	sctx->state[2] = SHA256_H2;
arch/x86/purgatory/sha256.c:	sctx->state[3] = SHA256_H3;
arch/x86/purgatory/sha256.c:	sctx->state[4] = SHA256_H4;
arch/x86/purgatory/sha256.c:	sctx->state[5] = SHA256_H5;
arch/x86/purgatory/sha256.c:	sctx->state[6] = SHA256_H6;
arch/x86/purgatory/sha256.c:	sctx->state[7] = SHA256_H7;
arch/x86/purgatory/sha256.c:	sctx->count = 0;
arch/x86/purgatory/sha256.c:	partial = sctx->count & 0x3f;
arch/x86/purgatory/sha256.c:	sctx->count += len;
arch/x86/purgatory/sha256.c:			memcpy(sctx->buf + partial, data, done + 64);
arch/x86/purgatory/sha256.c:			src = sctx->buf;
arch/x86/purgatory/sha256.c:			sha256_transform(sctx->state, src);
arch/x86/purgatory/sha256.c:	memcpy(sctx->buf + partial, src, len - done);
arch/x86/purgatory/sha256.c:	bits = cpu_to_be64(sctx->count << 3);
arch/x86/purgatory/sha256.c:	index = sctx->count & 0x3f;
arch/x86/purgatory/sha256.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/x86/mm/kmmio.c:	if (ctx->active) {
arch/x86/mm/kmmio.c:		if (page_base == ctx->addr) {
arch/x86/mm/kmmio.c:			pr_emerg("previous hit was at 0x%08lx.\n", ctx->addr);
arch/x86/mm/kmmio.c:	ctx->active++;
arch/x86/mm/kmmio.c:	ctx->fpage = faultpage;
arch/x86/mm/kmmio.c:	ctx->probe = get_kmmio_probe(page_base);
arch/x86/mm/kmmio.c:	ctx->saved_flags = (regs->flags & (X86_EFLAGS_TF | X86_EFLAGS_IF));
arch/x86/mm/kmmio.c:	ctx->addr = page_base;
arch/x86/mm/kmmio.c:	if (ctx->probe && ctx->probe->pre_handler)
arch/x86/mm/kmmio.c:		ctx->probe->pre_handler(ctx->probe, regs, addr);
arch/x86/mm/kmmio.c:	disarm_kmmio_fault_page(ctx->fpage);
arch/x86/mm/kmmio.c:	if (!ctx->active) {
arch/x86/mm/kmmio.c:	if (ctx->probe && ctx->probe->post_handler)
arch/x86/mm/kmmio.c:		ctx->probe->post_handler(ctx->probe, condition, regs);
arch/x86/mm/kmmio.c:	if (ctx->fpage->count)
arch/x86/mm/kmmio.c:		arm_kmmio_fault_page(ctx->fpage);
arch/x86/mm/kmmio.c:	regs->flags |= ctx->saved_flags;
arch/x86/mm/kmmio.c:	ctx->active--;
arch/x86/mm/kmmio.c:	BUG_ON(ctx->active);
arch/x86/events/intel/lbr.c:	if (task_ctx->lbr_callstack_users == 0 ||
arch/x86/events/intel/lbr.c:	    task_ctx->lbr_stack_state == LBR_NONE) {
arch/x86/events/intel/lbr.c:	tos = task_ctx->tos;
arch/x86/events/intel/lbr.c:		wrlbr_from(lbr_idx, task_ctx->lbr_from[i]);
arch/x86/events/intel/lbr.c:		wrlbr_to  (lbr_idx, task_ctx->lbr_to[i]);
arch/x86/events/intel/lbr.c:			wrmsrl(MSR_LBR_INFO_0 + lbr_idx, task_ctx->lbr_info[i]);
arch/x86/events/intel/lbr.c:	task_ctx->lbr_stack_state = LBR_NONE;
arch/x86/events/intel/lbr.c:	if (task_ctx->lbr_callstack_users == 0) {
arch/x86/events/intel/lbr.c:		task_ctx->lbr_stack_state = LBR_NONE;
arch/x86/events/intel/lbr.c:		task_ctx->lbr_from[i] = rdlbr_from(lbr_idx);
arch/x86/events/intel/lbr.c:		task_ctx->lbr_to[i]   = rdlbr_to(lbr_idx);
arch/x86/events/intel/lbr.c:			rdmsrl(MSR_LBR_INFO_0 + lbr_idx, task_ctx->lbr_info[i]);
arch/x86/events/intel/lbr.c:	task_ctx->tos = tos;
arch/x86/events/intel/lbr.c:	task_ctx->lbr_stack_state = LBR_VALID;
arch/x86/events/intel/lbr.c:	task_ctx = ctx ? ctx->task_ctx_data : NULL;
arch/x86/events/intel/lbr.c:	if (branch_user_callstack(cpuc->br_sel) && event->ctx->task_ctx_data) {
arch/x86/events/intel/lbr.c:		task_ctx = event->ctx->task_ctx_data;
arch/x86/events/intel/lbr.c:		task_ctx->lbr_callstack_users++;
arch/x86/events/intel/lbr.c:	perf_sched_cb_inc(event->ctx->pmu);
arch/x86/events/intel/lbr.c:	    event->ctx->task_ctx_data) {
arch/x86/events/intel/lbr.c:		task_ctx = event->ctx->task_ctx_data;
arch/x86/events/intel/lbr.c:		task_ctx->lbr_callstack_users--;
arch/x86/events/intel/lbr.c:	perf_sched_cb_dec(event->ctx->pmu);
arch/x86/events/intel/ds.c:	pebs_update_state(needed_cb, cpuc, event->ctx->pmu);
arch/x86/events/intel/ds.c:	pebs_update_state(needed_cb, cpuc, event->ctx->pmu);
arch/x86/net/bpf_jit_comp.c:	bool seen_ld_abs = ctx->seen_ld_abs | (oldproglen == 0);
arch/x86/net/bpf_jit_comp.c:	bool seen_ax_reg = ctx->seen_ax_reg | (oldproglen == 0);
arch/x86/net/bpf_jit_comp.c:			ctx->seen_ax_reg = seen_ax_reg = true;
arch/x86/net/bpf_jit_comp.c:				jmp_offset = ctx->cleanup_addr - (addrs[i] - 11);
arch/x86/net/bpf_jit_comp.c:			ctx->seen_ld_abs = seen_ld_abs = true;
arch/x86/net/bpf_jit_comp.c:				jmp_offset = ctx->cleanup_addr - addrs[i];
arch/x86/net/bpf_jit_comp.c:			ctx->cleanup_addr = proglen;
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->flag = HASH_UPDATE;
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (ctx->status & HASH_CTX_STS_COMPLETE) {
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->status = HASH_CTX_STS_COMPLETE;
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (ctx->partial_block_buffer_length == 0 &&
arch/x86/crypto/sha256-mb/sha256_mb.c:		    ctx->incoming_buffer_length) {
arch/x86/crypto/sha256-mb/sha256_mb.c:			const void *buffer = ctx->incoming_buffer;
arch/x86/crypto/sha256-mb/sha256_mb.c:			uint32_t len = ctx->incoming_buffer_length;
arch/x86/crypto/sha256-mb/sha256_mb.c:				memcpy(ctx->partial_block_buffer,
arch/x86/crypto/sha256-mb/sha256_mb.c:				ctx->partial_block_buffer_length = copy_len;
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->incoming_buffer_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:				ctx->job.buffer = (uint8_t *) buffer;
arch/x86/crypto/sha256-mb/sha256_mb.c:				ctx->job.len = len;
arch/x86/crypto/sha256-mb/sha256_mb.c:				sha256_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (ctx->status & HASH_CTX_STS_LAST) {
arch/x86/crypto/sha256-mb/sha256_mb.c:			uint8_t *buf = ctx->partial_block_buffer;
arch/x86/crypto/sha256-mb/sha256_mb.c:				sha256_pad(buf, ctx->total_length);
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->status = (HASH_CTX_STS_PROCESSING |
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->job.buffer = buf;
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->job.len = (uint32_t) n_extra_blocks;
arch/x86/crypto/sha256-mb/sha256_mb.c:				sha256_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->error = HASH_CTX_ERROR_INVALID_FLAGS;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (ctx->status & HASH_CTX_STS_PROCESSING) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_PROCESSING;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if ((ctx->status & HASH_CTX_STS_COMPLETE) && !(flags & HASH_FIRST)) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_COMPLETED;
arch/x86/crypto/sha256-mb/sha256_mb.c:		sha256_init_digest(ctx->job.result_digest);
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->total_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:		ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->error = HASH_CTX_ERROR_NONE;
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->incoming_buffer = buffer;
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->incoming_buffer_length = len;
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->status = (flags & HASH_LAST) ?
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->total_length += len;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (ctx->partial_block_buffer_length || len < SHA256_BLOCK_SIZE) {
arch/x86/crypto/sha256-mb/sha256_mb.c:					ctx->partial_block_buffer_length;
arch/x86/crypto/sha256-mb/sha256_mb.c:		&ctx->partial_block_buffer[ctx->partial_block_buffer_length],
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->partial_block_buffer_length += copy_len;
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->incoming_buffer = (const void *)
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->incoming_buffer_length = len - copy_len;
arch/x86/crypto/sha256-mb/sha256_mb.c:		assert(ctx->partial_block_buffer_length <= SHA256_BLOCK_SIZE);
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (ctx->partial_block_buffer_length >= SHA256_BLOCK_SIZE) {
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->job.buffer = ctx->partial_block_buffer;
arch/x86/crypto/sha256-mb/sha256_mb.c:			ctx->job.len = 1;
arch/x86/crypto/sha256-mb/sha256_mb.c:				sha256_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[0] = SHA256_H0;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[1] = SHA256_H1;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[2] = SHA256_H2;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[3] = SHA256_H3;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[4] = SHA256_H4;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[5] = SHA256_H5;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[6] = SHA256_H6;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->job.result_digest[7] = SHA256_H7;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->total_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct	sha256_hash_ctx *sctx = ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha256-mb/sha256_mb.c:	__be32	*dst = (__be32 *) rctx->out;
arch/x86/crypto/sha256-mb/sha256_mb.c:		dst[i] = cpu_to_be32(sctx->job.result_digest[i]);
arch/x86/crypto/sha256-mb/sha256_mb.c:	while (!(rctx->flag & HASH_DONE)) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		nbytes = crypto_ahash_walk_done(&rctx->walk, 0);
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha256-mb/sha256_mb.c:			rctx->flag |= HASH_DONE;
arch/x86/crypto/sha256-mb/sha256_mb.c:			if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha256-mb/sha256_mb.c:						ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha256-mb/sha256_mb.c:						rctx->walk.data, nbytes, flag);
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha256-mb/sha256_mb.c:	list_del(&rctx->waiter);
arch/x86/crypto/sha256-mb/sha256_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha256-mb/sha256_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha256-mb/sha256_mb.c:			list_del(&req_ctx->waiter);
arch/x86/crypto/sha256-mb/sha256_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha256-mb/sha256_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->tag.arrival = jiffies;    /* tag the arrival time */
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->tag.seq_num = cstate->next_seq_num++;
arch/x86/crypto/sha256-mb/sha256_mb.c:	next_flush = rctx->tag.arrival + delay;
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->tag.expire = next_flush;
arch/x86/crypto/sha256-mb/sha256_mb.c:	list_add_tail(&rctx->waiter, &cstate->work_list);
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha256-mb/sha256_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (crypto_ahash_walk_last(&rctx->walk))
arch/x86/crypto/sha256-mb/sha256_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sha_ctx = sha256_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha256-mb/sha256_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->flag |= HASH_FINAL;
arch/x86/crypto/sha256-mb/sha256_mb.c:	sha_ctx = sha256_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha256-mb/sha256_mb.c:	rctx->flag |= HASH_DONE | HASH_FINAL;
arch/x86/crypto/sha256-mb/sha256_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha256-mb/sha256_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha256-mb/sha256_mb.c:	mctx->alg_state = &sha256_mb_alg_state;
arch/x86/crypto/sha256-mb/sha256_mb.c:	ctx->mcryptd_tfm = mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha256-mb/sha256_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha256-mb/sha256_mb.c:	areq = &rctx->areq;
arch/x86/crypto/sha256-mb/sha256_mb.c:					rctx->complete, req);
arch/x86/crypto/sha256-mb/sha256_mb.c:		if (time_before(cur_time, rctx->tag.expire))
arch/x86/crypto/sha256-mb/sha256_mb.c:		next_flush = rctx->tag.expire;
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->flag = HASH_UPDATE;
arch/x86/crypto/sha512-mb/sha512_mb.c:		if (ctx->status & HASH_CTX_STS_COMPLETE) {
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->status = HASH_CTX_STS_COMPLETE;
arch/x86/crypto/sha512-mb/sha512_mb.c:		if (ctx->partial_block_buffer_length == 0 &&
arch/x86/crypto/sha512-mb/sha512_mb.c:		    ctx->incoming_buffer_length) {
arch/x86/crypto/sha512-mb/sha512_mb.c:			const void *buffer = ctx->incoming_buffer;
arch/x86/crypto/sha512-mb/sha512_mb.c:			uint32_t len = ctx->incoming_buffer_length;
arch/x86/crypto/sha512-mb/sha512_mb.c:				memcpy(ctx->partial_block_buffer,
arch/x86/crypto/sha512-mb/sha512_mb.c:				ctx->partial_block_buffer_length = copy_len;
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->incoming_buffer_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:				ctx->job.buffer = (uint8_t *) buffer;
arch/x86/crypto/sha512-mb/sha512_mb.c:				ctx->job.len = len;
arch/x86/crypto/sha512-mb/sha512_mb.c:					&ctx->job);
arch/x86/crypto/sha512-mb/sha512_mb.c:		if (ctx->status & HASH_CTX_STS_LAST) {
arch/x86/crypto/sha512-mb/sha512_mb.c:			uint8_t *buf = ctx->partial_block_buffer;
arch/x86/crypto/sha512-mb/sha512_mb.c:					sha512_pad(buf, ctx->total_length);
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->status = (HASH_CTX_STS_PROCESSING |
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->job.buffer = buf;
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->job.len = (uint32_t) n_extra_blocks;
arch/x86/crypto/sha512-mb/sha512_mb.c:				sha512_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha512-mb/sha512_mb.c:		ctx->error = HASH_CTX_ERROR_INVALID_FLAGS;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (ctx->status & HASH_CTX_STS_PROCESSING) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_PROCESSING;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if ((ctx->status & HASH_CTX_STS_COMPLETE) && !(flags & HASH_FIRST)) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_COMPLETED;
arch/x86/crypto/sha512-mb/sha512_mb.c:		sha512_init_digest(ctx->job.result_digest);
arch/x86/crypto/sha512-mb/sha512_mb.c:		ctx->total_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:		ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->error = HASH_CTX_ERROR_NONE;
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->incoming_buffer = buffer;
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->incoming_buffer_length = len;
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->status = (flags & HASH_LAST) ?
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->total_length += len;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (ctx->partial_block_buffer_length || len < SHA512_BLOCK_SIZE) {
arch/x86/crypto/sha512-mb/sha512_mb.c:					ctx->partial_block_buffer_length;
arch/x86/crypto/sha512-mb/sha512_mb.c:		(&ctx->partial_block_buffer[ctx->partial_block_buffer_length],
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->partial_block_buffer_length += copy_len;
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->incoming_buffer = (const void *)
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->incoming_buffer_length = len - copy_len;
arch/x86/crypto/sha512-mb/sha512_mb.c:		assert(ctx->partial_block_buffer_length <= SHA512_BLOCK_SIZE);
arch/x86/crypto/sha512-mb/sha512_mb.c:		if (ctx->partial_block_buffer_length >= SHA512_BLOCK_SIZE) {
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->job.buffer = ctx->partial_block_buffer;
arch/x86/crypto/sha512-mb/sha512_mb.c:			ctx->job.len = 1;
arch/x86/crypto/sha512-mb/sha512_mb.c:				sha512_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[0] = SHA512_H0;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[1] = SHA512_H1;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[2] = SHA512_H2;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[3] = SHA512_H3;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[4] = SHA512_H4;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[5] = SHA512_H5;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[6] = SHA512_H6;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->job.result_digest[7] = SHA512_H7;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->total_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct	sha512_hash_ctx *sctx = ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha512-mb/sha512_mb.c:	__be64	*dst = (__be64 *) rctx->out;
arch/x86/crypto/sha512-mb/sha512_mb.c:		dst[i] = cpu_to_be64(sctx->job.result_digest[i]);
arch/x86/crypto/sha512-mb/sha512_mb.c:	while (!(rctx->flag & HASH_DONE)) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		nbytes = crypto_ahash_walk_done(&rctx->walk, 0);
arch/x86/crypto/sha512-mb/sha512_mb.c:		if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha512-mb/sha512_mb.c:			rctx->flag |= HASH_DONE;
arch/x86/crypto/sha512-mb/sha512_mb.c:			if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha512-mb/sha512_mb.c:						ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha512-mb/sha512_mb.c:						rctx->walk.data, nbytes, flag);
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha512-mb/sha512_mb.c:	list_del(&rctx->waiter);
arch/x86/crypto/sha512-mb/sha512_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha512-mb/sha512_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha512-mb/sha512_mb.c:			list_del(&req_ctx->waiter);
arch/x86/crypto/sha512-mb/sha512_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha512-mb/sha512_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->tag.arrival = jiffies;    /* tag the arrival time */
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->tag.seq_num = cstate->next_seq_num++;
arch/x86/crypto/sha512-mb/sha512_mb.c:	next_flush = rctx->tag.arrival + delay;
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->tag.expire = next_flush;
arch/x86/crypto/sha512-mb/sha512_mb.c:	list_add_tail(&rctx->waiter, &cstate->work_list);
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha512-mb/sha512_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (crypto_ahash_walk_last(&rctx->walk))
arch/x86/crypto/sha512-mb/sha512_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sha_ctx = sha512_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha512-mb/sha512_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->flag |= HASH_FINAL;
arch/x86/crypto/sha512-mb/sha512_mb.c:	sha_ctx = sha512_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha512-mb/sha512_mb.c:	rctx->flag |= HASH_DONE | HASH_FINAL;
arch/x86/crypto/sha512-mb/sha512_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha512-mb/sha512_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha512-mb/sha512_mb.c:	mctx->alg_state = &sha512_mb_alg_state;
arch/x86/crypto/sha512-mb/sha512_mb.c:	ctx->mcryptd_tfm = mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha512-mb/sha512_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha512-mb/sha512_mb.c:	areq = &rctx->areq;
arch/x86/crypto/sha512-mb/sha512_mb.c:					rctx->complete, req);
arch/x86/crypto/sha512-mb/sha512_mb.c:		if time_before(cur_time, rctx->tag.expire)
arch/x86/crypto/sha512-mb/sha512_mb.c:		next_flush = rctx->tag.expire;
arch/x86/crypto/des3_ede_glue.c:	u32 *enc_ctx = ctx->enc_expkey;
arch/x86/crypto/des3_ede_glue.c:	u32 *dec_ctx = ctx->dec_expkey;
arch/x86/crypto/des3_ede_glue.c:	u32 *enc_ctx = ctx->enc_expkey;
arch/x86/crypto/des3_ede_glue.c:	u32 *dec_ctx = ctx->dec_expkey;
arch/x86/crypto/des3_ede_glue.c:	return ecb_crypt(desc, &walk, ctx->enc_expkey);
arch/x86/crypto/des3_ede_glue.c:	return ecb_crypt(desc, &walk, ctx->dec_expkey);
arch/x86/crypto/des3_ede_glue.c:	err = __des3_ede_setkey(ctx->enc_expkey, &tfm->crt_flags, key, keylen);
arch/x86/crypto/des3_ede_glue.c:		tmp = ror32(ctx->enc_expkey[i + 1], 4);
arch/x86/crypto/des3_ede_glue.c:		ctx->enc_expkey[i + 1] = tmp;
arch/x86/crypto/des3_ede_glue.c:		ctx->dec_expkey[j + 0] = ctx->enc_expkey[i + 0];
arch/x86/crypto/des3_ede_glue.c:		ctx->dec_expkey[j + 1] = tmp;
arch/x86/crypto/twofish_avx_glue.c:	ctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/twofish_avx_glue.c:		twofish_ecb_enc_8way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:		twofish_enc_blk_3way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:		twofish_enc_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:	ctx->fpu_enabled = twofish_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/twofish_avx_glue.c:		twofish_ecb_dec_8way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:		twofish_dec_blk_3way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:		twofish_dec_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/twofish_avx_glue.c:		.ctx = &ctx->twofish_ctx,
arch/x86/crypto/twofish_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/twofish_avx_glue.c:		.ctx = &ctx->twofish_ctx,
arch/x86/crypto/twofish_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/twofish_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/twofish_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/serpent_avx_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_avx_glue.c:		serpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx_glue.c:		__serpent_encrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_avx_glue.c:		serpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx_glue.c:		__serpent_decrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx_glue.c:	err = __serpent_setkey(&ctx->serpent_ctx, key, keylen -
arch/x86/crypto/serpent_avx_glue.c:	return lrw_init_table(&ctx->lrw_table, key + keylen -
arch/x86/crypto/serpent_avx_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_avx_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_avx_glue.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/serpent_avx_glue.c:	err = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);
arch/x86/crypto/serpent_avx_glue.c:	return __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);
arch/x86/crypto/serpent_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/serpent_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/poly1305_glue.c:	sctx->uset = false;
arch/x86/crypto/poly1305_glue.c:	sctx->wset = false;
arch/x86/crypto/poly1305_glue.c:	if (unlikely(!dctx->sset)) {
arch/x86/crypto/poly1305_glue.c:		if (unlikely(!sctx->wset)) {
arch/x86/crypto/poly1305_glue.c:			if (!sctx->uset) {
arch/x86/crypto/poly1305_glue.c:				memcpy(sctx->u, dctx->r, sizeof(sctx->u));
arch/x86/crypto/poly1305_glue.c:				poly1305_simd_mult(sctx->u, dctx->r);
arch/x86/crypto/poly1305_glue.c:				sctx->uset = true;
arch/x86/crypto/poly1305_glue.c:			memcpy(sctx->u + 5, sctx->u, sizeof(sctx->u));
arch/x86/crypto/poly1305_glue.c:			poly1305_simd_mult(sctx->u + 5, dctx->r);
arch/x86/crypto/poly1305_glue.c:			memcpy(sctx->u + 10, sctx->u + 5, sizeof(sctx->u));
arch/x86/crypto/poly1305_glue.c:			poly1305_simd_mult(sctx->u + 10, dctx->r);
arch/x86/crypto/poly1305_glue.c:			sctx->wset = true;
arch/x86/crypto/poly1305_glue.c:		poly1305_4block_avx2(dctx->h, src, dctx->r, blocks, sctx->u);
arch/x86/crypto/poly1305_glue.c:		if (unlikely(!sctx->uset)) {
arch/x86/crypto/poly1305_glue.c:			memcpy(sctx->u, dctx->r, sizeof(sctx->u));
arch/x86/crypto/poly1305_glue.c:			poly1305_simd_mult(sctx->u, dctx->r);
arch/x86/crypto/poly1305_glue.c:			sctx->uset = true;
arch/x86/crypto/poly1305_glue.c:		poly1305_2block_sse2(dctx->h, src, dctx->r, blocks, sctx->u);
arch/x86/crypto/poly1305_glue.c:		poly1305_block_sse2(dctx->h, src, dctx->r, 1);
arch/x86/crypto/poly1305_glue.c:	if (unlikely(dctx->buflen)) {
arch/x86/crypto/poly1305_glue.c:		bytes = min(srclen, POLY1305_BLOCK_SIZE - dctx->buflen);
arch/x86/crypto/poly1305_glue.c:		memcpy(dctx->buf + dctx->buflen, src, bytes);
arch/x86/crypto/poly1305_glue.c:		dctx->buflen += bytes;
arch/x86/crypto/poly1305_glue.c:		if (dctx->buflen == POLY1305_BLOCK_SIZE) {
arch/x86/crypto/poly1305_glue.c:			poly1305_simd_blocks(dctx, dctx->buf,
arch/x86/crypto/poly1305_glue.c:			dctx->buflen = 0;
arch/x86/crypto/poly1305_glue.c:		dctx->buflen = srclen;
arch/x86/crypto/poly1305_glue.c:		memcpy(dctx->buf, src, srclen);
arch/x86/crypto/fpu.c:	struct crypto_blkcipher *child = ctx->child;
arch/x86/crypto/fpu.c:	struct crypto_blkcipher *child = ctx->child;
arch/x86/crypto/fpu.c:	struct crypto_blkcipher *child = ctx->child;
arch/x86/crypto/fpu.c:	ctx->child = cipher;
arch/x86/crypto/fpu.c:	crypto_free_blkcipher(ctx->child);
arch/x86/crypto/crct10dif-pclmul_glue.c:	ctx->crc = 0;
arch/x86/crypto/crct10dif-pclmul_glue.c:		ctx->crc = crc_t10dif_pcl(ctx->crc, data, length);
arch/x86/crypto/crct10dif-pclmul_glue.c:		ctx->crc = crc_t10dif_generic(ctx->crc, data, length);
arch/x86/crypto/crct10dif-pclmul_glue.c:	*(__u16 *)out = ctx->crc;
arch/x86/crypto/crct10dif-pclmul_glue.c:	return __chksum_finup(&ctx->crc, data, len, out);
arch/x86/crypto/crct10dif-pclmul_glue.c:	return __chksum_finup(&ctx->crc, data, length, out);
arch/x86/crypto/twofish_glue_3way.c:	err = __twofish_setkey(&ctx->twofish_ctx, key, keylen - TF_BLOCK_SIZE,
arch/x86/crypto/twofish_glue_3way.c:	return lrw_init_table(&ctx->lrw_table, key + keylen - TF_BLOCK_SIZE);
arch/x86/crypto/twofish_glue_3way.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/twofish_glue_3way.c:		.crypt_ctx = &ctx->twofish_ctx,
arch/x86/crypto/twofish_glue_3way.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/twofish_glue_3way.c:		.crypt_ctx = &ctx->twofish_ctx,
arch/x86/crypto/twofish_glue_3way.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/twofish_glue_3way.c:	err = __twofish_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);
arch/x86/crypto/twofish_glue_3way.c:	return __twofish_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,
arch/x86/crypto/twofish_glue_3way.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/twofish_glue_3way.c:		.crypt_ctx = &ctx->crypt_ctx,
arch/x86/crypto/twofish_glue_3way.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/twofish_glue_3way.c:		.crypt_ctx = &ctx->crypt_ctx,
arch/x86/crypto/cast6_avx_glue.c:	ctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/cast6_avx_glue.c:		cast6_ecb_enc_8way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/cast6_avx_glue.c:		__cast6_encrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/cast6_avx_glue.c:	ctx->fpu_enabled = cast6_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/cast6_avx_glue.c:		cast6_ecb_dec_8way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/cast6_avx_glue.c:		__cast6_decrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/cast6_avx_glue.c:	err = __cast6_setkey(&ctx->cast6_ctx, key, keylen - CAST6_BLOCK_SIZE,
arch/x86/crypto/cast6_avx_glue.c:	return lrw_init_table(&ctx->lrw_table, key + keylen - CAST6_BLOCK_SIZE);
arch/x86/crypto/cast6_avx_glue.c:		.ctx = &ctx->cast6_ctx,
arch/x86/crypto/cast6_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/cast6_avx_glue.c:		.ctx = &ctx->cast6_ctx,
arch/x86/crypto/cast6_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/cast6_avx_glue.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/cast6_avx_glue.c:	err = __cast6_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);
arch/x86/crypto/cast6_avx_glue.c:	return __cast6_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,
arch/x86/crypto/cast6_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/cast6_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/serpent_sse2_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_sse2_glue.c:		serpent_enc_blk_xway(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_sse2_glue.c:		__serpent_encrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_sse2_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_sse2_glue.c:		serpent_dec_blk_xway(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_sse2_glue.c:		__serpent_decrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_sse2_glue.c:	err = __serpent_setkey(&ctx->serpent_ctx, key, keylen -
arch/x86/crypto/serpent_sse2_glue.c:	return lrw_init_table(&ctx->lrw_table, key + keylen -
arch/x86/crypto/serpent_sse2_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_sse2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_sse2_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_sse2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_sse2_glue.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/serpent_sse2_glue.c:	err = __serpent_setkey(&ctx->crypt_ctx, key, keylen / 2);
arch/x86/crypto/serpent_sse2_glue.c:	return __serpent_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2);
arch/x86/crypto/serpent_sse2_glue.c:		.ctx = &ctx->crypt_ctx,
arch/x86/crypto/serpent_sse2_glue.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/serpent_sse2_glue.c:		.ctx = &ctx->crypt_ctx,
arch/x86/crypto/serpent_sse2_glue.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/glue_helper.c:		fpu_enabled = glue_fpu_begin(bsize, gctx->fpu_blocks_limit,
arch/x86/crypto/glue_helper.c:		for (i = 0; i < gctx->num_funcs; i++) {
arch/x86/crypto/glue_helper.c:			func_bytes = bsize * gctx->funcs[i].num_blocks;
arch/x86/crypto/glue_helper.c:					gctx->funcs[i].fn_u.ecb(ctx, wdst,
arch/x86/crypto/glue_helper.c:	for (i = 0; i < gctx->num_funcs; i++) {
arch/x86/crypto/glue_helper.c:		num_blocks = gctx->funcs[i].num_blocks;
arch/x86/crypto/glue_helper.c:				gctx->funcs[i].fn_u.cbc(ctx, dst, src);
arch/x86/crypto/glue_helper.c:		fpu_enabled = glue_fpu_begin(bsize, gctx->fpu_blocks_limit,
arch/x86/crypto/glue_helper.c:	for (i = 0; i < gctx->num_funcs; i++) {
arch/x86/crypto/glue_helper.c:		num_blocks = gctx->funcs[i].num_blocks;
arch/x86/crypto/glue_helper.c:				gctx->funcs[i].fn_u.ctr(ctx, dst, src, &ctrblk);
arch/x86/crypto/glue_helper.c:		fpu_enabled = glue_fpu_begin(bsize, gctx->fpu_blocks_limit,
arch/x86/crypto/glue_helper.c:			gctx->funcs[gctx->num_funcs - 1].fn_u.ctr, desc, &walk);
arch/x86/crypto/glue_helper.c:	for (i = 0; i < gctx->num_funcs; i++) {
arch/x86/crypto/glue_helper.c:		num_blocks = gctx->funcs[i].num_blocks;
arch/x86/crypto/glue_helper.c:				gctx->funcs[i].fn_u.xts(ctx, dst, src,
arch/x86/crypto/glue_helper.c:	fpu_enabled = glue_fpu_begin(bsize, gctx->fpu_blocks_limit,
arch/x86/crypto/serpent_avx2_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_avx2_glue.c:		serpent_ecb_enc_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:		serpent_ecb_enc_8way_avx(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:		__serpent_encrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:	ctx->fpu_enabled = serpent_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/serpent_avx2_glue.c:		serpent_ecb_dec_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:		serpent_ecb_dec_8way_avx(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:		__serpent_decrypt(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/serpent_avx2_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_avx2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_avx2_glue.c:		.ctx = &ctx->serpent_ctx,
arch/x86/crypto/serpent_avx2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/serpent_avx2_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/serpent_avx2_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/sha1_ssse3_glue.c:	    (sctx->count % SHA1_BLOCK_SIZE) + len < SHA1_BLOCK_SIZE)
arch/x86/crypto/ghash-clmulni-intel_glue.c:	ctx->shash.a = (b << 1) | (a >> 63);
arch/x86/crypto/ghash-clmulni-intel_glue.c:	ctx->shash.b = (a << 1) | (b >> 63);
arch/x86/crypto/ghash-clmulni-intel_glue.c:		ctx->shash.b ^= ((u64)0xc2) << 56;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	u8 *dst = dctx->buffer;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	if (dctx->bytes) {
arch/x86/crypto/ghash-clmulni-intel_glue.c:		int n = min(srclen, dctx->bytes);
arch/x86/crypto/ghash-clmulni-intel_glue.c:		u8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);
arch/x86/crypto/ghash-clmulni-intel_glue.c:		dctx->bytes -= n;
arch/x86/crypto/ghash-clmulni-intel_glue.c:		if (!dctx->bytes)
arch/x86/crypto/ghash-clmulni-intel_glue.c:			clmul_ghash_mul(dst, &ctx->shash);
arch/x86/crypto/ghash-clmulni-intel_glue.c:	clmul_ghash_update(dst, src, srclen, &ctx->shash);
arch/x86/crypto/ghash-clmulni-intel_glue.c:		dctx->bytes = GHASH_BLOCK_SIZE - srclen;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	u8 *dst = dctx->buffer;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	if (dctx->bytes) {
arch/x86/crypto/ghash-clmulni-intel_glue.c:		u8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);
arch/x86/crypto/ghash-clmulni-intel_glue.c:		while (dctx->bytes--)
arch/x86/crypto/ghash-clmulni-intel_glue.c:		clmul_ghash_mul(dst, &ctx->shash);
arch/x86/crypto/ghash-clmulni-intel_glue.c:	dctx->bytes = 0;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	u8 *buf = dctx->buffer;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	struct crypto_ahash *child = &ctx->cryptd_tfm->base;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	ctx->cryptd_tfm = cryptd_tfm;
arch/x86/crypto/ghash-clmulni-intel_glue.c:	cryptd_free_ahash(ctx->cryptd_tfm);
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->flag = HASH_UPDATE;
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (ctx->status & HASH_CTX_STS_COMPLETE) {
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->status = HASH_CTX_STS_COMPLETE;
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (ctx->partial_block_buffer_length == 0 &&
arch/x86/crypto/sha1-mb/sha1_mb.c:		    ctx->incoming_buffer_length) {
arch/x86/crypto/sha1-mb/sha1_mb.c:			const void *buffer = ctx->incoming_buffer;
arch/x86/crypto/sha1-mb/sha1_mb.c:			uint32_t len = ctx->incoming_buffer_length;
arch/x86/crypto/sha1-mb/sha1_mb.c:				memcpy(ctx->partial_block_buffer,
arch/x86/crypto/sha1-mb/sha1_mb.c:				ctx->partial_block_buffer_length = copy_len;
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->incoming_buffer_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:				ctx->job.buffer = (uint8_t *) buffer;
arch/x86/crypto/sha1-mb/sha1_mb.c:				ctx->job.len = len;
arch/x86/crypto/sha1-mb/sha1_mb.c:										&ctx->job);
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (ctx->status & HASH_CTX_STS_LAST) {
arch/x86/crypto/sha1-mb/sha1_mb.c:			uint8_t *buf = ctx->partial_block_buffer;
arch/x86/crypto/sha1-mb/sha1_mb.c:					sha1_pad(buf, ctx->total_length);
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->status = (HASH_CTX_STS_PROCESSING |
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->job.buffer = buf;
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->job.len = (uint32_t) n_extra_blocks;
arch/x86/crypto/sha1-mb/sha1_mb.c:				sha1_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->error = HASH_CTX_ERROR_INVALID_FLAGS;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (ctx->status & HASH_CTX_STS_PROCESSING) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_PROCESSING;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if ((ctx->status & HASH_CTX_STS_COMPLETE) && !(flags & HASH_FIRST)) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->error = HASH_CTX_ERROR_ALREADY_COMPLETED;
arch/x86/crypto/sha1-mb/sha1_mb.c:		sha1_init_digest(ctx->job.result_digest);
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->total_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:		ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->error = HASH_CTX_ERROR_NONE;
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->incoming_buffer = buffer;
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->incoming_buffer_length = len;
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->status = (flags & HASH_LAST) ?
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->total_length += len;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (ctx->partial_block_buffer_length || len < SHA1_BLOCK_SIZE) {
arch/x86/crypto/sha1-mb/sha1_mb.c:					ctx->partial_block_buffer_length;
arch/x86/crypto/sha1-mb/sha1_mb.c:			memcpy(&ctx->partial_block_buffer[ctx->partial_block_buffer_length],
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->partial_block_buffer_length += copy_len;
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->incoming_buffer = (const void *)
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->incoming_buffer_length = len - copy_len;
arch/x86/crypto/sha1-mb/sha1_mb.c:		assert(ctx->partial_block_buffer_length <= SHA1_BLOCK_SIZE);
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (ctx->partial_block_buffer_length >= SHA1_BLOCK_SIZE) {
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->job.buffer = ctx->partial_block_buffer;
arch/x86/crypto/sha1-mb/sha1_mb.c:			ctx->job.len = 1;
arch/x86/crypto/sha1-mb/sha1_mb.c:				sha1_job_mgr_submit(&mgr->mgr, &ctx->job);
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->job.result_digest[0] = SHA1_H0;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->job.result_digest[1] = SHA1_H1;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->job.result_digest[2] = SHA1_H2;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->job.result_digest[3] = SHA1_H3;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->job.result_digest[4] = SHA1_H4;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->total_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->partial_block_buffer_length = 0;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sctx->status = HASH_CTX_STS_IDLE;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct	sha1_hash_ctx *sctx = ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha1-mb/sha1_mb.c:	__be32	*dst = (__be32 *) rctx->out;
arch/x86/crypto/sha1-mb/sha1_mb.c:		dst[i] = cpu_to_be32(sctx->job.result_digest[i]);
arch/x86/crypto/sha1-mb/sha1_mb.c:	while (!(rctx->flag & HASH_DONE)) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		nbytes = crypto_ahash_walk_done(&rctx->walk, 0);
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha1-mb/sha1_mb.c:			rctx->flag |= HASH_DONE;
arch/x86/crypto/sha1-mb/sha1_mb.c:			if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha1-mb/sha1_mb.c:						ahash_request_ctx(&rctx->areq);
arch/x86/crypto/sha1-mb/sha1_mb.c:						rctx->walk.data, nbytes, flag);
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (rctx->flag & HASH_FINAL)
arch/x86/crypto/sha1-mb/sha1_mb.c:	list_del(&rctx->waiter);
arch/x86/crypto/sha1-mb/sha1_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha1-mb/sha1_mb.c:		rctx->complete(&req->base, err);
arch/x86/crypto/sha1-mb/sha1_mb.c:			list_del(&req_ctx->waiter);
arch/x86/crypto/sha1-mb/sha1_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha1-mb/sha1_mb.c:				req_ctx->complete(&req->base, ret);
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->tag.arrival = jiffies;    /* tag the arrival time */
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->tag.seq_num = cstate->next_seq_num++;
arch/x86/crypto/sha1-mb/sha1_mb.c:	next_flush = rctx->tag.arrival + delay;
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->tag.expire = next_flush;
arch/x86/crypto/sha1-mb/sha1_mb.c:	list_add_tail(&rctx->waiter, &cstate->work_list);
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha1-mb/sha1_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (crypto_ahash_walk_last(&rctx->walk))
arch/x86/crypto/sha1-mb/sha1_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sha_ctx = sha1_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha1-mb/sha1_mb.c:	nbytes = crypto_ahash_walk_first(req, &rctx->walk);
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (crypto_ahash_walk_last(&rctx->walk)) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		rctx->flag |= HASH_DONE;
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->flag |= HASH_FINAL;
arch/x86/crypto/sha1-mb/sha1_mb.c:	sha_ctx = sha1_ctx_mgr_submit(cstate->mgr, sha_ctx, rctx->walk.data,
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (rctx->tag.cpu != smp_processor_id()) {
arch/x86/crypto/sha1-mb/sha1_mb.c:	rctx->flag |= HASH_DONE | HASH_FINAL;
arch/x86/crypto/sha1-mb/sha1_mb.c:	if (sha_ctx->error) {
arch/x86/crypto/sha1-mb/sha1_mb.c:		ret = sha_ctx->error;
arch/x86/crypto/sha1-mb/sha1_mb.c:	mctx->alg_state = &sha1_mb_alg_state;
arch/x86/crypto/sha1-mb/sha1_mb.c:	ctx->mcryptd_tfm = mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha1-mb/sha1_mb.c:	mcryptd_free_ahash(ctx->mcryptd_tfm);
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	struct mcryptd_ahash *mcryptd_tfm = ctx->mcryptd_tfm;
arch/x86/crypto/sha1-mb/sha1_mb.c:	areq = &rctx->areq;
arch/x86/crypto/sha1-mb/sha1_mb.c:					rctx->complete, req);
arch/x86/crypto/sha1-mb/sha1_mb.c:		if (time_before(cur_time, rctx->tag.expire))
arch/x86/crypto/sha1-mb/sha1_mb.c:		next_flush = rctx->tag.expire;
arch/x86/crypto/sha256_ssse3_glue.c:	    (sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)
arch/x86/crypto/camellia_aesni_avx2_glue.c:	ctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_ecb_enc_32way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_enc_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:	ctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_ecb_dec_32way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		camellia_dec_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx2_glue.c:		.ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_aesni_avx2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_aesni_avx2_glue.c:		.ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_aesni_avx2_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_aesni_avx2_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/camellia_aesni_avx2_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/camellia_aesni_avx_glue.c:	ctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_ecb_enc_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_enc_blk_2way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_enc_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:	ctx->fpu_enabled = camellia_fpu_begin(ctx->fpu_enabled, nbytes);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_ecb_dec_16way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_dec_blk_2way(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:		camellia_dec_blk(ctx->ctx, srcdst, srcdst);
arch/x86/crypto/camellia_aesni_avx_glue.c:		.ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_aesni_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_aesni_avx_glue.c:		.ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_aesni_avx_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_aesni_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/camellia_aesni_avx_glue.c:				     &ctx->tweak_ctx, &ctx->crypt_ctx);
arch/x86/crypto/camellia_glue.c:	cctx->key_length = key_len;
arch/x86/crypto/camellia_glue.c:		camellia_setup128(key, cctx->key_table);
arch/x86/crypto/camellia_glue.c:		camellia_setup192(key, cctx->key_table);
arch/x86/crypto/camellia_glue.c:		camellia_setup256(key, cctx->key_table);
arch/x86/crypto/camellia_glue.c:	err = __camellia_setkey(&ctx->camellia_ctx, key,
arch/x86/crypto/camellia_glue.c:	return lrw_init_table(&ctx->lrw_table,
arch/x86/crypto/camellia_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_glue.c:		.crypt_ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/camellia_glue.c:		.crypt_ctx = &ctx->camellia_ctx,
arch/x86/crypto/camellia_glue.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/camellia_glue.c:	err = __camellia_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);
arch/x86/crypto/camellia_glue.c:	return __camellia_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,
arch/x86/crypto/camellia_glue.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/camellia_glue.c:		.crypt_ctx = &ctx->crypt_ctx,
arch/x86/crypto/camellia_glue.c:		.tweak_ctx = &ctx->tweak_ctx,
arch/x86/crypto/camellia_glue.c:		.crypt_ctx = &ctx->crypt_ctx,
arch/x86/crypto/aesni-intel_glue.c:	if ((plaintext_len < AVX_GEN2_OPTSIZE) || (aes_ctx-> key_length != AES_KEYSIZE_128)){
arch/x86/crypto/aesni-intel_glue.c:	if ((ciphertext_len < AVX_GEN2_OPTSIZE) || (aes_ctx-> key_length != AES_KEYSIZE_128)) {
arch/x86/crypto/aesni-intel_glue.c:	if ((plaintext_len < AVX_GEN2_OPTSIZE) || (aes_ctx-> key_length != AES_KEYSIZE_128)) {
arch/x86/crypto/aesni-intel_glue.c:	if ((ciphertext_len < AVX_GEN2_OPTSIZE) || (aes_ctx-> key_length != AES_KEYSIZE_128)) {
arch/x86/crypto/aesni-intel_glue.c:	if (ctx->key_length == AES_KEYSIZE_128)
arch/x86/crypto/aesni-intel_glue.c:	else if (ctx->key_length == AES_KEYSIZE_192)
arch/x86/crypto/aesni-intel_glue.c:	err = aes_set_key_common(tfm, ctx->raw_aes_ctx, key,
arch/x86/crypto/aesni-intel_glue.c:	return lrw_init_table(&ctx->lrw_table, key + keylen - AES_BLOCK_SIZE);
arch/x86/crypto/aesni-intel_glue.c:	lrw_free_table(&ctx->lrw_table);
arch/x86/crypto/aesni-intel_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/aesni-intel_glue.c:		.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),
arch/x86/crypto/aesni-intel_glue.c:		.table_ctx = &ctx->lrw_table,
arch/x86/crypto/aesni-intel_glue.c:		.crypt_ctx = aes_ctx(ctx->raw_aes_ctx),
arch/x86/crypto/aesni-intel_glue.c:	err = aes_set_key_common(tfm, ctx->raw_crypt_ctx, key, keylen / 2);
arch/x86/crypto/aesni-intel_glue.c:	return aes_set_key_common(tfm, ctx->raw_tweak_ctx, key + keylen / 2,
arch/x86/crypto/aesni-intel_glue.c:				     aes_ctx(ctx->raw_tweak_ctx),
arch/x86/crypto/aesni-intel_glue.c:				     aes_ctx(ctx->raw_crypt_ctx));
arch/x86/crypto/aesni-intel_glue.c:				     aes_ctx(ctx->raw_tweak_ctx),
arch/x86/crypto/aesni-intel_glue.c:				     aes_ctx(ctx->raw_crypt_ctx));
arch/x86/crypto/aesni-intel_glue.c:		.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),
arch/x86/crypto/aesni-intel_glue.c:		.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),
arch/x86/crypto/aesni-intel_glue.c:		.tweak_ctx = aes_ctx(ctx->raw_tweak_ctx),
arch/x86/crypto/aesni-intel_glue.c:		.crypt_ctx = aes_ctx(ctx->raw_crypt_ctx),
arch/x86/crypto/aesni-intel_glue.c:	memcpy(ctx->nonce, key + key_len, sizeof(ctx->nonce));
arch/x86/crypto/aesni-intel_glue.c:				  &ctx->aes_key_expanded, key, key_len) ?:
arch/x86/crypto/aesni-intel_glue.c:	       rfc4106_set_hash_subkey(ctx->hash_subkey, key, key_len);
arch/x86/crypto/aesni-intel_glue.c:	void *aes_ctx = &(ctx->aes_key_expanded);
arch/x86/crypto/aesni-intel_glue.c:		*(iv+i) = ctx->nonce[i];
arch/x86/crypto/aesni-intel_glue.c:			  ctx->hash_subkey, assoc, req->assoclen - 8,
arch/x86/crypto/aesni-intel_glue.c:	void *aes_ctx = &(ctx->aes_key_expanded);
arch/x86/crypto/aesni-intel_glue.c:		*(iv+i) = ctx->nonce[i];
arch/x86/crypto/aesni-intel_glue.c:			  ctx->hash_subkey, assoc, req->assoclen - 8,
arch/x86/crypto/sha512_ssse3_glue.c:	    (sctx->count[0] % SHA512_BLOCK_SIZE) + len < SHA512_BLOCK_SIZE)
arch/mips/math-emu/cp1emu.c:		(si) = (int)get_fpr32(&ctx->fpr[x], 0);			\
arch/mips/math-emu/cp1emu.c:		(si) = (int)get_fpr32(&ctx->fpr[(x) & ~1], (x) & 1);	\
arch/mips/math-emu/cp1emu.c:		set_fpr32(&ctx->fpr[x], 0, si);				\
arch/mips/math-emu/cp1emu.c:		for (i = 1; i < ARRAY_SIZE(ctx->fpr[x].val32); i++)	\
arch/mips/math-emu/cp1emu.c:			set_fpr32(&ctx->fpr[x], i, 0);			\
arch/mips/math-emu/cp1emu.c:		set_fpr32(&ctx->fpr[(x) & ~1], (x) & 1, si);		\
arch/mips/math-emu/cp1emu.c:#define SIFROMHREG(si, x)	((si) = (int)get_fpr32(&ctx->fpr[x], 1))
arch/mips/math-emu/cp1emu.c:	set_fpr32(&ctx->fpr[x], 1, si);					\
arch/mips/math-emu/cp1emu.c:	for (i = 2; i < ARRAY_SIZE(ctx->fpr[x].val32); i++)		\
arch/mips/math-emu/cp1emu.c:		set_fpr32(&ctx->fpr[x], i, 0);				\
arch/mips/math-emu/cp1emu.c:	((di) = get_fpr64(&ctx->fpr[(x) & ~(cop1_64bit(xcp) == 0)], 0))
arch/mips/math-emu/cp1emu.c:	set_fpr64(&ctx->fpr[fpr], 0, di);				\
arch/mips/math-emu/cp1emu.c:	for (i = 1; i < ARRAY_SIZE(ctx->fpr[x].val64); i++)		\
arch/mips/math-emu/cp1emu.c:		set_fpr64(&ctx->fpr[fpr], i, 0);			\
arch/mips/math-emu/cp1emu.c:	u32 fcr31 = ctx->fcr31;
arch/mips/math-emu/cp1emu.c:	u32 fcr31 = ctx->fcr31;
arch/mips/math-emu/cp1emu.c:	ctx->fcr31 = fcr31;
arch/mips/math-emu/cp1emu.c:			if ((ctx->fcr31 >> 5) & ctx->fcr31 & FPU_CSR_ALL_E) {
arch/mips/math-emu/cp1emu.c:			cond = ctx->fcr31 & cbit;
arch/mips/math-emu/cp1emu.c:		if (((ctx->fcr31 & cond) != 0) == ((MIPSInst_RT(ir) & 1) != 0))
arch/mips/math-emu/cp1emu.c:			ctx->fcr31 = (ctx->fcr31 & ~FPU_CSR_ALL_X) | rcsr;
arch/mips/math-emu/cp1emu.c:			if ((ctx->fcr31 >> 5) & ctx->fcr31 & FPU_CSR_ALL_E) {
arch/mips/math-emu/cp1emu.c:				   ctx->fcr31); */
arch/mips/math-emu/cp1emu.c:			if (((ctx->fcr31 & cond) != 0) !=
arch/mips/math-emu/cp1emu.c:			if (((ctx->fcr31 & cond) != 0) !=
arch/mips/math-emu/cp1emu.c:	ctx->fcr31 = (ctx->fcr31 & ~FPU_CSR_ALL_X) | rcsr;
arch/mips/math-emu/cp1emu.c:	if ((ctx->fcr31 >> 5) & ctx->fcr31 & FPU_CSR_ALL_E) {
arch/mips/math-emu/cp1emu.c:		/*printk ("SIGFPE: FPU csr = %08x\n",ctx->fcr31); */
arch/mips/math-emu/cp1emu.c:			ctx->fcr31 |= cbit;
arch/mips/math-emu/cp1emu.c:			ctx->fcr31 &= ~cbit;
arch/mips/math-emu/cp1emu.c:			 * The 'ieee754_csr' is an alias of ctx->fcr31.
arch/mips/math-emu/cp1emu.c:			 * No need to copy ctx->fcr31 to ieee754_csr.
arch/mips/math-emu/dsemul.c:	spin_lock(&mm_ctx->bd_emupage_lock);
arch/mips/math-emu/dsemul.c:	if (!mm_ctx->bd_emupage_allocmap) {
arch/mips/math-emu/dsemul.c:		mm_ctx->bd_emupage_allocmap =
arch/mips/math-emu/dsemul.c:		if (!mm_ctx->bd_emupage_allocmap) {
arch/mips/math-emu/dsemul.c:	idx = bitmap_find_free_region(mm_ctx->bd_emupage_allocmap,
arch/mips/math-emu/dsemul.c:		spin_unlock(&mm_ctx->bd_emupage_lock);
arch/mips/math-emu/dsemul.c:		if (!wait_event_killable(mm_ctx->bd_emupage_queue,
arch/mips/math-emu/dsemul.c:			!bitmap_full(mm_ctx->bd_emupage_allocmap,
arch/mips/math-emu/dsemul.c:	spin_unlock(&mm_ctx->bd_emupage_lock);
arch/mips/math-emu/dsemul.c:	spin_lock(&mm_ctx->bd_emupage_lock);
arch/mips/math-emu/dsemul.c:	bitmap_clear(mm_ctx->bd_emupage_allocmap, idx, 1);
arch/mips/math-emu/dsemul.c:	wake_up(&mm_ctx->bd_emupage_queue);
arch/mips/math-emu/dsemul.c:	spin_unlock(&mm_ctx->bd_emupage_lock);
arch/mips/math-emu/dsemul.c:	kfree(mm_ctx->bd_emupage_allocmap);
arch/mips/pci/pci-alchemy.c:	ctx->wired_entry = read_c0_wired();
arch/mips/pci/pci-alchemy.c:	add_wired_entry(0, 0, (unsigned long)ctx->pci_cfg_vm->addr, PM_4K);
arch/mips/pci/pci-alchemy.c:	ctx->last_elo0 = ctx->last_elo1 = ~0;
arch/mips/pci/pci-alchemy.c:	r = __raw_readl(ctx->regs + PCI_REG_STATCMD) & 0x0000ffff;
arch/mips/pci/pci-alchemy.c:	__raw_writel(r, ctx->regs + PCI_REG_STATCMD);
arch/mips/pci/pci-alchemy.c:	if (ctx->board_pci_idsel(device, 1) == 0) {
arch/mips/pci/pci-alchemy.c:	if ((entryLo0 != ctx->last_elo0) || (entryLo1 != ctx->last_elo1)) {
arch/mips/pci/pci-alchemy.c:		mod_wired_entry(ctx->wired_entry, entryLo0, entryLo1,
arch/mips/pci/pci-alchemy.c:				(unsigned long)ctx->pci_cfg_vm->addr, PM_4K);
arch/mips/pci/pci-alchemy.c:		ctx->last_elo0 = entryLo0;
arch/mips/pci/pci-alchemy.c:		ctx->last_elo1 = entryLo1;
arch/mips/pci/pci-alchemy.c:		__raw_writel(*data, ctx->pci_cfg_vm->addr + offset);
arch/mips/pci/pci-alchemy.c:		*data = __raw_readl(ctx->pci_cfg_vm->addr + offset);
arch/mips/pci/pci-alchemy.c:	status = __raw_readl(ctx->regs + PCI_REG_STATCMD);
arch/mips/pci/pci-alchemy.c:		__raw_writel(status & 0xf000ffff, ctx->regs + PCI_REG_STATCMD);
arch/mips/pci/pci-alchemy.c:	(void)ctx->board_pci_idsel(device, 0);
arch/mips/pci/pci-alchemy.c:	ctx->pm[0]  = __raw_readl(ctx->regs + PCI_REG_CMEM);
arch/mips/pci/pci-alchemy.c:	ctx->pm[1]  = __raw_readl(ctx->regs + PCI_REG_CONFIG) & 0x0009ffff;
arch/mips/pci/pci-alchemy.c:	ctx->pm[2]  = __raw_readl(ctx->regs + PCI_REG_B2BMASK_CCH);
arch/mips/pci/pci-alchemy.c:	ctx->pm[3]  = __raw_readl(ctx->regs + PCI_REG_B2BBASE0_VID);
arch/mips/pci/pci-alchemy.c:	ctx->pm[4]  = __raw_readl(ctx->regs + PCI_REG_B2BBASE1_SID);
arch/mips/pci/pci-alchemy.c:	ctx->pm[5]  = __raw_readl(ctx->regs + PCI_REG_MWMASK_DEV);
arch/mips/pci/pci-alchemy.c:	ctx->pm[6]  = __raw_readl(ctx->regs + PCI_REG_MWBASE_REV_CCL);
arch/mips/pci/pci-alchemy.c:	ctx->pm[7]  = __raw_readl(ctx->regs + PCI_REG_ID);
arch/mips/pci/pci-alchemy.c:	ctx->pm[8]  = __raw_readl(ctx->regs + PCI_REG_CLASSREV);
arch/mips/pci/pci-alchemy.c:	ctx->pm[9]  = __raw_readl(ctx->regs + PCI_REG_PARAM);
arch/mips/pci/pci-alchemy.c:	ctx->pm[10] = __raw_readl(ctx->regs + PCI_REG_MBAR);
arch/mips/pci/pci-alchemy.c:	ctx->pm[11] = __raw_readl(ctx->regs + PCI_REG_TIMEOUT);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[0],  ctx->regs + PCI_REG_CMEM);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[2],  ctx->regs + PCI_REG_B2BMASK_CCH);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[3],  ctx->regs + PCI_REG_B2BBASE0_VID);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[4],  ctx->regs + PCI_REG_B2BBASE1_SID);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[5],  ctx->regs + PCI_REG_MWMASK_DEV);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[6],  ctx->regs + PCI_REG_MWBASE_REV_CCL);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[7],  ctx->regs + PCI_REG_ID);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[8],  ctx->regs + PCI_REG_CLASSREV);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[9],  ctx->regs + PCI_REG_PARAM);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[10], ctx->regs + PCI_REG_MBAR);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[11], ctx->regs + PCI_REG_TIMEOUT);
arch/mips/pci/pci-alchemy.c:	__raw_writel(ctx->pm[1],  ctx->regs + PCI_REG_CONFIG);
arch/mips/pci/pci-alchemy.c:	ctx->wired_entry = 8191;	/* impossibly high value */
arch/mips/pci/pci-alchemy.c:	ctx->regs = ioremap_nocache(r->start, resource_size(r));
arch/mips/pci/pci-alchemy.c:	if (!ctx->regs) {
arch/mips/pci/pci-alchemy.c:	ctx->alchemy_pci_ctrl.io_map_base = (unsigned long)virt_io;
arch/mips/pci/pci-alchemy.c:		val = __raw_readl(ctx->regs + PCI_REG_CONFIG);
arch/mips/pci/pci-alchemy.c:		__raw_writel(val, ctx->regs + PCI_REG_CONFIG);
arch/mips/pci/pci-alchemy.c:		ctx->board_map_irq = pd->board_map_irq;
arch/mips/pci/pci-alchemy.c:		ctx->board_pci_idsel = pd->board_pci_idsel;
arch/mips/pci/pci-alchemy.c:		ctx->board_pci_idsel = alchemy_pci_def_idsel;
arch/mips/pci/pci-alchemy.c:	ctx->alchemy_pci_ctrl.pci_ops = &alchemy_pci_ops;
arch/mips/pci/pci-alchemy.c:	ctx->alchemy_pci_ctrl.mem_resource = &alchemy_pci_def_memres;
arch/mips/pci/pci-alchemy.c:	ctx->alchemy_pci_ctrl.io_resource = &alchemy_pci_def_iores;
arch/mips/pci/pci-alchemy.c:	ctx->pci_cfg_vm = get_vm_area(0x2000, VM_IOREMAP);
arch/mips/pci/pci-alchemy.c:	if (!ctx->pci_cfg_vm) {
arch/mips/pci/pci-alchemy.c:	ctx->wired_entry = 8191;	/* impossibly high value */
arch/mips/pci/pci-alchemy.c:	set_io_port_base((unsigned long)ctx->alchemy_pci_ctrl.io_map_base);
arch/mips/pci/pci-alchemy.c:	val = __raw_readl(ctx->regs + PCI_REG_CONFIG);
arch/mips/pci/pci-alchemy.c:	__raw_writel(val, ctx->regs + PCI_REG_CONFIG);
arch/mips/pci/pci-alchemy.c:	register_pci_controller(&ctx->alchemy_pci_ctrl);
arch/mips/pci/pci-alchemy.c:	iounmap(ctx->regs);
arch/mips/pci/pci-alchemy.c:	if (ctx && ctx->board_map_irq)
arch/mips/pci/pci-alchemy.c:		return ctx->board_map_irq(dev, slot, pin);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	u64 *hash = (u64 *)ctx->hash;
arch/mips/cavium-octeon/crypto/octeon-md5.c:	u64 *hash = (u64 *)ctx->hash;
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->hash[0] = cpu_to_le32(MD5_H0);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->hash[1] = cpu_to_le32(MD5_H1);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->hash[2] = cpu_to_le32(MD5_H2);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->hash[3] = cpu_to_le32(MD5_H3);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->byte_count = 0;
arch/mips/cavium-octeon/crypto/octeon-md5.c:	const u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->byte_count += len;
arch/mips/cavium-octeon/crypto/octeon-md5.c:		memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
arch/mips/cavium-octeon/crypto/octeon-md5.c:	memcpy((char *)mctx->block + (sizeof(mctx->block) - avail), data,
arch/mips/cavium-octeon/crypto/octeon-md5.c:	octeon_md5_transform(mctx->block);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	while (len >= sizeof(mctx->block)) {
arch/mips/cavium-octeon/crypto/octeon-md5.c:		data += sizeof(mctx->block);
arch/mips/cavium-octeon/crypto/octeon-md5.c:		len -= sizeof(mctx->block);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	memcpy(mctx->block, data, len);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	const unsigned int offset = mctx->byte_count & 0x3f;
arch/mips/cavium-octeon/crypto/octeon-md5.c:	char *p = (char *)mctx->block + offset;
arch/mips/cavium-octeon/crypto/octeon-md5.c:		octeon_md5_transform(mctx->block);
arch/mips/cavium-octeon/crypto/octeon-md5.c:		p = (char *)mctx->block;
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->block[14] = cpu_to_le32(mctx->byte_count << 3);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	mctx->block[15] = cpu_to_le32(mctx->byte_count >> 29);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	octeon_md5_transform(mctx->block);
arch/mips/cavium-octeon/crypto/octeon-md5.c:	memcpy(out, mctx->hash, sizeof(mctx->hash));
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[0], 0);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[1], 1);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[2], 2);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[3], 3);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[4], 4);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[5], 5);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[6], 6);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	write_octeon_64bit_hash_sha512(sctx->state[7], 7);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[0] = read_octeon_64bit_hash_sha512(0);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[1] = read_octeon_64bit_hash_sha512(1);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[2] = read_octeon_64bit_hash_sha512(2);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[3] = read_octeon_64bit_hash_sha512(3);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[4] = read_octeon_64bit_hash_sha512(4);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[5] = read_octeon_64bit_hash_sha512(5);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[6] = read_octeon_64bit_hash_sha512(6);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[7] = read_octeon_64bit_hash_sha512(7);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[0] = SHA512_H0;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[1] = SHA512_H1;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[2] = SHA512_H2;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[3] = SHA512_H3;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[4] = SHA512_H4;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[5] = SHA512_H5;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[6] = SHA512_H6;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[7] = SHA512_H7;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->count[0] = sctx->count[1] = 0;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[0] = SHA384_H0;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[1] = SHA384_H1;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[2] = SHA384_H2;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[3] = SHA384_H3;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[4] = SHA384_H4;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[5] = SHA384_H5;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[6] = SHA384_H6;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->state[7] = SHA384_H7;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	sctx->count[0] = sctx->count[1] = 0;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	index = sctx->count[0] % SHA512_BLOCK_SIZE;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	if ((sctx->count[0] += len) < len)
arch/mips/cavium-octeon/crypto/octeon-sha512.c:		sctx->count[1]++;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:		memcpy(&sctx->buf[index], data, part_len);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:		octeon_sha512_transform(sctx->buf);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	memcpy(&sctx->buf[index], &data[i], len - i);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	if ((sctx->count[0] % SHA512_BLOCK_SIZE) + len < SHA512_BLOCK_SIZE)
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	bits[1] = cpu_to_be64(sctx->count[0] << 3);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	bits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);
arch/mips/cavium-octeon/crypto/octeon-sha512.c:	index = sctx->count[0] & 0x7f;
arch/mips/cavium-octeon/crypto/octeon-sha512.c:		dst[i] = cpu_to_be64(sctx->state[i]);
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	u64 *hash = (u64 *)sctx->state;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	} hash_tail = { { sctx->state[4], } };
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	u64 *hash = (u64 *)sctx->state;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[4]	= hash_tail.word[0];
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[0] = SHA1_H0;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[1] = SHA1_H1;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[2] = SHA1_H2;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[3] = SHA1_H3;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->state[4] = SHA1_H4;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->count = 0;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	partial = sctx->count % SHA1_BLOCK_SIZE;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	sctx->count += len;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:			memcpy(sctx->buffer + partial, data,
arch/mips/cavium-octeon/crypto/octeon-sha1.c:			src = sctx->buffer;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	memcpy(sctx->buffer + partial, src, len - done);
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	if ((sctx->count % SHA1_BLOCK_SIZE) + len < SHA1_BLOCK_SIZE)
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	bits = cpu_to_be64(sctx->count << 3);
arch/mips/cavium-octeon/crypto/octeon-sha1.c:	index = sctx->count & 0x3f;
arch/mips/cavium-octeon/crypto/octeon-sha1.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	u64 *hash = (u64 *)sctx->state;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	u64 *hash = (u64 *)sctx->state;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[0] = SHA224_H0;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[1] = SHA224_H1;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[2] = SHA224_H2;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[3] = SHA224_H3;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[4] = SHA224_H4;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[5] = SHA224_H5;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[6] = SHA224_H6;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[7] = SHA224_H7;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->count = 0;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[0] = SHA256_H0;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[1] = SHA256_H1;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[2] = SHA256_H2;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[3] = SHA256_H3;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[4] = SHA256_H4;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[5] = SHA256_H5;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[6] = SHA256_H6;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->state[7] = SHA256_H7;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->count = 0;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	partial = sctx->count % SHA256_BLOCK_SIZE;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	sctx->count += len;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:			memcpy(sctx->buf + partial, data,
arch/mips/cavium-octeon/crypto/octeon-sha256.c:			src = sctx->buf;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	memcpy(sctx->buf + partial, src, len - done);
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	if ((sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	bits = cpu_to_be64(sctx->count << 3);
arch/mips/cavium-octeon/crypto/octeon-sha256.c:	index = sctx->count & 0x3f;
arch/mips/cavium-octeon/crypto/octeon-sha256.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/mips/net/bpf_jit.c:		u32 *p = &(ctx)->target[ctx->idx];	\
arch/mips/net/bpf_jit.c:		u32 *p = &(ctx)->target[ctx->idx];	\
arch/mips/net/bpf_jit.c:	if (ctx->target != NULL) {
arch/mips/net/bpf_jit.c:			u32 *p = &ctx->target[ctx->idx];
arch/mips/net/bpf_jit.c:			p = &ctx->target[ctx->idx + 1];
arch/mips/net/bpf_jit.c:			u32 *p = &ctx->target[ctx->idx];
arch/mips/net/bpf_jit.c:	ctx->idx++;
arch/mips/net/bpf_jit.c:		ctx->idx++;
arch/mips/net/bpf_jit.c:	if (ctx->target != NULL) {
arch/mips/net/bpf_jit.c:		u32 *p = &ctx->target[ctx->idx];
arch/mips/net/bpf_jit.c:		p = &ctx->target[ctx->idx + 1];
arch/mips/net/bpf_jit.c:	ctx->idx += 2; /* 2 insts */
arch/mips/net/bpf_jit.c:	if (ctx->target != NULL) {
arch/mips/net/bpf_jit.c:		u32 *p = &ctx->target[ctx->idx];
arch/mips/net/bpf_jit.c:		p = &ctx->target[ctx->idx + 1];
arch/mips/net/bpf_jit.c:	ctx->idx += 2; /* 2 insts */
arch/mips/net/bpf_jit.c:	if (ctx->target == NULL)
arch/mips/net/bpf_jit.c:	 * ctx->idx currently points to the branch instruction
arch/mips/net/bpf_jit.c:	return ctx->offsets[tgt] -
arch/mips/net/bpf_jit.c:		(ctx->idx * 4 - ctx->prologue_bytes) - 4;
arch/mips/net/bpf_jit.c:	if (ctx->target != NULL) {
arch/mips/net/bpf_jit.c:		u32 *p = &ctx->target[ctx->idx];
arch/mips/net/bpf_jit.c:	ctx->idx++;
arch/mips/net/bpf_jit.c:	tmp_flags = sflags = ctx->flags >> SEEN_SREG_SFT;
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_CALL) {
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_MEM) {
arch/mips/net/bpf_jit.c:	tmp_flags = sflags = ctx->flags >> SEEN_SREG_SFT;
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_CALL)
arch/mips/net/bpf_jit.c:	sp_off += hweight32(ctx->flags >> SEEN_SREG_SFT) * SZREG;
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_MEM)
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_CALL)
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_SKB)
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_SKB_DATA) {
arch/mips/net/bpf_jit.c:	if (ctx->flags & SEEN_X)
arch/mips/net/bpf_jit.c:	if (bpf_needs_clear_a(&ctx->skf->insns[0]))
arch/mips/net/bpf_jit.c:	const struct bpf_prog *prog = ctx->skf;
arch/mips/net/bpf_jit.c:		if (ctx->target == NULL)
arch/mips/net/bpf_jit.c:			ctx->offsets[i] = ctx->idx * 4;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_MEM | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_CALL | SEEN_OFF |
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_OFF | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_MEM;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_SKB;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_CALL | SEEN_SKB;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_MEM | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_MEM | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:				ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:				ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:				ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X;
arch/mips/net/bpf_jit.c:					ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:					ctx->flags |= SEEN_A |
arch/mips/net/bpf_jit.c:					ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:					ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:					ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_X | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_X;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_OFF | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_A | SEEN_OFF;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB;
arch/mips/net/bpf_jit.c:			ctx->flags |= SEEN_SKB | SEEN_A;
arch/mips/net/bpf_jit.c:	if (ctx->target == NULL)
arch/mips/net/bpf_jit.c:		ctx->offsets[i] = ctx->idx * 4;
arch/sh/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/sh/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/sh/kernel/irq.c:		irqctx->tinfo.task = curctx->tinfo.task;
arch/sh/kernel/irq.c:		irqctx->tinfo.previous_sp = current_stack_pointer;
arch/sh/kernel/irq.c:		irqctx->tinfo.preempt_count =
arch/sh/kernel/irq.c:			(irqctx->tinfo.preempt_count & ~SOFTIRQ_MASK) |
arch/sh/kernel/irq.c:			(curctx->tinfo.preempt_count & SOFTIRQ_MASK);
arch/sh/kernel/irq.c:	irqctx->tinfo.task		= NULL;
arch/sh/kernel/irq.c:	irqctx->tinfo.cpu		= cpu;
arch/sh/kernel/irq.c:	irqctx->tinfo.preempt_count	= HARDIRQ_OFFSET;
arch/sh/kernel/irq.c:	irqctx->tinfo.addr_limit	= MAKE_MM_SEG(0);
arch/sh/kernel/irq.c:	irqctx->tinfo.task		= NULL;
arch/sh/kernel/irq.c:	irqctx->tinfo.cpu		= cpu;
arch/sh/kernel/irq.c:	irqctx->tinfo.preempt_count	= 0;
arch/sh/kernel/irq.c:	irqctx->tinfo.addr_limit	= MAKE_MM_SEG(0);
arch/sh/kernel/irq.c:	irqctx->tinfo.task = curctx->task;
arch/sh/kernel/irq.c:	irqctx->tinfo.previous_sp = current_stack_pointer;
arch/frv/mm/mmu-context.c:	if (!list_empty(&ctx->id_link)) {
arch/frv/mm/mmu-context.c:		list_move_tail(&ctx->id_link, &cxn_owners_lru);
arch/frv/mm/mmu-context.c:		ctx->id = cxn;
arch/frv/mm/mmu-context.c:		list_add_tail(&ctx->id_link, &cxn_owners_lru);
arch/frv/mm/mmu-context.c:	return ctx->id;
arch/frv/mm/mmu-context.c:	ctx->id_busy = 1;
arch/frv/mm/mmu-context.c:	asm volatile("movgs %0,cxnr"   : : "r"(ctx->id));
arch/frv/mm/mmu-context.c:	asm volatile("movgs %0,scr0"   : : "r"(ctx->itlb_cached_pge));
arch/frv/mm/mmu-context.c:	asm volatile("movgs %0,dampr4" : : "r"(ctx->itlb_ptd_mapping));
arch/frv/mm/mmu-context.c:	asm volatile("movgs %0,scr1"   : : "r"(ctx->dtlb_cached_pge));
arch/frv/mm/mmu-context.c:	asm volatile("movgs %0,dampr5" : : "r"(ctx->dtlb_ptd_mapping));
arch/frv/mm/mmu-context.c:	if (!list_empty(&ctx->id_link)) {
arch/frv/mm/mmu-context.c:		if (ctx->id == cxn_pinned)
arch/frv/mm/mmu-context.c:		list_del_init(&ctx->id_link);
arch/frv/mm/mmu-context.c:		clear_bit(ctx->id, cxn_bitmap);
arch/frv/mm/mmu-context.c:		__flush_tlb_mm(ctx->id);
arch/frv/mm/mmu-context.c:		ctx->id = 0;
arch/sparc/crypto/des_glue.c:	des_sparc64_key_expand((const u32 *) key, &dctx->encrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:	encrypt_to_decrypt(&dctx->decrypt_expkey[0], &dctx->encrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:	const u64 *K = ctx->encrypt_expkey;
arch/sparc/crypto/des_glue.c:	const u64 *K = ctx->decrypt_expkey;
arch/sparc/crypto/des_glue.c:		des_sparc64_load_keys(&ctx->encrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:		des_sparc64_load_keys(&ctx->decrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:	des_sparc64_load_keys(&ctx->encrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:	des_sparc64_load_keys(&ctx->decrypt_expkey[0]);
arch/sparc/crypto/des_glue.c:	memcpy(&dctx->encrypt_expkey[0], &k1[0], sizeof(k1));
arch/sparc/crypto/des_glue.c:	encrypt_to_decrypt(&dctx->encrypt_expkey[DES_EXPKEY_WORDS / 2], &k2[0]);
arch/sparc/crypto/des_glue.c:	memcpy(&dctx->encrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],
arch/sparc/crypto/des_glue.c:	encrypt_to_decrypt(&dctx->decrypt_expkey[0], &k3[0]);
arch/sparc/crypto/des_glue.c:	memcpy(&dctx->decrypt_expkey[DES_EXPKEY_WORDS / 2],
arch/sparc/crypto/des_glue.c:	encrypt_to_decrypt(&dctx->decrypt_expkey[(DES_EXPKEY_WORDS / 2) * 2],
arch/sparc/crypto/des_glue.c:	const u64 *K = ctx->encrypt_expkey;
arch/sparc/crypto/des_glue.c:	const u64 *K = ctx->decrypt_expkey;
arch/sparc/crypto/des_glue.c:		K = &ctx->encrypt_expkey[0];
arch/sparc/crypto/des_glue.c:		K = &ctx->decrypt_expkey[0];
arch/sparc/crypto/des_glue.c:	K = &ctx->encrypt_expkey[0];
arch/sparc/crypto/des_glue.c:	K = &ctx->decrypt_expkey[0];
arch/sparc/crypto/sha256_glue.c:	sctx->state[0] = SHA224_H0;
arch/sparc/crypto/sha256_glue.c:	sctx->state[1] = SHA224_H1;
arch/sparc/crypto/sha256_glue.c:	sctx->state[2] = SHA224_H2;
arch/sparc/crypto/sha256_glue.c:	sctx->state[3] = SHA224_H3;
arch/sparc/crypto/sha256_glue.c:	sctx->state[4] = SHA224_H4;
arch/sparc/crypto/sha256_glue.c:	sctx->state[5] = SHA224_H5;
arch/sparc/crypto/sha256_glue.c:	sctx->state[6] = SHA224_H6;
arch/sparc/crypto/sha256_glue.c:	sctx->state[7] = SHA224_H7;
arch/sparc/crypto/sha256_glue.c:	sctx->count = 0;
arch/sparc/crypto/sha256_glue.c:	sctx->state[0] = SHA256_H0;
arch/sparc/crypto/sha256_glue.c:	sctx->state[1] = SHA256_H1;
arch/sparc/crypto/sha256_glue.c:	sctx->state[2] = SHA256_H2;
arch/sparc/crypto/sha256_glue.c:	sctx->state[3] = SHA256_H3;
arch/sparc/crypto/sha256_glue.c:	sctx->state[4] = SHA256_H4;
arch/sparc/crypto/sha256_glue.c:	sctx->state[5] = SHA256_H5;
arch/sparc/crypto/sha256_glue.c:	sctx->state[6] = SHA256_H6;
arch/sparc/crypto/sha256_glue.c:	sctx->state[7] = SHA256_H7;
arch/sparc/crypto/sha256_glue.c:	sctx->count = 0;
arch/sparc/crypto/sha256_glue.c:	sctx->count += len;
arch/sparc/crypto/sha256_glue.c:		memcpy(sctx->buf + partial, data, done);
arch/sparc/crypto/sha256_glue.c:		sha256_sparc64_transform(sctx->state, sctx->buf, 1);
arch/sparc/crypto/sha256_glue.c:		sha256_sparc64_transform(sctx->state, data + done, rounds);
arch/sparc/crypto/sha256_glue.c:	memcpy(sctx->buf, data + done, len - done);
arch/sparc/crypto/sha256_glue.c:	unsigned int partial = sctx->count % SHA256_BLOCK_SIZE;
arch/sparc/crypto/sha256_glue.c:		sctx->count += len;
arch/sparc/crypto/sha256_glue.c:		memcpy(sctx->buf + partial, data, len);
arch/sparc/crypto/sha256_glue.c:	bits = cpu_to_be64(sctx->count << 3);
arch/sparc/crypto/sha256_glue.c:	index = sctx->count % SHA256_BLOCK_SIZE;
arch/sparc/crypto/sha256_glue.c:		sctx->count += padlen;
arch/sparc/crypto/sha256_glue.c:		memcpy(sctx->buf + index, padding, padlen);
arch/sparc/crypto/sha256_glue.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/sparc/crypto/aes_glue.c:		ctx->expanded_key_length = 0xb0;
arch/sparc/crypto/aes_glue.c:		ctx->ops = &aes128_ops;
arch/sparc/crypto/aes_glue.c:		ctx->expanded_key_length = 0xd0;
arch/sparc/crypto/aes_glue.c:		ctx->ops = &aes192_ops;
arch/sparc/crypto/aes_glue.c:		ctx->expanded_key_length = 0xf0;
arch/sparc/crypto/aes_glue.c:		ctx->ops = &aes256_ops;
arch/sparc/crypto/aes_glue.c:	aes_sparc64_key_expand((const u32 *)in_key, &ctx->key[0], key_len);
arch/sparc/crypto/aes_glue.c:	ctx->key_length = key_len;
arch/sparc/crypto/aes_glue.c:	ctx->ops->encrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);
arch/sparc/crypto/aes_glue.c:	ctx->ops->decrypt(&ctx->key[0], (const u32 *) src, (u32 *) dst);
arch/sparc/crypto/aes_glue.c:	ctx->ops->load_encrypt_keys(&ctx->key[0]);
arch/sparc/crypto/aes_glue.c:			ctx->ops->ecb_encrypt(&ctx->key[0],
arch/sparc/crypto/aes_glue.c:	ctx->ops->load_decrypt_keys(&ctx->key[0]);
arch/sparc/crypto/aes_glue.c:	key_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];
arch/sparc/crypto/aes_glue.c:			ctx->ops->ecb_decrypt(key_end,
arch/sparc/crypto/aes_glue.c:	ctx->ops->load_encrypt_keys(&ctx->key[0]);
arch/sparc/crypto/aes_glue.c:			ctx->ops->cbc_encrypt(&ctx->key[0],
arch/sparc/crypto/aes_glue.c:	ctx->ops->load_decrypt_keys(&ctx->key[0]);
arch/sparc/crypto/aes_glue.c:	key_end = &ctx->key[ctx->expanded_key_length / sizeof(u64)];
arch/sparc/crypto/aes_glue.c:			ctx->ops->cbc_decrypt(key_end,
arch/sparc/crypto/aes_glue.c:	ctx->ops->ecb_encrypt(&ctx->key[0], (const u64 *)ctrblk,
arch/sparc/crypto/aes_glue.c:	ctx->ops->load_encrypt_keys(&ctx->key[0]);
arch/sparc/crypto/aes_glue.c:			ctx->ops->ctr_crypt(&ctx->key[0],
arch/sparc/crypto/sha1_glue.c:	sctx->count += len;
arch/sparc/crypto/sha1_glue.c:		memcpy(sctx->buffer + partial, data, done);
arch/sparc/crypto/sha1_glue.c:		sha1_sparc64_transform(sctx->state, sctx->buffer, 1);
arch/sparc/crypto/sha1_glue.c:		sha1_sparc64_transform(sctx->state, data + done, rounds);
arch/sparc/crypto/sha1_glue.c:	memcpy(sctx->buffer, data + done, len - done);
arch/sparc/crypto/sha1_glue.c:	unsigned int partial = sctx->count % SHA1_BLOCK_SIZE;
arch/sparc/crypto/sha1_glue.c:		sctx->count += len;
arch/sparc/crypto/sha1_glue.c:		memcpy(sctx->buffer + partial, data, len);
arch/sparc/crypto/sha1_glue.c:	bits = cpu_to_be64(sctx->count << 3);
arch/sparc/crypto/sha1_glue.c:	index = sctx->count % SHA1_BLOCK_SIZE;
arch/sparc/crypto/sha1_glue.c:		sctx->count += padlen;
arch/sparc/crypto/sha1_glue.c:		memcpy(sctx->buffer + index, padding, padlen);
arch/sparc/crypto/sha1_glue.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/sparc/crypto/sha512_glue.c:	sctx->state[0] = SHA512_H0;
arch/sparc/crypto/sha512_glue.c:	sctx->state[1] = SHA512_H1;
arch/sparc/crypto/sha512_glue.c:	sctx->state[2] = SHA512_H2;
arch/sparc/crypto/sha512_glue.c:	sctx->state[3] = SHA512_H3;
arch/sparc/crypto/sha512_glue.c:	sctx->state[4] = SHA512_H4;
arch/sparc/crypto/sha512_glue.c:	sctx->state[5] = SHA512_H5;
arch/sparc/crypto/sha512_glue.c:	sctx->state[6] = SHA512_H6;
arch/sparc/crypto/sha512_glue.c:	sctx->state[7] = SHA512_H7;
arch/sparc/crypto/sha512_glue.c:	sctx->count[0] = sctx->count[1] = 0;
arch/sparc/crypto/sha512_glue.c:	sctx->state[0] = SHA384_H0;
arch/sparc/crypto/sha512_glue.c:	sctx->state[1] = SHA384_H1;
arch/sparc/crypto/sha512_glue.c:	sctx->state[2] = SHA384_H2;
arch/sparc/crypto/sha512_glue.c:	sctx->state[3] = SHA384_H3;
arch/sparc/crypto/sha512_glue.c:	sctx->state[4] = SHA384_H4;
arch/sparc/crypto/sha512_glue.c:	sctx->state[5] = SHA384_H5;
arch/sparc/crypto/sha512_glue.c:	sctx->state[6] = SHA384_H6;
arch/sparc/crypto/sha512_glue.c:	sctx->state[7] = SHA384_H7;
arch/sparc/crypto/sha512_glue.c:	sctx->count[0] = sctx->count[1] = 0;
arch/sparc/crypto/sha512_glue.c:	if ((sctx->count[0] += len) < len)
arch/sparc/crypto/sha512_glue.c:		sctx->count[1]++;
arch/sparc/crypto/sha512_glue.c:		memcpy(sctx->buf + partial, data, done);
arch/sparc/crypto/sha512_glue.c:		sha512_sparc64_transform(sctx->state, sctx->buf, 1);
arch/sparc/crypto/sha512_glue.c:		sha512_sparc64_transform(sctx->state, data + done, rounds);
arch/sparc/crypto/sha512_glue.c:	memcpy(sctx->buf, data + done, len - done);
arch/sparc/crypto/sha512_glue.c:	unsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;
arch/sparc/crypto/sha512_glue.c:		if ((sctx->count[0] += len) < len)
arch/sparc/crypto/sha512_glue.c:			sctx->count[1]++;
arch/sparc/crypto/sha512_glue.c:		memcpy(sctx->buf + partial, data, len);
arch/sparc/crypto/sha512_glue.c:	bits[1] = cpu_to_be64(sctx->count[0] << 3);
arch/sparc/crypto/sha512_glue.c:	bits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);
arch/sparc/crypto/sha512_glue.c:	index = sctx->count[0] % SHA512_BLOCK_SIZE;
arch/sparc/crypto/sha512_glue.c:		if ((sctx->count[0] += padlen) < padlen)
arch/sparc/crypto/sha512_glue.c:			sctx->count[1]++;
arch/sparc/crypto/sha512_glue.c:		memcpy(sctx->buf + index, padding, padlen);
arch/sparc/crypto/sha512_glue.c:		dst[i] = cpu_to_be64(sctx->state[i]);
arch/sparc/crypto/md5_glue.c:	mctx->hash[0] = cpu_to_le32(MD5_H0);
arch/sparc/crypto/md5_glue.c:	mctx->hash[1] = cpu_to_le32(MD5_H1);
arch/sparc/crypto/md5_glue.c:	mctx->hash[2] = cpu_to_le32(MD5_H2);
arch/sparc/crypto/md5_glue.c:	mctx->hash[3] = cpu_to_le32(MD5_H3);
arch/sparc/crypto/md5_glue.c:	mctx->byte_count = 0;
arch/sparc/crypto/md5_glue.c:	sctx->byte_count += len;
arch/sparc/crypto/md5_glue.c:		memcpy((u8 *)sctx->block + partial, data, done);
arch/sparc/crypto/md5_glue.c:		md5_sparc64_transform(sctx->hash, (u8 *)sctx->block, 1);
arch/sparc/crypto/md5_glue.c:		md5_sparc64_transform(sctx->hash, data + done, rounds);
arch/sparc/crypto/md5_glue.c:	memcpy(sctx->block, data + done, len - done);
arch/sparc/crypto/md5_glue.c:	unsigned int partial = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;
arch/sparc/crypto/md5_glue.c:		sctx->byte_count += len;
arch/sparc/crypto/md5_glue.c:		memcpy((u8 *)sctx->block + partial, data, len);
arch/sparc/crypto/md5_glue.c:	bits = cpu_to_le64(sctx->byte_count << 3);
arch/sparc/crypto/md5_glue.c:	index = sctx->byte_count % MD5_HMAC_BLOCK_SIZE;
arch/sparc/crypto/md5_glue.c:		sctx->byte_count += padlen;
arch/sparc/crypto/md5_glue.c:		memcpy((u8 *)sctx->block + index, padding, padlen);
arch/sparc/crypto/md5_glue.c:		dst[i] = sctx->hash[i];
arch/sparc/crypto/camellia_glue.c:	ctx->key_len = key_len;
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_key_expand(in_key, &ctx->encrypt_key[0],
arch/sparc/crypto/camellia_glue.c:				    key_len, &ctx->decrypt_key[0]);
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_crypt(&ctx->encrypt_key[0],
arch/sparc/crypto/camellia_glue.c:			       (u32 *) dst, ctx->key_len);
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_crypt(&ctx->decrypt_key[0],
arch/sparc/crypto/camellia_glue.c:			       (u32 *) dst, ctx->key_len);
arch/sparc/crypto/camellia_glue.c:	if (ctx->key_len != 16)
arch/sparc/crypto/camellia_glue.c:		key = &ctx->encrypt_key[0];
arch/sparc/crypto/camellia_glue.c:		key = &ctx->decrypt_key[0];
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_load_keys(key, ctx->key_len);
arch/sparc/crypto/camellia_glue.c:	if (ctx->key_len != 16)
arch/sparc/crypto/camellia_glue.c:	key = &ctx->encrypt_key[0];
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_load_keys(key, ctx->key_len);
arch/sparc/crypto/camellia_glue.c:	if (ctx->key_len != 16)
arch/sparc/crypto/camellia_glue.c:	key = &ctx->decrypt_key[0];
arch/sparc/crypto/camellia_glue.c:	camellia_sparc64_load_keys(key, ctx->key_len);
arch/s390/crypto/des_s390.c:	memcpy(ctx->key, key, key_len);
arch/s390/crypto/des_s390.c:	cpacf_km(CPACF_KM_DEA, ctx->key, out, in, DES_BLOCK_SIZE);
arch/s390/crypto/des_s390.c:		 ctx->key, out, in, DES_BLOCK_SIZE);
arch/s390/crypto/des_s390.c:		cpacf_km(fc, ctx->key, walk->dst.virt.addr,
arch/s390/crypto/des_s390.c:	memcpy(param.key, ctx->key, DES3_KEY_SIZE);
arch/s390/crypto/des_s390.c:	memcpy(ctx->key, key, key_len);
arch/s390/crypto/des_s390.c:	cpacf_km(CPACF_KM_TDEA_192, ctx->key, dst, src, DES_BLOCK_SIZE);
arch/s390/crypto/des_s390.c:		 ctx->key, dst, src, DES_BLOCK_SIZE);
arch/s390/crypto/des_s390.c:		cpacf_kmctr(fc, ctx->key, walk->dst.virt.addr,
arch/s390/crypto/des_s390.c:		cpacf_kmctr(fc, ctx->key, buf, walk->src.virt.addr,
arch/s390/crypto/ghash_s390.c:	memcpy(dctx->key, ctx->key, GHASH_BLOCK_SIZE);
arch/s390/crypto/ghash_s390.c:	memcpy(ctx->key, key, GHASH_BLOCK_SIZE);
arch/s390/crypto/ghash_s390.c:	u8 *buf = dctx->buffer;
arch/s390/crypto/ghash_s390.c:	if (dctx->bytes) {
arch/s390/crypto/ghash_s390.c:		u8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);
arch/s390/crypto/ghash_s390.c:		n = min(srclen, dctx->bytes);
arch/s390/crypto/ghash_s390.c:		dctx->bytes -= n;
arch/s390/crypto/ghash_s390.c:		if (!dctx->bytes) {
arch/s390/crypto/ghash_s390.c:		dctx->bytes = GHASH_BLOCK_SIZE - srclen;
arch/s390/crypto/ghash_s390.c:	u8 *buf = dctx->buffer;
arch/s390/crypto/ghash_s390.c:	if (dctx->bytes) {
arch/s390/crypto/ghash_s390.c:		u8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);
arch/s390/crypto/ghash_s390.c:		memset(pos, 0, dctx->bytes);
arch/s390/crypto/ghash_s390.c:		dctx->bytes = 0;
arch/s390/crypto/ghash_s390.c:		memcpy(dst, dctx->icv, GHASH_BLOCK_SIZE);
arch/s390/crypto/aes_s390.c:	sctx->fallback.cip->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;
arch/s390/crypto/aes_s390.c:	sctx->fallback.cip->base.crt_flags |= (tfm->crt_flags &
arch/s390/crypto/aes_s390.c:	ret = crypto_cipher_setkey(sctx->fallback.cip, in_key, key_len);
arch/s390/crypto/aes_s390.c:		tfm->crt_flags |= (sctx->fallback.cip->base.crt_flags &
arch/s390/crypto/aes_s390.c:	sctx->fc = (fc && cpacf_test_func(&km_functions, fc)) ? fc : 0;
arch/s390/crypto/aes_s390.c:	if (!sctx->fc)
arch/s390/crypto/aes_s390.c:	sctx->key_len = key_len;
arch/s390/crypto/aes_s390.c:	memcpy(sctx->key, in_key, key_len);
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc)) {
arch/s390/crypto/aes_s390.c:		crypto_cipher_encrypt_one(sctx->fallback.cip, out, in);
arch/s390/crypto/aes_s390.c:	cpacf_km(sctx->fc, &sctx->key, out, in, AES_BLOCK_SIZE);
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc)) {
arch/s390/crypto/aes_s390.c:		crypto_cipher_decrypt_one(sctx->fallback.cip, out, in);
arch/s390/crypto/aes_s390.c:	cpacf_km(sctx->fc | CPACF_DECRYPT,
arch/s390/crypto/aes_s390.c:		 &sctx->key, out, in, AES_BLOCK_SIZE);
arch/s390/crypto/aes_s390.c:	sctx->fallback.cip = crypto_alloc_cipher(name, 0,
arch/s390/crypto/aes_s390.c:	if (IS_ERR(sctx->fallback.cip)) {
arch/s390/crypto/aes_s390.c:		return PTR_ERR(sctx->fallback.cip);
arch/s390/crypto/aes_s390.c:	crypto_free_cipher(sctx->fallback.cip);
arch/s390/crypto/aes_s390.c:	sctx->fallback.cip = NULL;
arch/s390/crypto/aes_s390.c:	crypto_skcipher_clear_flags(sctx->fallback.blk, CRYPTO_TFM_REQ_MASK);
arch/s390/crypto/aes_s390.c:	crypto_skcipher_set_flags(sctx->fallback.blk, tfm->crt_flags &
arch/s390/crypto/aes_s390.c:	ret = crypto_skcipher_setkey(sctx->fallback.blk, key, len);
arch/s390/crypto/aes_s390.c:	tfm->crt_flags |= crypto_skcipher_get_flags(sctx->fallback.blk) &
arch/s390/crypto/aes_s390.c:	SKCIPHER_REQUEST_ON_STACK(req, sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	skcipher_request_set_tfm(req, sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	SKCIPHER_REQUEST_ON_STACK(req, sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	skcipher_request_set_tfm(req, sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	sctx->fc = (fc && cpacf_test_func(&km_functions, fc)) ? fc : 0;
arch/s390/crypto/aes_s390.c:	if (!sctx->fc)
arch/s390/crypto/aes_s390.c:	sctx->key_len = key_len;
arch/s390/crypto/aes_s390.c:	memcpy(sctx->key, in_key, key_len);
arch/s390/crypto/aes_s390.c:		cpacf_km(sctx->fc | modifier, sctx->key,
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/aes_s390.c:	sctx->fallback.blk = crypto_alloc_skcipher(name, 0,
arch/s390/crypto/aes_s390.c:	if (IS_ERR(sctx->fallback.blk)) {
arch/s390/crypto/aes_s390.c:		return PTR_ERR(sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	crypto_free_skcipher(sctx->fallback.blk);
arch/s390/crypto/aes_s390.c:	sctx->fc = (fc && cpacf_test_func(&kmc_functions, fc)) ? fc : 0;
arch/s390/crypto/aes_s390.c:	if (!sctx->fc)
arch/s390/crypto/aes_s390.c:	sctx->key_len = key_len;
arch/s390/crypto/aes_s390.c:	memcpy(sctx->key, in_key, key_len);
arch/s390/crypto/aes_s390.c:	memcpy(param.key, sctx->key, sctx->key_len);
arch/s390/crypto/aes_s390.c:		cpacf_kmc(sctx->fc | modifier, &param,
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/aes_s390.c:	crypto_skcipher_clear_flags(xts_ctx->fallback, CRYPTO_TFM_REQ_MASK);
arch/s390/crypto/aes_s390.c:	crypto_skcipher_set_flags(xts_ctx->fallback, tfm->crt_flags &
arch/s390/crypto/aes_s390.c:	ret = crypto_skcipher_setkey(xts_ctx->fallback, key, len);
arch/s390/crypto/aes_s390.c:	tfm->crt_flags |= crypto_skcipher_get_flags(xts_ctx->fallback) &
arch/s390/crypto/aes_s390.c:	SKCIPHER_REQUEST_ON_STACK(req, xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	skcipher_request_set_tfm(req, xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	SKCIPHER_REQUEST_ON_STACK(req, xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	skcipher_request_set_tfm(req, xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	xts_ctx->fc = (fc && cpacf_test_func(&km_functions, fc)) ? fc : 0;
arch/s390/crypto/aes_s390.c:	if (!xts_ctx->fc)
arch/s390/crypto/aes_s390.c:	xts_ctx->key_len = key_len;
arch/s390/crypto/aes_s390.c:	memcpy(xts_ctx->key, in_key, key_len);
arch/s390/crypto/aes_s390.c:	memcpy(xts_ctx->pcc_key, in_key + key_len, key_len);
arch/s390/crypto/aes_s390.c:	offset = xts_ctx->key_len & 0x10;
arch/s390/crypto/aes_s390.c:	memcpy(pcc_param.key + offset, xts_ctx->pcc_key, xts_ctx->key_len);
arch/s390/crypto/aes_s390.c:	cpacf_pcc(xts_ctx->fc, pcc_param.key + offset);
arch/s390/crypto/aes_s390.c:	memcpy(xts_param.key + offset, xts_ctx->key, xts_ctx->key_len);
arch/s390/crypto/aes_s390.c:		cpacf_km(xts_ctx->fc | modifier, xts_param.key + offset,
arch/s390/crypto/aes_s390.c:	if (unlikely(!xts_ctx->fc))
arch/s390/crypto/aes_s390.c:	if (unlikely(!xts_ctx->fc))
arch/s390/crypto/aes_s390.c:	xts_ctx->fallback = crypto_alloc_skcipher(name, 0,
arch/s390/crypto/aes_s390.c:	if (IS_ERR(xts_ctx->fallback)) {
arch/s390/crypto/aes_s390.c:		return PTR_ERR(xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	crypto_free_skcipher(xts_ctx->fallback);
arch/s390/crypto/aes_s390.c:	sctx->fc = (fc && cpacf_test_func(&kmctr_functions, fc)) ? fc : 0;
arch/s390/crypto/aes_s390.c:	if (!sctx->fc)
arch/s390/crypto/aes_s390.c:	sctx->key_len = key_len;
arch/s390/crypto/aes_s390.c:	memcpy(sctx->key, in_key, key_len);
arch/s390/crypto/aes_s390.c:		cpacf_kmctr(sctx->fc | modifier, sctx->key,
arch/s390/crypto/aes_s390.c:		cpacf_kmctr(sctx->fc | modifier, sctx->key,
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/aes_s390.c:	if (unlikely(!sctx->fc))
arch/s390/crypto/crc32-vx.c:	mctx->key = 0;
arch/s390/crypto/crc32-vx.c:	mctx->key = ~0;
arch/s390/crypto/crc32-vx.c:	ctx->crc = mctx->key;
arch/s390/crypto/crc32-vx.c:	if (newkeylen != sizeof(mctx->key)) {
arch/s390/crypto/crc32-vx.c:	mctx->key = le32_to_cpu(*(__le32 *)newkey);
arch/s390/crypto/crc32-vx.c:	if (newkeylen != sizeof(mctx->key)) {
arch/s390/crypto/crc32-vx.c:	mctx->key = be32_to_cpu(*(__be32 *)newkey);
arch/s390/crypto/crc32-vx.c:	*(__le32 *)out = cpu_to_le32p(&ctx->crc);
arch/s390/crypto/crc32-vx.c:	*(__be32 *)out = cpu_to_be32p(&ctx->crc);
arch/s390/crypto/crc32-vx.c:	*(__le32 *)out = ~cpu_to_le32p(&ctx->crc);
arch/s390/crypto/crc32-vx.c:		ctx->crc = func(ctx->crc, data, datalen);		      \
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[0] = 0x6a09e667f3bcc908ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[2] = 0xbb67ae8584caa73bULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[4] = 0x3c6ef372fe94f82bULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[6] = 0xa54ff53a5f1d36f1ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[8] = 0x510e527fade682d1ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[10] = 0x9b05688c2b3e6c1fULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[12] = 0x1f83d9abfb41bd6bULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[14] = 0x5be0cd19137e2179ULL;
arch/s390/crypto/sha512_s390.c:	ctx->count = 0;
arch/s390/crypto/sha512_s390.c:	ctx->func = CPACF_KIMD_SHA_512;
arch/s390/crypto/sha512_s390.c:	octx->count[0] = sctx->count;
arch/s390/crypto/sha512_s390.c:	octx->count[1] = 0;
arch/s390/crypto/sha512_s390.c:	memcpy(octx->state, sctx->state, sizeof(octx->state));
arch/s390/crypto/sha512_s390.c:	memcpy(octx->buf, sctx->buf, sizeof(octx->buf));
arch/s390/crypto/sha512_s390.c:	if (unlikely(ictx->count[1]))
arch/s390/crypto/sha512_s390.c:	sctx->count = ictx->count[0];
arch/s390/crypto/sha512_s390.c:	memcpy(sctx->state, ictx->state, sizeof(ictx->state));
arch/s390/crypto/sha512_s390.c:	memcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));
arch/s390/crypto/sha512_s390.c:	sctx->func = CPACF_KIMD_SHA_512;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[0] = 0xcbbb9d5dc1059ed8ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[2] = 0x629a292a367cd507ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[4] = 0x9159015a3070dd17ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[6] = 0x152fecd8f70e5939ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[8] = 0x67332667ffc00b31ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[10] = 0x8eb44a8768581511ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[12] = 0xdb0c2e0d64f98fa7ULL;
arch/s390/crypto/sha512_s390.c:	*(__u64 *)&ctx->state[14] = 0x47b5481dbefa4fa4ULL;
arch/s390/crypto/sha512_s390.c:	ctx->count = 0;
arch/s390/crypto/sha512_s390.c:	ctx->func = CPACF_KIMD_SHA_512;
arch/s390/crypto/sha256_s390.c:	sctx->state[0] = SHA256_H0;
arch/s390/crypto/sha256_s390.c:	sctx->state[1] = SHA256_H1;
arch/s390/crypto/sha256_s390.c:	sctx->state[2] = SHA256_H2;
arch/s390/crypto/sha256_s390.c:	sctx->state[3] = SHA256_H3;
arch/s390/crypto/sha256_s390.c:	sctx->state[4] = SHA256_H4;
arch/s390/crypto/sha256_s390.c:	sctx->state[5] = SHA256_H5;
arch/s390/crypto/sha256_s390.c:	sctx->state[6] = SHA256_H6;
arch/s390/crypto/sha256_s390.c:	sctx->state[7] = SHA256_H7;
arch/s390/crypto/sha256_s390.c:	sctx->count = 0;
arch/s390/crypto/sha256_s390.c:	sctx->func = CPACF_KIMD_SHA_256;
arch/s390/crypto/sha256_s390.c:	octx->count = sctx->count;
arch/s390/crypto/sha256_s390.c:	memcpy(octx->state, sctx->state, sizeof(octx->state));
arch/s390/crypto/sha256_s390.c:	memcpy(octx->buf, sctx->buf, sizeof(octx->buf));
arch/s390/crypto/sha256_s390.c:	sctx->count = ictx->count;
arch/s390/crypto/sha256_s390.c:	memcpy(sctx->state, ictx->state, sizeof(ictx->state));
arch/s390/crypto/sha256_s390.c:	memcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));
arch/s390/crypto/sha256_s390.c:	sctx->func = CPACF_KIMD_SHA_256;
arch/s390/crypto/sha256_s390.c:	sctx->state[0] = SHA224_H0;
arch/s390/crypto/sha256_s390.c:	sctx->state[1] = SHA224_H1;
arch/s390/crypto/sha256_s390.c:	sctx->state[2] = SHA224_H2;
arch/s390/crypto/sha256_s390.c:	sctx->state[3] = SHA224_H3;
arch/s390/crypto/sha256_s390.c:	sctx->state[4] = SHA224_H4;
arch/s390/crypto/sha256_s390.c:	sctx->state[5] = SHA224_H5;
arch/s390/crypto/sha256_s390.c:	sctx->state[6] = SHA224_H6;
arch/s390/crypto/sha256_s390.c:	sctx->state[7] = SHA224_H7;
arch/s390/crypto/sha256_s390.c:	sctx->count = 0;
arch/s390/crypto/sha256_s390.c:	sctx->func = CPACF_KIMD_SHA_256;
arch/s390/crypto/sha_common.c:	index = ctx->count & (bsize - 1);
arch/s390/crypto/sha_common.c:	ctx->count += len;
arch/s390/crypto/sha_common.c:		memcpy(ctx->buf + index, data, bsize - index);
arch/s390/crypto/sha_common.c:		cpacf_kimd(ctx->func, ctx->state, ctx->buf, bsize);
arch/s390/crypto/sha_common.c:		cpacf_kimd(ctx->func, ctx->state, data, n);
arch/s390/crypto/sha_common.c:		memcpy(ctx->buf + index , data, len);
arch/s390/crypto/sha_common.c:	index = ctx->count & (bsize - 1);
arch/s390/crypto/sha_common.c:	ctx->buf[index] = 0x80;
arch/s390/crypto/sha_common.c:	memset(ctx->buf + index, 0x00, end - index - 8);
arch/s390/crypto/sha_common.c:	bits = ctx->count * 8;
arch/s390/crypto/sha_common.c:	memcpy(ctx->buf + end - 8, &bits, sizeof(bits));
arch/s390/crypto/sha_common.c:	cpacf_kimd(ctx->func, ctx->state, ctx->buf, end);
arch/s390/crypto/sha_common.c:	memcpy(out, ctx->state, crypto_shash_digestsize(desc->tfm));
arch/s390/crypto/sha1_s390.c:	sctx->state[0] = SHA1_H0;
arch/s390/crypto/sha1_s390.c:	sctx->state[1] = SHA1_H1;
arch/s390/crypto/sha1_s390.c:	sctx->state[2] = SHA1_H2;
arch/s390/crypto/sha1_s390.c:	sctx->state[3] = SHA1_H3;
arch/s390/crypto/sha1_s390.c:	sctx->state[4] = SHA1_H4;
arch/s390/crypto/sha1_s390.c:	sctx->count = 0;
arch/s390/crypto/sha1_s390.c:	sctx->func = CPACF_KIMD_SHA_1;
arch/s390/crypto/sha1_s390.c:	octx->count = sctx->count;
arch/s390/crypto/sha1_s390.c:	memcpy(octx->state, sctx->state, sizeof(octx->state));
arch/s390/crypto/sha1_s390.c:	memcpy(octx->buffer, sctx->buf, sizeof(octx->buffer));
arch/s390/crypto/sha1_s390.c:	sctx->count = ictx->count;
arch/s390/crypto/sha1_s390.c:	memcpy(sctx->state, ictx->state, sizeof(ictx->state));
arch/s390/crypto/sha1_s390.c:	memcpy(sctx->buf, ictx->buffer, sizeof(ictx->buffer));
arch/s390/crypto/sha1_s390.c:	sctx->func = CPACF_KIMD_SHA_1;
arch/metag/kernel/traps.c:			if (dsp_ctx->ram[i] == NULL) {
arch/metag/kernel/traps.c:				dsp_ctx->ram[i] = kmalloc(sz, GFP_KERNEL);
arch/metag/kernel/traps.c:				if (dsp_ctx->ram[i] == NULL)
arch/metag/kernel/traps.c:				if (ram_sz[i] > dsp_ctx->ram_sz[i]) {
arch/metag/kernel/traps.c:					kfree(dsp_ctx->ram[i]);
arch/metag/kernel/traps.c:					dsp_ctx->ram[i] = kmalloc(sz,
arch/metag/kernel/traps.c:					if (dsp_ctx->ram[i] == NULL)
arch/metag/kernel/traps.c:				__TBIDspramSaveA(ram_sz[i], dsp_ctx->ram[i]);
arch/metag/kernel/traps.c:				__TBIDspramSaveB(ram_sz[i], dsp_ctx->ram[i]);
arch/metag/kernel/traps.c:			dsp_ctx->ram_sz[i] = ram_sz[i];
arch/metag/kernel/traps.c:		__TBINestInts(State, &dsp_ctx->regs, mask);
arch/metag/kernel/traps.c:		if (dsp_ctx->ram_sz[0] > 0)
arch/metag/kernel/traps.c:			__TBIDspramRestoreA(dsp_ctx->ram_sz[0],
arch/metag/kernel/traps.c:					    dsp_ctx->ram[0]);
arch/metag/kernel/traps.c:		if (dsp_ctx->ram_sz[1] > 0)
arch/metag/kernel/traps.c:			__TBIDspramRestoreB(dsp_ctx->ram_sz[1],
arch/metag/kernel/traps.c:					    dsp_ctx->ram[1]);
arch/metag/kernel/traps.c:		D0_8 |= (dsp_ctx->ram_sz[1] | dsp_ctx->ram_sz[0]) & 0xffff;
arch/metag/kernel/process.c:			ctx->ram[i] = kmemdup(ctx->ram[i], ctx->ram_sz[i],
arch/metag/kernel/irq.c:		irqctx->tinfo.task = curctx->tinfo.task;
arch/metag/kernel/irq.c:		irqctx->tinfo.preempt_count =
arch/metag/kernel/irq.c:			(irqctx->tinfo.preempt_count & ~SOFTIRQ_MASK) |
arch/metag/kernel/irq.c:			(curctx->tinfo.preempt_count & SOFTIRQ_MASK);
arch/metag/kernel/irq.c:	irqctx->tinfo.task              = NULL;
arch/metag/kernel/irq.c:	irqctx->tinfo.cpu               = cpu;
arch/metag/kernel/irq.c:	irqctx->tinfo.preempt_count     = HARDIRQ_OFFSET;
arch/metag/kernel/irq.c:	irqctx->tinfo.addr_limit        = MAKE_MM_SEG(0);
arch/metag/kernel/irq.c:	irqctx->tinfo.task              = NULL;
arch/metag/kernel/irq.c:	irqctx->tinfo.cpu               = cpu;
arch/metag/kernel/irq.c:	irqctx->tinfo.preempt_count     = 0;
arch/metag/kernel/irq.c:	irqctx->tinfo.addr_limit        = MAKE_MM_SEG(0);
arch/metag/kernel/irq.c:	irqctx->tinfo.task = curctx->task;
arch/arm/net/bpf_jit_32.c:	if (ctx->target != NULL)
arch/arm/net/bpf_jit_32.c:		ctx->target[ctx->idx] = inst;
arch/arm/net/bpf_jit_32.c:	ctx->idx++;
arch/arm/net/bpf_jit_32.c:	if ((ctx->skf->len > 1) ||
arch/arm/net/bpf_jit_32.c:	    (ctx->skf->insns[0].code == (BPF_RET | BPF_A)))
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_CALL)
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & (SEEN_DATA | SEEN_SKB))
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_DATA)
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_X)
arch/arm/net/bpf_jit_32.c:	return fls(ctx->seen & SEEN_MEM);
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & (SEEN_DATA | SEEN_SKB))
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_DATA) {
arch/arm/net/bpf_jit_32.c:	if (ctx->flags & FLAG_NEED_X_RESET)
arch/arm/net/bpf_jit_32.c:	if (bpf_needs_clear_a(&ctx->skf->insns[0]))
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_MEM)
arch/arm/net/bpf_jit_32.c:	if (ctx->seen & SEEN_MEM)
arch/arm/net/bpf_jit_32.c:		if (ctx->seen & SEEN_CALL)
arch/arm/net/bpf_jit_32.c:	if (!(ctx->seen & SEEN_CALL))
arch/arm/net/bpf_jit_32.c:	if (ctx->target == NULL) {
arch/arm/net/bpf_jit_32.c:		ctx->imm_count++;
arch/arm/net/bpf_jit_32.c:	while ((i < ctx->imm_count) && ctx->imms[i]) {
arch/arm/net/bpf_jit_32.c:		if (ctx->imms[i] == k)
arch/arm/net/bpf_jit_32.c:	if (ctx->imms[i] == 0)
arch/arm/net/bpf_jit_32.c:		ctx->imms[i] = k;
arch/arm/net/bpf_jit_32.c:	offset =  ctx->offsets[ctx->skf->len];
arch/arm/net/bpf_jit_32.c:	offset += ctx->prologue_bytes;
arch/arm/net/bpf_jit_32.c:	offset += ctx->epilogue_bytes;
arch/arm/net/bpf_jit_32.c:	ctx->target[offset / 4] = k;
arch/arm/net/bpf_jit_32.c:	imm = offset - (8 + ctx->idx * 4);
arch/arm/net/bpf_jit_32.c:		ctx->flags |= FLAG_IMM_OVERFLOW;
arch/arm/net/bpf_jit_32.c:	if (ctx->target == NULL)
arch/arm/net/bpf_jit_32.c:	imm  = ctx->offsets[tgt] + ctx->prologue_bytes - (ctx->idx * 4 + 8);
arch/arm/net/bpf_jit_32.c:	if (ctx->ret0_fp_idx >= 0) {
arch/arm/net/bpf_jit_32.c:		_emit(cond, ARM_B(b_imm(ctx->ret0_fp_idx, ctx)), ctx);
arch/arm/net/bpf_jit_32.c:		_emit(cond, ARM_B(b_imm(ctx->skf->len, ctx)), ctx);
arch/arm/net/bpf_jit_32.c:	ctx->seen |= SEEN_CALL;
arch/arm/net/bpf_jit_32.c:	if (!(ctx->seen & SEEN_X))
arch/arm/net/bpf_jit_32.c:		ctx->flags |= FLAG_NEED_X_RESET;
arch/arm/net/bpf_jit_32.c:	ctx->seen |= SEEN_X;
arch/arm/net/bpf_jit_32.c:	const struct bpf_prog *prog = ctx->skf;
arch/arm/net/bpf_jit_32.c:		if (ctx->target == NULL)
arch/arm/net/bpf_jit_32.c:			ctx->offsets[i] = ctx->idx * 4;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_MEM_WORD(k);
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_DATA | SEEN_CALL;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_X;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_X | SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_X | SEEN_MEM_WORD(k);
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_X | SEEN_DATA | SEEN_CALL;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_MEM_WORD(k);
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_MEM_WORD(k);
arch/arm/net/bpf_jit_32.c:			if ((k == 0) && (ctx->ret0_fp_idx < 0))
arch/arm/net/bpf_jit_32.c:				ctx->ret0_fp_idx = i;
arch/arm/net/bpf_jit_32.c:			if (i != ctx->skf->len - 1)
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_X;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB | SEEN_CALL;
arch/arm/net/bpf_jit_32.c:			ctx->seen |= SEEN_SKB;
arch/arm/net/bpf_jit_32.c:		if (ctx->flags & FLAG_IMM_OVERFLOW)
arch/arm/net/bpf_jit_32.c:	if (ctx->target == NULL)
arch/arm/net/bpf_jit_32.c:		ctx->offsets[i] = ctx->idx * 4;
arch/arm/net/bpf_jit_32.c:	/* fake pass to fill in the ctx->seen */
arch/arm/crypto/aesbs-glue.c:	if (private_AES_set_encrypt_key(in_key, bits, &ctx->enc)) {
arch/arm/crypto/aesbs-glue.c:	ctx->dec.rk = ctx->enc;
arch/arm/crypto/aesbs-glue.c:	private_AES_set_decrypt_key(in_key, bits, &ctx->dec.rk);
arch/arm/crypto/aesbs-glue.c:	ctx->dec.converted = 0;
arch/arm/crypto/aesbs-glue.c:	if (private_AES_set_encrypt_key(in_key, bits, &ctx->enc.rk)) {
arch/arm/crypto/aesbs-glue.c:	ctx->enc.converted = 0;
arch/arm/crypto/aesbs-glue.c:	if (private_AES_set_encrypt_key(in_key, bits, &ctx->enc.rk)) {
arch/arm/crypto/aesbs-glue.c:	ctx->dec.rk = ctx->enc.rk;
arch/arm/crypto/aesbs-glue.c:	private_AES_set_decrypt_key(in_key, bits, &ctx->dec.rk);
arch/arm/crypto/aesbs-glue.c:	private_AES_set_encrypt_key(in_key + key_len / 2, bits, &ctx->twkey);
arch/arm/crypto/aesbs-glue.c:	ctx->enc.converted = ctx->dec.converted = 0;
arch/arm/crypto/aesbs-glue.c:				AES_encrypt(src, src, &ctx->enc);
arch/arm/crypto/aesbs-glue.c:				AES_encrypt(walk.iv, dst, &ctx->enc);
arch/arm/crypto/aesbs-glue.c:				  walk.nbytes, &ctx->dec, walk.iv);
arch/arm/crypto/aesbs-glue.c:			AES_decrypt(src, dst, &ctx->dec.rk);
arch/arm/crypto/aesbs-glue.c:					   &ctx->enc, walk.iv);
arch/arm/crypto/aesbs-glue.c:		AES_encrypt(walk.iv, ks, &ctx->enc.rk);
arch/arm/crypto/aesbs-glue.c:	AES_encrypt(walk.iv, walk.iv, &ctx->twkey);
arch/arm/crypto/aesbs-glue.c:				  walk.nbytes, &ctx->enc, walk.iv);
arch/arm/crypto/aesbs-glue.c:	AES_encrypt(walk.iv, walk.iv, &ctx->twkey);
arch/arm/crypto/aesbs-glue.c:				  walk.nbytes, &ctx->dec, walk.iv);
arch/arm/crypto/sha1_neon_glue.c:	    (sctx->count % SHA1_BLOCK_SIZE) + len < SHA1_BLOCK_SIZE)
arch/arm/crypto/sha256_neon_glue.c:	    (sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:	return 6 + ctx->key_length / 4;
arch/arm/crypto/aes-ce-glue.c:	memcpy(ctx->key_enc, in_key, key_len);
arch/arm/crypto/aes-ce-glue.c:	ctx->key_length = key_len;
arch/arm/crypto/aes-ce-glue.c:		u32 *rki = ctx->key_enc + (i * kwords);
arch/arm/crypto/aes-ce-glue.c:	key_enc = (struct aes_block *)ctx->key_enc;
arch/arm/crypto/aes-ce-glue.c:	key_dec = (struct aes_block *)ctx->key_dec;
arch/arm/crypto/aes-ce-glue.c:	ret = ce_aes_expandkey(&ctx->key1, in_key, key_len / 2);
arch/arm/crypto/aes-ce-glue.c:		ret = ce_aes_expandkey(&ctx->key2, &in_key[key_len / 2],
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key_enc, num_rounds(ctx), blocks);
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key_dec, num_rounds(ctx), blocks);
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key_enc, num_rounds(ctx), blocks,
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key_dec, num_rounds(ctx), blocks,
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key_enc, num_rounds(ctx), blocks,
arch/arm/crypto/aes-ce-glue.c:		ce_aes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc,
arch/arm/crypto/aes-ce-glue.c:	int err, first, rounds = num_rounds(&ctx->key1);
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key1.key_enc, rounds, blocks,
arch/arm/crypto/aes-ce-glue.c:				   walk.iv, (u8 *)ctx->key2.key_enc, first);
arch/arm/crypto/aes-ce-glue.c:	int err, first, rounds = num_rounds(&ctx->key1);
arch/arm/crypto/aes-ce-glue.c:				   (u8 *)ctx->key1.key_dec, rounds, blocks,
arch/arm/crypto/aes-ce-glue.c:				   walk.iv, (u8 *)ctx->key2.key_enc, first);
arch/arm/crypto/aes_glue.c:	AES_encrypt(src, dst, &ctx->enc_key);
arch/arm/crypto/aes_glue.c:	AES_decrypt(src, dst, &ctx->dec_key);
arch/arm/crypto/aes_glue.c:	if (private_AES_set_encrypt_key(in_key, key_len, &ctx->enc_key) == -1) {
arch/arm/crypto/aes_glue.c:	ctx->dec_key = ctx->enc_key;
arch/arm/crypto/aes_glue.c:	if (private_AES_set_decrypt_key(in_key, key_len, &ctx->dec_key) == -1) {
arch/arm/crypto/sha1-ce-glue.c:	    (sctx->count % SHA1_BLOCK_SIZE) + len < SHA1_BLOCK_SIZE)
arch/arm/crypto/sha2-ce-glue.c:	    (sctx->count % SHA256_BLOCK_SIZE) + len < SHA256_BLOCK_SIZE)
arch/arm/crypto/ghash-ce-glue.c:	unsigned int partial = ctx->count % GHASH_BLOCK_SIZE;
arch/arm/crypto/ghash-ce-glue.c:	ctx->count += len;
arch/arm/crypto/ghash-ce-glue.c:			memcpy(ctx->buf + partial, src, p);
arch/arm/crypto/ghash-ce-glue.c:		pmull_ghash_update(blocks, ctx->digest, src, key,
arch/arm/crypto/ghash-ce-glue.c:				   partial ? ctx->buf : NULL);
arch/arm/crypto/ghash-ce-glue.c:		memcpy(ctx->buf + partial, src, len);
arch/arm/crypto/ghash-ce-glue.c:	unsigned int partial = ctx->count % GHASH_BLOCK_SIZE;
arch/arm/crypto/ghash-ce-glue.c:		memset(ctx->buf + partial, 0, GHASH_BLOCK_SIZE - partial);
arch/arm/crypto/ghash-ce-glue.c:		pmull_ghash_update(1, ctx->digest, ctx->buf, key, NULL);
arch/arm/crypto/ghash-ce-glue.c:	put_unaligned_be64(ctx->digest[1], dst);
arch/arm/crypto/ghash-ce-glue.c:	put_unaligned_be64(ctx->digest[0], dst + 8);
arch/arm/crypto/ghash-ce-glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/arm/crypto/ghash-ce-glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/arm/crypto/ghash-ce-glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/arm/crypto/ghash-ce-glue.c:	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;
arch/arm/crypto/ghash-ce-glue.c:	desc->tfm = cryptd_ahash_child(ctx->cryptd_tfm);
arch/arm/crypto/ghash-ce-glue.c:	struct crypto_ahash *child = &ctx->cryptd_tfm->base;
arch/arm/crypto/ghash-ce-glue.c:	ctx->cryptd_tfm = cryptd_tfm;
arch/arm/crypto/ghash-ce-glue.c:	cryptd_free_ahash(ctx->cryptd_tfm);
arch/arm/crypto/sha512-neon-glue.c:	    (sctx->count[0] % SHA512_BLOCK_SIZE) + len < SHA512_BLOCK_SIZE)
arch/arm64/kernel/signal.c:	err = __copy_to_user(ctx->vregs, fpsimd->vregs, sizeof(fpsimd->vregs));
arch/arm64/kernel/signal.c:	__put_user_error(fpsimd->fpsr, &ctx->fpsr, err);
arch/arm64/kernel/signal.c:	__put_user_error(fpsimd->fpcr, &ctx->fpcr, err);
arch/arm64/kernel/signal.c:	__put_user_error(FPSIMD_MAGIC, &ctx->head.magic, err);
arch/arm64/kernel/signal.c:	__put_user_error(sizeof(struct fpsimd_context), &ctx->head.size, err);
arch/arm64/kernel/signal.c:	__get_user_error(magic, &ctx->head.magic, err);
arch/arm64/kernel/signal.c:	__get_user_error(size, &ctx->head.size, err);
arch/arm64/kernel/signal.c:	err = __copy_from_user(fpsimd.vregs, ctx->vregs,
arch/arm64/kernel/signal.c:	__get_user_error(fpsimd.fpsr, &ctx->fpsr, err);
arch/arm64/kernel/signal.c:	__get_user_error(fpsimd.fpcr, &ctx->fpcr, err);
arch/arm64/kernel/signal.c:		__put_user_error(ESR_MAGIC, &esr_ctx->head.magic, err);
arch/arm64/kernel/signal.c:		__put_user_error(sizeof(*esr_ctx), &esr_ctx->head.size, err);
arch/arm64/kernel/signal.c:		__put_user_error(current->thread.fault_code, &esr_ctx->esr, err);
arch/arm64/net/bpf_jit_comp.c:	if (ctx->image != NULL)
arch/arm64/net/bpf_jit_comp.c:		ctx->image[ctx->idx] = cpu_to_le32(insn);
arch/arm64/net/bpf_jit_comp.c:	ctx->idx++;
arch/arm64/net/bpf_jit_comp.c:	int to = ctx->offset[bpf_to];
arch/arm64/net/bpf_jit_comp.c:	int from = ctx->offset[bpf_from] - 1;
arch/arm64/net/bpf_jit_comp.c:	int to = ctx->epilogue_offset;
arch/arm64/net/bpf_jit_comp.c:	int from = ctx->idx;
arch/arm64/net/bpf_jit_comp.c:	const int idx0 = ctx->idx;
arch/arm64/net/bpf_jit_comp.c:	cur_offset = ctx->idx - idx0;
arch/arm64/net/bpf_jit_comp.c:	const int idx0 = ctx->idx;
arch/arm64/net/bpf_jit_comp.c:#define cur_offset (ctx->idx - idx0)
arch/arm64/net/bpf_jit_comp.c:	const int i = insn - ctx->prog->insnsi;
arch/arm64/net/bpf_jit_comp.c:		if (i == ctx->prog->len - 1)
arch/arm64/net/bpf_jit_comp.c:	const struct bpf_prog *prog = ctx->prog;
arch/arm64/net/bpf_jit_comp.c:			if (ctx->image == NULL)
arch/arm64/net/bpf_jit_comp.c:				ctx->offset[i] = ctx->idx;
arch/arm64/net/bpf_jit_comp.c:		if (ctx->image == NULL)
arch/arm64/net/bpf_jit_comp.c:			ctx->offset[i] = ctx->idx;
arch/arm64/net/bpf_jit_comp.c:	for (i = 0; i < ctx->idx; i++) {
arch/arm64/net/bpf_jit_comp.c:		u32 a64_insn = le32_to_cpu(ctx->image[i]);
arch/arm64/net/bpf_jit_comp.c:	/* 1. Initial fake pass to compute ctx->idx. */
arch/arm64/net/bpf_jit_comp.c:	/* Fake pass to fill in ctx->offset. */
arch/arm64/crypto/aes-ce-cipher.c:	return 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-ce-cipher.c:				"1"(ctx->key_enc),
arch/arm64/crypto/aes-ce-cipher.c:				"1"(ctx->key_dec),
arch/arm64/crypto/aes-ce-cipher.c:	memcpy(ctx->key_enc, in_key, key_len);
arch/arm64/crypto/aes-ce-cipher.c:	ctx->key_length = key_len;
arch/arm64/crypto/aes-ce-cipher.c:		u32 *rki = ctx->key_enc + (i * kwords);
arch/arm64/crypto/aes-ce-cipher.c:	key_enc = (struct aes_block *)ctx->key_enc;
arch/arm64/crypto/aes-ce-cipher.c:	key_dec = (struct aes_block *)ctx->key_dec;
arch/arm64/crypto/crc32-arm64.c:	ctx->crc = mctx->key;
arch/arm64/crypto/crc32-arm64.c:	if (keylen != sizeof(mctx->key)) {
arch/arm64/crypto/crc32-arm64.c:	mctx->key = get_unaligned_le32(key);
arch/arm64/crypto/crc32-arm64.c:	ctx->crc = crc32_arm64_le_hw(ctx->crc, data, length);
arch/arm64/crypto/crc32-arm64.c:	ctx->crc = crc32c_arm64_le_hw(ctx->crc, data, length);
arch/arm64/crypto/crc32-arm64.c:	put_unaligned_le32(ctx->crc, out);
arch/arm64/crypto/crc32-arm64.c:	put_unaligned_le32(~ctx->crc, out);
arch/arm64/crypto/crc32-arm64.c:	return __chksum_finup(ctx->crc, data, len, out);
arch/arm64/crypto/crc32-arm64.c:	return __chksumc_finup(ctx->crc, data, len, out);
arch/arm64/crypto/crc32-arm64.c:	return __chksum_finup(mctx->key, data, length, out);
arch/arm64/crypto/crc32-arm64.c:	return __chksumc_finup(mctx->key, data, length, out);
arch/arm64/crypto/crc32-arm64.c:	mctx->key = 0;
arch/arm64/crypto/crc32-arm64.c:	mctx->key = ~0;
arch/arm64/crypto/aes-glue.c:	ret = aes_expandkey(&ctx->key1, in_key, key_len / 2);
arch/arm64/crypto/aes-glue.c:		ret = aes_expandkey(&ctx->key2, &in_key[key_len / 2],
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key_enc, rounds, blocks, first);
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key_dec, rounds, blocks, first);
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key_enc, rounds, blocks, walk.iv,
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key_dec, rounds, blocks, walk.iv,
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key_enc, rounds, blocks, walk.iv,
arch/arm64/crypto/aes-glue.c:		aes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc, rounds,
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key1.key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key1.key_enc, rounds, blocks,
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key2.key_enc, walk.iv, first);
arch/arm64/crypto/aes-glue.c:	int err, first, rounds = 6 + ctx->key1.key_length / 4;
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key1.key_dec, rounds, blocks,
arch/arm64/crypto/aes-glue.c:				(u8 *)ctx->key2.key_enc, walk.iv, first);
arch/arm64/crypto/sha1-ce-glue.c:	sctx->finalize = 0;
arch/arm64/crypto/sha1-ce-glue.c:	bool finalize = !sctx->sst.count && !(len % SHA1_BLOCK_SIZE);
arch/arm64/crypto/sha1-ce-glue.c:	sctx->finalize = finalize;
arch/arm64/crypto/sha1-ce-glue.c:	sctx->finalize = 0;
arch/arm64/crypto/sha2-ce-glue.c:	sctx->finalize = 0;
arch/arm64/crypto/sha2-ce-glue.c:	bool finalize = !sctx->sst.count && !(len % SHA256_BLOCK_SIZE);
arch/arm64/crypto/sha2-ce-glue.c:	sctx->finalize = finalize;
arch/arm64/crypto/sha2-ce-glue.c:	sctx->finalize = 0;
arch/arm64/crypto/aes-ce-ccm-glue.c:	return 6 + ctx->key_length / 4;
arch/arm64/crypto/aes-ce-ccm-glue.c:	ce_aes_ccm_auth_data(mac, (u8 *)&ltag, ltag.len, &macp, ctx->key_enc,
arch/arm64/crypto/aes-ce-ccm-glue.c:		ce_aes_ccm_auth_data(mac, p, n, &macp, ctx->key_enc,
arch/arm64/crypto/aes-ce-ccm-glue.c:				   walk.nbytes - tail, ctx->key_enc,
arch/arm64/crypto/aes-ce-ccm-glue.c:		ce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));
arch/arm64/crypto/aes-ce-ccm-glue.c:				   walk.nbytes - tail, ctx->key_enc,
arch/arm64/crypto/aes-ce-ccm-glue.c:		ce_aes_ccm_final(mac, buf, ctx->key_enc, num_rounds(ctx));
arch/arm64/crypto/ghash-ce-glue.c:	unsigned int partial = ctx->count % GHASH_BLOCK_SIZE;
arch/arm64/crypto/ghash-ce-glue.c:	ctx->count += len;
arch/arm64/crypto/ghash-ce-glue.c:			memcpy(ctx->buf + partial, src, p);
arch/arm64/crypto/ghash-ce-glue.c:		pmull_ghash_update(blocks, ctx->digest, src, key,
arch/arm64/crypto/ghash-ce-glue.c:				   partial ? ctx->buf : NULL);
arch/arm64/crypto/ghash-ce-glue.c:		memcpy(ctx->buf + partial, src, len);
arch/arm64/crypto/ghash-ce-glue.c:	unsigned int partial = ctx->count % GHASH_BLOCK_SIZE;
arch/arm64/crypto/ghash-ce-glue.c:		memset(ctx->buf + partial, 0, GHASH_BLOCK_SIZE - partial);
arch/arm64/crypto/ghash-ce-glue.c:		pmull_ghash_update(1, ctx->digest, ctx->buf, key, NULL);
arch/arm64/crypto/ghash-ce-glue.c:	put_unaligned_be64(ctx->digest[1], dst);
arch/arm64/crypto/ghash-ce-glue.c:	put_unaligned_be64(ctx->digest[0], dst + 8);
arch/microblaze/kernel/process.c:	if (in_sched_functions(ctx->r15))
arch/microblaze/kernel/process.c:		return (unsigned long)ctx->r15;
arch/microblaze/kernel/process.c:		return ctx->r14;
arch/powerpc/platforms/cell/spu_manage.c:	ctx->ops->master_start(ctx);
arch/powerpc/platforms/cell/spu_manage.c:	ctx->ops->master_stop(ctx);
arch/powerpc/platforms/cell/spufs/fault.c:	if (ctx->flags & SPU_CREATE_EVENTS_ENABLED) {
arch/powerpc/platforms/cell/spufs/fault.c:		ctx->event_return |= type;
arch/powerpc/platforms/cell/spufs/fault.c:		wake_up_all(&ctx->stop_wq);
arch/powerpc/platforms/cell/spufs/fault.c:		ctx->ops->restart_dma(ctx);
arch/powerpc/platforms/cell/spufs/fault.c:			ctx->ops->npc_read(ctx) - 4;
arch/powerpc/platforms/cell/spufs/fault.c:	unsigned long stat = ctx->csa.class_0_pending & CLASS0_INTR_MASK;
arch/powerpc/platforms/cell/spufs/fault.c:		spufs_handle_event(ctx, ctx->csa.class_0_dar,
arch/powerpc/platforms/cell/spufs/fault.c:		spufs_handle_event(ctx, ctx->csa.class_0_dar,
arch/powerpc/platforms/cell/spufs/fault.c:		spufs_handle_event(ctx, ctx->csa.class_0_dar,
arch/powerpc/platforms/cell/spufs/fault.c:	ctx->csa.class_0_pending = 0;
arch/powerpc/platforms/cell/spufs/fault.c:	ea = ctx->csa.class_1_dar;
arch/powerpc/platforms/cell/spufs/fault.c:	dsisr = ctx->csa.class_1_dsisr;
arch/powerpc/platforms/cell/spufs/fault.c:		dsisr, ctx->state);
arch/powerpc/platforms/cell/spufs/fault.c:	ctx->stats.hash_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:	if (ctx->state == SPU_STATE_RUNNABLE)
arch/powerpc/platforms/cell/spufs/fault.c:		ctx->spu->stats.hash_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/fault.c:	ctx->csa.class_1_dar = ctx->csa.class_1_dsisr = 0;
arch/powerpc/platforms/cell/spufs/fault.c:			ctx->stats.maj_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:			ctx->stats.min_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:		if (ctx->state == SPU_STATE_RUNNABLE) {
arch/powerpc/platforms/cell/spufs/fault.c:				ctx->spu->stats.maj_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:				ctx->spu->stats.min_flt++;
arch/powerpc/platforms/cell/spufs/fault.c:		if (ctx->spu)
arch/powerpc/platforms/cell/spufs/fault.c:			ctx->ops->restart_dma(ctx);
arch/powerpc/platforms/cell/spufs/run.c:			ctx->csa.class_0_pending = spu->class_0_pending;
arch/powerpc/platforms/cell/spufs/run.c:			ctx->csa.class_0_dar = spu->class_0_dar;
arch/powerpc/platforms/cell/spufs/run.c:			ctx->csa.class_1_dsisr = spu->class_1_dsisr;
arch/powerpc/platforms/cell/spufs/run.c:			ctx->csa.class_1_dar = spu->class_1_dar;
arch/powerpc/platforms/cell/spufs/run.c:		wake_up_all(&ctx->stop_wq);
arch/powerpc/platforms/cell/spufs/run.c:	*stat = ctx->ops->status_read(ctx);
arch/powerpc/platforms/cell/spufs/run.c:	if (test_bit(SPU_SCHED_NOTIFY_ACTIVE, &ctx->sched_flags))
arch/powerpc/platforms/cell/spufs/run.c:	dsisr = ctx->csa.class_1_dsisr;
arch/powerpc/platforms/cell/spufs/run.c:	if (ctx->csa.class_0_pending)
arch/powerpc/platforms/cell/spufs/run.c:	mfc_cntl = &ctx->spu->priv2->mfc_control_RW;
arch/powerpc/platforms/cell/spufs/run.c:	sr1 = spu_mfc_sr1_get(ctx->spu);
arch/powerpc/platforms/cell/spufs/run.c:	spu_mfc_sr1_set(ctx->spu, sr1);
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->signal1_write(ctx, (unsigned long)isolated_loader >> 32);
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->signal2_write(ctx,
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->runcntl_write(ctx,
arch/powerpc/platforms/cell/spufs/run.c:	while (((status = ctx->ops->status_read(ctx)) & status_loading) ==
arch/powerpc/platforms/cell/spufs/run.c:		ctx->ops->runcntl_write(ctx, SPU_RUNCNTL_RUNNABLE);
arch/powerpc/platforms/cell/spufs/run.c:		ctx->ops->runcntl_write(ctx, SPU_RUNCNTL_STOP);
arch/powerpc/platforms/cell/spufs/run.c:	spu_mfc_sr1_set(ctx->spu, sr1);
arch/powerpc/platforms/cell/spufs/run.c:	if (ctx->flags & SPU_CREATE_NOSCHED) {
arch/powerpc/platforms/cell/spufs/run.c:		if (ctx->state == SPU_STATE_SAVED) {
arch/powerpc/platforms/cell/spufs/run.c:	if (ctx->flags & SPU_CREATE_ISOLATE) {
arch/powerpc/platforms/cell/spufs/run.c:		if (!(ctx->ops->status_read(ctx) & SPU_STATUS_ISOLATED_STATE)) {
arch/powerpc/platforms/cell/spufs/run.c:		runcntl = ctx->ops->runcntl_read(ctx) &
arch/powerpc/platforms/cell/spufs/run.c:		ctx->ops->privcntl_write(ctx, privcntl);
arch/powerpc/platforms/cell/spufs/run.c:		ctx->ops->npc_write(ctx, *npc);
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->runcntl_write(ctx, runcntl);
arch/powerpc/platforms/cell/spufs/run.c:	if (ctx->flags & SPU_CREATE_NOSCHED) {
arch/powerpc/platforms/cell/spufs/run.c:		if (ctx->state == SPU_STATE_SAVED) {
arch/powerpc/platforms/cell/spufs/run.c:	set_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags);
arch/powerpc/platforms/cell/spufs/run.c:	*status = ctx->ops->status_read(ctx);
arch/powerpc/platforms/cell/spufs/run.c:	*npc = ctx->ops->npc_read(ctx);
arch/powerpc/platforms/cell/spufs/run.c:	clear_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags);
arch/powerpc/platforms/cell/spufs/run.c:	npc = ctx->ops->npc_read(ctx) & ~3;
arch/powerpc/platforms/cell/spufs/run.c:	ls = (void __iomem *)ctx->ops->get_ls(ctx);
arch/powerpc/platforms/cell/spufs/run.c:		mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/run.c:	ls = (void __iomem *)ctx->ops->get_ls(ctx);
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->npc_write(ctx, npc);
arch/powerpc/platforms/cell/spufs/run.c:	ctx->ops->runcntl_write(ctx, SPU_RUNCNTL_RUNNABLE);
arch/powerpc/platforms/cell/spufs/run.c:	if (mutex_lock_interruptible(&ctx->run_mutex))
arch/powerpc/platforms/cell/spufs/run.c:	ctx->event_return = 0;
arch/powerpc/platforms/cell/spufs/run.c:		ret = spufs_wait(ctx->stop_wq, spu_stopped(ctx, &status));
arch/powerpc/platforms/cell/spufs/run.c:			mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/run.c:		spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/run.c:						&ctx->sched_flags))) {
arch/powerpc/platforms/cell/spufs/run.c:		ctx->stats.libassist++;
arch/powerpc/platforms/cell/spufs/run.c:	*event = ctx->event_return;
arch/powerpc/platforms/cell/spufs/run.c:	mutex_unlock(&ctx->run_mutex);
arch/powerpc/platforms/cell/spufs/spufs.h:/* ctx->sched_flags */
arch/powerpc/platforms/cell/spufs/spufs.h:		/* updates protected by ctx->state_mutex */
arch/powerpc/platforms/cell/spufs/spufs.h:	return mutex_lock_interruptible(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/spufs.h:	mutex_unlock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->local_store = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->local_store = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	char *local_store = ctx->ops->get_ls(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	local_store = ctx->ops->get_ls(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->state == SPU_STATE_SAVED) {
arch/powerpc/platforms/cell/spufs/file.c:		pfn = vmalloc_to_pfn(ctx->csa.lscsa->ls + offset);
arch/powerpc/platforms/cell/spufs/file.c:		pfn = (ctx->spu->local_store_phys + offset) >> PAGE_SHIFT;
arch/powerpc/platforms/cell/spufs/file.c:	local_store = ctx->ops->get_ls(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->state == SPU_STATE_SAVED) {
arch/powerpc/platforms/cell/spufs/file.c:		ret = spufs_wait(ctx->run_wq, ctx->state == SPU_STATE_RUNNABLE);
arch/powerpc/platforms/cell/spufs/file.c:		spu_context_trace(spufs_ps_fault__wake, ctx, ctx->spu);
arch/powerpc/platforms/cell/spufs/file.c:		area = ctx->spu->problem_phys + ps_offs;
arch/powerpc/platforms/cell/spufs/file.c:		spu_context_trace(spufs_ps_fault__insert, ctx, ctx->spu);
arch/powerpc/platforms/cell/spufs/file.c:	*val = ctx->ops->status_read(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->runcntl_write(ctx, val);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->cntl = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->cntl = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	if (*pos >= sizeof(ctx->csa.lscsa->gprs))
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:		ret = ctx->ops->mbox_read(ctx, &mbox_data);
arch/powerpc/platforms/cell/spufs/file.c:	mbox_stat = ctx->ops->mbox_stat_read(ctx) & 0xff;
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->ops->ibox_read(ctx, data);
arch/powerpc/platforms/cell/spufs/file.c:	return fasync_helper(fd, file, on, &ctx->ibox_fasync);
arch/powerpc/platforms/cell/spufs/file.c:	wake_up_all(&ctx->ibox_wq);
arch/powerpc/platforms/cell/spufs/file.c:	kill_fasync(&ctx->ibox_fasync, SIGIO, POLLIN);
arch/powerpc/platforms/cell/spufs/file.c:		count = spufs_wait(ctx->ibox_wq, spu_ibox_read(ctx, &ibox_data));
arch/powerpc/platforms/cell/spufs/file.c:		ret = ctx->ops->ibox_read(ctx, &ibox_data);
arch/powerpc/platforms/cell/spufs/file.c:	poll_wait(file, &ctx->ibox_wq, wait);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/file.c:	mask = ctx->ops->mbox_stat_poll(ctx, POLLIN | POLLRDNORM);
arch/powerpc/platforms/cell/spufs/file.c:	ibox_stat = (ctx->ops->mbox_stat_read(ctx) >> 16) & 0xff;
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->ops->wbox_write(ctx, data);
arch/powerpc/platforms/cell/spufs/file.c:	ret = fasync_helper(fd, file, on, &ctx->wbox_fasync);
arch/powerpc/platforms/cell/spufs/file.c:	wake_up_all(&ctx->wbox_wq);
arch/powerpc/platforms/cell/spufs/file.c:	kill_fasync(&ctx->wbox_fasync, SIGIO, POLLOUT);
arch/powerpc/platforms/cell/spufs/file.c:		count = spufs_wait(ctx->wbox_wq, spu_wbox_write(ctx, wbox_data));
arch/powerpc/platforms/cell/spufs/file.c:	poll_wait(file, &ctx->wbox_wq, wait);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/file.c:	mask = ctx->ops->mbox_stat_poll(ctx, POLLOUT | POLLWRNORM);
arch/powerpc/platforms/cell/spufs/file.c:	wbox_stat = (ctx->ops->mbox_stat_read(ctx) >> 8) & 0xff;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->signal1 = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->signal1 = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->csa.spu_chnlcnt_RW[3]) {
arch/powerpc/platforms/cell/spufs/file.c:		data = ctx->csa.spu_chnldata_RW[3];
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->signal1_write(ctx, data);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->signal2 = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->signal2 = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->csa.spu_chnlcnt_RW[4]) {
arch/powerpc/platforms/cell/spufs/file.c:		data =  ctx->csa.spu_chnldata_RW[4];
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->signal2_write(ctx, data);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->signal1_type_set(ctx, val);
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->ops->signal1_type_get(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->signal2_type_set(ctx, val);
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->ops->signal2_type_get(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->mss = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->mss = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->psmap = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->psmap = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->owner != current->mm)
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->mfc = inode->i_mapping;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->mfc = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/file.c:	wake_up_all(&ctx->mfc_wq);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->mfc_fasync) {
arch/powerpc/platforms/cell/spufs/file.c:		free_elements = ctx->ops->get_mfc_free_elements(ctx);
arch/powerpc/platforms/cell/spufs/file.c:		tagstatus = ctx->ops->read_mfc_tagstatus(ctx);
arch/powerpc/platforms/cell/spufs/file.c:		if (tagstatus & ctx->tagwait)
arch/powerpc/platforms/cell/spufs/file.c:		kill_fasync(&ctx->mfc_fasync, SIGIO, mask);
arch/powerpc/platforms/cell/spufs/file.c:	*status = ctx->ops->read_mfc_tagstatus(ctx) & ctx->tagwait;
arch/powerpc/platforms/cell/spufs/file.c:	ctx->tagwait &= ~*status;
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->set_mfc_query(ctx, ctx->tagwait, 1);
arch/powerpc/platforms/cell/spufs/file.c:		status = ctx->ops->read_mfc_tagstatus(ctx);
arch/powerpc/platforms/cell/spufs/file.c:		if (!(status & ctx->tagwait))
arch/powerpc/platforms/cell/spufs/file.c:			ctx->tagwait &= ~status;
arch/powerpc/platforms/cell/spufs/file.c:		ret = spufs_wait(ctx->mfc_wq,
arch/powerpc/platforms/cell/spufs/file.c:	*error = ctx->ops->send_mfc_command(ctx, &cmd);
arch/powerpc/platforms/cell/spufs/file.c:		ctx->ops->set_mfc_query(ctx, ctx->tagwait, 1);
arch/powerpc/platforms/cell/spufs/file.c:		*error = ctx->ops->send_mfc_command(ctx, &cmd);
arch/powerpc/platforms/cell/spufs/file.c:	ret = spufs_wait(ctx->run_wq, ctx->state == SPU_STATE_RUNNABLE);
arch/powerpc/platforms/cell/spufs/file.c:		ret = ctx->ops->send_mfc_command(ctx, &cmd);
arch/powerpc/platforms/cell/spufs/file.c:		ret = spufs_wait(ctx->mfc_wq,
arch/powerpc/platforms/cell/spufs/file.c:	ctx->tagwait |= 1 << cmd.tag;
arch/powerpc/platforms/cell/spufs/file.c:	poll_wait(file, &ctx->mfc_wq, wait);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->set_mfc_query(ctx, ctx->tagwait, 2);
arch/powerpc/platforms/cell/spufs/file.c:	free_elements = ctx->ops->get_mfc_free_elements(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	tagstatus = ctx->ops->read_mfc_tagstatus(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	if (tagstatus & ctx->tagwait)
arch/powerpc/platforms/cell/spufs/file.c:		free_elements, tagstatus, ctx->tagwait);
arch/powerpc/platforms/cell/spufs/file.c:	ret = spufs_wait(ctx->mfc_wq,
arch/powerpc/platforms/cell/spufs/file.c:			 ctx->ops->set_mfc_query(ctx, ctx->tagwait, 2));
arch/powerpc/platforms/cell/spufs/file.c:	ret = spufs_wait(ctx->mfc_wq,
arch/powerpc/platforms/cell/spufs/file.c:			 ctx->ops->read_mfc_tagstatus(ctx) == ctx->tagwait);
arch/powerpc/platforms/cell/spufs/file.c:	return fasync_helper(fd, file, on, &ctx->mfc_fasync);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->ops->npc_write(ctx, val);
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->ops->npc_read(ctx);
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:		ctx->csa.priv2.mfc_control_RW |= MFC_CNTL_DECREMENTER_RUNNING;
arch/powerpc/platforms/cell/spufs/file.c:		ctx->csa.priv2.mfc_control_RW &= ~MFC_CNTL_DECREMENTER_RUNNING;
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->csa.priv2.mfc_control_RW & MFC_CNTL_DECREMENTER_RUNNING)
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_state *state = &ctx->csa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	struct spu_lscsa *lscsa = ctx->csa.lscsa;
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->state == SPU_STATE_RUNNABLE)
arch/powerpc/platforms/cell/spufs/file.c:		num = ctx->spu->number;
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->object_id;
arch/powerpc/platforms/cell/spufs/file.c:	ctx->object_id = id;
arch/powerpc/platforms/cell/spufs/file.c:	return ctx->csa.priv2.spu_lslr_RW;
arch/powerpc/platforms/cell/spufs/file.c:	if (!(ctx->flags & SPU_CREATE_NOSCHED))
arch/powerpc/platforms/cell/spufs/file.c:	if (!(ctx->flags & SPU_CREATE_ISOLATE))
arch/powerpc/platforms/cell/spufs/file.c:	if (!(ctx->csa.prob.mb_stat_R & 0x0000ff))
arch/powerpc/platforms/cell/spufs/file.c:	data = ctx->csa.prob.pu_mb_R;
arch/powerpc/platforms/cell/spufs/file.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	if (!(ctx->csa.prob.mb_stat_R & 0xff0000))
arch/powerpc/platforms/cell/spufs/file.c:	data = ctx->csa.priv2.puint_mb_R;
arch/powerpc/platforms/cell/spufs/file.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	wbox_stat = ctx->csa.prob.mb_stat_R;
arch/powerpc/platforms/cell/spufs/file.c:		data[i] = ctx->csa.spu_mailbox_data[i];
arch/powerpc/platforms/cell/spufs/file.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	info.dma_info_type = ctx->csa.priv2.spu_tag_status_query_RW;
arch/powerpc/platforms/cell/spufs/file.c:	info.dma_info_mask = ctx->csa.lscsa->tag_mask.slot[0];
arch/powerpc/platforms/cell/spufs/file.c:	info.dma_info_status = ctx->csa.spu_chnldata_RW[24];
arch/powerpc/platforms/cell/spufs/file.c:	info.dma_info_stall_and_notify = ctx->csa.spu_chnldata_RW[25];
arch/powerpc/platforms/cell/spufs/file.c:	info.dma_info_atomic_command_status = ctx->csa.spu_chnldata_RW[27];
arch/powerpc/platforms/cell/spufs/file.c:		spuqp = &ctx->csa.priv2.spuq[i];
arch/powerpc/platforms/cell/spufs/file.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	info.proxydma_info_type = ctx->csa.prob.dma_querytype_RW;
arch/powerpc/platforms/cell/spufs/file.c:	info.proxydma_info_mask = ctx->csa.prob.dma_querymask_RW;
arch/powerpc/platforms/cell/spufs/file.c:	info.proxydma_info_status = ctx->csa.prob.dma_tagstatus_R;
arch/powerpc/platforms/cell/spufs/file.c:		puqp = &ctx->csa.priv2.puq[i];
arch/powerpc/platforms/cell/spufs/file.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/file.c:	seq_printf(s, "%d\n", ctx->tid);
arch/powerpc/platforms/cell/spufs/file.c:	unsigned long long time = ctx->stats.times[state];
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->spu && ctx->stats.util_state == state) {
arch/powerpc/platforms/cell/spufs/file.c:		time += ktime_get_ns() - ctx->stats.tstamp;
arch/powerpc/platforms/cell/spufs/file.c:	unsigned long long slb_flts = ctx->stats.slb_flt;
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->state == SPU_STATE_RUNNABLE) {
arch/powerpc/platforms/cell/spufs/file.c:		slb_flts += (ctx->spu->stats.slb_flt -
arch/powerpc/platforms/cell/spufs/file.c:			     ctx->stats.slb_flt_base);
arch/powerpc/platforms/cell/spufs/file.c:	unsigned long long class2_intrs = ctx->stats.class2_intr;
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->state == SPU_STATE_RUNNABLE) {
arch/powerpc/platforms/cell/spufs/file.c:		class2_intrs += (ctx->spu->stats.class2_intr -
arch/powerpc/platforms/cell/spufs/file.c:				 ctx->stats.class2_intr_base);
arch/powerpc/platforms/cell/spufs/file.c:		ctx_state_names[ctx->stats.util_state],
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.vol_ctx_switch,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.invol_ctx_switch,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.hash_flt,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.min_flt,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.maj_flt,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->stats.libassist);
arch/powerpc/platforms/cell/spufs/file.c:	return (ctx->switch_log->head - ctx->switch_log->tail) %
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->switch_log) {
arch/powerpc/platforms/cell/spufs/file.c:	ctx->switch_log = kmalloc(sizeof(struct switch_log) +
arch/powerpc/platforms/cell/spufs/file.c:	if (!ctx->switch_log) {
arch/powerpc/platforms/cell/spufs/file.c:	ctx->switch_log->head = ctx->switch_log->tail = 0;
arch/powerpc/platforms/cell/spufs/file.c:	init_waitqueue_head(&ctx->switch_log->wait);
arch/powerpc/platforms/cell/spufs/file.c:	kfree(ctx->switch_log);
arch/powerpc/platforms/cell/spufs/file.c:	ctx->switch_log = NULL;
arch/powerpc/platforms/cell/spufs/file.c:	p = ctx->switch_log->log + ctx->switch_log->tail % SWITCH_LOG_BUFSIZE;
arch/powerpc/platforms/cell/spufs/file.c:				 * ctx->switch_log is stable).
arch/powerpc/platforms/cell/spufs/file.c:				error = spufs_wait(ctx->switch_log->wait,
arch/powerpc/platforms/cell/spufs/file.c:			ctx->switch_log->tail =
arch/powerpc/platforms/cell/spufs/file.c:				(ctx->switch_log->tail + 1) %
arch/powerpc/platforms/cell/spufs/file.c:	poll_wait(file, &ctx->switch_log->wait, wait);
arch/powerpc/platforms/cell/spufs/file.c: * Must be called with ctx->state_mutex held.
arch/powerpc/platforms/cell/spufs/file.c:	if (!ctx->switch_log)
arch/powerpc/platforms/cell/spufs/file.c:		p = ctx->switch_log->log + ctx->switch_log->head;
arch/powerpc/platforms/cell/spufs/file.c:		ctx->switch_log->head =
arch/powerpc/platforms/cell/spufs/file.c:			(ctx->switch_log->head + 1) % SWITCH_LOG_BUFSIZE;
arch/powerpc/platforms/cell/spufs/file.c:	wake_up(&ctx->switch_log->wait);
arch/powerpc/platforms/cell/spufs/file.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/file.c:	if (ctx->spu) {
arch/powerpc/platforms/cell/spufs/file.c:		struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/file.c:		struct spu_state *csa = &ctx->csa;
arch/powerpc/platforms/cell/spufs/file.c:		ctx->state == SPU_STATE_SAVED ? 'S' : 'R',
arch/powerpc/platforms/cell/spufs/file.c:		ctx->flags,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->sched_flags,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->prio,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->time_slice,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->spu ? ctx->spu->number : -1,
arch/powerpc/platforms/cell/spufs/file.c:		!list_empty(&ctx->rq) ? 'q' : ' ',
arch/powerpc/platforms/cell/spufs/file.c:		ctx->csa.class_0_pending,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->csa.class_0_dar,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->csa.class_1_dsisr,
arch/powerpc/platforms/cell/spufs/file.c:		ctx->ops->runcntl_read(ctx),
arch/powerpc/platforms/cell/spufs/file.c:		ctx->ops->status_read(ctx));
arch/powerpc/platforms/cell/spufs/file.c:	mutex_unlock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->mb_stat_R);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be32(&ctx->spu->problem->signal_notify1, data);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be32(&ctx->spu->problem->signal_notify2, data);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return ((in_be64(&ctx->spu->priv2->spu_cfg_RW) & 1) != 0);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return ((in_be64(&ctx->spu->priv2->spu_cfg_RW) & 2) != 0);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->spu_npc_RW);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be32(&ctx->spu->problem->spu_npc_RW, val);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->spu_status_R);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return ctx->spu->local_store;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be64(&ctx->spu->priv2->spu_privcntl_RW, val);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->spu_runcntl_RW);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_lock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be32(&ctx->spu->problem->spu_runcntl_RW, val);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_unlock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_lock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	out_be32(&ctx->spu->problem->spu_runcntl_RW, SPU_RUNCNTL_STOP);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	while (in_be32(&ctx->spu->problem->spu_status_R) & SPU_STATUS_RUNNING)
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_unlock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu_problem __iomem *prob = ctx->spu->problem;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_lock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_unlock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->dma_tagstatus_R);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	return in_be32(&ctx->spu->problem->dma_qstatus_R);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu_problem __iomem *prob = ctx->spu->problem;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_lock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	spin_unlock_irq(&ctx->spu->register_lock);
arch/powerpc/platforms/cell/spufs/hw_ops.c:	struct spu_priv2 __iomem *priv2 = ctx->spu->priv2;
arch/powerpc/platforms/cell/spufs/hw_ops.c:	if (!test_bit(SPU_CONTEXT_SWITCH_PENDING, &ctx->spu->flags))
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ch0_cnt = ctx->csa.spu_chnlcnt_RW[0];
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ch0_data = ctx->csa.spu_chnldata_RW[0];
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ch1_data = ctx->csa.spu_chnldata_RW[1];
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.spu_chnldata_RW[0] |= event;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnlcnt_RW[0] = 1;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	mbox_stat = ctx->csa.prob.mb_stat_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		*data = ctx->csa.prob.pu_mb_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.mb_stat_R &= ~(0x0000ff);
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnlcnt_RW[28] = 1;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.mb_stat_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock_irq(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	stat = ctx->csa.prob.mb_stat_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:			ctx->csa.priv1.int_stat_class2_RW &=
arch/powerpc/platforms/cell/spufs/backing_ops.c:			ctx->csa.priv1.int_mask_class2_RW |=
arch/powerpc/platforms/cell/spufs/backing_ops.c:			ctx->csa.priv1.int_stat_class2_RW &=
arch/powerpc/platforms/cell/spufs/backing_ops.c:			ctx->csa.priv1.int_mask_class2_RW |=
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock_irq(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	if (ctx->csa.prob.mb_stat_R & 0xff0000) {
arch/powerpc/platforms/cell/spufs/backing_ops.c:		*data = ctx->csa.priv2.puint_mb_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.mb_stat_R &= ~(0xff0000);
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnlcnt_RW[30] = 1;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.priv1.int_mask_class2_RW |= CLASS2_ENABLE_MAILBOX_INTR;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	if ((ctx->csa.prob.mb_stat_R) & 0x00ff00) {
arch/powerpc/platforms/cell/spufs/backing_ops.c:		int slot = ctx->csa.spu_chnlcnt_RW[29];
arch/powerpc/platforms/cell/spufs/backing_ops.c:		int avail = (ctx->csa.prob.mb_stat_R & 0x00ff00) >> 8;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_mailbox_data[slot] = data;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnlcnt_RW[29] = ++slot;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.mb_stat_R &= ~(0x00ff00);
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.mb_stat_R |= (((4 - slot) & 0xff) << 8);
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.priv1.int_mask_class2_RW |=
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.spu_chnldata_RW[3];
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	if (ctx->csa.priv2.spu_cfg_RW & 0x1)
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnldata_RW[3] |= data;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnldata_RW[3] = data;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.spu_chnlcnt_RW[3] = 1;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.spu_chnldata_RW[4];
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	if (ctx->csa.priv2.spu_cfg_RW & 0x2)
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnldata_RW[4] |= data;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.spu_chnldata_RW[4] = data;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.spu_chnlcnt_RW[4] = 1;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	tmp = ctx->csa.priv2.spu_cfg_RW;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.priv2.spu_cfg_RW = tmp;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ((ctx->csa.priv2.spu_cfg_RW & 1) != 0);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	tmp = ctx->csa.priv2.spu_cfg_RW;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.priv2.spu_cfg_RW = tmp;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ((ctx->csa.priv2.spu_cfg_RW & 2) != 0);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.spu_npc_RW;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.prob.spu_npc_RW = val;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.spu_status_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.lscsa->ls;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.priv2.spu_privcntl_RW = val;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.spu_runcntl_RW;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.prob.spu_runcntl_RW = val;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.spu_status_R &=
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.spu_status_R |= SPU_STATUS_RUNNING;
arch/powerpc/platforms/cell/spufs/backing_ops.c:		ctx->csa.prob.spu_status_R &= ~SPU_STATUS_RUNNING;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	struct spu_state *csa = &ctx->csa;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	struct spu_state *csa = &ctx->csa;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	struct spu_problem_collapsed *prob = &ctx->csa.prob;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.prob.dma_tagstatus_R &= mask;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.dma_tagstatus_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	return ctx->csa.prob.dma_qstatus_R;
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_lock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	spin_unlock(&ctx->csa.register_lock);
arch/powerpc/platforms/cell/spufs/backing_ops.c:	ctx->csa.priv2.mfc_control_RW |= MFC_CNTL_RESTART_DMA_COMMAND;
arch/powerpc/platforms/cell/spufs/context.c:	if (spu_init_csa(&ctx->csa))
arch/powerpc/platforms/cell/spufs/context.c:	spin_lock_init(&ctx->mmio_lock);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_init(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/context.c:	kref_init(&ctx->kref);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_init(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_init(&ctx->run_mutex);
arch/powerpc/platforms/cell/spufs/context.c:	init_waitqueue_head(&ctx->ibox_wq);
arch/powerpc/platforms/cell/spufs/context.c:	init_waitqueue_head(&ctx->wbox_wq);
arch/powerpc/platforms/cell/spufs/context.c:	init_waitqueue_head(&ctx->stop_wq);
arch/powerpc/platforms/cell/spufs/context.c:	init_waitqueue_head(&ctx->mfc_wq);
arch/powerpc/platforms/cell/spufs/context.c:	init_waitqueue_head(&ctx->run_wq);
arch/powerpc/platforms/cell/spufs/context.c:	ctx->state = SPU_STATE_SAVED;
arch/powerpc/platforms/cell/spufs/context.c:	ctx->ops = &spu_backing_ops;
arch/powerpc/platforms/cell/spufs/context.c:	ctx->owner = get_task_mm(current);
arch/powerpc/platforms/cell/spufs/context.c:	INIT_LIST_HEAD(&ctx->rq);
arch/powerpc/platforms/cell/spufs/context.c:	INIT_LIST_HEAD(&ctx->aff_list);
arch/powerpc/platforms/cell/spufs/context.c:	ctx->stats.util_state = SPU_UTIL_IDLE_LOADED;
arch/powerpc/platforms/cell/spufs/context.c:	ctx->stats.tstamp = ktime_get_ns();
arch/powerpc/platforms/cell/spufs/context.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_unlock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/context.c:	spu_fini_csa(&ctx->csa);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->gang)
arch/powerpc/platforms/cell/spufs/context.c:		spu_gang_remove_ctx(ctx->gang, ctx);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->prof_priv_kref)
arch/powerpc/platforms/cell/spufs/context.c:		kref_put(ctx->prof_priv_kref, ctx->prof_priv_release);
arch/powerpc/platforms/cell/spufs/context.c:	BUG_ON(!list_empty(&ctx->rq));
arch/powerpc/platforms/cell/spufs/context.c:	kfree(ctx->switch_log);
arch/powerpc/platforms/cell/spufs/context.c:	kref_get(&ctx->kref);
arch/powerpc/platforms/cell/spufs/context.c:	return kref_put(&ctx->kref, &destroy_spu_context);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->state != SPU_STATE_SAVED)
arch/powerpc/platforms/cell/spufs/context.c:	mm = ctx->owner;
arch/powerpc/platforms/cell/spufs/context.c:	ctx->owner = NULL;
arch/powerpc/platforms/cell/spufs/context.c:	mutex_lock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->local_store)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->local_store, 0, LS_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->mfc)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->mfc, 0, SPUFS_MFC_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->cntl)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->cntl, 0, SPUFS_CNTL_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->signal1)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->signal1, 0, SPUFS_SIGNAL_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->signal2)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->signal2, 0, SPUFS_SIGNAL_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->mss)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->mss, 0, SPUFS_MSS_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->psmap)
arch/powerpc/platforms/cell/spufs/context.c:		unmap_mapping_range(ctx->psmap, 0, SPUFS_PS_MAP_SIZE, 1);
arch/powerpc/platforms/cell/spufs/context.c:	mutex_unlock(&ctx->mapping_lock);
arch/powerpc/platforms/cell/spufs/context.c:	if (ctx->state != SPU_STATE_SAVED) {
arch/powerpc/platforms/cell/spufs/context.c:		set_bit(SPU_SCHED_WAS_ACTIVE, &ctx->sched_flags);
arch/powerpc/platforms/cell/spufs/context.c:	BUG_ON(ctx->state != SPU_STATE_SAVED);
arch/powerpc/platforms/cell/spufs/context.c:	if (test_and_clear_bit(SPU_SCHED_WAS_ACTIVE, &ctx->sched_flags) &&
arch/powerpc/platforms/cell/spufs/context.c:			test_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags))
arch/powerpc/platforms/cell/spufs/coredump.c:	if (ctx->flags & SPU_CREATE_NOSCHED)
arch/powerpc/platforms/cell/spufs/switch.c:	spu_cpu_affinity_set(spu, ctx->last_ran);
arch/powerpc/platforms/cell/spufs/inode.c:	ctx->flags = flags;
arch/powerpc/platforms/cell/spufs/inode.c:	    gang->aff_ref_ctx->flags & SPU_CREATE_AFFINITY_MEM)
arch/powerpc/platforms/cell/spufs/inode.c:		ctx->gang->aff_ref_ctx = ctx;
arch/powerpc/platforms/cell/spufs/inode.c:				&ctx->gang->aff_list_head);
arch/powerpc/platforms/cell/spufs/inode.c:		if (list_is_last(&neighbor->aff_list, &ctx->gang->aff_list_head)
arch/powerpc/platforms/cell/spufs/inode.c:			list_add(&ctx->aff_list, &neighbor->aff_list);
arch/powerpc/platforms/cell/spufs/inode.c:			list_add_tail(&ctx->aff_list, &neighbor->aff_list);
arch/powerpc/platforms/cell/spufs/inode.c:				ctx->aff_head = 1;
arch/powerpc/platforms/cell/spufs/inode.c:		if (!ctx->gang->aff_ref_ctx)
arch/powerpc/platforms/cell/spufs/inode.c:			ctx->gang->aff_ref_ctx = ctx;
arch/powerpc/platforms/cell/spufs/gang.c:	ctx->gang = get_spu_gang(gang);
arch/powerpc/platforms/cell/spufs/gang.c:	list_add(&ctx->gang_list, &gang->list);
arch/powerpc/platforms/cell/spufs/gang.c:	WARN_ON(ctx->gang != gang);
arch/powerpc/platforms/cell/spufs/gang.c:	if (!list_empty(&ctx->aff_list)) {
arch/powerpc/platforms/cell/spufs/gang.c:		list_del_init(&ctx->aff_list);
arch/powerpc/platforms/cell/spufs/gang.c:	list_del_init(&ctx->gang_list);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->prio < NORMAL_PRIO)
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->time_slice = SCALE_PRIO(DEF_SPU_TIMESLICE * 4, ctx->prio);
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->time_slice = SCALE_PRIO(DEF_SPU_TIMESLICE, ctx->prio);
arch/powerpc/platforms/cell/spufs/sched.c:	BUG_ON(!list_empty(&ctx->rq));
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->tid = current->pid;
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->prio = current->prio;
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->prio = current->static_prio;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->policy = current->policy;
arch/powerpc/platforms/cell/spufs/sched.c:	cpumask_copy(&ctx->cpus_allowed, tsk_cpus_allowed(current));
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->last_ran = raw_smp_processor_id();
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->state == SPU_STATE_RUNNABLE) {
arch/powerpc/platforms/cell/spufs/sched.c:		node = ctx->spu->node;
arch/powerpc/platforms/cell/spufs/sched.c:		if (cpumask_intersects(mask, &ctx->cpus_allowed))
arch/powerpc/platforms/cell/spufs/sched.c:					&ctx->sched_flags);
arch/powerpc/platforms/cell/spufs/sched.c:				wake_up_all(&ctx->stop_wq);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->flags & SPU_CREATE_NOSCHED)
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.slb_flt_base = spu->stats.slb_flt;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.class2_intr_base = spu->stats.class2_intr;
arch/powerpc/platforms/cell/spufs/sched.c:	spu_associate_mm(spu, ctx->owner);
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->spu = spu;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->ops = &spu_hw_ops;
arch/powerpc/platforms/cell/spufs/sched.c:	spu_restore(&ctx->csa, spu);
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->state = SPU_STATE_RUNNABLE;
arch/powerpc/platforms/cell/spufs/sched.c:	return (!spu->ctx || !(spu->ctx->flags & SPU_CREATE_NOSCHED));
arch/powerpc/platforms/cell/spufs/sched.c:		if (list_empty(&ctx->aff_list))
arch/powerpc/platforms/cell/spufs/sched.c:			list_add(&ctx->aff_list, &gang->aff_list_head);
arch/powerpc/platforms/cell/spufs/sched.c:	list_for_each_entry_reverse(ctx, &gang->aff_ref_ctx->aff_list,
arch/powerpc/platforms/cell/spufs/sched.c:		if (&ctx->aff_list == &gang->aff_list_head)
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->aff_offset = offset--;
arch/powerpc/platforms/cell/spufs/sched.c:	list_for_each_entry(ctx, gang->aff_ref_ctx->aff_list.prev, aff_list) {
arch/powerpc/platforms/cell/spufs/sched.c:		if (&ctx->aff_list == &gang->aff_list_head)
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->aff_offset = offset++;
arch/powerpc/platforms/cell/spufs/sched.c:			if (spu->ctx && spu->ctx->gang && !spu->ctx->aff_offset
arch/powerpc/platforms/cell/spufs/sched.c:					&& spu->ctx->gang->aff_ref_spu)
arch/powerpc/platforms/cell/spufs/sched.c:				available_spus -= spu->ctx->gang->contexts;
arch/powerpc/platforms/cell/spufs/sched.c:		if (available_spus < ctx->gang->contexts) {
arch/powerpc/platforms/cell/spufs/sched.c:	mem_aff = gang->aff_ref_ctx->flags & SPU_CREATE_AFFINITY_MEM;
arch/powerpc/platforms/cell/spufs/sched.c:	list_for_each_entry_reverse(ctx, &gang->aff_ref_ctx->aff_list,
arch/powerpc/platforms/cell/spufs/sched.c:		if (&ctx->aff_list == &gang->aff_list_head)
arch/powerpc/platforms/cell/spufs/sched.c:		lowest_offset = ctx->aff_offset;
arch/powerpc/platforms/cell/spufs/sched.c:	struct spu_gang *gang = ctx->gang;
arch/powerpc/platforms/cell/spufs/sched.c:	if (list_empty(&ctx->aff_list))
arch/powerpc/platforms/cell/spufs/sched.c:	if (atomic_read(&ctx->gang->aff_sched_count) == 0)
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->gang->aff_ref_spu = NULL;
arch/powerpc/platforms/cell/spufs/sched.c: 	if (spu->ctx->flags & SPU_CREATE_NOSCHED)
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->gang)
arch/powerpc/platforms/cell/spufs/sched.c:		 * If ctx->gang->aff_sched_count is positive, SPU affinity is
arch/powerpc/platforms/cell/spufs/sched.c:		atomic_dec_if_positive(&ctx->gang->aff_sched_count);
arch/powerpc/platforms/cell/spufs/sched.c:	spu_save(&ctx->csa, spu);
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->state = SPU_STATE_SAVED;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->ops = &spu_backing_ops;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.slb_flt +=
arch/powerpc/platforms/cell/spufs/sched.c:		(spu->stats.slb_flt - ctx->stats.slb_flt_base);
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.class2_intr +=
arch/powerpc/platforms/cell/spufs/sched.c:		(spu->stats.class2_intr - ctx->stats.class2_intr_base);
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->spu = NULL;
arch/powerpc/platforms/cell/spufs/sched.c:		wake_up_all(&ctx->stop_wq);
arch/powerpc/platforms/cell/spufs/sched.c:	if (list_empty(&ctx->rq)) {
arch/powerpc/platforms/cell/spufs/sched.c:		list_add_tail(&ctx->rq, &spu_prio->runq[ctx->prio]);
arch/powerpc/platforms/cell/spufs/sched.c:		set_bit(ctx->prio, spu_prio->bitmap);
arch/powerpc/platforms/cell/spufs/sched.c:	int prio = ctx->prio;
arch/powerpc/platforms/cell/spufs/sched.c:	if (!list_empty(&ctx->rq)) {
arch/powerpc/platforms/cell/spufs/sched.c:		list_del_init(&ctx->rq);
arch/powerpc/platforms/cell/spufs/sched.c:	BUG_ON(!(ctx->flags & SPU_CREATE_NOSCHED));
arch/powerpc/platforms/cell/spufs/sched.c:	prepare_to_wait_exclusive(&ctx->stop_wq, &wait, TASK_INTERRUPTIBLE);
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_unlock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:	remove_wait_queue(&ctx->stop_wq, &wait);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->gang) {
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_lock(&ctx->gang->aff_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:			aff_ref_spu = ctx->gang->aff_ref_spu;
arch/powerpc/platforms/cell/spufs/sched.c:			atomic_inc(&ctx->gang->aff_sched_count);
arch/powerpc/platforms/cell/spufs/sched.c:			mutex_unlock(&ctx->gang->aff_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:			spu = ctx_location(aff_ref_spu, ctx->aff_offset, node);
arch/powerpc/platforms/cell/spufs/sched.c:			atomic_dec(&ctx->gang->aff_sched_count);
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_unlock(&ctx->gang->aff_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:			if (tmp && tmp->prio > ctx->prio &&
arch/powerpc/platforms/cell/spufs/sched.c:			 * This nests ctx->state_mutex, but we always lock
arch/powerpc/platforms/cell/spufs/sched.c:			if (!spu || victim->prio <= ctx->prio) {
arch/powerpc/platforms/cell/spufs/sched.c:		wake_up_all(&ctx->run_wq);
arch/powerpc/platforms/cell/spufs/sched.c:	mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->state == SPU_STATE_SAVED)
arch/powerpc/platforms/cell/spufs/sched.c: * Should be called with ctx->state_mutex held.
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.invol_ctx_switch++;
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->spu)
arch/powerpc/platforms/cell/spufs/sched.c:	if (!spu && rt_prio(ctx->prio))
arch/powerpc/platforms/cell/spufs/sched.c:		runcntl = ctx->ops->runcntl_read(ctx);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->flags & SPU_CREATE_NOSCHED) {
arch/powerpc/platforms/cell/spufs/sched.c:	struct spu *spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/sched.c:					mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:	if (!(ctx->flags & SPU_CREATE_NOSCHED)) {
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_lock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:		mutex_unlock(&ctx->state_mutex);
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->state != SPU_STATE_RUNNABLE)
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->flags & SPU_CREATE_NOSCHED)
arch/powerpc/platforms/cell/spufs/sched.c:	if (ctx->policy == SCHED_FIFO)
arch/powerpc/platforms/cell/spufs/sched.c:	if (--ctx->time_slice && test_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags))
arch/powerpc/platforms/cell/spufs/sched.c:	spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/sched.c:	new = grab_runnable_context(ctx->prio + 1, spu->node);
arch/powerpc/platforms/cell/spufs/sched.c:		if (test_bit(SPU_SCHED_SPU_RUN, &ctx->sched_flags))
arch/powerpc/platforms/cell/spufs/sched.c:		if (!ctx->time_slice)
arch/powerpc/platforms/cell/spufs/sched.c:			ctx->time_slice++;
arch/powerpc/platforms/cell/spufs/sched.c:	delta = curtime - ctx->stats.tstamp;
arch/powerpc/platforms/cell/spufs/sched.c:	WARN_ON(!mutex_is_locked(&ctx->state_mutex));
arch/powerpc/platforms/cell/spufs/sched.c:	spu = ctx->spu;
arch/powerpc/platforms/cell/spufs/sched.c:	old_state = ctx->stats.util_state;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.util_state = new_state;
arch/powerpc/platforms/cell/spufs/sched.c:	ctx->stats.tstamp = curtime;
arch/powerpc/platforms/cell/spufs/sched.c:		ctx->stats.times[old_state] += delta;
arch/powerpc/platforms/cell/spufs/sputrace.h:		__entry->owner_tid = ctx->tid;
arch/powerpc/platforms/cell/spu_notify.c:				     ctx ? ctx->object_id : 0, spu);
arch/powerpc/platforms/cell/spu_notify.c:	ctx->prof_priv_kref = prof_info_kref;
arch/powerpc/platforms/cell/spu_notify.c:	ctx->prof_priv_release = prof_info_release;
arch/powerpc/platforms/cell/spu_notify.c:	return ctx->prof_priv_kref;
arch/powerpc/platforms/ps3/spu.c:	ctx->ops->runcntl_stop(ctx);
arch/powerpc/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/powerpc/kernel/hw_breakpoint.c: * Atomic: we hold the counter->ctx->lock and we only handle variables
arch/powerpc/kernel/hw_breakpoint.c:	if (bp->ctx && bp->ctx->task && bp->ctx->task != ((void *)-1L))
arch/powerpc/kernel/hw_breakpoint.c:		bp->ctx->task->thread.last_hit_ubp = NULL;
arch/powerpc/kernel/signal_64.c:	    get_user(new_msr, &new_ctx->uc_mcontext.gp_regs[PT_MSR]))
arch/powerpc/kernel/signal_64.c:		    || setup_sigcontext(&old_ctx->uc_mcontext, current, 0, NULL, 0,
arch/powerpc/kernel/signal_64.c:		    || __copy_to_user(&old_ctx->uc_sigmask,
arch/powerpc/kernel/signal_64.c:	if (__copy_from_user(&set, &new_ctx->uc_sigmask, sizeof(set)))
arch/powerpc/kernel/signal_64.c:	if (restore_sigcontext(current, NULL, 0, &new_ctx->uc_mcontext))
arch/powerpc/kernel/signal_32.c:		if (__get_user(cmcp, &new_ctx->uc_regs))
arch/powerpc/kernel/signal_32.c:		 * case old_ctx->uc_mcontext won't be either.
arch/powerpc/kernel/signal_32.c:		 * Because we have the old_ctx->uc_pad2 field
arch/powerpc/kernel/signal_32.c:		 * before old_ctx->uc_mcontext, we need to round down
arch/powerpc/kernel/signal_32.c:		 * from &old_ctx->uc_mcontext to a 16-byte boundary.
arch/powerpc/kernel/signal_32.c:			((unsigned long) &old_ctx->uc_mcontext & ~0xfUL);
arch/powerpc/kernel/signal_32.c:		    || put_sigset_t(&old_ctx->uc_sigmask, &current->blocked)
arch/powerpc/kernel/signal_32.c:		    || __put_user(to_user_ptr(mctx), &old_ctx->uc_regs))
arch/powerpc/kernel/signal_32.c:	restore_altstack(&ctx->uc_stack);
arch/powerpc/perf/callchain.c:	return mctx->mc_gregs;
arch/powerpc/perf/core-book3s.c:	if (event->ctx->task && cpuhw->bhrb_context != event->ctx) {
arch/powerpc/perf/core-book3s.c:	perf_sched_cb_inc(event->ctx->pmu);
arch/powerpc/perf/core-book3s.c:	perf_sched_cb_dec(event->ctx->pmu);
arch/powerpc/net/bpf_jit_comp.c:	if (ctx->seen & (SEEN_MEM | SEEN_DATAREF)) {
arch/powerpc/net/bpf_jit_comp.c:		if (ctx->seen & SEEN_DATAREF) {
arch/powerpc/net/bpf_jit_comp.c:		if (ctx->seen & SEEN_MEM) {
arch/powerpc/net/bpf_jit_comp.c:				if (ctx->seen & (1 << (i-r_M)))
arch/powerpc/net/bpf_jit_comp.c:	if (ctx->seen & SEEN_DATAREF) {
arch/powerpc/net/bpf_jit_comp.c:	if (ctx->seen & SEEN_XREG) {
arch/powerpc/net/bpf_jit_comp.c:	if (ctx->seen & (SEEN_MEM | SEEN_DATAREF)) {
arch/powerpc/net/bpf_jit_comp.c:		if (ctx->seen & SEEN_DATAREF) {
arch/powerpc/net/bpf_jit_comp.c:		if (ctx->seen & SEEN_MEM) {
arch/powerpc/net/bpf_jit_comp.c:				if (ctx->seen & (1 << (i-r_M)))
arch/powerpc/net/bpf_jit_comp.c:		addrs[i] = ctx->idx * 4;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			if (ctx->pc_ret0 != -1) {
arch/powerpc/net/bpf_jit_comp.c:				PPC_BCC(COND_EQ, addrs[ctx->pc_ret0]);
arch/powerpc/net/bpf_jit_comp.c:				PPC_BCC_SHORT(COND_NE, (ctx->idx*4)+12);
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:				if (ctx->pc_ret0 == -1)
arch/powerpc/net/bpf_jit_comp.c:					ctx->pc_ret0 = i;
arch/powerpc/net/bpf_jit_comp.c:				if (ctx->seen)
arch/powerpc/net/bpf_jit_comp.c:				if (ctx->seen)
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_MEM | (1<<(K & 0xf));
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_MEM | (1<<(K & 0xf));
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_MEM | (1<<(K & 0xf));
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_XREG | SEEN_MEM | (1<<(K & 0xf));
arch/powerpc/net/bpf_jit_comp.c:			if (ctx->pc_ret0 != -1) {
arch/powerpc/net/bpf_jit_comp.c:				PPC_BCC(COND_EQ, addrs[ctx->pc_ret0]);
arch/powerpc/net/bpf_jit_comp.c:				PPC_BCC_SHORT(COND_NE, ctx->idx * 4 + 12);
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_DATAREF;
arch/powerpc/net/bpf_jit_comp.c:			ctx->seen |= SEEN_DATAREF | SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:				ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:				ctx->seen |= SEEN_XREG;
arch/powerpc/net/bpf_jit_comp.c:	addrs[i] = ctx->idx * 4;
arch/powerpc/net/bpf_jit_comp64.c:	return (ctx->seen & (1 << (31 - b2p[i])));
arch/powerpc/net/bpf_jit_comp64.c:	ctx->seen |= (1 << (31 - b2p[i]));
arch/powerpc/net/bpf_jit_comp64.c:	return ctx->seen & SEEN_FUNC || bpf_is_seen_register(ctx, BPF_REG_FP);
arch/powerpc/net/bpf_jit_comp64.c:	if (ctx->seen & SEEN_TAILCALL) {
arch/powerpc/net/bpf_jit_comp64.c:		if (ctx->seen & SEEN_FUNC) {
arch/powerpc/net/bpf_jit_comp64.c:	if (ctx->seen & SEEN_SKB) {
arch/powerpc/net/bpf_jit_comp64.c:	if (ctx->seen & SEEN_SKB) {
arch/powerpc/net/bpf_jit_comp64.c:		if (ctx->seen & SEEN_FUNC) {
arch/powerpc/net/bpf_jit_comp64.c:		addrs[i] = ctx->idx * 4;
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_NE, (ctx->idx * 4) + 12);
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_NE, (ctx->idx * 4) + 12);
arch/powerpc/net/bpf_jit_comp64.c:				 * ctx->seen will be reliable in pass2, but
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + 12);
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (7*4));
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (3*4));
arch/powerpc/net/bpf_jit_comp64.c:			PPC_BCC_SHORT(COND_EQ, (ctx->idx * 4) + (7*4));
arch/powerpc/net/bpf_jit_comp64.c:			addrs[++i] = ctx->idx * 4;
arch/powerpc/net/bpf_jit_comp64.c:			ctx->seen |= SEEN_FUNC;
arch/powerpc/net/bpf_jit_comp64.c:			ctx->seen |= SEEN_SKB;
arch/powerpc/net/bpf_jit_comp64.c:			ctx->seen |= SEEN_FUNC;
arch/powerpc/net/bpf_jit_comp64.c:			ctx->seen |= SEEN_TAILCALL;
arch/powerpc/net/bpf_jit_comp64.c:	addrs[i] = ctx->idx * 4;
arch/powerpc/net/bpf_jit.h:#define EMIT(instr)		PLANT_INSTR(image, ctx->idx, instr)
arch/powerpc/net/bpf_jit.h:				     (((dest) - (ctx->idx * 4)) & 0x03fffffc))
arch/powerpc/net/bpf_jit.h:					     (((dest) - (ctx->idx * 4)) &     \
arch/powerpc/net/bpf_jit.h:		if (is_nearbranch((dest) - (ctx->idx * 4))) {		      \
arch/powerpc/net/bpf_jit.h:			PPC_BCC_SHORT(cond ^ COND_CMP_TRUE, (ctx->idx+2)*4);  \
arch/powerpc/kvm/book3s_64_mmu_hv.c:	struct kvm *kvm = ctx->kvm;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	first_pass = ctx->first_pass;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	flags = ctx->flags;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	i = ctx->index;
arch/powerpc/kvm/book3s_64_mmu_hv.c:			ctx->first_pass = 0;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	ctx->index = i;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	struct kvm *kvm = ctx->kvm;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	if (!(ctx->flags & KVM_GET_HTAB_WRITE))
arch/powerpc/kvm/book3s_64_mmu_hv.c:		atomic_dec(&ctx->kvm->arch.hpte_mod_interest);
arch/powerpc/kvm/book3s_64_mmu_hv.c:	kvm_put_kvm(ctx->kvm);
arch/powerpc/kvm/book3s_64_mmu_hv.c:	ctx->kvm = kvm;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	ctx->index = ghf->start_index;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	ctx->flags = ghf->flags;
arch/powerpc/kvm/book3s_64_mmu_hv.c:	ctx->first_pass = 1;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->state[0] = SHA1_H0;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->state[1] = SHA1_H1;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->state[2] = SHA1_H2;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->state[3] = SHA1_H3;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->state[4] = SHA1_H4;
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->count = 0;
arch/powerpc/crypto/sha1-spe-glue.c:	const unsigned int offset = sctx->count & 0x3f;
arch/powerpc/crypto/sha1-spe-glue.c:		sctx->count += len;
arch/powerpc/crypto/sha1-spe-glue.c:		memcpy((char *)sctx->buffer + offset, src, len);
arch/powerpc/crypto/sha1-spe-glue.c:	sctx->count += len;
arch/powerpc/crypto/sha1-spe-glue.c:		memcpy((char *)sctx->buffer + offset, src, avail);
arch/powerpc/crypto/sha1-spe-glue.c:		ppc_spe_sha1_transform(sctx->state, (const u8 *)sctx->buffer, 1);
arch/powerpc/crypto/sha1-spe-glue.c:		ppc_spe_sha1_transform(sctx->state, src, bytes >> 6);
arch/powerpc/crypto/sha1-spe-glue.c:	memcpy((char *)sctx->buffer, src, len);
arch/powerpc/crypto/sha1-spe-glue.c:	const unsigned int offset = sctx->count & 0x3f;
arch/powerpc/crypto/sha1-spe-glue.c:	char *p = (char *)sctx->buffer + offset;
arch/powerpc/crypto/sha1-spe-glue.c:	__be64 *pbits = (__be64 *)(((char *)&sctx->buffer) + 56);
arch/powerpc/crypto/sha1-spe-glue.c:		ppc_spe_sha1_transform(sctx->state, sctx->buffer, 1);
arch/powerpc/crypto/sha1-spe-glue.c:		p = (char *)sctx->buffer;
arch/powerpc/crypto/sha1-spe-glue.c:	*pbits = cpu_to_be64(sctx->count << 3);
arch/powerpc/crypto/sha1-spe-glue.c:	ppc_spe_sha1_transform(sctx->state, sctx->buffer, 1);
arch/powerpc/crypto/sha1-spe-glue.c:	dst[0] = cpu_to_be32(sctx->state[0]);
arch/powerpc/crypto/sha1-spe-glue.c:	dst[1] = cpu_to_be32(sctx->state[1]);
arch/powerpc/crypto/sha1-spe-glue.c:	dst[2] = cpu_to_be32(sctx->state[2]);
arch/powerpc/crypto/sha1-spe-glue.c:	dst[3] = cpu_to_be32(sctx->state[3]);
arch/powerpc/crypto/sha1-spe-glue.c:	dst[4] = cpu_to_be32(sctx->state[4]);
arch/powerpc/crypto/md5-glue.c:	sctx->hash[0] = MD5_H0;
arch/powerpc/crypto/md5-glue.c:	sctx->hash[1] = MD5_H1;
arch/powerpc/crypto/md5-glue.c:	sctx->hash[2] = MD5_H2;
arch/powerpc/crypto/md5-glue.c:	sctx->hash[3] =	MD5_H3;
arch/powerpc/crypto/md5-glue.c:	sctx->byte_count = 0;
arch/powerpc/crypto/md5-glue.c:	const unsigned int offset = sctx->byte_count & 0x3f;
arch/powerpc/crypto/md5-glue.c:	sctx->byte_count += len;
arch/powerpc/crypto/md5-glue.c:		memcpy((char *)sctx->block + offset, src, len);
arch/powerpc/crypto/md5-glue.c:		memcpy((char *)sctx->block + offset, src, avail);
arch/powerpc/crypto/md5-glue.c:		ppc_md5_transform(sctx->hash, (const u8 *)sctx->block, 1);
arch/powerpc/crypto/md5-glue.c:		ppc_md5_transform(sctx->hash, src, len >> 6);
arch/powerpc/crypto/md5-glue.c:	memcpy((char *)sctx->block, src, len);
arch/powerpc/crypto/md5-glue.c:	const unsigned int offset = sctx->byte_count & 0x3f;
arch/powerpc/crypto/md5-glue.c:	const u8 *src = (const u8 *)sctx->block;
arch/powerpc/crypto/md5-glue.c:	__le64 *pbits = (__le64 *)((char *)sctx->block + 56);
arch/powerpc/crypto/md5-glue.c:		ppc_md5_transform(sctx->hash, src, 1);
arch/powerpc/crypto/md5-glue.c:		p = (char *)sctx->block;
arch/powerpc/crypto/md5-glue.c:	*pbits = cpu_to_le64(sctx->byte_count << 3);
arch/powerpc/crypto/md5-glue.c:	ppc_md5_transform(sctx->hash, src, 1);
arch/powerpc/crypto/md5-glue.c:	dst[0] = cpu_to_le32(sctx->hash[0]);
arch/powerpc/crypto/md5-glue.c:	dst[1] = cpu_to_le32(sctx->hash[1]);
arch/powerpc/crypto/md5-glue.c:	dst[2] = cpu_to_le32(sctx->hash[2]);
arch/powerpc/crypto/md5-glue.c:	dst[3] = cpu_to_le32(sctx->hash[3]);
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[0] = SHA256_H0;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[1] = SHA256_H1;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[2] = SHA256_H2;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[3] = SHA256_H3;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[4] = SHA256_H4;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[5] = SHA256_H5;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[6] = SHA256_H6;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[7] = SHA256_H7;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->count = 0;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[0] = SHA224_H0;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[1] = SHA224_H1;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[2] = SHA224_H2;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[3] = SHA224_H3;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[4] = SHA224_H4;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[5] = SHA224_H5;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[6] = SHA224_H6;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->state[7] = SHA224_H7;
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->count = 0;
arch/powerpc/crypto/sha256-spe-glue.c:	const unsigned int offset = sctx->count & 0x3f;
arch/powerpc/crypto/sha256-spe-glue.c:		sctx->count += len;
arch/powerpc/crypto/sha256-spe-glue.c:		memcpy((char *)sctx->buf + offset, src, len);
arch/powerpc/crypto/sha256-spe-glue.c:	sctx->count += len;
arch/powerpc/crypto/sha256-spe-glue.c:		memcpy((char *)sctx->buf + offset, src, avail);
arch/powerpc/crypto/sha256-spe-glue.c:		ppc_spe_sha256_transform(sctx->state, (const u8 *)sctx->buf, 1);
arch/powerpc/crypto/sha256-spe-glue.c:		ppc_spe_sha256_transform(sctx->state, src, bytes >> 6);
arch/powerpc/crypto/sha256-spe-glue.c:	memcpy((char *)sctx->buf, src, len);
arch/powerpc/crypto/sha256-spe-glue.c:	const unsigned int offset = sctx->count & 0x3f;
arch/powerpc/crypto/sha256-spe-glue.c:	char *p = (char *)sctx->buf + offset;
arch/powerpc/crypto/sha256-spe-glue.c:	__be64 *pbits = (__be64 *)(((char *)&sctx->buf) + 56);
arch/powerpc/crypto/sha256-spe-glue.c:		ppc_spe_sha256_transform(sctx->state, sctx->buf, 1);
arch/powerpc/crypto/sha256-spe-glue.c:		p = (char *)sctx->buf;
arch/powerpc/crypto/sha256-spe-glue.c:	*pbits = cpu_to_be64(sctx->count << 3);
arch/powerpc/crypto/sha256-spe-glue.c:	ppc_spe_sha256_transform(sctx->state, sctx->buf, 1);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[0] = cpu_to_be32(sctx->state[0]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[1] = cpu_to_be32(sctx->state[1]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[2] = cpu_to_be32(sctx->state[2]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[3] = cpu_to_be32(sctx->state[3]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[4] = cpu_to_be32(sctx->state[4]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[5] = cpu_to_be32(sctx->state[5]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[6] = cpu_to_be32(sctx->state[6]);
arch/powerpc/crypto/sha256-spe-glue.c:	dst[7] = cpu_to_be32(sctx->state[7]);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 4;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_128(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 5;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_192(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 6;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_256(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:	ppc_generate_decrypt_key(ctx->key_dec, ctx->key_enc, key_len);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 4;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_128(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_128(ctx->key_twk, in_key + AES_KEYSIZE_128);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 5;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_192(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_192(ctx->key_twk, in_key + AES_KEYSIZE_192);
arch/powerpc/crypto/aes-spe-glue.c:		ctx->rounds = 6;
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_256(ctx->key_enc, in_key);
arch/powerpc/crypto/aes-spe-glue.c:		ppc_expand_key_256(ctx->key_twk, in_key + AES_KEYSIZE_256);
arch/powerpc/crypto/aes-spe-glue.c:	ppc_generate_decrypt_key(ctx->key_dec, ctx->key_enc, key_len);
arch/powerpc/crypto/aes-spe-glue.c:	ppc_encrypt_aes(out, in, ctx->key_enc, ctx->rounds);
arch/powerpc/crypto/aes-spe-glue.c:	ppc_decrypt_aes(out, in, ctx->key_dec, ctx->rounds);
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_enc, ctx->rounds, nbytes);
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_dec, ctx->rounds, nbytes);
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_enc, ctx->rounds, nbytes, walk.iv);
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_dec, ctx->rounds, nbytes, walk.iv);
arch/powerpc/crypto/aes-spe-glue.c:			      ctx->key_enc, ctx->rounds, pbytes , walk.iv);
arch/powerpc/crypto/aes-spe-glue.c:	twk = ctx->key_twk;
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_enc, ctx->rounds, nbytes, walk.iv, twk);
arch/powerpc/crypto/aes-spe-glue.c:	twk = ctx->key_twk;
arch/powerpc/crypto/aes-spe-glue.c:				ctx->key_dec, ctx->rounds, nbytes, walk.iv, twk);
arch/powerpc/crypto/sha1.c:	partial = sctx->count & 0x3f;
arch/powerpc/crypto/sha1.c:	sctx->count += len;
arch/powerpc/crypto/sha1.c:			memcpy(sctx->buffer + partial, data, done + 64);
arch/powerpc/crypto/sha1.c:			src = sctx->buffer;
arch/powerpc/crypto/sha1.c:			powerpc_sha_transform(sctx->state, src, temp);
arch/powerpc/crypto/sha1.c:	memcpy(sctx->buffer + partial, src, len - done);
arch/powerpc/crypto/sha1.c:	bits = cpu_to_be64(sctx->count << 3);
arch/powerpc/crypto/sha1.c:	index = sctx->count & 0x3f;
arch/powerpc/crypto/sha1.c:		dst[i] = cpu_to_be32(sctx->state[i]);
arch/cris/arch-v32/drivers/cryptocop.c:	if ((tc->tctx->init.alg == cryptocop_alg_aes) && (tc->tcfg->flags & CRYPTOCOP_DECRYPT)) {
arch/cris/arch-v32/drivers/cryptocop.c:		if (!tc->tctx->dec_key_set){
arch/cris/arch-v32/drivers/cryptocop.c:			get_aes_decrypt_key(tc->tctx->dec_key, tc->tctx->init.key, tc->tctx->init.keylen);
arch/cris/arch-v32/drivers/cryptocop.c:			tc->tctx->dec_key_set = 1;
arch/cris/arch-v32/drivers/cryptocop.c:		key_desc->dma_descr->buf = (char*)virt_to_phys(tc->tctx->dec_key);
arch/cris/arch-v32/drivers/cryptocop.c:		key_desc->dma_descr->after = key_desc->dma_descr->buf + tc->tctx->init.keylen/8;
arch/cris/arch-v32/drivers/cryptocop.c:		key_desc->dma_descr->buf = (char*)virt_to_phys(tc->tctx->init.key);
arch/cris/arch-v32/drivers/cryptocop.c:		key_desc->dma_descr->after = key_desc->dma_descr->buf + tc->tctx->init.keylen/8;
arch/cris/arch-v32/drivers/cryptocop.c:	switch (tc->tctx->init.keylen) {
arch/cris/arch-v32/drivers/cryptocop.c:		switch (tctx->init.alg){
arch/cris/arch-v32/drivers/cryptocop.c:			switch (tctx->init.cipher_mode) {
arch/cris/arch-v32/drivers/cryptocop.c:				DEBUG_API(printk("cryptocop_setup_dma_list: cipher_ctx, bad cipher mode==%d\n", tctx->init.cipher_mode));
arch/cris/arch-v32/drivers/cryptocop.c:			switch (tctx->init.alg){
arch/cris/arch-v32/drivers/cryptocop.c:				panic("cryptocop_setup_dma_list: impossible algorithm %d\n", tctx->init.alg);
arch/cris/arch-v32/drivers/cryptocop.c:			(*int_op)->tdes_mode = tctx->init.tdes_mode;
arch/cris/arch-v32/drivers/cryptocop.c:			switch (tctx->init.alg){
arch/cris/arch-v32/drivers/cryptocop.c:			(*int_op)->csum_mode = tctx->init.csum_mode;
arch/cris/arch-v32/drivers/cryptocop.c:			DEBUG_API(printk("cryptocop_setup_dma_list: invalid algorithm %d specified in tfrm %d.\n", tctx->init.alg, tcfg->tid));
arch/cris/arch-v32/drivers/cryptocop.c:	if (cipher_ctx.tcfg && (cipher_ctx.tctx->init.alg != cryptocop_alg_mem2mem)){
arch/cris/arch-v32/drivers/cryptocop.c:		if ((cipher_ctx.tctx->init.cipher_mode == cryptocop_cipher_mode_cbc) && (cipher_ctx.tcfg->flags & CRYPTOCOP_EXPLICIT_IV)) {
arch/arc/include/asm/processor.h:/* These DPFP regs need to be saved/restored across ctx-sw */
block/blk-cgroup.c: * result.  @ctx->blkg points to the blkg to be updated and @ctx->body the
block/blk-cgroup.c:	ctx->disk = disk;
block/blk-cgroup.c:	ctx->blkg = blkg;
block/blk-cgroup.c:	ctx->body = body;
block/blk-cgroup.c:	__releases(ctx->disk->queue->queue_lock) __releases(rcu)
block/blk-cgroup.c:	spin_unlock_irq(ctx->disk->queue->queue_lock);
block/blk-cgroup.c:	owner = ctx->disk->fops->owner;
block/blk-cgroup.c:	put_disk(ctx->disk);
block/blk.h:		return blk_mq_map_queue(q, ctx->cpu)->fq;
block/blk-mq-sysfs.c:	q = ctx->queue;
block/blk-mq-sysfs.c:	q = ctx->queue;
block/blk-mq-sysfs.c:	q = hctx->queue;
block/blk-mq-sysfs.c:	q = hctx->queue;
block/blk-mq-sysfs.c:	return sprintf(page, "%lu %lu\n", ctx->rq_dispatched[1],
block/blk-mq-sysfs.c:				ctx->rq_dispatched[0]);
block/blk-mq-sysfs.c:	return sprintf(page, "%lu\n", ctx->rq_merged);
block/blk-mq-sysfs.c:	return sprintf(page, "%lu %lu\n", ctx->rq_completed[1],
block/blk-mq-sysfs.c:				ctx->rq_completed[0]);
block/blk-mq-sysfs.c:	spin_lock(&ctx->lock);
block/blk-mq-sysfs.c:	ret = sysfs_list_show(page, &ctx->rq_list, "CTX pending");
block/blk-mq-sysfs.c:	spin_unlock(&ctx->lock);
block/blk-mq-sysfs.c:		       hctx->poll_considered, hctx->poll_invoked,
block/blk-mq-sysfs.c:		       hctx->poll_success);
block/blk-mq-sysfs.c:	hctx->poll_considered = hctx->poll_invoked = hctx->poll_success = 0;
block/blk-mq-sysfs.c:	return sprintf(page, "%lu\n", hctx->queued);
block/blk-mq-sysfs.c:	return sprintf(page, "%lu\n", hctx->run);
block/blk-mq-sysfs.c:	page += sprintf(page, "%8u\t%lu\n", 0U, hctx->dispatched[0]);
block/blk-mq-sysfs.c:		page += sprintf(page, "%8u\t%lu\n", d, hctx->dispatched[i]);
block/blk-mq-sysfs.c:						hctx->dispatched[i]);
block/blk-mq-sysfs.c:	spin_lock(&hctx->lock);
block/blk-mq-sysfs.c:	ret = sysfs_list_show(page, &hctx->dispatch, "HCTX pending");
block/blk-mq-sysfs.c:	spin_unlock(&hctx->lock);
block/blk-mq-sysfs.c:	return blk_mq_tag_sysfs_show(hctx->tags, page);
block/blk-mq-sysfs.c:	return sprintf(page, "%u\n", atomic_read(&hctx->nr_active));
block/blk-mq-sysfs.c:	for_each_cpu(i, hctx->cpumask) {
block/blk-mq-sysfs.c:	if (!hctx->nr_ctx)
block/blk-mq-sysfs.c:		kobject_del(&ctx->kobj);
block/blk-mq-sysfs.c:	kobject_del(&hctx->kobj);
block/blk-mq-sysfs.c:	struct request_queue *q = hctx->queue;
block/blk-mq-sysfs.c:	if (!hctx->nr_ctx)
block/blk-mq-sysfs.c:	ret = kobject_add(&hctx->kobj, &q->mq_kobj, "%u", hctx->queue_num);
block/blk-mq-sysfs.c:		ret = kobject_add(&ctx->kobj, &hctx->kobj, "cpu%u", ctx->cpu);
block/blk-mq-sysfs.c:			kobject_put(&ctx->kobj);
block/blk-mq-sysfs.c:		kobject_put(&hctx->kobj);
block/blk-mq-sysfs.c:	kobject_init(&hctx->kobj, &blk_mq_hw_ktype);
block/blk-mq-sysfs.c:		kobject_init(&ctx->kobj, &blk_mq_ctx_ktype);
block/blk-mq.h:	return hctx->nr_ctx && hctx->tags;
block/blk-mq-tag.c:	if (!test_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state) &&
block/blk-mq-tag.c:	    !test_and_set_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
block/blk-mq-tag.c:		atomic_inc(&hctx->tags->active_queues);
block/blk-mq-tag.c:	struct blk_mq_tags *tags = hctx->tags;
block/blk-mq-tag.c:	if (!test_and_clear_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
block/blk-mq-tag.c:	if (!hctx || !(hctx->flags & BLK_MQ_F_TAG_SHARED))
block/blk-mq-tag.c:	if (!test_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
block/blk-mq-tag.c:	users = atomic_read(&hctx->tags->active_queues);
block/blk-mq-tag.c:	return atomic_read(&hctx->nr_active) < depth;
block/blk-mq-tag.c:		data->hctx = blk_mq_map_queue(data->q, data->ctx->cpu);
block/blk-mq-tag.c:			bt = &data->hctx->tags->breserved_tags;
block/blk-mq-tag.c:			bt = &hctx->tags->bitmap_tags;
block/blk-mq-tag.c:	tag = bt_get(data, &data->hctx->tags->bitmap_tags, data->hctx,
block/blk-mq-tag.c:		     data->hctx->tags);
block/blk-mq-tag.c:		return tag + data->hctx->tags->nr_reserved_tags;
block/blk-mq-tag.c:	if (unlikely(!data->hctx->tags->nr_reserved_tags)) {
block/blk-mq-tag.c:	tag = bt_get(data, &data->hctx->tags->breserved_tags, NULL,
block/blk-mq-tag.c:		     data->hctx->tags);
block/blk-mq-tag.c:	struct blk_mq_tags *tags = hctx->tags;
block/blk-mq-tag.c:		sbitmap_queue_clear(&tags->bitmap_tags, real_tag, ctx->cpu);
block/blk-mq-tag.c:		sbitmap_queue_clear(&tags->breserved_tags, tag, ctx->cpu);
block/blk-mq-tag.c:	struct blk_mq_tags *tags = hctx->tags;
block/blk-mq-tag.c:	if (rq->q == hctx->queue)
block/blk-mq-tag.c:		struct blk_mq_tags *tags = hctx->tags;
block/blk-mq-tag.c:		hctx = blk_mq_map_queue(q, rq->mq_ctx->cpu);
block/blk-mq-tag.c:		hwq = hctx->queue_num;
block/blk-mq.c:	return sbitmap_any_bit_set(&hctx->ctx_map);
block/blk-mq.c:	if (!sbitmap_test_bit(&hctx->ctx_map, ctx->index_hw))
block/blk-mq.c:		sbitmap_set_bit(&hctx->ctx_map, ctx->index_hw);
block/blk-mq.c:	sbitmap_clear_bit(&hctx->ctx_map, ctx->index_hw);
block/blk-mq.c:			blk_mq_tag_wakeup_all(hctx->tags, true);
block/blk-mq.c:	return blk_mq_has_free_tags(hctx->tags);
block/blk-mq.c:	ctx->rq_dispatched[rw_is_sync(op, op_flags)]++;
block/blk-mq.c:		rq = data->hctx->tags->rqs[tag];
block/blk-mq.c:			atomic_inc(&data->hctx->nr_active);
block/blk-mq.c:	hctx = blk_mq_map_queue(q, ctx->cpu);
block/blk-mq.c:	ctx = __blk_mq_get_ctx(q, cpumask_first(hctx->cpumask));
block/blk-mq.c:		atomic_dec(&hctx->nr_active);
block/blk-mq.c:	ctx->rq_completed[rq_is_sync(rq)]++;
block/blk-mq.c:	blk_mq_free_hctx_request(blk_mq_map_queue(rq->q, rq->mq_ctx->cpu), rq);
block/blk-mq.c:		shared = cpus_share_cache(cpu, ctx->cpu);
block/blk-mq.c:	if (cpu != ctx->cpu && !shared && cpu_online(ctx->cpu)) {
block/blk-mq.c:		smp_call_function_single_async(ctx->cpu, &rq->csd);
block/blk-mq.c:	list_for_each_entry_reverse(rq, &ctx->rq_list, queuelist) {
block/blk-mq.c:				ctx->rq_merged++;
block/blk-mq.c:				ctx->rq_merged++;
block/blk-mq.c:	struct blk_mq_ctx *ctx = hctx->ctxs[bitnr];
block/blk-mq.c:	spin_lock(&ctx->lock);
block/blk-mq.c:	list_splice_tail_init(&ctx->rq_list, flush_data->list);
block/blk-mq.c:	spin_unlock(&ctx->lock);
block/blk-mq.c:	sbitmap_for_each_set(&hctx->ctx_map, flush_busy_ctx, &data);
block/blk-mq.c: * items on the hctx->dispatch list. Ignore that for now.
block/blk-mq.c:	struct request_queue *q = hctx->queue;
block/blk-mq.c:	if (unlikely(test_bit(BLK_MQ_S_STOPPED, &hctx->state)))
block/blk-mq.c:	WARN_ON(!cpumask_test_cpu(raw_smp_processor_id(), hctx->cpumask) &&
block/blk-mq.c:		cpu_online(hctx->next_cpu));
block/blk-mq.c:	hctx->run++;
block/blk-mq.c:	if (!list_empty_careful(&hctx->dispatch)) {
block/blk-mq.c:		spin_lock(&hctx->lock);
block/blk-mq.c:		if (!list_empty(&hctx->dispatch))
block/blk-mq.c:			list_splice_init(&hctx->dispatch, &rq_list);
block/blk-mq.c:		spin_unlock(&hctx->lock);
block/blk-mq.c:	hctx->dispatched[queued_to_index(queued)]++;
block/blk-mq.c:	 * Any items that need requeuing? Stuff them into hctx->dispatch,
block/blk-mq.c:		spin_lock(&hctx->lock);
block/blk-mq.c:		list_splice(&rq_list, &hctx->dispatch);
block/blk-mq.c:		spin_unlock(&hctx->lock);
block/blk-mq.c:		 * requests in rq_list aren't added into hctx->dispatch yet,
block/blk-mq.c:	if (hctx->queue->nr_hw_queues == 1)
block/blk-mq.c:	if (--hctx->next_cpu_batch <= 0) {
block/blk-mq.c:		next_cpu = cpumask_next(hctx->next_cpu, hctx->cpumask);
block/blk-mq.c:			next_cpu = cpumask_first(hctx->cpumask);
block/blk-mq.c:		hctx->next_cpu = next_cpu;
block/blk-mq.c:		hctx->next_cpu_batch = BLK_MQ_CPU_WORK_BATCH;
block/blk-mq.c:	return hctx->next_cpu;
block/blk-mq.c:	if (unlikely(test_bit(BLK_MQ_S_STOPPED, &hctx->state) ||
block/blk-mq.c:	if (!async && !(hctx->flags & BLK_MQ_F_BLOCKING)) {
block/blk-mq.c:		if (cpumask_test_cpu(cpu, hctx->cpumask)) {
block/blk-mq.c:	kblockd_schedule_work_on(blk_mq_hctx_next_cpu(hctx), &hctx->run_work);
block/blk-mq.c:		    list_empty_careful(&hctx->dispatch)) ||
block/blk-mq.c:		    test_bit(BLK_MQ_S_STOPPED, &hctx->state))
block/blk-mq.c:	cancel_work(&hctx->run_work);
block/blk-mq.c:	cancel_delayed_work(&hctx->delay_work);
block/blk-mq.c:	set_bit(BLK_MQ_S_STOPPED, &hctx->state);
block/blk-mq.c:	clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
block/blk-mq.c:		if (!test_bit(BLK_MQ_S_STOPPED, &hctx->state))
block/blk-mq.c:		clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
block/blk-mq.c:	if (test_and_clear_bit(BLK_MQ_S_STOPPED, &hctx->state))
block/blk-mq.c:			&hctx->delay_work, msecs_to_jiffies(msecs));
block/blk-mq.c:	trace_block_rq_insert(hctx->queue, rq);
block/blk-mq.c:		list_add(&rq->queuelist, &ctx->rq_list);
block/blk-mq.c:		list_add_tail(&rq->queuelist, &ctx->rq_list);
block/blk-mq.c:	struct blk_mq_hw_ctx *hctx = blk_mq_map_queue(q, ctx->cpu);
block/blk-mq.c:	spin_lock(&ctx->lock);
block/blk-mq.c:	spin_unlock(&ctx->lock);
block/blk-mq.c:	struct blk_mq_hw_ctx *hctx = blk_mq_map_queue(q, ctx->cpu);
block/blk-mq.c:	 * preemption doesn't flush plug list, so it's possible ctx->cpu is
block/blk-mq.c:	spin_lock(&ctx->lock);
block/blk-mq.c:	spin_unlock(&ctx->lock);
block/blk-mq.c:	return (hctx->flags & BLK_MQ_F_SHOULD_MERGE) &&
block/blk-mq.c:		!blk_queue_nomerges(hctx->queue);
block/blk-mq.c:		spin_lock(&ctx->lock);
block/blk-mq.c:		spin_unlock(&ctx->lock);
block/blk-mq.c:		struct request_queue *q = hctx->queue;
block/blk-mq.c:		spin_lock(&ctx->lock);
block/blk-mq.c:		spin_unlock(&ctx->lock);
block/blk-mq.c:	hctx = blk_mq_map_queue(q, ctx->cpu);
block/blk-mq.c:	data->hctx->queued++;
block/blk-mq.c:	struct blk_mq_hw_ctx *hctx = blk_mq_map_queue(q, rq->mq_ctx->cpu);
block/blk-mq.c:	blk_qc_t new_cookie = blk_tag_to_qc_t(rq->tag, hctx->queue_num);
block/blk-mq.c:	cookie = blk_tag_to_qc_t(rq->tag, data.hctx->queue_num);
block/blk-mq.c:	    !(data.hctx->flags & BLK_MQ_F_DEFER_ISSUE)) {
block/blk-mq.c:		if (test_bit(BLK_MQ_S_STOPPED, &data.hctx->state) ||
block/blk-mq.c:	cookie = blk_tag_to_qc_t(rq->tag, data.hctx->queue_num);
block/blk-mq.c:	ctx = __blk_mq_get_ctx(hctx->queue, cpu);
block/blk-mq.c:	spin_lock(&ctx->lock);
block/blk-mq.c:	if (!list_empty(&ctx->rq_list)) {
block/blk-mq.c:		list_splice_init(&ctx->rq_list, &tmp);
block/blk-mq.c:	spin_unlock(&ctx->lock);
block/blk-mq.c:	spin_lock(&hctx->lock);
block/blk-mq.c:	list_splice_tail_init(&tmp, &hctx->dispatch);
block/blk-mq.c:	spin_unlock(&hctx->lock);
block/blk-mq.c:					    &hctx->cpuhp_dead);
block/blk-mq.c:/* hctx->ctxs will be freed in queue's release handler */
block/blk-mq.c:				       hctx->fq->flush_rq, hctx_idx,
block/blk-mq.c:	blk_free_flush_queue(hctx->fq);
block/blk-mq.c:	sbitmap_free(&hctx->ctx_map);
block/blk-mq.c:		free_cpumask_var(hctx->cpumask);
block/blk-mq.c:	node = hctx->numa_node;
block/blk-mq.c:		node = hctx->numa_node = set->numa_node;
block/blk-mq.c:	INIT_WORK(&hctx->run_work, blk_mq_run_work_fn);
block/blk-mq.c:	INIT_DELAYED_WORK(&hctx->delay_work, blk_mq_delay_work_fn);
block/blk-mq.c:	spin_lock_init(&hctx->lock);
block/blk-mq.c:	INIT_LIST_HEAD(&hctx->dispatch);
block/blk-mq.c:	hctx->queue = q;
block/blk-mq.c:	hctx->queue_num = hctx_idx;
block/blk-mq.c:	hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
block/blk-mq.c:	cpuhp_state_add_instance_nocalls(CPUHP_BLK_MQ_DEAD, &hctx->cpuhp_dead);
block/blk-mq.c:	hctx->tags = set->tags[hctx_idx];
block/blk-mq.c:	hctx->ctxs = kmalloc_node(nr_cpu_ids * sizeof(void *),
block/blk-mq.c:	if (!hctx->ctxs)
block/blk-mq.c:	if (sbitmap_init_node(&hctx->ctx_map, nr_cpu_ids, ilog2(8), GFP_KERNEL,
block/blk-mq.c:	hctx->nr_ctx = 0;
block/blk-mq.c:	hctx->fq = blk_alloc_flush_queue(q, hctx->numa_node, set->cmd_size);
block/blk-mq.c:	if (!hctx->fq)
block/blk-mq.c:				   hctx->fq->flush_rq, hctx_idx,
block/blk-mq.c:	kfree(hctx->fq);
block/blk-mq.c:	sbitmap_free(&hctx->ctx_map);
block/blk-mq.c:	kfree(hctx->ctxs);
block/blk-mq.c:		__ctx->cpu = i;
block/blk-mq.c:		spin_lock_init(&__ctx->lock);
block/blk-mq.c:		INIT_LIST_HEAD(&__ctx->rq_list);
block/blk-mq.c:		__ctx->queue = q;
block/blk-mq.c:		if (nr_hw_queues > 1 && hctx->numa_node == NUMA_NO_NODE)
block/blk-mq.c:			hctx->numa_node = local_memory_node(cpu_to_node(i));
block/blk-mq.c:	 * Avoid others reading imcomplete hctx->cpumask through sysfs
block/blk-mq.c:		cpumask_clear(hctx->cpumask);
block/blk-mq.c:		hctx->nr_ctx = 0;
block/blk-mq.c:			cpumask_set_cpu(i, hctx->cpumask);
block/blk-mq.c:		ctx->index_hw = hctx->nr_ctx;
block/blk-mq.c:		hctx->ctxs[hctx->nr_ctx++] = ctx;
block/blk-mq.c:		if (!hctx->nr_ctx) {
block/blk-mq.c:			hctx->tags = NULL;
block/blk-mq.c:		hctx->tags = set->tags[i];
block/blk-mq.c:		WARN_ON(!hctx->tags);
block/blk-mq.c:		sbitmap_resize(&hctx->ctx_map, hctx->nr_ctx);
block/blk-mq.c:		if (cpumask_first(hctx->cpumask) < nr_cpu_ids) {
block/blk-mq.c:			hctx->next_cpu = cpumask_first(hctx->cpumask);
block/blk-mq.c:			hctx->next_cpu_batch = BLK_MQ_CPU_WORK_BATCH;
block/blk-mq.c:			hctx->flags |= BLK_MQ_F_TAG_SHARED;
block/blk-mq.c:			hctx->flags &= ~BLK_MQ_F_TAG_SHARED;
block/blk-mq.c:		kfree(hctx->ctxs);
block/blk-mq.c:			if (hctx->tags) {
block/blk-mq.c:				blk_mq_free_rq_map(set, hctx->tags, j);
block/blk-mq.c:			free_cpumask_var(hctx->cpumask);
block/blk-mq.c:			kobject_put(&hctx->kobj);
block/blk-mq.c:			kfree(hctx->ctxs);
block/blk-mq.c:			cpumask_clear_cpu(cpu, hctx->cpumask);
block/blk-mq.c: * pending bitmap and tries to retrieve requests in hctx->ctxs[0]->rq_list.
block/blk-mq.c:			cpumask_set_cpu(cpu, hctx->cpumask);
block/blk-mq.c:		if (!hctx->tags)
block/blk-mq.c:		ret = blk_mq_tag_update_depth(hctx->tags, nr);
block/blk-mq-tag.h:	return sbq_wait_ptr(bt, &hctx->wait_index);
block/blk-mq-tag.h:	if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
block/blk-mq-tag.h:	if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
block/blk-mq-tag.h:	hctx->tags->rqs[tag] = rq;
block/blk-flush.c:		hctx = blk_mq_map_queue(q, flush_rq->mq_ctx->cpu);
block/blk-flush.c:		hctx = blk_mq_map_queue(q, first_rq->mq_ctx->cpu);
block/blk-flush.c:	hctx = blk_mq_map_queue(q, ctx->cpu);
block/blk-core.c:			cancel_work_sync(&hctx->run_work);
block/blk-core.c:			cancel_delayed_work_sync(&hctx->delay_work);
block/blk-core.c:	hctx->poll_considered++;
block/blk-core.c:		hctx->poll_invoked++;
block/blk-core.c:			hctx->poll_success++;
crypto/lzo.c:	ctx->lzo_comp_mem = kmalloc(LZO1X_MEM_COMPRESS,
crypto/lzo.c:	if (!ctx->lzo_comp_mem)
crypto/lzo.c:		ctx->lzo_comp_mem = vmalloc(LZO1X_MEM_COMPRESS);
crypto/lzo.c:	if (!ctx->lzo_comp_mem)
crypto/lzo.c:	kvfree(ctx->lzo_comp_mem);
crypto/lzo.c:	err = lzo1x_1_compress(src, slen, dst, &tmp_len, ctx->lzo_comp_mem);
crypto/poly1305_generic.c:	memset(dctx->h, 0, sizeof(dctx->h));
crypto/poly1305_generic.c:	dctx->buflen = 0;
crypto/poly1305_generic.c:	dctx->rset = false;
crypto/poly1305_generic.c:	dctx->sset = false;
crypto/poly1305_generic.c:	dctx->r[0] = (le32_to_cpuvp(key +  0) >> 0) & 0x3ffffff;
crypto/poly1305_generic.c:	dctx->r[1] = (le32_to_cpuvp(key +  3) >> 2) & 0x3ffff03;
crypto/poly1305_generic.c:	dctx->r[2] = (le32_to_cpuvp(key +  6) >> 4) & 0x3ffc0ff;
crypto/poly1305_generic.c:	dctx->r[3] = (le32_to_cpuvp(key +  9) >> 6) & 0x3f03fff;
crypto/poly1305_generic.c:	dctx->r[4] = (le32_to_cpuvp(key + 12) >> 8) & 0x00fffff;
crypto/poly1305_generic.c:	dctx->s[0] = le32_to_cpuvp(key +  0);
crypto/poly1305_generic.c:	dctx->s[1] = le32_to_cpuvp(key +  4);
crypto/poly1305_generic.c:	dctx->s[2] = le32_to_cpuvp(key +  8);
crypto/poly1305_generic.c:	dctx->s[3] = le32_to_cpuvp(key + 12);
crypto/poly1305_generic.c:	if (!dctx->sset) {
crypto/poly1305_generic.c:		if (!dctx->rset && srclen >= POLY1305_BLOCK_SIZE) {
crypto/poly1305_generic.c:			dctx->rset = true;
crypto/poly1305_generic.c:			dctx->sset = true;
crypto/poly1305_generic.c:	if (unlikely(!dctx->sset)) {
crypto/poly1305_generic.c:	r0 = dctx->r[0];
crypto/poly1305_generic.c:	r1 = dctx->r[1];
crypto/poly1305_generic.c:	r2 = dctx->r[2];
crypto/poly1305_generic.c:	r3 = dctx->r[3];
crypto/poly1305_generic.c:	r4 = dctx->r[4];
crypto/poly1305_generic.c:	h0 = dctx->h[0];
crypto/poly1305_generic.c:	h1 = dctx->h[1];
crypto/poly1305_generic.c:	h2 = dctx->h[2];
crypto/poly1305_generic.c:	h3 = dctx->h[3];
crypto/poly1305_generic.c:	h4 = dctx->h[4];
crypto/poly1305_generic.c:	dctx->h[0] = h0;
crypto/poly1305_generic.c:	dctx->h[1] = h1;
crypto/poly1305_generic.c:	dctx->h[2] = h2;
crypto/poly1305_generic.c:	dctx->h[3] = h3;
crypto/poly1305_generic.c:	dctx->h[4] = h4;
crypto/poly1305_generic.c:	if (unlikely(dctx->buflen)) {
crypto/poly1305_generic.c:		bytes = min(srclen, POLY1305_BLOCK_SIZE - dctx->buflen);
crypto/poly1305_generic.c:		memcpy(dctx->buf + dctx->buflen, src, bytes);
crypto/poly1305_generic.c:		dctx->buflen += bytes;
crypto/poly1305_generic.c:		if (dctx->buflen == POLY1305_BLOCK_SIZE) {
crypto/poly1305_generic.c:			poly1305_blocks(dctx, dctx->buf,
crypto/poly1305_generic.c:			dctx->buflen = 0;
crypto/poly1305_generic.c:		dctx->buflen = srclen;
crypto/poly1305_generic.c:		memcpy(dctx->buf, src, srclen);
crypto/poly1305_generic.c:	if (unlikely(!dctx->sset))
crypto/poly1305_generic.c:	if (unlikely(dctx->buflen)) {
crypto/poly1305_generic.c:		dctx->buf[dctx->buflen++] = 1;
crypto/poly1305_generic.c:		memset(dctx->buf + dctx->buflen, 0,
crypto/poly1305_generic.c:		       POLY1305_BLOCK_SIZE - dctx->buflen);
crypto/poly1305_generic.c:		poly1305_blocks(dctx, dctx->buf, POLY1305_BLOCK_SIZE, 0);
crypto/poly1305_generic.c:	h0 = dctx->h[0];
crypto/poly1305_generic.c:	h1 = dctx->h[1];
crypto/poly1305_generic.c:	h2 = dctx->h[2];
crypto/poly1305_generic.c:	h3 = dctx->h[3];
crypto/poly1305_generic.c:	h4 = dctx->h[4];
crypto/poly1305_generic.c:	f = (f >> 32) + h0 + dctx->s[0]; mac[0] = cpu_to_le32(f);
crypto/poly1305_generic.c:	f = (f >> 32) + h1 + dctx->s[1]; mac[1] = cpu_to_le32(f);
crypto/poly1305_generic.c:	f = (f >> 32) + h2 + dctx->s[2]; mac[2] = cpu_to_le32(f);
crypto/poly1305_generic.c:	f = (f >> 32) + h3 + dctx->s[3]; mac[3] = cpu_to_le32(f);
crypto/ecdh.c:	ctx->curve_id = params.curve_id;
crypto/ecdh.c:	ctx->ndigits = ndigits;
crypto/ecdh.c:	if (ecc_is_key_valid(ctx->curve_id, ctx->ndigits,
crypto/ecdh.c:	memcpy(ctx->private_key, params.key, params.key_size);
crypto/ecdh.c:	nbytes = ctx->ndigits << ECC_DIGITS_TO_BYTES_SHIFT;
crypto/ecdh.c:		copied = sg_copy_to_buffer(req->src, 1, ctx->public_key,
crypto/ecdh.c:		ret = crypto_ecdh_shared_secret(ctx->curve_id, ctx->ndigits,
crypto/ecdh.c:					 (const u8 *)ctx->private_key, nbytes,
crypto/ecdh.c:					 (const u8 *)ctx->public_key, 2 * nbytes,
crypto/ecdh.c:					 (u8 *)ctx->shared_secret, nbytes);
crypto/ecdh.c:		buf = ctx->shared_secret;
crypto/ecdh.c:		ret = ecdh_make_pub_key(ctx->curve_id, ctx->ndigits,
crypto/ecdh.c:					(const u8 *)ctx->private_key, nbytes,
crypto/ecdh.c:					(u8 *)ctx->public_key,
crypto/ecdh.c:					sizeof(ctx->public_key));
crypto/ecdh.c:		buf = ctx->public_key;
crypto/ecdh.c:	int nbytes = ctx->ndigits << ECC_DIGITS_TO_BYTES_SHIFT;
crypto/des_generic.c:	memcpy(dctx->expkey, tmp, sizeof(dctx->expkey));
crypto/des_generic.c:	const u32 *K = ctx->expkey;
crypto/des_generic.c:	const u32 *K = ctx->expkey + DES_EXPKEY_WORDS - 2;
crypto/des_generic.c:	u32 *expkey = dctx->expkey;
crypto/des_generic.c:	const u32 *K = dctx->expkey;
crypto/des_generic.c:	const u32 *K = dctx->expkey + DES3_EDE_EXPKEY_WORDS - 2;
crypto/hmac.c:	struct crypto_shash *hash = ctx->hash;
crypto/hmac.c:	desc->tfm = ctx->hash;
crypto/hmac.c:	ctx->hash = hash;
crypto/hmac.c:	crypto_free_shash(ctx->hash);
crypto/xcbc.c:	u8 *consts = PTR_ALIGN(&ctx->ctx[0], alignmask + 1);
crypto/xcbc.c:	if ((err = crypto_cipher_setkey(ctx->child, inkey, keylen)))
crypto/xcbc.c:	crypto_cipher_encrypt_one(ctx->child, consts, (u8 *)ks + bs);
crypto/xcbc.c:	crypto_cipher_encrypt_one(ctx->child, consts + bs, (u8 *)ks + bs * 2);
crypto/xcbc.c:	crypto_cipher_encrypt_one(ctx->child, key1, (u8 *)ks);
crypto/xcbc.c:	return crypto_cipher_setkey(ctx->child, key1, bs);
crypto/xcbc.c:	u8 *prev = PTR_ALIGN(&ctx->ctx[0], alignmask + 1) + bs;
crypto/xcbc.c:	ctx->len = 0;
crypto/xcbc.c:	struct crypto_cipher *tfm = tctx->child;
crypto/xcbc.c:	u8 *odds = PTR_ALIGN(&ctx->ctx[0], alignmask + 1);
crypto/xcbc.c:	if ((ctx->len + len) <= bs) {
crypto/xcbc.c:		memcpy(odds + ctx->len, p, len);
crypto/xcbc.c:		ctx->len += len;
crypto/xcbc.c:	memcpy(odds + ctx->len, p, bs - ctx->len);
crypto/xcbc.c:	len -= bs - ctx->len;
crypto/xcbc.c:	p += bs - ctx->len;
crypto/xcbc.c:	ctx->len = 0;
crypto/xcbc.c:		ctx->len = len;
crypto/xcbc.c:	struct crypto_cipher *tfm = tctx->child;
crypto/xcbc.c:	u8 *consts = PTR_ALIGN(&tctx->ctx[0], alignmask + 1);
crypto/xcbc.c:	u8 *odds = PTR_ALIGN(&ctx->ctx[0], alignmask + 1);
crypto/xcbc.c:	if (ctx->len != bs) {
crypto/xcbc.c:		u8 *p = odds + ctx->len;
crypto/xcbc.c:		rlen = bs - ctx->len -1;
crypto/xcbc.c:	ctx->child = cipher;
crypto/xcbc.c:	crypto_free_cipher(ctx->child);
crypto/seed.c:	u32 *keyout = ctx->keysched;
crypto/seed.c:	const u32 *ks = ctx->keysched;
crypto/seed.c:	const u32 *ks = ctx->keysched;
crypto/vmac.c:	ctx->polytmp[0] = ctx->polykey[0] ;
crypto/vmac.c:	ctx->polytmp[1] = ctx->polykey[1] ;
crypto/vmac.c:	ctx->first_block_processed = 0;
crypto/vmac.c:	const u64 *kptr = (u64 *)ctx->nhkey;
crypto/vmac.c:	u64 pkh = ctx->polykey[0];
crypto/vmac.c:	u64 pkl = ctx->polykey[1];
crypto/vmac.c:	ch = ctx->polytmp[0];
crypto/vmac.c:	cl = ctx->polytmp[1];
crypto/vmac.c:	if (!ctx->first_block_processed) {
crypto/vmac.c:		ctx->first_block_processed = 1;
crypto/vmac.c:	ctx->polytmp[0] = ch;
crypto/vmac.c:	ctx->polytmp[1] = cl;
crypto/vmac.c:	const u64 *kptr = (u64 *)ctx->nhkey;
crypto/vmac.c:	u64 pkh = ctx->polykey[0];
crypto/vmac.c:	u64 pkl = ctx->polykey[1];
crypto/vmac.c:	if (ctx->first_block_processed) {
crypto/vmac.c:		ch = ctx->polytmp[0];
crypto/vmac.c:		cl = ctx->polytmp[1];
crypto/vmac.c:	return l3hash(ch, cl, ctx->l3key[0], ctx->l3key[1], remaining);
crypto/vmac.c:	in_n = ctx->__vmac_ctx.cached_nonce;
crypto/vmac.c:	out_p = ctx->__vmac_ctx.cached_aes;
crypto/vmac.c:		crypto_cipher_encrypt_one(ctx->child,
crypto/vmac.c:	h = vhash(m, mbytes, (u64 *)0, &ctx->__vmac_ctx);
crypto/vmac.c:	err = crypto_cipher_setkey(ctx->child, user_key, VMAC_KEY_LEN);
crypto/vmac.c:	for (i = 0; i < sizeof(ctx->__vmac_ctx.nhkey)/8; i += 2) {
crypto/vmac.c:		crypto_cipher_encrypt_one(ctx->child,
crypto/vmac.c:		ctx->__vmac_ctx.nhkey[i] = be64_to_cpup(out);
crypto/vmac.c:		ctx->__vmac_ctx.nhkey[i+1] = be64_to_cpup(out+1);
crypto/vmac.c:	for (i = 0; i < sizeof(ctx->__vmac_ctx.polykey)/8; i += 2) {
crypto/vmac.c:		crypto_cipher_encrypt_one(ctx->child,
crypto/vmac.c:		ctx->__vmac_ctx.polytmp[i] =
crypto/vmac.c:			ctx->__vmac_ctx.polykey[i] =
crypto/vmac.c:		ctx->__vmac_ctx.polytmp[i+1] =
crypto/vmac.c:			ctx->__vmac_ctx.polykey[i+1] =
crypto/vmac.c:	for (i = 0; i < sizeof(ctx->__vmac_ctx.l3key)/8; i += 2) {
crypto/vmac.c:			crypto_cipher_encrypt_one(ctx->child,
crypto/vmac.c:			ctx->__vmac_ctx.l3key[i] = be64_to_cpup(out);
crypto/vmac.c:			ctx->__vmac_ctx.l3key[i+1] = be64_to_cpup(out+1);
crypto/vmac.c:		} while (ctx->__vmac_ctx.l3key[i] >= p64
crypto/vmac.c:			|| ctx->__vmac_ctx.l3key[i+1] >= p64);
crypto/vmac.c:	ctx->__vmac_ctx.cached_nonce[0] = (u64)-1; /* Ensure illegal nonce */
crypto/vmac.c:	ctx->__vmac_ctx.cached_nonce[1] = (u64)0;  /* Ensure illegal nonce */
crypto/vmac.c:	ctx->__vmac_ctx.first_block_processed = 0;
crypto/vmac.c:	expand = VMAC_NHBYTES - ctx->partial_size > 0 ?
crypto/vmac.c:			VMAC_NHBYTES - ctx->partial_size : 0;
crypto/vmac.c:	memcpy(ctx->partial + ctx->partial_size, p, min);
crypto/vmac.c:	ctx->partial_size += min;
crypto/vmac.c:	vhash_update(ctx->partial, VMAC_NHBYTES, &ctx->__vmac_ctx);
crypto/vmac.c:	ctx->partial_size = 0;
crypto/vmac.c:		memcpy(ctx->partial, p + len - (len % VMAC_NHBYTES),
crypto/vmac.c:		ctx->partial_size = len % VMAC_NHBYTES;
crypto/vmac.c:	vhash_update(p, len - len % VMAC_NHBYTES, &ctx->__vmac_ctx);
crypto/vmac.c:	if (ctx->partial_size) {
crypto/vmac.c:		memset(ctx->partial + ctx->partial_size, 0,
crypto/vmac.c:			VMAC_NHBYTES - ctx->partial_size);
crypto/vmac.c:	mac = vmac(ctx->partial, ctx->partial_size, nonce, NULL, ctx);
crypto/vmac.c:	memset(&ctx->__vmac_ctx, 0, sizeof(struct vmac_ctx));
crypto/vmac.c:	ctx->partial_size = 0;
crypto/vmac.c:	ctx->child = cipher;
crypto/vmac.c:	crypto_free_cipher(ctx->child);
crypto/serpent_generic.c:	u32 *k = ctx->expkey;
crypto/serpent_generic.c:	const u32 *k = ctx->expkey;
crypto/serpent_generic.c:	const u32 *k = ctx->expkey;
crypto/ghash-generic.c:	if (ctx->gf128)
crypto/ghash-generic.c:		gf128mul_free_4k(ctx->gf128);
crypto/ghash-generic.c:	ctx->gf128 = gf128mul_init_4k_lle((be128 *)key);
crypto/ghash-generic.c:	if (!ctx->gf128)
crypto/ghash-generic.c:	u8 *dst = dctx->buffer;
crypto/ghash-generic.c:	if (!ctx->gf128)
crypto/ghash-generic.c:	if (dctx->bytes) {
crypto/ghash-generic.c:		int n = min(srclen, dctx->bytes);
crypto/ghash-generic.c:		u8 *pos = dst + (GHASH_BLOCK_SIZE - dctx->bytes);
crypto/ghash-generic.c:		dctx->bytes -= n;
crypto/ghash-generic.c:		if (!dctx->bytes)
crypto/ghash-generic.c:			gf128mul_4k_lle((be128 *)dst, ctx->gf128);
crypto/ghash-generic.c:		gf128mul_4k_lle((be128 *)dst, ctx->gf128);
crypto/ghash-generic.c:		dctx->bytes = GHASH_BLOCK_SIZE - srclen;
crypto/ghash-generic.c:	u8 *dst = dctx->buffer;
crypto/ghash-generic.c:	if (dctx->bytes) {
crypto/ghash-generic.c:		u8 *tmp = dst + (GHASH_BLOCK_SIZE - dctx->bytes);
crypto/ghash-generic.c:		while (dctx->bytes--)
crypto/ghash-generic.c:		gf128mul_4k_lle((be128 *)dst, ctx->gf128);
crypto/ghash-generic.c:	dctx->bytes = 0;
crypto/ghash-generic.c:	u8 *buf = dctx->buffer;
crypto/ghash-generic.c:	if (!ctx->gf128)
crypto/ghash-generic.c:	if (ctx->gf128)
crypto/ghash-generic.c:		gf128mul_free_4k(ctx->gf128);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x0]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x1]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x2]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x3]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x4]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x5]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x6]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x7]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x8]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x9]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xa]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xb]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xc]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xd]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xe]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xf]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xf]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xe]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xd]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xc]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0xb]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0xa]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x9]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x8]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x7]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x6]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x5]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x4]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x3]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x2]);
crypto/fcrypt.c:	F_ENCRYPT(X.l, X.r, ctx->sched[0x1]);
crypto/fcrypt.c:	F_ENCRYPT(X.r, X.l, ctx->sched[0x0]);
crypto/fcrypt.c:	ctx->sched[0x0] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x1] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x2] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x3] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x4] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x5] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x6] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x7] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x8] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0x9] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xa] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xb] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xc] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xd] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xe] = cpu_to_be32(k); ror56_64(k, 11);
crypto/fcrypt.c:	ctx->sched[0xf] = cpu_to_be32(k);
crypto/fcrypt.c:	ctx->sched[0x0] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x1] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x2] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x3] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x4] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x5] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x6] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x7] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x8] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0x9] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xa] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xb] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xc] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xd] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xe] = cpu_to_be32(lo); ror56(hi, lo, 11);
crypto/fcrypt.c:	ctx->sched[0xf] = cpu_to_be32(lo);
crypto/dh.c:	mpi_free(ctx->p);
crypto/dh.c:	mpi_free(ctx->g);
crypto/dh.c:	mpi_free(ctx->xa);
crypto/dh.c:	return mpi_powm(val, base, ctx->xa, ctx->p);
crypto/dh.c:	ctx->p = mpi_read_raw_data(params->p, params->p_size);
crypto/dh.c:	if (!ctx->p)
crypto/dh.c:	ctx->g = mpi_read_raw_data(params->g, params->g_size);
crypto/dh.c:	if (!ctx->g)
crypto/dh.c:	ctx->xa = mpi_read_raw_data(params.key, params.key_size);
crypto/dh.c:	if (!ctx->xa)
crypto/dh.c:	if (unlikely(!ctx->xa)) {
crypto/dh.c:		base = ctx->g;
crypto/dh.c:	return mpi_get_size(ctx->p);
crypto/sha3_generic.c:	sctx->md_len = digest_sz;
crypto/sha3_generic.c:	sctx->rsiz = 200 - 2 * digest_sz;
crypto/sha3_generic.c:	sctx->rsizw = sctx->rsiz / 8;
crypto/sha3_generic.c:	if ((sctx->partial + len) > (sctx->rsiz - 1)) {
crypto/sha3_generic.c:		if (sctx->partial) {
crypto/sha3_generic.c:			done = -sctx->partial;
crypto/sha3_generic.c:			memcpy(sctx->buf + sctx->partial, data,
crypto/sha3_generic.c:			       done + sctx->rsiz);
crypto/sha3_generic.c:			src = sctx->buf;
crypto/sha3_generic.c:			for (i = 0; i < sctx->rsizw; i++)
crypto/sha3_generic.c:				sctx->st[i] ^= ((u64 *) src)[i];
crypto/sha3_generic.c:			keccakf(sctx->st);
crypto/sha3_generic.c:			done += sctx->rsiz;
crypto/sha3_generic.c:		} while (done + (sctx->rsiz - 1) < len);
crypto/sha3_generic.c:		sctx->partial = 0;
crypto/sha3_generic.c:	memcpy(sctx->buf + sctx->partial, src, len - done);
crypto/sha3_generic.c:	sctx->partial += (len - done);
crypto/sha3_generic.c:	unsigned int i, inlen = sctx->partial;
crypto/sha3_generic.c:	sctx->buf[inlen++] = 0x06;
crypto/sha3_generic.c:	memset(sctx->buf + inlen, 0, sctx->rsiz - inlen);
crypto/sha3_generic.c:	sctx->buf[sctx->rsiz - 1] |= 0x80;
crypto/sha3_generic.c:	for (i = 0; i < sctx->rsizw; i++)
crypto/sha3_generic.c:		sctx->st[i] ^= ((u64 *) sctx->buf)[i];
crypto/sha3_generic.c:	keccakf(sctx->st);
crypto/sha3_generic.c:	for (i = 0; i < sctx->rsizw; i++)
crypto/sha3_generic.c:		sctx->st[i] = cpu_to_le64(sctx->st[i]);
crypto/sha3_generic.c:	memcpy(out, sctx->st, sctx->md_len);
crypto/twofish_generic.c:     (ctx->s[0][(a) & 0xFF]) ^ (ctx->s[1][((a) >> 8) & 0xFF]) \
crypto/twofish_generic.c:   ^ (ctx->s[2][((a) >> 16) & 0xFF]) ^ (ctx->s[3][(a) >> 24])
crypto/twofish_generic.c:     (ctx->s[1][(b) & 0xFF]) ^ (ctx->s[2][((b) >> 8) & 0xFF]) \
crypto/twofish_generic.c:   ^ (ctx->s[3][((b) >> 16) & 0xFF]) ^ (ctx->s[0][(b) >> 24])
crypto/twofish_generic.c:   x += y; y += x + ctx->k[2 * (n) + 1]; \
crypto/twofish_generic.c:   (c) ^= x + ctx->k[2 * (n)]; \
crypto/twofish_generic.c:   (d) ^= y + ctx->k[2 * (n) + 1]; \
crypto/twofish_generic.c:   (c) ^= (x + ctx->k[2 * (n)])
crypto/twofish_generic.c:   x = le32_to_cpu(src[n]) ^ ctx->w[m]
crypto/twofish_generic.c:   x ^= ctx->w[m]; \
crypto/aead.c:	return crypto_aead_setkey(ctx->child, key, keylen);
crypto/aead.c:	return crypto_aead_setauthsize(ctx->child, authsize);
crypto/aead.c:	spin_lock_init(&ctx->lock);
crypto/aead.c:	err = crypto_rng_get_bytes(crypto_default_rng, ctx->salt,
crypto/aead.c:	ctx->sknull = crypto_get_default_null_skcipher2();
crypto/aead.c:	err = PTR_ERR(ctx->sknull);
crypto/aead.c:	if (IS_ERR(ctx->sknull))
crypto/aead.c:	ctx->child = child;
crypto/aead.c:	crypto_free_aead(ctx->child);
crypto/rmd160.c:	rctx->byte_count = 0;
crypto/rmd160.c:	rctx->state[0] = RMD_H0;
crypto/rmd160.c:	rctx->state[1] = RMD_H1;
crypto/rmd160.c:	rctx->state[2] = RMD_H2;
crypto/rmd160.c:	rctx->state[3] = RMD_H3;
crypto/rmd160.c:	rctx->state[4] = RMD_H4;
crypto/rmd160.c:	memset(rctx->buffer, 0, sizeof(rctx->buffer));
crypto/rmd160.c:	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
crypto/rmd160.c:	rctx->byte_count += len;
crypto/rmd160.c:		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd160.c:	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd160.c:	rmd160_transform(rctx->state, rctx->buffer);
crypto/rmd160.c:	while (len >= sizeof(rctx->buffer)) {
crypto/rmd160.c:		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
crypto/rmd160.c:		rmd160_transform(rctx->state, rctx->buffer);
crypto/rmd160.c:		data += sizeof(rctx->buffer);
crypto/rmd160.c:		len -= sizeof(rctx->buffer);
crypto/rmd160.c:	memcpy(rctx->buffer, data, len);
crypto/rmd160.c:	bits = cpu_to_le64(rctx->byte_count << 3);
crypto/rmd160.c:	index = rctx->byte_count & 0x3f;
crypto/rmd160.c:		dst[i] = cpu_to_le32p(&rctx->state[i]);
crypto/chacha20poly1305.c:	memcpy(iv + sizeof(leicb), ctx->salt, ctx->saltlen);
crypto/chacha20poly1305.c:	memcpy(iv + sizeof(leicb) + ctx->saltlen, req->iv,
crypto/chacha20poly1305.c:	       CHACHA20_IV_SIZE - sizeof(leicb) - ctx->saltlen);
crypto/chacha20poly1305.c:	u8 tag[sizeof(rctx->tag)];
crypto/chacha20poly1305.c:				 req->assoclen + rctx->cryptlen,
crypto/chacha20poly1305.c:	if (crypto_memneq(tag, rctx->tag, sizeof(tag)))
crypto/chacha20poly1305.c:	scatterwalk_map_and_copy(rctx->tag, req->dst,
crypto/chacha20poly1305.c:				 req->assoclen + rctx->cryptlen,
crypto/chacha20poly1305.c:				 sizeof(rctx->tag), 1);
crypto/chacha20poly1305.c:	struct chacha_req *creq = &rctx->u.chacha;
crypto/chacha20poly1305.c:	if (rctx->cryptlen == 0)
crypto/chacha20poly1305.c:	sg_init_table(rctx->src, 2);
crypto/chacha20poly1305.c:	src = scatterwalk_ffwd(rctx->src, req->src, req->assoclen);
crypto/chacha20poly1305.c:		sg_init_table(rctx->dst, 2);
crypto/chacha20poly1305.c:		dst = scatterwalk_ffwd(rctx->dst, req->dst, req->assoclen);
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:				   rctx->cryptlen, creq->iv);
crypto/chacha20poly1305.c:	if (rctx->cryptlen == req->cryptlen) /* encrypting */
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	len = cpu_to_le64(rctx->assoclen);
crypto/chacha20poly1305.c:	len = cpu_to_le64(rctx->cryptlen);
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:				rctx->tag, sizeof(preq->tail));
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	padlen = (bs - (rctx->cryptlen % bs)) % bs;
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	if (rctx->cryptlen == req->cryptlen) /* encrypting */
crypto/chacha20poly1305.c:	sg_init_table(rctx->src, 2);
crypto/chacha20poly1305.c:	crypt = scatterwalk_ffwd(rctx->src, crypt, req->assoclen);
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, crypt, NULL, rctx->cryptlen);
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	padlen = (bs - (rctx->assoclen % bs)) % bs;
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, req->src, NULL, rctx->assoclen);
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	sg_set_buf(preq->src, rctx->key, sizeof(rctx->key));
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, preq->src, NULL, sizeof(rctx->key));
crypto/chacha20poly1305.c:	struct poly_req *preq = &rctx->u.poly;
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	struct chacha_req *creq = &rctx->u.chacha;
crypto/chacha20poly1305.c:	rctx->assoclen = req->assoclen;
crypto/chacha20poly1305.c:		if (rctx->assoclen < 8)
crypto/chacha20poly1305.c:		rctx->assoclen -= 8;
crypto/chacha20poly1305.c:	memset(rctx->key, 0, sizeof(rctx->key));
crypto/chacha20poly1305.c:	sg_set_buf(creq->src, rctx->key, sizeof(rctx->key));
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:	struct chacha_req *creq = &rctx->u.chacha;
crypto/chacha20poly1305.c:	sg_init_table(rctx->src, 2);
crypto/chacha20poly1305.c:	src = scatterwalk_ffwd(rctx->src, req->src, req->assoclen);
crypto/chacha20poly1305.c:		sg_init_table(rctx->dst, 2);
crypto/chacha20poly1305.c:		dst = scatterwalk_ffwd(rctx->dst, req->dst, req->assoclen);
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:	rctx->cryptlen = req->cryptlen;
crypto/chacha20poly1305.c:	rctx->cryptlen = req->cryptlen - POLY1305_DIGEST_SIZE;
crypto/chacha20poly1305.c:	if (keylen != ctx->saltlen + CHACHA20_KEY_SIZE)
crypto/chacha20poly1305.c:	keylen -= ctx->saltlen;
crypto/chacha20poly1305.c:	memcpy(ctx->salt, key + keylen, ctx->saltlen);
crypto/chacha20poly1305.c:	crypto_skcipher_clear_flags(ctx->chacha, CRYPTO_TFM_REQ_MASK);
crypto/chacha20poly1305.c:	crypto_skcipher_set_flags(ctx->chacha, crypto_aead_get_flags(aead) &
crypto/chacha20poly1305.c:	err = crypto_skcipher_setkey(ctx->chacha, key, keylen);
crypto/chacha20poly1305.c:	crypto_aead_set_flags(aead, crypto_skcipher_get_flags(ctx->chacha) &
crypto/chacha20poly1305.c:	poly = crypto_spawn_ahash(&ictx->poly);
crypto/chacha20poly1305.c:	chacha = crypto_spawn_skcipher2(&ictx->chacha);
crypto/chacha20poly1305.c:	ctx->chacha = chacha;
crypto/chacha20poly1305.c:	ctx->poly = poly;
crypto/chacha20poly1305.c:	ctx->saltlen = ictx->saltlen;
crypto/chacha20poly1305.c:	crypto_free_ahash(ctx->poly);
crypto/chacha20poly1305.c:	crypto_free_skcipher(ctx->chacha);
crypto/chacha20poly1305.c:	crypto_drop_skcipher(&ctx->chacha);
crypto/chacha20poly1305.c:	crypto_drop_ahash(&ctx->poly);
crypto/chacha20poly1305.c:	ctx->saltlen = CHACHAPOLY_IV_SIZE - ivsize;
crypto/chacha20poly1305.c:	err = crypto_init_ahash_spawn(&ctx->poly, poly_hash,
crypto/chacha20poly1305.c:	crypto_set_skcipher_spawn(&ctx->chacha, aead_crypto_instance(inst));
crypto/chacha20poly1305.c:	err = crypto_grab_skcipher2(&ctx->chacha, chacha_name, 0,
crypto/chacha20poly1305.c:	chacha = crypto_spawn_skcipher_alg(&ctx->chacha);
crypto/chacha20poly1305.c:				     ctx->saltlen;
crypto/chacha20poly1305.c:	crypto_drop_skcipher(&ctx->chacha);
crypto/chacha20poly1305.c:	crypto_drop_ahash(&ctx->poly);
crypto/ccm.c:	struct crypto_skcipher *ctr = ctx->ctr;
crypto/ccm.c:	struct crypto_cipher *tfm = ctx->cipher;
crypto/ccm.c:	u8 *odata = pctx->odata;
crypto/ccm.c:	u8 *idata = pctx->idata;
crypto/ccm.c:	getlen = bs - pctx->ilen;
crypto/ccm.c:		memcpy(idata + pctx->ilen, data, getlen);
crypto/ccm.c:		pctx->ilen = 0;
crypto/ccm.c:		memcpy(idata + pctx->ilen, data, datalen);
crypto/ccm.c:		pctx->ilen += datalen;
crypto/ccm.c:			crypto_yield(pctx->flags);
crypto/ccm.c:	if (pctx->ilen) {
crypto/ccm.c:		u8 *odata = pctx->odata;
crypto/ccm.c:		u8 *idata = pctx->idata;
crypto/ccm.c:		padlen = 16 - pctx->ilen;
crypto/ccm.c:		memset(idata + pctx->ilen, 0, padlen);
crypto/ccm.c:		pctx->ilen = 0;
crypto/ccm.c:	struct crypto_cipher *cipher = ctx->cipher;
crypto/ccm.c:	u8 *odata = pctx->odata;
crypto/ccm.c:	u8 *idata = pctx->idata;
crypto/ccm.c:		pctx->ilen = format_adata(idata, assoclen);
crypto/ccm.c:		pctx->ilen = 0;
crypto/ccm.c:	u8 *odata = pctx->odata;
crypto/ccm.c:	pctx->flags = aead_request_flags(req);
crypto/ccm.c:	sg_init_table(pctx->src, 3);
crypto/ccm.c:	sg_set_buf(pctx->src, tag, 16);
crypto/ccm.c:	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
crypto/ccm.c:	if (sg != pctx->src + 1)
crypto/ccm.c:		sg_chain(pctx->src, 2, sg);
crypto/ccm.c:		sg_init_table(pctx->dst, 3);
crypto/ccm.c:		sg_set_buf(pctx->dst, tag, 16);
crypto/ccm.c:		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
crypto/ccm.c:		if (sg != pctx->dst + 1)
crypto/ccm.c:			sg_chain(pctx->dst, 2, sg);
crypto/ccm.c:	struct skcipher_request *skreq = &pctx->skreq;
crypto/ccm.c:	u8 *odata = pctx->odata;
crypto/ccm.c:	err = crypto_ccm_auth(req, sg_next(pctx->src), cryptlen);
crypto/ccm.c:	dst = pctx->src;
crypto/ccm.c:		dst = pctx->dst;
crypto/ccm.c:	skcipher_request_set_tfm(skreq, ctx->ctr);
crypto/ccm.c:	skcipher_request_set_callback(skreq, pctx->flags,
crypto/ccm.c:	skcipher_request_set_crypt(skreq, pctx->src, dst, cryptlen + 16, iv);
crypto/ccm.c:	pctx->flags = 0;
crypto/ccm.c:	dst = sg_next(req->src == req->dst ? pctx->src : pctx->dst);
crypto/ccm.c:		if (!err && crypto_memneq(pctx->auth_tag, pctx->odata, authsize))
crypto/ccm.c:	struct skcipher_request *skreq = &pctx->skreq;
crypto/ccm.c:	u8 *authtag = pctx->auth_tag;
crypto/ccm.c:	u8 *odata = pctx->odata;
crypto/ccm.c:	u8 *iv = pctx->idata;
crypto/ccm.c:	scatterwalk_map_and_copy(authtag, sg_next(pctx->src), cryptlen,
crypto/ccm.c:	dst = pctx->src;
crypto/ccm.c:		dst = pctx->dst;
crypto/ccm.c:	skcipher_request_set_tfm(skreq, ctx->ctr);
crypto/ccm.c:	skcipher_request_set_callback(skreq, pctx->flags,
crypto/ccm.c:	skcipher_request_set_crypt(skreq, pctx->src, dst, cryptlen + 16, iv);
crypto/ccm.c:	cipher = crypto_spawn_cipher(&ictx->cipher);
crypto/ccm.c:	ctr = crypto_spawn_skcipher2(&ictx->ctr);
crypto/ccm.c:	ctx->cipher = cipher;
crypto/ccm.c:	ctx->ctr = ctr;
crypto/ccm.c:	crypto_free_cipher(ctx->cipher);
crypto/ccm.c:	crypto_free_skcipher(ctx->ctr);
crypto/ccm.c:	crypto_drop_spawn(&ctx->cipher);
crypto/ccm.c:	crypto_drop_skcipher(&ctx->ctr);
crypto/ccm.c:	err = crypto_init_spawn(&ictx->cipher, cipher,
crypto/ccm.c:	crypto_set_skcipher_spawn(&ictx->ctr, aead_crypto_instance(inst));
crypto/ccm.c:	err = crypto_grab_skcipher2(&ictx->ctr, ctr_name, 0,
crypto/ccm.c:	ctr = crypto_spawn_skcipher_alg(&ictx->ctr);
crypto/ccm.c:	crypto_drop_skcipher(&ictx->ctr);
crypto/ccm.c:	crypto_drop_spawn(&ictx->cipher);
crypto/ccm.c:	struct crypto_aead *child = ctx->child;
crypto/ccm.c:	memcpy(ctx->nonce, key + keylen, 3);
crypto/ccm.c:	return crypto_aead_setauthsize(ctx->child, authsize);
crypto/ccm.c:	struct aead_request *subreq = &rctx->subreq;
crypto/ccm.c:	struct crypto_aead *child = ctx->child;
crypto/ccm.c:	memcpy(iv + 1, ctx->nonce, 3);
crypto/ccm.c:	sg_init_table(rctx->src, 3);
crypto/ccm.c:	sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
crypto/ccm.c:	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
crypto/ccm.c:	if (sg != rctx->src + 1)
crypto/ccm.c:		sg_chain(rctx->src, 2, sg);
crypto/ccm.c:		sg_init_table(rctx->dst, 3);
crypto/ccm.c:		sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
crypto/ccm.c:		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
crypto/ccm.c:		if (sg != rctx->dst + 1)
crypto/ccm.c:			sg_chain(rctx->dst, 2, sg);
crypto/ccm.c:	aead_request_set_crypt(subreq, rctx->src,
crypto/ccm.c:			       req->src == req->dst ? rctx->src : rctx->dst,
crypto/ccm.c:	ctx->child = aead;
crypto/ccm.c:	crypto_free_aead(ctx->child);
crypto/gcm.c:	struct crypto_ahash *ghash = ctx->ghash;
crypto/gcm.c:	struct crypto_skcipher *ctr = ctx->ctr;
crypto/gcm.c:	memset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));
crypto/gcm.c:	memcpy(pctx->iv, req->iv, 12);
crypto/gcm.c:	memcpy(pctx->iv + 12, &counter, 4);
crypto/gcm.c:	sg_init_table(pctx->src, 3);
crypto/gcm.c:	sg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));
crypto/gcm.c:	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
crypto/gcm.c:	if (sg != pctx->src + 1)
crypto/gcm.c:		sg_chain(pctx->src, 2, sg);
crypto/gcm.c:		sg_init_table(pctx->dst, 3);
crypto/gcm.c:		sg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));
crypto/gcm.c:		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
crypto/gcm.c:		if (sg != pctx->dst + 1)
crypto/gcm.c:			sg_chain(pctx->dst, 2, sg);
crypto/gcm.c:	struct skcipher_request *skreq = &pctx->u.skreq;
crypto/gcm.c:	dst = req->src == req->dst ? pctx->src : pctx->dst;
crypto/gcm.c:	skcipher_request_set_tfm(skreq, ctx->ctr);
crypto/gcm.c:	skcipher_request_set_crypt(skreq, pctx->src, dst,
crypto/gcm.c:				     cryptlen + sizeof(pctx->auth_tag),
crypto/gcm.c:				     pctx->iv);
crypto/gcm.c:	struct ahash_request *ahreq = &pctx->u.ahreq;
crypto/gcm.c:	struct ahash_request *ahreq = &pctx->u.ahreq;
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	lengths.b = cpu_to_be64(gctx->cryptlen * 8);
crypto/gcm.c:	memcpy(pctx->iauth_tag, &lengths, 16);
crypto/gcm.c:	sg_init_one(&pctx->sg, pctx->iauth_tag, 16);
crypto/gcm.c:	ahash_request_set_crypt(ahreq, &pctx->sg,
crypto/gcm.c:				pctx->iauth_tag, sizeof(lengths));
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	return gctx->complete(req, flags);
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	remain = gcm_remain(gctx->cryptlen);
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	if (gctx->cryptlen)
crypto/gcm.c:				       gctx->src, gctx->cryptlen, flags) ?:
crypto/gcm.c:	struct ahash_request *ahreq = &pctx->u.ahreq;
crypto/gcm.c:	ahash_request_set_tfm(ahreq, ctx->ghash);
crypto/gcm.c:	u8 *auth_tag = pctx->auth_tag;
crypto/gcm.c:	crypto_xor(auth_tag, pctx->iauth_tag, 16);
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	gctx->src = sg_next(req->src == req->dst ? pctx->src : pctx->dst);
crypto/gcm.c:	gctx->cryptlen = req->cryptlen;
crypto/gcm.c:	gctx->complete = gcm_enc_copy_hash;
crypto/gcm.c:	struct skcipher_request *skreq = &pctx->u.skreq;
crypto/gcm.c:	u8 *auth_tag = pctx->auth_tag;
crypto/gcm.c:	u8 *iauth_tag = pctx->iauth_tag;
crypto/gcm.c:	struct skcipher_request *skreq = &pctx->u.skreq;
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	crypto_gcm_init_crypt(req, gctx->cryptlen);
crypto/gcm.c:	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;
crypto/gcm.c:	gctx->src = sg_next(pctx->src);
crypto/gcm.c:	gctx->cryptlen = cryptlen;
crypto/gcm.c:	gctx->complete = gcm_dec_hash_continue;
crypto/gcm.c:	ghash = crypto_spawn_ahash(&ictx->ghash);
crypto/gcm.c:	ctr = crypto_spawn_skcipher2(&ictx->ctr);
crypto/gcm.c:	ctx->ctr = ctr;
crypto/gcm.c:	ctx->ghash = ghash;
crypto/gcm.c:	crypto_free_ahash(ctx->ghash);
crypto/gcm.c:	crypto_free_skcipher(ctx->ctr);
crypto/gcm.c:	crypto_drop_skcipher(&ctx->ctr);
crypto/gcm.c:	crypto_drop_ahash(&ctx->ghash);
crypto/gcm.c:	err = crypto_init_ahash_spawn(&ctx->ghash, ghash,
crypto/gcm.c:	crypto_set_skcipher_spawn(&ctx->ctr, aead_crypto_instance(inst));
crypto/gcm.c:	err = crypto_grab_skcipher2(&ctx->ctr, ctr_name, 0,
crypto/gcm.c:	ctr = crypto_spawn_skcipher_alg(&ctx->ctr);
crypto/gcm.c:	crypto_drop_skcipher(&ctx->ctr);
crypto/gcm.c:	crypto_drop_ahash(&ctx->ghash);
crypto/gcm.c:	struct crypto_aead *child = ctx->child;
crypto/gcm.c:	memcpy(ctx->nonce, key + keylen, 4);
crypto/gcm.c:	return crypto_aead_setauthsize(ctx->child, authsize);
crypto/gcm.c:	struct aead_request *subreq = &rctx->subreq;
crypto/gcm.c:	struct crypto_aead *child = ctx->child;
crypto/gcm.c:	memcpy(iv, ctx->nonce, 4);
crypto/gcm.c:	sg_init_table(rctx->src, 3);
crypto/gcm.c:	sg_set_buf(rctx->src, iv + 12, req->assoclen - 8);
crypto/gcm.c:	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
crypto/gcm.c:	if (sg != rctx->src + 1)
crypto/gcm.c:		sg_chain(rctx->src, 2, sg);
crypto/gcm.c:		sg_init_table(rctx->dst, 3);
crypto/gcm.c:		sg_set_buf(rctx->dst, iv + 12, req->assoclen - 8);
crypto/gcm.c:		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
crypto/gcm.c:		if (sg != rctx->dst + 1)
crypto/gcm.c:			sg_chain(rctx->dst, 2, sg);
crypto/gcm.c:	aead_request_set_crypt(subreq, rctx->src,
crypto/gcm.c:			       req->src == req->dst ? rctx->src : rctx->dst,
crypto/gcm.c:	ctx->child = aead;
crypto/gcm.c:	crypto_free_aead(ctx->child);
crypto/gcm.c:	struct crypto_aead *child = ctx->child;
crypto/gcm.c:	memcpy(ctx->nonce, key + keylen, 4);
crypto/gcm.c:	return crypto_aead_setauthsize(ctx->child, authsize);
crypto/gcm.c:	struct aead_request *subreq = &rctx->subreq;
crypto/gcm.c:	u8 *iv = PTR_ALIGN((u8 *)(rctx + 1) + crypto_aead_reqsize(ctx->child),
crypto/gcm.c:			   crypto_aead_alignmask(ctx->child) + 1);
crypto/gcm.c:	memcpy(iv, ctx->nonce, 4);
crypto/gcm.c:	aead_request_set_tfm(subreq, ctx->child);
crypto/gcm.c:	SKCIPHER_REQUEST_ON_STACK(nreq, ctx->null);
crypto/gcm.c:	skcipher_request_set_tfm(nreq, ctx->null);
crypto/gcm.c:	struct crypto_aead_spawn *spawn = &ictx->aead;
crypto/gcm.c:	ctx->child = aead;
crypto/gcm.c:	ctx->null = null;
crypto/gcm.c:	crypto_free_aead(ctx->child);
crypto/gcm.c:	crypto_drop_aead(&ctx->aead);
crypto/gcm.c:	spawn = &ctx->aead;
crypto/authencesn.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authencesn.c:	struct crypto_skcipher *enc = ctx->enc;
crypto/authencesn.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authencesn.c:	u8 *hash = PTR_ALIGN((u8 *)areq_ctx->tail,
crypto/authencesn.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authencesn.c:	u8 *hash = PTR_ALIGN((u8 *)areq_ctx->tail,
crypto/authencesn.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ctx->reqoff);
crypto/authencesn.c:	sg_init_table(areq_ctx->dst, 2);
crypto/authencesn.c:	dst = scatterwalk_ffwd(areq_ctx->dst, dst, 4);
crypto/authencesn.c:	SKCIPHER_REQUEST_ON_STACK(skreq, ctx->null);
crypto/authencesn.c:	skcipher_request_set_tfm(skreq, ctx->null);
crypto/authencesn.c:	struct skcipher_request *skreq = (void *)(areq_ctx->tail +
crypto/authencesn.c:						  ctx->reqoff);
crypto/authencesn.c:	struct crypto_skcipher *enc = ctx->enc;
crypto/authencesn.c:	sg_init_table(areq_ctx->src, 2);
crypto/authencesn.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, assoclen);
crypto/authencesn.c:		sg_init_table(areq_ctx->dst, 2);
crypto/authencesn.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, assoclen);
crypto/authencesn.c:	struct skcipher_request *skreq = (void *)(areq_ctx->tail +
crypto/authencesn.c:						  ctx->reqoff);
crypto/authencesn.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authencesn.c:	u8 *ohash = PTR_ALIGN((u8 *)areq_ctx->tail,
crypto/authencesn.c:	sg_init_table(areq_ctx->dst, 2);
crypto/authencesn.c:	dst = scatterwalk_ffwd(areq_ctx->dst, dst, assoclen);
crypto/authencesn.c:	skcipher_request_set_tfm(skreq, ctx->enc);
crypto/authencesn.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ctx->reqoff);
crypto/authencesn.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authencesn.c:	u8 *ohash = PTR_ALIGN((u8 *)areq_ctx->tail,
crypto/authencesn.c:	sg_init_table(areq_ctx->dst, 2);
crypto/authencesn.c:	dst = scatterwalk_ffwd(areq_ctx->dst, dst, 4);
crypto/authencesn.c:	auth = crypto_spawn_ahash(&ictx->auth);
crypto/authencesn.c:	enc = crypto_spawn_skcipher2(&ictx->enc);
crypto/authencesn.c:	ctx->auth = auth;
crypto/authencesn.c:	ctx->enc = enc;
crypto/authencesn.c:	ctx->null = null;
crypto/authencesn.c:	ctx->reqoff = ALIGN(2 * crypto_ahash_digestsize(auth),
crypto/authencesn.c:		ctx->reqoff +
crypto/authencesn.c:	crypto_free_ahash(ctx->auth);
crypto/authencesn.c:	crypto_free_skcipher(ctx->enc);
crypto/authencesn.c:	crypto_drop_skcipher(&ctx->enc);
crypto/authencesn.c:	crypto_drop_ahash(&ctx->auth);
crypto/authencesn.c:	err = crypto_init_ahash_spawn(&ctx->auth, auth,
crypto/authencesn.c:	crypto_set_skcipher_spawn(&ctx->enc, aead_crypto_instance(inst));
crypto/authencesn.c:	err = crypto_grab_skcipher2(&ctx->enc, enc_name, 0,
crypto/authencesn.c:	enc = crypto_spawn_skcipher_alg(&ctx->enc);
crypto/authencesn.c:	crypto_drop_skcipher(&ctx->enc);
crypto/authencesn.c:	crypto_drop_ahash(&ctx->auth);
crypto/blowfish_generic.c:	const u32 *P = ctx->p;
crypto/blowfish_generic.c:	const u32 *S = ctx->s;
crypto/blowfish_generic.c:	const u32 *P = ctx->p;
crypto/blowfish_generic.c:	const u32 *S = ctx->s;
crypto/ansi_cprng.c:	hexdump("Input DT: ", ctx->DT, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	hexdump("Input I: ", ctx->I, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	hexdump("Input V: ", ctx->V, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:			memcpy(tmp, ctx->DT, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:			output = ctx->I;
crypto/ansi_cprng.c:			xor_vectors(ctx->I, ctx->V, tmp, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:			output = ctx->rand_data;
crypto/ansi_cprng.c:			if (!memcmp(ctx->rand_data, ctx->last_rand_data,
crypto/ansi_cprng.c:				ctx->flags |= PRNG_NEED_RESET;
crypto/ansi_cprng.c:			memcpy(ctx->last_rand_data, ctx->rand_data,
crypto/ansi_cprng.c:			xor_vectors(ctx->rand_data, ctx->I, tmp,
crypto/ansi_cprng.c:			output = ctx->V;
crypto/ansi_cprng.c:		crypto_cipher_encrypt_one(ctx->tfm, output, tmp);
crypto/ansi_cprng.c:		ctx->DT[i] += 1;
crypto/ansi_cprng.c:		if (ctx->DT[i] != 0)
crypto/ansi_cprng.c:	ctx->rand_data_valid = 0;
crypto/ansi_cprng.c:	hexdump("Output DT: ", ctx->DT, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	hexdump("Output I: ", ctx->I, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	hexdump("Output V: ", ctx->V, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	hexdump("New Random Data: ", ctx->rand_data, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	spin_lock_bh(&ctx->prng_lock);
crypto/ansi_cprng.c:	if (ctx->flags & PRNG_NEED_RESET)
crypto/ansi_cprng.c:	if (ctx->flags & PRNG_FIXED_SIZE) {
crypto/ansi_cprng.c:	if (ctx->rand_data_valid == DEFAULT_BLK_SZ) {
crypto/ansi_cprng.c:		while (ctx->rand_data_valid < DEFAULT_BLK_SZ) {
crypto/ansi_cprng.c:			*ptr = ctx->rand_data[ctx->rand_data_valid];
crypto/ansi_cprng.c:			ctx->rand_data_valid++;
crypto/ansi_cprng.c:		if (ctx->rand_data_valid == DEFAULT_BLK_SZ) {
crypto/ansi_cprng.c:		if (ctx->rand_data_valid > 0)
crypto/ansi_cprng.c:		memcpy(ptr, ctx->rand_data, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:		ctx->rand_data_valid += DEFAULT_BLK_SZ;
crypto/ansi_cprng.c:	spin_unlock_bh(&ctx->prng_lock);
crypto/ansi_cprng.c:	crypto_free_cipher(ctx->tfm);
crypto/ansi_cprng.c:	spin_lock_bh(&ctx->prng_lock);
crypto/ansi_cprng.c:	ctx->flags |= PRNG_NEED_RESET;
crypto/ansi_cprng.c:		memcpy(ctx->V, V, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:		memcpy(ctx->V, DEFAULT_V_SEED, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:		memcpy(ctx->DT, DT, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:		memset(ctx->DT, 0, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	memset(ctx->rand_data, 0, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	memset(ctx->last_rand_data, 0, DEFAULT_BLK_SZ);
crypto/ansi_cprng.c:	ctx->rand_data_valid = DEFAULT_BLK_SZ;
crypto/ansi_cprng.c:	ret = crypto_cipher_setkey(ctx->tfm, prng_key, klen);
crypto/ansi_cprng.c:			crypto_cipher_get_flags(ctx->tfm));
crypto/ansi_cprng.c:	ctx->flags &= ~PRNG_NEED_RESET;
crypto/ansi_cprng.c:	spin_unlock_bh(&ctx->prng_lock);
crypto/ansi_cprng.c:	spin_lock_init(&ctx->prng_lock);
crypto/ansi_cprng.c:	ctx->tfm = crypto_alloc_cipher("aes", 0, 0);
crypto/ansi_cprng.c:	if (IS_ERR(ctx->tfm)) {
crypto/ansi_cprng.c:		return PTR_ERR(ctx->tfm);
crypto/ansi_cprng.c:	ctx->flags |= PRNG_NEED_RESET;
crypto/michael_mic.c:	mctx->pending_len = 0;
crypto/michael_mic.c:	mctx->l = ctx->l;
crypto/michael_mic.c:	mctx->r = ctx->r;
crypto/michael_mic.c:	if (mctx->pending_len) {
crypto/michael_mic.c:		int flen = 4 - mctx->pending_len;
crypto/michael_mic.c:		memcpy(&mctx->pending[mctx->pending_len], data, flen);
crypto/michael_mic.c:		mctx->pending_len += flen;
crypto/michael_mic.c:		if (mctx->pending_len < 4)
crypto/michael_mic.c:		src = (const __le32 *)mctx->pending;
crypto/michael_mic.c:		mctx->l ^= le32_to_cpup(src);
crypto/michael_mic.c:		michael_block(mctx->l, mctx->r);
crypto/michael_mic.c:		mctx->pending_len = 0;
crypto/michael_mic.c:		mctx->l ^= le32_to_cpup(src++);
crypto/michael_mic.c:		michael_block(mctx->l, mctx->r);
crypto/michael_mic.c:		mctx->pending_len = len;
crypto/michael_mic.c:		memcpy(mctx->pending, src, len);
crypto/michael_mic.c:	u8 *data = mctx->pending;
crypto/michael_mic.c:	switch (mctx->pending_len) {
crypto/michael_mic.c:		mctx->l ^= 0x5a;
crypto/michael_mic.c:		mctx->l ^= data[0] | 0x5a00;
crypto/michael_mic.c:		mctx->l ^= data[0] | (data[1] << 8) | 0x5a0000;
crypto/michael_mic.c:		mctx->l ^= data[0] | (data[1] << 8) | (data[2] << 16) |
crypto/michael_mic.c:	michael_block(mctx->l, mctx->r);
crypto/michael_mic.c:	michael_block(mctx->l, mctx->r);
crypto/michael_mic.c:	dst[0] = cpu_to_le32(mctx->l);
crypto/michael_mic.c:	dst[1] = cpu_to_le32(mctx->r);
crypto/michael_mic.c:	mctx->l = le32_to_cpu(data[0]);
crypto/michael_mic.c:	mctx->r = le32_to_cpu(data[1]);
crypto/rmd256.c:	rctx->byte_count = 0;
crypto/rmd256.c:	rctx->state[0] = RMD_H0;
crypto/rmd256.c:	rctx->state[1] = RMD_H1;
crypto/rmd256.c:	rctx->state[2] = RMD_H2;
crypto/rmd256.c:	rctx->state[3] = RMD_H3;
crypto/rmd256.c:	rctx->state[4] = RMD_H5;
crypto/rmd256.c:	rctx->state[5] = RMD_H6;
crypto/rmd256.c:	rctx->state[6] = RMD_H7;
crypto/rmd256.c:	rctx->state[7] = RMD_H8;
crypto/rmd256.c:	memset(rctx->buffer, 0, sizeof(rctx->buffer));
crypto/rmd256.c:	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
crypto/rmd256.c:	rctx->byte_count += len;
crypto/rmd256.c:		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd256.c:	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd256.c:	rmd256_transform(rctx->state, rctx->buffer);
crypto/rmd256.c:	while (len >= sizeof(rctx->buffer)) {
crypto/rmd256.c:		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
crypto/rmd256.c:		rmd256_transform(rctx->state, rctx->buffer);
crypto/rmd256.c:		data += sizeof(rctx->buffer);
crypto/rmd256.c:		len -= sizeof(rctx->buffer);
crypto/rmd256.c:	memcpy(rctx->buffer, data, len);
crypto/rmd256.c:	bits = cpu_to_le64(rctx->byte_count << 3);
crypto/rmd256.c:	index = rctx->byte_count & 0x3f;
crypto/rmd256.c:		dst[i] = cpu_to_le32p(&rctx->state[i]);
crypto/rmd128.c:	rctx->byte_count = 0;
crypto/rmd128.c:	rctx->state[0] = RMD_H0;
crypto/rmd128.c:	rctx->state[1] = RMD_H1;
crypto/rmd128.c:	rctx->state[2] = RMD_H2;
crypto/rmd128.c:	rctx->state[3] = RMD_H3;
crypto/rmd128.c:	memset(rctx->buffer, 0, sizeof(rctx->buffer));
crypto/rmd128.c:	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
crypto/rmd128.c:	rctx->byte_count += len;
crypto/rmd128.c:		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd128.c:	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd128.c:	rmd128_transform(rctx->state, rctx->buffer);
crypto/rmd128.c:	while (len >= sizeof(rctx->buffer)) {
crypto/rmd128.c:		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
crypto/rmd128.c:		rmd128_transform(rctx->state, rctx->buffer);
crypto/rmd128.c:		data += sizeof(rctx->buffer);
crypto/rmd128.c:		len -= sizeof(rctx->buffer);
crypto/rmd128.c:	memcpy(rctx->buffer, data, len);
crypto/rmd128.c:	bits = cpu_to_le64(rctx->byte_count << 3);
crypto/rmd128.c:	index = rctx->byte_count & 0x3f;
crypto/rmd128.c:		dst[i] = cpu_to_le32p(&rctx->state[i]);
crypto/deflate.c:	struct z_stream_s *stream = &ctx->comp_stream;
crypto/deflate.c:	struct z_stream_s *stream = &ctx->decomp_stream;
crypto/deflate.c:	zlib_deflateEnd(&ctx->comp_stream);
crypto/deflate.c:	vfree(ctx->comp_stream.workspace);
crypto/deflate.c:	zlib_inflateEnd(&ctx->decomp_stream);
crypto/deflate.c:	vfree(ctx->decomp_stream.workspace);
crypto/deflate.c:	struct z_stream_s *stream = &dctx->comp_stream;
crypto/deflate.c:	struct z_stream_s *stream = &dctx->decomp_stream;
crypto/ecb.c:	struct crypto_cipher *child = ctx->child;
crypto/ecb.c:	struct crypto_cipher *child = ctx->child;
crypto/ecb.c:	struct crypto_cipher *child = ctx->child;
crypto/ecb.c:	ctx->child = cipher;
crypto/ecb.c:	crypto_free_cipher(ctx->child);
crypto/xts.c:	struct crypto_cipher *child = ctx->tweak;
crypto/xts.c:	child = ctx->child;
crypto/xts.c:		.tfm = crypto_cipher_tfm(ctx->child),
crypto/xts.c:	tw(crypto_cipher_tfm(ctx->tweak), w->iv, w->iv);
crypto/xts.c:	return crypt(desc, &w, ctx, crypto_cipher_alg(ctx->tweak)->cia_encrypt,
crypto/xts.c:		     crypto_cipher_alg(ctx->child)->cia_encrypt);
crypto/xts.c:	return crypt(desc, &w, ctx, crypto_cipher_alg(ctx->tweak)->cia_encrypt,
crypto/xts.c:		     crypto_cipher_alg(ctx->child)->cia_decrypt);
crypto/xts.c:	ctx->child = cipher;
crypto/xts.c:		crypto_free_cipher(ctx->child);
crypto/xts.c:		crypto_free_cipher(ctx->child);
crypto/xts.c:	ctx->tweak = cipher;
crypto/xts.c:	crypto_free_cipher(ctx->child);
crypto/xts.c:	crypto_free_cipher(ctx->tweak);
crypto/algif_rng.c:	genlen = crypto_rng_get_bytes(ctx->drng, result, len);
crypto/algif_rng.c:	sock_kfree_s(sk, ctx, ctx->len);
crypto/algif_rng.c:	ctx->len = len;
crypto/algif_rng.c:	ctx->drng = private;
crypto/pcbc.c:	struct crypto_cipher *child = ctx->child;
crypto/pcbc.c:	struct crypto_cipher *child = ctx->child;
crypto/pcbc.c:	struct crypto_cipher *child = ctx->child;
crypto/pcbc.c:	ctx->child = cipher;
crypto/pcbc.c:	crypto_free_cipher(ctx->child);
crypto/842.c:	return sw842_compress(src, slen, dst, dlen, ctx->wmem);
crypto/rmd320.c:	rctx->byte_count = 0;
crypto/rmd320.c:	rctx->state[0] = RMD_H0;
crypto/rmd320.c:	rctx->state[1] = RMD_H1;
crypto/rmd320.c:	rctx->state[2] = RMD_H2;
crypto/rmd320.c:	rctx->state[3] = RMD_H3;
crypto/rmd320.c:	rctx->state[4] = RMD_H4;
crypto/rmd320.c:	rctx->state[5] = RMD_H5;
crypto/rmd320.c:	rctx->state[6] = RMD_H6;
crypto/rmd320.c:	rctx->state[7] = RMD_H7;
crypto/rmd320.c:	rctx->state[8] = RMD_H8;
crypto/rmd320.c:	rctx->state[9] = RMD_H9;
crypto/rmd320.c:	memset(rctx->buffer, 0, sizeof(rctx->buffer));
crypto/rmd320.c:	const u32 avail = sizeof(rctx->buffer) - (rctx->byte_count & 0x3f);
crypto/rmd320.c:	rctx->byte_count += len;
crypto/rmd320.c:		memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd320.c:	memcpy((char *)rctx->buffer + (sizeof(rctx->buffer) - avail),
crypto/rmd320.c:	rmd320_transform(rctx->state, rctx->buffer);
crypto/rmd320.c:	while (len >= sizeof(rctx->buffer)) {
crypto/rmd320.c:		memcpy(rctx->buffer, data, sizeof(rctx->buffer));
crypto/rmd320.c:		rmd320_transform(rctx->state, rctx->buffer);
crypto/rmd320.c:		data += sizeof(rctx->buffer);
crypto/rmd320.c:		len -= sizeof(rctx->buffer);
crypto/rmd320.c:	memcpy(rctx->buffer, data, len);
crypto/rmd320.c:	bits = cpu_to_le64(rctx->byte_count << 3);
crypto/rmd320.c:	index = rctx->byte_count & 0x3f;
crypto/rmd320.c:		dst[i] = cpu_to_le32p(&rctx->state[i]);
crypto/cts.c:	struct crypto_skcipher *child = ctx->child;
crypto/cts.c:	struct crypto_skcipher *child = ctx->child;
crypto/cts.c:	struct skcipher_request *subreq = &rctx->subreq;
crypto/cts.c:	offset = rctx->offset;
crypto/cts.c:	sg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);
crypto/cts.c:	struct skcipher_request *subreq = &rctx->subreq;
crypto/cts.c:	skcipher_request_set_tfm(subreq, ctx->child);
crypto/cts.c:	rctx->offset = offset;
crypto/cts.c:	struct skcipher_request *subreq = &rctx->subreq;
crypto/cts.c:	offset = rctx->offset;
crypto/cts.c:	sg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);
crypto/cts.c:	struct skcipher_request *subreq = &rctx->subreq;
crypto/cts.c:	skcipher_request_set_tfm(subreq, ctx->child);
crypto/cts.c:	rctx->offset = offset;
crypto/cts.c:	ctx->child = cipher;
crypto/cts.c:	crypto_free_skcipher(ctx->child);
crypto/mcryptd.c:	rctx->tag.cpu = cpu;
crypto/mcryptd.c:	return ictx->queue;
crypto/mcryptd.c:	struct crypto_ahash_spawn *spawn = &ictx->spawn;
crypto/mcryptd.c:	ctx->child = hash;
crypto/mcryptd.c:	crypto_free_ahash(ctx->child);
crypto/mcryptd.c:	struct crypto_ahash *child = ctx->child;
crypto/mcryptd.c:	rctx->complete = req->base.complete;
crypto/mcryptd.c:	struct crypto_ahash *child = ctx->child;
crypto/mcryptd.c:	struct ahash_request *desc = &rctx->areq;
crypto/mcryptd.c:						rctx->complete, req_async);
crypto/mcryptd.c:	rctx->out = req->result;
crypto/mcryptd.c:	rctx->complete(&req->base, err);
crypto/mcryptd.c:	rctx->out = req->result;
crypto/mcryptd.c:	err = ahash_mcryptd_update(&rctx->areq);
crypto/mcryptd.c:		req->base.complete = rctx->complete;
crypto/mcryptd.c:	rctx->complete(&req->base, err);
crypto/mcryptd.c:	rctx->out = req->result;
crypto/mcryptd.c:	err = ahash_mcryptd_final(&rctx->areq);
crypto/mcryptd.c:		req->base.complete = rctx->complete;
crypto/mcryptd.c:	rctx->complete(&req->base, err);
crypto/mcryptd.c:	rctx->out = req->result;
crypto/mcryptd.c:	err = ahash_mcryptd_finup(&rctx->areq);
crypto/mcryptd.c:		req->base.complete = rctx->complete;
crypto/mcryptd.c:	rctx->complete(&req->base, err);
crypto/mcryptd.c:	struct crypto_ahash *child = ctx->child;
crypto/mcryptd.c:	struct ahash_request *desc = &rctx->areq;
crypto/mcryptd.c:						rctx->complete, req_async);
crypto/mcryptd.c:	rctx->out = req->result;
crypto/mcryptd.c:	rctx->complete(&req->base, err);
crypto/mcryptd.c:	return crypto_ahash_export(&rctx->areq, out);
crypto/mcryptd.c:	return crypto_ahash_import(&rctx->areq, in);
crypto/mcryptd.c:	ctx->queue = queue;
crypto/mcryptd.c:	err = crypto_init_ahash_spawn(&ctx->spawn, halg,
crypto/mcryptd.c:		crypto_drop_ahash(&ctx->spawn);
crypto/mcryptd.c:		crypto_drop_ahash(&hctx->spawn);
crypto/mcryptd.c:		crypto_drop_spawn(&ctx->spawn);
crypto/mcryptd.c:	return ctx->child;
crypto/mcryptd.c:	return &rctx->areq;
crypto/algif_hash.c:	if (ctx->result)
crypto/algif_hash.c:	ds = crypto_ahash_digestsize(crypto_ahash_reqtfm(&ctx->req));
crypto/algif_hash.c:	ctx->result = sock_kmalloc(sk, ds, GFP_KERNEL);
crypto/algif_hash.c:	if (!ctx->result)
crypto/algif_hash.c:	memset(ctx->result, 0, ds);
crypto/algif_hash.c:	if (!ctx->result)
crypto/algif_hash.c:	ds = crypto_ahash_digestsize(crypto_ahash_reqtfm(&ctx->req));
crypto/algif_hash.c:	sock_kzfree_s(sk, ctx->result, ds);
crypto/algif_hash.c:	ctx->result = NULL;
crypto/algif_hash.c:	if (!ctx->more) {
crypto/algif_hash.c:		err = af_alg_wait_for_completion(crypto_ahash_init(&ctx->req),
crypto/algif_hash.c:						&ctx->completion);
crypto/algif_hash.c:	ctx->more = 0;
crypto/algif_hash.c:		len = af_alg_make_sg(&ctx->sgl, &msg->msg_iter, len);
crypto/algif_hash.c:		ahash_request_set_crypt(&ctx->req, ctx->sgl.sg, NULL, len);
crypto/algif_hash.c:		err = af_alg_wait_for_completion(crypto_ahash_update(&ctx->req),
crypto/algif_hash.c:						 &ctx->completion);
crypto/algif_hash.c:		af_alg_free_sg(&ctx->sgl);
crypto/algif_hash.c:	ctx->more = msg->msg_flags & MSG_MORE;
crypto/algif_hash.c:	if (!ctx->more) {
crypto/algif_hash.c:		ahash_request_set_crypt(&ctx->req, NULL, ctx->result, 0);
crypto/algif_hash.c:		err = af_alg_wait_for_completion(crypto_ahash_final(&ctx->req),
crypto/algif_hash.c:						 &ctx->completion);
crypto/algif_hash.c:	sg_init_table(ctx->sgl.sg, 1);
crypto/algif_hash.c:	sg_set_page(ctx->sgl.sg, page, size, offset);
crypto/algif_hash.c:	} else if (!ctx->more)
crypto/algif_hash.c:	ahash_request_set_crypt(&ctx->req, ctx->sgl.sg, ctx->result, size);
crypto/algif_hash.c:		if (ctx->more)
crypto/algif_hash.c:			err = crypto_ahash_finup(&ctx->req);
crypto/algif_hash.c:			err = crypto_ahash_digest(&ctx->req);
crypto/algif_hash.c:		if (!ctx->more) {
crypto/algif_hash.c:			err = crypto_ahash_init(&ctx->req);
crypto/algif_hash.c:			err = af_alg_wait_for_completion(err, &ctx->completion);
crypto/algif_hash.c:		err = crypto_ahash_update(&ctx->req);
crypto/algif_hash.c:	err = af_alg_wait_for_completion(err, &ctx->completion);
crypto/algif_hash.c:	ctx->more = flags & MSG_MORE;
crypto/algif_hash.c:	unsigned ds = crypto_ahash_digestsize(crypto_ahash_reqtfm(&ctx->req));
crypto/algif_hash.c:	result = ctx->result;
crypto/algif_hash.c:	ahash_request_set_crypt(&ctx->req, NULL, ctx->result, 0);
crypto/algif_hash.c:	if (!result && !ctx->more) {
crypto/algif_hash.c:				crypto_ahash_init(&ctx->req),
crypto/algif_hash.c:				&ctx->completion);
crypto/algif_hash.c:	if (!result || ctx->more) {
crypto/algif_hash.c:		ctx->more = 0;
crypto/algif_hash.c:		err = af_alg_wait_for_completion(crypto_ahash_final(&ctx->req),
crypto/algif_hash.c:						 &ctx->completion);
crypto/algif_hash.c:	err = memcpy_to_msg(msg, ctx->result, len);
crypto/algif_hash.c:	struct ahash_request *req = &ctx->req;
crypto/algif_hash.c:	more = ctx->more;
crypto/algif_hash.c:	sock_kfree_s(sk, ctx, ctx->len);
crypto/algif_hash.c:	ctx->result = NULL;
crypto/algif_hash.c:	ctx->len = len;
crypto/algif_hash.c:	ctx->more = 0;
crypto/algif_hash.c:	af_alg_init_completion(&ctx->completion);
crypto/algif_hash.c:	ahash_request_set_tfm(&ctx->req, hash);
crypto/algif_hash.c:	ahash_request_set_callback(&ctx->req, CRYPTO_TFM_REQ_MAY_BACKLOG,
crypto/algif_hash.c:				   af_alg_complete, &ctx->completion);
crypto/cryptd.c:	return ictx->queue;
crypto/cryptd.c:	struct crypto_blkcipher *child = ctx->child;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	refcnt = atomic_read(&ctx->refcnt);
crypto/cryptd.c:	rctx->complete(&req->base, err);
crypto/cryptd.c:	if (err != -EINPROGRESS && refcnt && atomic_dec_and_test(&ctx->refcnt))
crypto/cryptd.c:	struct crypto_blkcipher *child = ctx->child;
crypto/cryptd.c:	struct crypto_blkcipher *child = ctx->child;
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	struct crypto_spawn *spawn = &ictx->spawn;
crypto/cryptd.c:	ctx->child = cipher;
crypto/cryptd.c:	crypto_free_blkcipher(ctx->child);
crypto/cryptd.c:	ctx->queue = queue;
crypto/cryptd.c:	err = crypto_init_spawn(&ctx->spawn, alg, inst,
crypto/cryptd.c:		crypto_drop_spawn(&ctx->spawn);
crypto/cryptd.c:	struct crypto_shash_spawn *spawn = &ictx->spawn;
crypto/cryptd.c:	ctx->child = hash;
crypto/cryptd.c:	crypto_free_shash(ctx->child);
crypto/cryptd.c:	struct crypto_shash *child = ctx->child;
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	int refcnt = atomic_read(&ctx->refcnt);
crypto/cryptd.c:	rctx->complete(&req->base, err);
crypto/cryptd.c:	if (err != -EINPROGRESS && refcnt && atomic_dec_and_test(&ctx->refcnt))
crypto/cryptd.c:	struct crypto_shash *child = ctx->child;
crypto/cryptd.c:	struct shash_desc *desc = &rctx->desc;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	err = shash_ahash_update(req, &rctx->desc);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	err = crypto_shash_final(&rctx->desc, req->result);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	err = shash_ahash_finup(req, &rctx->desc);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	struct crypto_shash *child = ctx->child;
crypto/cryptd.c:	struct shash_desc *desc = &rctx->desc;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	return crypto_shash_export(&rctx->desc, out);
crypto/cryptd.c:	desc->tfm = ctx->child;
crypto/cryptd.c:	ctx->queue = queue;
crypto/cryptd.c:	err = crypto_init_shash_spawn(&ctx->spawn, salg,
crypto/cryptd.c:		crypto_drop_shash(&ctx->spawn);
crypto/cryptd.c:	struct crypto_aead *child = ctx->child;
crypto/cryptd.c:	struct crypto_aead *child = ctx->child;
crypto/cryptd.c:	compl = rctx->complete;
crypto/cryptd.c:	refcnt = atomic_read(&ctx->refcnt);
crypto/cryptd.c:	if (err != -EINPROGRESS && refcnt && atomic_dec_and_test(&ctx->refcnt))
crypto/cryptd.c:	struct crypto_aead *child = ctx->child;
crypto/cryptd.c:	struct crypto_aead *child = ctx->child;
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	struct crypto_aead_spawn *spawn = &ictx->aead_spawn;
crypto/cryptd.c:	ctx->child = cipher;
crypto/cryptd.c:	crypto_free_aead(ctx->child);
crypto/cryptd.c:	ctx->queue = queue;
crypto/cryptd.c:	crypto_set_aead_spawn(&ctx->aead_spawn, aead_crypto_instance(inst));
crypto/cryptd.c:	err = crypto_grab_aead(&ctx->aead_spawn, name, type, mask);
crypto/cryptd.c:	alg = crypto_spawn_aead_alg(&ctx->aead_spawn);
crypto/cryptd.c:		crypto_drop_aead(&ctx->aead_spawn);
crypto/cryptd.c:		crypto_drop_shash(&hctx->spawn);
crypto/cryptd.c:		crypto_drop_aead(&aead_ctx->aead_spawn);
crypto/cryptd.c:		crypto_drop_spawn(&ctx->spawn);
crypto/cryptd.c:	atomic_set(&ctx->refcnt, 1);
crypto/cryptd.c:	return ctx->child;
crypto/cryptd.c:	return atomic_read(&ctx->refcnt) - 1;
crypto/cryptd.c:	if (atomic_dec_and_test(&ctx->refcnt))
crypto/cryptd.c:	atomic_set(&ctx->refcnt, 1);
crypto/cryptd.c:	return ctx->child;
crypto/cryptd.c:	return &rctx->desc;
crypto/cryptd.c:	return atomic_read(&ctx->refcnt) - 1;
crypto/cryptd.c:	if (atomic_dec_and_test(&ctx->refcnt))
crypto/cryptd.c:	atomic_set(&ctx->refcnt, 1);
crypto/cryptd.c:	return ctx->child;
crypto/cryptd.c:	return atomic_read(&ctx->refcnt) - 1;
crypto/cryptd.c:	if (atomic_dec_and_test(&ctx->refcnt))
crypto/algif_skcipher.c:			  ctx->used, 0);
crypto/algif_skcipher.c:	sgl = list_entry(ctx->tsgl.prev, struct skcipher_sg_list, list);
crypto/algif_skcipher.c:	if (!list_empty(&ctx->tsgl))
crypto/algif_skcipher.c:		list_add_tail(&sgl->list, &ctx->tsgl);
crypto/algif_skcipher.c:	while (!list_empty(&ctx->tsgl)) {
crypto/algif_skcipher.c:		sgl = list_first_entry(&ctx->tsgl, struct skcipher_sg_list,
crypto/algif_skcipher.c:			ctx->used -= plen;
crypto/algif_skcipher.c:	if (!ctx->used)
crypto/algif_skcipher.c:		ctx->merge = 0;
crypto/algif_skcipher.c:	skcipher_pull_sgl(sk, ctx->used, 1);
crypto/algif_skcipher.c:		if (sk_wait_event(sk, &timeout, ctx->used)) {
crypto/algif_skcipher.c:	if (!ctx->used)
crypto/algif_skcipher.c:	if (!ctx->more && ctx->used)
crypto/algif_skcipher.c:		ctx->enc = enc;
crypto/algif_skcipher.c:			memcpy(ctx->iv, con.iv->iv, ivsize);
crypto/algif_skcipher.c:		if (ctx->merge) {
crypto/algif_skcipher.c:			sgl = list_entry(ctx->tsgl.prev,
crypto/algif_skcipher.c:			ctx->merge = (sg->offset + sg->length) &
crypto/algif_skcipher.c:			ctx->used += len;
crypto/algif_skcipher.c:		sgl = list_entry(ctx->tsgl.prev, struct skcipher_sg_list, list);
crypto/algif_skcipher.c:			ctx->used += plen;
crypto/algif_skcipher.c:		ctx->merge = plen & (PAGE_SIZE - 1);
crypto/algif_skcipher.c:	ctx->more = msg->msg_flags & MSG_MORE;
crypto/algif_skcipher.c:	if (!ctx->more && ctx->used)
crypto/algif_skcipher.c:	ctx->merge = 0;
crypto/algif_skcipher.c:	sgl = list_entry(ctx->tsgl.prev, struct skcipher_sg_list, list);
crypto/algif_skcipher.c:	ctx->used += size;
crypto/algif_skcipher.c:	ctx->more = flags & MSG_MORE;
crypto/algif_skcipher.c:	list_for_each_entry(sgl, &ctx->tsgl, list) {
crypto/algif_skcipher.c:	sreq->inflight = &ctx->inflight;
crypto/algif_skcipher.c:	memcpy(iv, ctx->iv, ivsize);
crypto/algif_skcipher.c:		if (!ctx->used) {
crypto/algif_skcipher.c:		sgl = list_first_entry(&ctx->tsgl,
crypto/algif_skcipher.c:		used = min_t(unsigned long, ctx->used,
crypto/algif_skcipher.c:	err = ctx->enc ? crypto_skcipher_encrypt(req) :
crypto/algif_skcipher.c:		atomic_inc(&ctx->inflight);
crypto/algif_skcipher.c:		if (!ctx->used) {
crypto/algif_skcipher.c:		used = min_t(unsigned long, ctx->used, msg_data_left(msg));
crypto/algif_skcipher.c:		used = af_alg_make_sg(&ctx->rsgl, &msg->msg_iter, used);
crypto/algif_skcipher.c:		if (ctx->more || used < ctx->used)
crypto/algif_skcipher.c:		sgl = list_first_entry(&ctx->tsgl,
crypto/algif_skcipher.c:		skcipher_request_set_crypt(&ctx->req, sg, ctx->rsgl.sg, used,
crypto/algif_skcipher.c:					   ctx->iv);
crypto/algif_skcipher.c:				ctx->enc ?
crypto/algif_skcipher.c:					crypto_skcipher_encrypt(&ctx->req) :
crypto/algif_skcipher.c:					crypto_skcipher_decrypt(&ctx->req),
crypto/algif_skcipher.c:				&ctx->completion);
crypto/algif_skcipher.c:		af_alg_free_sg(&ctx->rsgl);
crypto/algif_skcipher.c:	if (ctx->used)
crypto/algif_skcipher.c:	while (atomic_read(&ctx->inflight) && ctr++ < 100)
crypto/algif_skcipher.c:	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(&ctx->req);
crypto/algif_skcipher.c:	if (atomic_read(&ctx->inflight))
crypto/algif_skcipher.c:	sock_kzfree_s(sk, ctx->iv, crypto_skcipher_ivsize(tfm));
crypto/algif_skcipher.c:	sock_kfree_s(sk, ctx, ctx->len);
crypto/algif_skcipher.c:	ctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(skcipher),
crypto/algif_skcipher.c:	if (!ctx->iv) {
crypto/algif_skcipher.c:	memset(ctx->iv, 0, crypto_skcipher_ivsize(skcipher));
crypto/algif_skcipher.c:	INIT_LIST_HEAD(&ctx->tsgl);
crypto/algif_skcipher.c:	ctx->len = len;
crypto/algif_skcipher.c:	ctx->used = 0;
crypto/algif_skcipher.c:	ctx->more = 0;
crypto/algif_skcipher.c:	ctx->merge = 0;
crypto/algif_skcipher.c:	ctx->enc = 0;
crypto/algif_skcipher.c:	atomic_set(&ctx->inflight, 0);
crypto/algif_skcipher.c:	af_alg_init_completion(&ctx->completion);
crypto/algif_skcipher.c:	skcipher_request_set_tfm(&ctx->req, skcipher);
crypto/algif_skcipher.c:	skcipher_request_set_callback(&ctx->req, CRYPTO_TFM_REQ_MAY_SLEEP |
crypto/algif_skcipher.c:				      af_alg_complete, &ctx->completion);
crypto/arc4.c:	ctx->x = 1;
crypto/arc4.c:	ctx->y = 0;
crypto/arc4.c:		ctx->S[i] = i;
crypto/arc4.c:		u32 a = ctx->S[i];
crypto/arc4.c:		ctx->S[i] = ctx->S[j];
crypto/arc4.c:		ctx->S[j] = a;
crypto/arc4.c:	u32 *const S = ctx->S;
crypto/arc4.c:	x = ctx->x;
crypto/arc4.c:	y = ctx->y;
crypto/arc4.c:	ctx->x = x;
crypto/arc4.c:	ctx->y = y;
crypto/md5.c:	le32_to_cpu_array(ctx->block, sizeof(ctx->block) / sizeof(u32));
crypto/md5.c:	md5_transform(ctx->hash, ctx->block);
crypto/md5.c:	mctx->hash[0] = MD5_H0;
crypto/md5.c:	mctx->hash[1] = MD5_H1;
crypto/md5.c:	mctx->hash[2] = MD5_H2;
crypto/md5.c:	mctx->hash[3] = MD5_H3;
crypto/md5.c:	mctx->byte_count = 0;
crypto/md5.c:	const u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);
crypto/md5.c:	mctx->byte_count += len;
crypto/md5.c:		memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
crypto/md5.c:	memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
crypto/md5.c:	while (len >= sizeof(mctx->block)) {
crypto/md5.c:		memcpy(mctx->block, data, sizeof(mctx->block));
crypto/md5.c:		data += sizeof(mctx->block);
crypto/md5.c:		len -= sizeof(mctx->block);
crypto/md5.c:	memcpy(mctx->block, data, len);
crypto/md5.c:	const unsigned int offset = mctx->byte_count & 0x3f;
crypto/md5.c:	char *p = (char *)mctx->block + offset;
crypto/md5.c:		p = (char *)mctx->block;
crypto/md5.c:	mctx->block[14] = mctx->byte_count << 3;
crypto/md5.c:	mctx->block[15] = mctx->byte_count >> 29;
crypto/md5.c:	le32_to_cpu_array(mctx->block, (sizeof(mctx->block) -
crypto/md5.c:	md5_transform(mctx->hash, mctx->block);
crypto/md5.c:	cpu_to_le32_array(mctx->hash, sizeof(mctx->hash) / sizeof(u32));
crypto/md5.c:	memcpy(out, mctx->hash, sizeof(mctx->hash));
crypto/cbc.c:	struct crypto_cipher *child = ctx->child;
crypto/cbc.c:	struct crypto_cipher *child = ctx->child;
crypto/cbc.c:	struct crypto_cipher *child = ctx->child;
crypto/cbc.c:	ctx->child = cipher;
crypto/cbc.c:	crypto_free_cipher(ctx->child);
crypto/aes_generic.c:	t ^= ctx->key_enc[4 * i];		\
crypto/aes_generic.c:	ctx->key_enc[4 * i + 4] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[4 * i + 1];		\
crypto/aes_generic.c:	ctx->key_enc[4 * i + 5] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[4 * i + 2];		\
crypto/aes_generic.c:	ctx->key_enc[4 * i + 6] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[4 * i + 3];		\
crypto/aes_generic.c:	ctx->key_enc[4 * i + 7] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 6] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i + 1];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 7] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i + 2];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 8] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i + 3];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 9] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i + 4];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 10] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[6 * i + 5];		\
crypto/aes_generic.c:	ctx->key_enc[6 * i + 11] = t;		\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 8] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 1];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 9] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 2];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 10] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 3];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 11] = t;			\
crypto/aes_generic.c:	t  = ctx->key_enc[8 * i + 4] ^ ls_box(t);	\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 12] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 5];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 13] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 6];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 14] = t;			\
crypto/aes_generic.c:	t ^= ctx->key_enc[8 * i + 7];			\
crypto/aes_generic.c:	ctx->key_enc[8 * i + 15] = t;			\
crypto/aes_generic.c:	ctx->key_length = key_len;
crypto/aes_generic.c:	ctx->key_dec[key_len + 24] = ctx->key_enc[0] = le32_to_cpu(key[0]);
crypto/aes_generic.c:	ctx->key_dec[key_len + 25] = ctx->key_enc[1] = le32_to_cpu(key[1]);
crypto/aes_generic.c:	ctx->key_dec[key_len + 26] = ctx->key_enc[2] = le32_to_cpu(key[2]);
crypto/aes_generic.c:	ctx->key_dec[key_len + 27] = ctx->key_enc[3] = le32_to_cpu(key[3]);
crypto/aes_generic.c:		t = ctx->key_enc[3];
crypto/aes_generic.c:		ctx->key_enc[4] = le32_to_cpu(key[4]);
crypto/aes_generic.c:		t = ctx->key_enc[5] = le32_to_cpu(key[5]);
crypto/aes_generic.c:		ctx->key_enc[4] = le32_to_cpu(key[4]);
crypto/aes_generic.c:		ctx->key_enc[5] = le32_to_cpu(key[5]);
crypto/aes_generic.c:		ctx->key_enc[6] = le32_to_cpu(key[6]);
crypto/aes_generic.c:		t = ctx->key_enc[7] = le32_to_cpu(key[7]);
crypto/aes_generic.c:	ctx->key_dec[0] = ctx->key_enc[key_len + 24];
crypto/aes_generic.c:	ctx->key_dec[1] = ctx->key_enc[key_len + 25];
crypto/aes_generic.c:	ctx->key_dec[2] = ctx->key_enc[key_len + 26];
crypto/aes_generic.c:	ctx->key_dec[3] = ctx->key_enc[key_len + 27];
crypto/aes_generic.c:		imix_col(ctx->key_dec[j], ctx->key_enc[i]);
crypto/aes_generic.c:	const u32 *kp = ctx->key_enc + 4;
crypto/aes_generic.c:	const int key_len = ctx->key_length;
crypto/aes_generic.c:	b0[0] = le32_to_cpu(src[0]) ^ ctx->key_enc[0];
crypto/aes_generic.c:	b0[1] = le32_to_cpu(src[1]) ^ ctx->key_enc[1];
crypto/aes_generic.c:	b0[2] = le32_to_cpu(src[2]) ^ ctx->key_enc[2];
crypto/aes_generic.c:	b0[3] = le32_to_cpu(src[3]) ^ ctx->key_enc[3];
crypto/aes_generic.c:	const int key_len = ctx->key_length;
crypto/aes_generic.c:	const u32 *kp = ctx->key_dec + 4;
crypto/aes_generic.c:	b0[0] = le32_to_cpu(src[0]) ^  ctx->key_dec[0];
crypto/aes_generic.c:	b0[1] = le32_to_cpu(src[1]) ^  ctx->key_dec[1];
crypto/aes_generic.c:	b0[2] = le32_to_cpu(src[2]) ^  ctx->key_dec[2];
crypto/aes_generic.c:	b0[3] = le32_to_cpu(src[3]) ^  ctx->key_dec[3];
crypto/ablk_helper.c:	struct crypto_ablkcipher *child = &ctx->cryptd_tfm->base;
crypto/ablk_helper.c:	desc.tfm = cryptd_ablkcipher_child(ctx->cryptd_tfm);
crypto/ablk_helper.c:	    (in_atomic() && cryptd_ablkcipher_queued(ctx->cryptd_tfm))) {
crypto/ablk_helper.c:		ablkcipher_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);
crypto/ablk_helper.c:	    (in_atomic() && cryptd_ablkcipher_queued(ctx->cryptd_tfm))) {
crypto/ablk_helper.c:		ablkcipher_request_set_tfm(cryptd_req, &ctx->cryptd_tfm->base);
crypto/ablk_helper.c:		desc.tfm = cryptd_ablkcipher_child(ctx->cryptd_tfm);
crypto/ablk_helper.c:	cryptd_free_ablkcipher(ctx->cryptd_tfm);
crypto/ablk_helper.c:	ctx->cryptd_tfm = cryptd_tfm;
crypto/lrw.c:	if (ctx->table)
crypto/lrw.c:		gf128mul_free_64k(ctx->table);
crypto/lrw.c:	ctx->table = gf128mul_init_64k_bbe((be128 *)tweak);
crypto/lrw.c:	if (!ctx->table)
crypto/lrw.c:		ctx->mulinc[i] = tmp;
crypto/lrw.c:		gf128mul_64k_bbe(&ctx->mulinc[i], ctx->table);
crypto/lrw.c:	if (ctx->table)
crypto/lrw.c:		gf128mul_free_64k(ctx->table);
crypto/lrw.c:	struct crypto_cipher *child = ctx->child;
crypto/lrw.c:	return lrw_init_table(&ctx->table, tweak);
crypto/lrw.c:		.tfm = crypto_cipher_tfm(ctx->child),
crypto/lrw.c:	gf128mul_64k_bbe(&s.t, ctx->table.table);
crypto/lrw.c:				  &ctx->table.mulinc[get_index128(iv)]);
crypto/lrw.c:		     crypto_cipher_alg(ctx->child)->cia_encrypt);
crypto/lrw.c:		     crypto_cipher_alg(ctx->child)->cia_decrypt);
crypto/lrw.c:	gf128mul_64k_bbe(&t_buf[0], ctx->table);
crypto/lrw.c:						&ctx->mulinc[get_index128(iv)]);
crypto/lrw.c:	ctx->child = cipher;
crypto/lrw.c:	lrw_free_table(&ctx->table);
crypto/lrw.c:	crypto_free_cipher(ctx->child);
crypto/khazad.c:		ctx->E[r] = T0[(int)(K1 >> 56)       ] ^
crypto/khazad.c:		K1 = ctx->E[r];
crypto/khazad.c:	ctx->D[0] = ctx->E[KHAZAD_ROUNDS];
crypto/khazad.c:		K1 = ctx->E[KHAZAD_ROUNDS - r];
crypto/khazad.c:		ctx->D[r] = T0[(int)S[(int)(K1 >> 56)       ] & 0xff] ^
crypto/khazad.c:	ctx->D[KHAZAD_ROUNDS] = ctx->E[0];
crypto/khazad.c:	khazad_crypt(ctx->E, dst, src);
crypto/khazad.c:	khazad_crypt(ctx->D, dst, src);
crypto/lz4hc.c:	ctx->lz4hc_comp_mem = vmalloc(LZ4HC_MEM_COMPRESS);
crypto/lz4hc.c:	if (!ctx->lz4hc_comp_mem)
crypto/lz4hc.c:	vfree(ctx->lz4hc_comp_mem);
crypto/lz4hc.c:	err = lz4hc_compress(src, slen, dst, &tmp_len, ctx->lz4hc_comp_mem);
crypto/chacha20_generic.c:	state[4]  = ctx->key[0];
crypto/chacha20_generic.c:	state[5]  = ctx->key[1];
crypto/chacha20_generic.c:	state[6]  = ctx->key[2];
crypto/chacha20_generic.c:	state[7]  = ctx->key[3];
crypto/chacha20_generic.c:	state[8]  = ctx->key[4];
crypto/chacha20_generic.c:	state[9]  = ctx->key[5];
crypto/chacha20_generic.c:	state[10] = ctx->key[6];
crypto/chacha20_generic.c:	state[11] = ctx->key[7];
crypto/chacha20_generic.c:	for (i = 0; i < ARRAY_SIZE(ctx->key); i++)
crypto/chacha20_generic.c:		ctx->key[i] = le32_to_cpuvp(key + i * sizeof(u32));
crypto/salsa20_generic.c:	ctx->input[1] = U8TO32_LITTLE(k + 0);
crypto/salsa20_generic.c:	ctx->input[2] = U8TO32_LITTLE(k + 4);
crypto/salsa20_generic.c:	ctx->input[3] = U8TO32_LITTLE(k + 8);
crypto/salsa20_generic.c:	ctx->input[4] = U8TO32_LITTLE(k + 12);
crypto/salsa20_generic.c:	ctx->input[11] = U8TO32_LITTLE(k + 0);
crypto/salsa20_generic.c:	ctx->input[12] = U8TO32_LITTLE(k + 4);
crypto/salsa20_generic.c:	ctx->input[13] = U8TO32_LITTLE(k + 8);
crypto/salsa20_generic.c:	ctx->input[14] = U8TO32_LITTLE(k + 12);
crypto/salsa20_generic.c:	ctx->input[0] = U8TO32_LITTLE(constants + 0);
crypto/salsa20_generic.c:	ctx->input[5] = U8TO32_LITTLE(constants + 4);
crypto/salsa20_generic.c:	ctx->input[10] = U8TO32_LITTLE(constants + 8);
crypto/salsa20_generic.c:	ctx->input[15] = U8TO32_LITTLE(constants + 12);
crypto/salsa20_generic.c:	ctx->input[6] = U8TO32_LITTLE(iv + 0);
crypto/salsa20_generic.c:	ctx->input[7] = U8TO32_LITTLE(iv + 4);
crypto/salsa20_generic.c:	ctx->input[8] = 0;
crypto/salsa20_generic.c:	ctx->input[9] = 0;
crypto/salsa20_generic.c:		salsa20_wordtobyte(buf, ctx->input);
crypto/salsa20_generic.c:		ctx->input[8]++;
crypto/salsa20_generic.c:		if (!ctx->input[8])
crypto/salsa20_generic.c:			ctx->input[9]++;
crypto/ctr.c:	struct crypto_cipher *child = ctx->child;
crypto/ctr.c:	struct crypto_cipher *child = ctx->child;
crypto/ctr.c:	ctx->child = cipher;
crypto/ctr.c:	crypto_free_cipher(ctx->child);
crypto/ctr.c:	struct crypto_skcipher *child = ctx->child;
crypto/ctr.c:	memcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
crypto/ctr.c:	struct crypto_skcipher *child = ctx->child;
crypto/ctr.c:	struct skcipher_request *subreq = &rctx->subreq;
crypto/ctr.c:	u8 *iv = rctx->iv;
crypto/ctr.c:	memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
crypto/ctr.c:	ctx->child = cipher;
crypto/ctr.c:	crypto_free_skcipher(ctx->child);
crypto/camellia_generic.c:	cctx->key_length = key_len;
crypto/camellia_generic.c:		camellia_setup128(key, cctx->key_table);
crypto/camellia_generic.c:		camellia_setup192(key, cctx->key_table);
crypto/camellia_generic.c:		camellia_setup256(key, cctx->key_table);
crypto/camellia_generic.c:	if (cctx->key_length == 16)
crypto/camellia_generic.c:	camellia_do_encrypt(cctx->key_table, tmp, max);
crypto/camellia_generic.c:	if (cctx->key_length == 16)
crypto/camellia_generic.c:	camellia_do_decrypt(cctx->key_table, tmp, max);
crypto/keywrap.c:	struct crypto_cipher *child = ctx->child;
crypto/keywrap.c:	struct crypto_cipher *child = ctx->child;
crypto/keywrap.c:	struct crypto_cipher *child = ctx->child;
crypto/keywrap.c:	ctx->child = cipher;
crypto/keywrap.c:	crypto_free_cipher(ctx->child);
crypto/twofish_common.c:   ctx->s[0][i] = mds[0][q0[(a) ^ sa] ^ se]; \
crypto/twofish_common.c:   ctx->s[1][i] = mds[1][q0[(b) ^ sb] ^ sf]; \
crypto/twofish_common.c:   ctx->s[2][i] = mds[2][q1[(a) ^ sc] ^ sg]; \
crypto/twofish_common.c:   ctx->s[3][i] = mds[3][q1[(b) ^ sd] ^ sh]
crypto/twofish_common.c:   ctx->s[0][i] = mds[0][q0[q0[(b) ^ sa] ^ se] ^ si]; \
crypto/twofish_common.c:   ctx->s[1][i] = mds[1][q0[q1[(b) ^ sb] ^ sf] ^ sj]; \
crypto/twofish_common.c:   ctx->s[2][i] = mds[2][q1[q0[(a) ^ sc] ^ sg] ^ sk]; \
crypto/twofish_common.c:   ctx->s[3][i] = mds[3][q1[q1[(a) ^ sd] ^ sh] ^ sl];
crypto/twofish_common.c:   ctx->s[0][i] = mds[0][q0[q0[q1[(b) ^ sa] ^ se] ^ si] ^ sm]; \
crypto/twofish_common.c:   ctx->s[1][i] = mds[1][q0[q1[q1[(a) ^ sb] ^ sf] ^ sj] ^ sn]; \
crypto/twofish_common.c:   ctx->s[2][i] = mds[2][q1[q0[q0[(a) ^ sc] ^ sg] ^ sk] ^ so]; \
crypto/twofish_common.c:   ctx->s[3][i] = mds[3][q1[q1[q0[(b) ^ sd] ^ sh] ^ sl] ^ sp];
crypto/twofish_common.c:   x += y; y += x; ctx->a[j] = x; \
crypto/twofish_common.c:   ctx->a[(j) + 1] = rol32(y, 9)
crypto/twofish_common.c:   x += y; y += x; ctx->a[j] = x; \
crypto/twofish_common.c:   ctx->a[(j) + 1] = rol32(y, 9)
crypto/twofish_common.c:   x += y; y += x; ctx->a[j] = x; \
crypto/twofish_common.c:   ctx->a[(j) + 1] = rol32(y, 9)
crypto/md4.c:	le32_to_cpu_array(ctx->block, ARRAY_SIZE(ctx->block));
crypto/md4.c:	md4_transform(ctx->hash, ctx->block);
crypto/md4.c:	mctx->hash[0] = 0x67452301;
crypto/md4.c:	mctx->hash[1] = 0xefcdab89;
crypto/md4.c:	mctx->hash[2] = 0x98badcfe;
crypto/md4.c:	mctx->hash[3] = 0x10325476;
crypto/md4.c:	mctx->byte_count = 0;
crypto/md4.c:	const u32 avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);
crypto/md4.c:	mctx->byte_count += len;
crypto/md4.c:		memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
crypto/md4.c:	memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
crypto/md4.c:	while (len >= sizeof(mctx->block)) {
crypto/md4.c:		memcpy(mctx->block, data, sizeof(mctx->block));
crypto/md4.c:		data += sizeof(mctx->block);
crypto/md4.c:		len -= sizeof(mctx->block);
crypto/md4.c:	memcpy(mctx->block, data, len);
crypto/md4.c:	const unsigned int offset = mctx->byte_count & 0x3f;
crypto/md4.c:	char *p = (char *)mctx->block + offset;
crypto/md4.c:		p = (char *)mctx->block;
crypto/md4.c:	mctx->block[14] = mctx->byte_count << 3;
crypto/md4.c:	mctx->block[15] = mctx->byte_count >> 29;
crypto/md4.c:	le32_to_cpu_array(mctx->block, (sizeof(mctx->block) -
crypto/md4.c:	md4_transform(mctx->hash, mctx->block);
crypto/md4.c:	cpu_to_le32_array(mctx->hash, ARRAY_SIZE(mctx->hash));
crypto/md4.c:	memcpy(out, mctx->hash, sizeof(mctx->hash));
crypto/echainiv.c:	aead_request_set_tfm(subreq, ctx->child);
crypto/echainiv.c:		SKCIPHER_REQUEST_ON_STACK(nreq, ctx->sknull);
crypto/echainiv.c:		skcipher_request_set_tfm(nreq, ctx->sknull);
crypto/echainiv.c:		memcpy(&a, ctx->salt + ivsize - 8, 8);
crypto/echainiv.c:	aead_request_set_tfm(subreq, ctx->child);
crypto/tea.c:	ctx->KEY[0] = le32_to_cpu(key[0]);
crypto/tea.c:	ctx->KEY[1] = le32_to_cpu(key[1]);
crypto/tea.c:	ctx->KEY[2] = le32_to_cpu(key[2]);
crypto/tea.c:	ctx->KEY[3] = le32_to_cpu(key[3]);
crypto/tea.c:	k0 = ctx->KEY[0];
crypto/tea.c:	k1 = ctx->KEY[1];
crypto/tea.c:	k2 = ctx->KEY[2];
crypto/tea.c:	k3 = ctx->KEY[3];
crypto/tea.c:	k0 = ctx->KEY[0];
crypto/tea.c:	k1 = ctx->KEY[1];
crypto/tea.c:	k2 = ctx->KEY[2];
crypto/tea.c:	k3 = ctx->KEY[3];
crypto/tea.c:	ctx->KEY[0] = le32_to_cpu(key[0]);
crypto/tea.c:	ctx->KEY[1] = le32_to_cpu(key[1]);
crypto/tea.c:	ctx->KEY[2] = le32_to_cpu(key[2]);
crypto/tea.c:	ctx->KEY[3] = le32_to_cpu(key[3]);
crypto/tea.c:		y += ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum&3]); 
crypto/tea.c:		z += ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 &3]); 
crypto/tea.c:		z -= ((y << 4 ^ y >> 5) + y) ^ (sum + ctx->KEY[sum>>11 & 3]);
crypto/tea.c:		y -= ((z << 4 ^ z >> 5) + z) ^ (sum + ctx->KEY[sum & 3]);
crypto/tea.c:		y += (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum&3];
crypto/tea.c:		z += (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 &3];
crypto/tea.c:		z -= (y << 4 ^ y >> 5) + (y ^ sum) + ctx->KEY[sum>>11 & 3];
crypto/tea.c:		y -= (z << 4 ^ z >> 5) + (z ^ sum) + ctx->KEY[sum & 3];
crypto/crct10dif_generic.c:	ctx->crc = 0;
crypto/crct10dif_generic.c:	ctx->crc = crc_t10dif_generic(ctx->crc, data, length);
crypto/crct10dif_generic.c:	*(__u16 *)out = ctx->crc;
crypto/crct10dif_generic.c:	return __chksum_finup(&ctx->crc, data, len, out);
crypto/crct10dif_generic.c:	return __chksum_finup(&ctx->crc, data, length, out);
crypto/blowfish_common.c:	const u32 *P = bctx->p;
crypto/blowfish_common.c:	const u32 *S = bctx->s;
crypto/blowfish_common.c:	u32 *P = ctx->p;
crypto/blowfish_common.c:	u32 *S = ctx->s;
crypto/cmac.c:	__be64 *consts = PTR_ALIGN((void *)ctx->ctx, alignmask + 1);
crypto/cmac.c:	err = crypto_cipher_setkey(ctx->child, inkey, keylen);
crypto/cmac.c:	crypto_cipher_encrypt_one(ctx->child, (u8 *)consts, (u8 *)consts);
crypto/cmac.c:	u8 *prev = PTR_ALIGN((void *)ctx->ctx, alignmask + 1) + bs;
crypto/cmac.c:	ctx->len = 0;
crypto/cmac.c:	struct crypto_cipher *tfm = tctx->child;
crypto/cmac.c:	u8 *odds = PTR_ALIGN((void *)ctx->ctx, alignmask + 1);
crypto/cmac.c:	if ((ctx->len + len) <= bs) {
crypto/cmac.c:		memcpy(odds + ctx->len, p, len);
crypto/cmac.c:		ctx->len += len;
crypto/cmac.c:	memcpy(odds + ctx->len, p, bs - ctx->len);
crypto/cmac.c:	len -= bs - ctx->len;
crypto/cmac.c:	p += bs - ctx->len;
crypto/cmac.c:	ctx->len = 0;
crypto/cmac.c:		ctx->len = len;
crypto/cmac.c:	struct crypto_cipher *tfm = tctx->child;
crypto/cmac.c:	u8 *consts = PTR_ALIGN((void *)tctx->ctx, alignmask + 1);
crypto/cmac.c:	u8 *odds = PTR_ALIGN((void *)ctx->ctx, alignmask + 1);
crypto/cmac.c:	if (ctx->len != bs) {
crypto/cmac.c:		u8 *p = odds + ctx->len;
crypto/cmac.c:		rlen = bs - ctx->len - 1;
crypto/cmac.c:	ctx->child = cipher;
crypto/cmac.c:	crypto_free_cipher(ctx->child);
crypto/tgr192.c:	a = aa = tctx->a;
crypto/tgr192.c:	b = bb = tctx->b;
crypto/tgr192.c:	c = cc = tctx->c;
crypto/tgr192.c:	tctx->a = a;
crypto/tgr192.c:	tctx->b = b;
crypto/tgr192.c:	tctx->c = c;
crypto/tgr192.c:	tctx->a = 0x0123456789abcdefULL;
crypto/tgr192.c:	tctx->b = 0xfedcba9876543210ULL;
crypto/tgr192.c:	tctx->c = 0xf096a5b4c3b2e187ULL;
crypto/tgr192.c:	tctx->nblocks = 0;
crypto/tgr192.c:	tctx->count = 0;
crypto/tgr192.c:	if (tctx->count == 64) {	/* flush the buffer */
crypto/tgr192.c:		tgr192_transform(tctx, tctx->hash);
crypto/tgr192.c:		tctx->count = 0;
crypto/tgr192.c:		tctx->nblocks++;
crypto/tgr192.c:	if (tctx->count) {
crypto/tgr192.c:		for (; len && tctx->count < 64; len--) {
crypto/tgr192.c:			tctx->hash[tctx->count++] = *inbuf++;
crypto/tgr192.c:		tctx->count = 0;
crypto/tgr192.c:		tctx->nblocks++;
crypto/tgr192.c:	for (; len && tctx->count < 64; len--) {
crypto/tgr192.c:		tctx->hash[tctx->count++] = *inbuf++;
crypto/tgr192.c:	t = tctx->nblocks;
crypto/tgr192.c:	if ((lsb = t + tctx->count) < t) {	/* add the count */
crypto/tgr192.c:	if (tctx->count < 56) {	/* enough room */
crypto/tgr192.c:		tctx->hash[tctx->count++] = 0x01;	/* pad */
crypto/tgr192.c:		while (tctx->count < 56) {
crypto/tgr192.c:			tctx->hash[tctx->count++] = 0;	/* pad */
crypto/tgr192.c:		tctx->hash[tctx->count++] = 0x01;	/* pad character */
crypto/tgr192.c:		while (tctx->count < 64) {
crypto/tgr192.c:			tctx->hash[tctx->count++] = 0;
crypto/tgr192.c:		memset(tctx->hash, 0, 56);    /* fill next block with zeroes */
crypto/tgr192.c:	le32p = (__le32 *)&tctx->hash[56];
crypto/tgr192.c:	tgr192_transform(tctx, tctx->hash);
crypto/tgr192.c:	be64p = (__be64 *)tctx->hash;
crypto/tgr192.c:	dst[0] = be64p[0] = cpu_to_be64(tctx->a);
crypto/tgr192.c:	dst[1] = be64p[1] = cpu_to_be64(tctx->b);
crypto/tgr192.c:	dst[2] = be64p[2] = cpu_to_be64(tctx->c);
crypto/anubis.c:	ctx->key_len = key_len * 8;
crypto/anubis.c:	N = ctx->key_len >> 5;
crypto/anubis.c:	ctx->R = R = 8 + N;
crypto/anubis.c:		ctx->E[r][0] = K0;
crypto/anubis.c:		ctx->E[r][1] = K1;
crypto/anubis.c:		ctx->E[r][2] = K2;
crypto/anubis.c:		ctx->E[r][3] = K3;
crypto/anubis.c:		ctx->D[0][i] = ctx->E[R][i];
crypto/anubis.c:		ctx->D[R][i] = ctx->E[0][i];
crypto/anubis.c:			u32 v = ctx->E[R - r][i];
crypto/anubis.c:			ctx->D[r][i] =
crypto/anubis.c:	anubis_crypt(ctx->E, dst, src, ctx->R);
crypto/anubis.c:	anubis_crypt(ctx->D, dst, src, ctx->R);
crypto/rsa-pkcs1pad.c:	ctx->key_size = 0;
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_set_pub_key(ctx->child, key, keylen);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_maxsize(ctx->child);
crypto/rsa-pkcs1pad.c:	ctx->key_size = err;
crypto/rsa-pkcs1pad.c:	ctx->key_size = 0;
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_set_priv_key(ctx->child, key, keylen);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_maxsize(ctx->child);
crypto/rsa-pkcs1pad.c:	ctx->key_size = err;
crypto/rsa-pkcs1pad.c:	return ctx->key_size ?: -EINVAL;
crypto/rsa-pkcs1pad.c:	len = req_ctx->child_req.dst_len;
crypto/rsa-pkcs1pad.c:	pad_len = ctx->key_size - len;
crypto/rsa-pkcs1pad.c:	out_buf = kzalloc(ctx->key_size, GFP_ATOMIC);
crypto/rsa-pkcs1pad.c:			    sg_nents_for_len(req->dst, ctx->key_size),
crypto/rsa-pkcs1pad.c:			    out_buf, ctx->key_size);
crypto/rsa-pkcs1pad.c:	req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	kfree(req_ctx->in_buf);
crypto/rsa-pkcs1pad.c:	if (!ctx->key_size)
crypto/rsa-pkcs1pad.c:	if (req->src_len > ctx->key_size - 11)
crypto/rsa-pkcs1pad.c:	if (req->dst_len < ctx->key_size) {
crypto/rsa-pkcs1pad.c:		req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
crypto/rsa-pkcs1pad.c:	if (!req_ctx->in_buf)
crypto/rsa-pkcs1pad.c:	ps_end = ctx->key_size - req->src_len - 2;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf[0] = 0x02;
crypto/rsa-pkcs1pad.c:		req_ctx->in_buf[i] = 1 + prandom_u32_max(255);
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf[ps_end] = 0x00;
crypto/rsa-pkcs1pad.c:	pkcs1pad_sg_set_buf(req_ctx->in_sg, req_ctx->in_buf,
crypto/rsa-pkcs1pad.c:			ctx->key_size - 1 - req->src_len, req->src);
crypto/rsa-pkcs1pad.c:	req_ctx->out_buf = kmalloc(ctx->key_size, GFP_KERNEL);
crypto/rsa-pkcs1pad.c:	if (!req_ctx->out_buf) {
crypto/rsa-pkcs1pad.c:		kfree(req_ctx->in_buf);
crypto/rsa-pkcs1pad.c:	pkcs1pad_sg_set_buf(req_ctx->out_sg, req_ctx->out_buf,
crypto/rsa-pkcs1pad.c:			ctx->key_size, NULL);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req_ctx->in_sg,
crypto/rsa-pkcs1pad.c:				   req->dst, ctx->key_size - 1, req->dst_len);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_encrypt(&req_ctx->child_req);
crypto/rsa-pkcs1pad.c:	dst_len = req_ctx->child_req.dst_len;
crypto/rsa-pkcs1pad.c:	if (dst_len < ctx->key_size - 1)
crypto/rsa-pkcs1pad.c:	out_buf = req_ctx->out_buf;
crypto/rsa-pkcs1pad.c:	if (dst_len == ctx->key_size) {
crypto/rsa-pkcs1pad.c:	kzfree(req_ctx->out_buf);
crypto/rsa-pkcs1pad.c:	if (!ctx->key_size || req->src_len != ctx->key_size)
crypto/rsa-pkcs1pad.c:	req_ctx->out_buf = kmalloc(ctx->key_size, GFP_KERNEL);
crypto/rsa-pkcs1pad.c:	if (!req_ctx->out_buf)
crypto/rsa-pkcs1pad.c:	pkcs1pad_sg_set_buf(req_ctx->out_sg, req_ctx->out_buf,
crypto/rsa-pkcs1pad.c:			    ctx->key_size, NULL);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req->src,
crypto/rsa-pkcs1pad.c:				   req_ctx->out_sg, req->src_len,
crypto/rsa-pkcs1pad.c:				   ctx->key_size);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_decrypt(&req_ctx->child_req);
crypto/rsa-pkcs1pad.c:	const struct rsa_asn1_template *digest_info = ictx->digest_info;
crypto/rsa-pkcs1pad.c:	if (!ctx->key_size)
crypto/rsa-pkcs1pad.c:	if (req->src_len + digest_size > ctx->key_size - 11)
crypto/rsa-pkcs1pad.c:	if (req->dst_len < ctx->key_size) {
crypto/rsa-pkcs1pad.c:		req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
crypto/rsa-pkcs1pad.c:	if (!req_ctx->in_buf)
crypto/rsa-pkcs1pad.c:	ps_end = ctx->key_size - digest_size - req->src_len - 2;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf[0] = 0x01;
crypto/rsa-pkcs1pad.c:	memset(req_ctx->in_buf + 1, 0xff, ps_end - 1);
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf[ps_end] = 0x00;
crypto/rsa-pkcs1pad.c:	memcpy(req_ctx->in_buf + ps_end + 1, digest_info->data,
crypto/rsa-pkcs1pad.c:	pkcs1pad_sg_set_buf(req_ctx->in_sg, req_ctx->in_buf,
crypto/rsa-pkcs1pad.c:			ctx->key_size - 1 - req->src_len, req->src);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req_ctx->in_sg,
crypto/rsa-pkcs1pad.c:				   req->dst, ctx->key_size - 1, req->dst_len);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_sign(&req_ctx->child_req);
crypto/rsa-pkcs1pad.c:	const struct rsa_asn1_template *digest_info = ictx->digest_info;
crypto/rsa-pkcs1pad.c:	dst_len = req_ctx->child_req.dst_len;
crypto/rsa-pkcs1pad.c:	if (dst_len < ctx->key_size - 1)
crypto/rsa-pkcs1pad.c:	out_buf = req_ctx->out_buf;
crypto/rsa-pkcs1pad.c:	if (dst_len == ctx->key_size) {
crypto/rsa-pkcs1pad.c:	kzfree(req_ctx->out_buf);
crypto/rsa-pkcs1pad.c:	if (!ctx->key_size || req->src_len < ctx->key_size)
crypto/rsa-pkcs1pad.c:	req_ctx->out_buf = kmalloc(ctx->key_size, GFP_KERNEL);
crypto/rsa-pkcs1pad.c:	if (!req_ctx->out_buf)
crypto/rsa-pkcs1pad.c:	pkcs1pad_sg_set_buf(req_ctx->out_sg, req_ctx->out_buf,
crypto/rsa-pkcs1pad.c:			    ctx->key_size, NULL);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_tfm(&req_ctx->child_req, ctx->child);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req->src,
crypto/rsa-pkcs1pad.c:				   req_ctx->out_sg, req->src_len,
crypto/rsa-pkcs1pad.c:				   ctx->key_size);
crypto/rsa-pkcs1pad.c:	err = crypto_akcipher_verify(&req_ctx->child_req);
crypto/rsa-pkcs1pad.c:	child_tfm = crypto_spawn_akcipher(&ictx->spawn);
crypto/rsa-pkcs1pad.c:	ctx->child = child_tfm;
crypto/rsa-pkcs1pad.c:	crypto_free_akcipher(ctx->child);
crypto/rsa-pkcs1pad.c:	struct crypto_akcipher_spawn *spawn = &ctx->spawn;
crypto/rsa-pkcs1pad.c:	spawn = &ctx->spawn;
crypto/rsa-pkcs1pad.c:	ctx->digest_info = digest_info;
crypto/crc32c_generic.c:	ctx->crc = mctx->key;
crypto/crc32c_generic.c:	if (keylen != sizeof(mctx->key)) {
crypto/crc32c_generic.c:	mctx->key = le32_to_cpu(*(__le32 *)key);
crypto/crc32c_generic.c:	ctx->crc = __crc32c_le(ctx->crc, data, length);
crypto/crc32c_generic.c:	*(__le32 *)out = ~cpu_to_le32p(&ctx->crc);
crypto/crc32c_generic.c:	return __chksum_finup(&ctx->crc, data, len, out);
crypto/crc32c_generic.c:	return __chksum_finup(&mctx->key, data, length, out);
crypto/crc32c_generic.c:	mctx->key = ~0;
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "md4";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "md5";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "sha1";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "sha256";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "sha384";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "sha512";
crypto/asymmetric_keys/mscode_parser.c:		ctx->digest_algo = "sha224";
crypto/asymmetric_keys/mscode_parser.c:	ctx->digest = kmemdup(value, vlen, GFP_KERNEL);
crypto/asymmetric_keys/mscode_parser.c:	if (!ctx->digest)
crypto/asymmetric_keys/mscode_parser.c:	ctx->digest_len = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg = kzalloc(sizeof(struct pkcs7_message), GFP_KERNEL);
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->msg)
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo = kzalloc(sizeof(struct pkcs7_signed_info), GFP_KERNEL);
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->sinfo)
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo->sig = kzalloc(sizeof(struct public_key_signature),
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->sinfo->sig)
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->data = (unsigned long)data;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->ppcerts = &ctx->certs;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->ppsinfo = &ctx->msg->signed_infos;
crypto/asymmetric_keys/pkcs7_parser.c:	ret = pkcs7_check_authattrs(ctx->msg);
crypto/asymmetric_keys/pkcs7_parser.c:	msg = ctx->msg;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg = NULL;
crypto/asymmetric_keys/pkcs7_parser.c:	while (ctx->certs) {
crypto/asymmetric_keys/pkcs7_parser.c:		struct x509_certificate *cert = ctx->certs;
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->certs = cert->next;
crypto/asymmetric_keys/pkcs7_parser.c:	pkcs7_free_signed_info(ctx->sinfo);
crypto/asymmetric_keys/pkcs7_parser.c:	pkcs7_free_message(ctx->msg);
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->last_oid = look_up_OID(value, vlen);
crypto/asymmetric_keys/pkcs7_parser.c:	if (ctx->last_oid == OID__NR) {
crypto/asymmetric_keys/pkcs7_parser.c:		       (unsigned long)value - ctx->data, buffer);
crypto/asymmetric_keys/pkcs7_parser.c:	switch (ctx->last_oid) {
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "md4";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "md5";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "sha1";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "sha256";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "sha384";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "sha512";
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->hash_algo = "sha224";
crypto/asymmetric_keys/pkcs7_parser.c:		printk("Unsupported digest algo: %u\n", ctx->last_oid);
crypto/asymmetric_keys/pkcs7_parser.c:	switch (ctx->last_oid) {
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->sinfo->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/pkcs7_parser.c:		printk("Unsupported pkey algo: %u\n", ctx->last_oid);
crypto/asymmetric_keys/pkcs7_parser.c:	if (ctx->last_oid != OID_signed_data) {
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->version = version = *(const u8 *)value;
crypto/asymmetric_keys/pkcs7_parser.c:		if (ctx->msg->version != 1)
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->expect_skid = false;
crypto/asymmetric_keys/pkcs7_parser.c:		if (ctx->msg->version == 1)
crypto/asymmetric_keys/pkcs7_parser.c:		ctx->expect_skid = true;
crypto/asymmetric_keys/pkcs7_parser.c:			 tag, (unsigned long)ctx - ctx->data);
crypto/asymmetric_keys/pkcs7_parser.c:	x509->index = ++ctx->x509_index;
crypto/asymmetric_keys/pkcs7_parser.c:	*ctx->ppcerts = x509;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->ppcerts = &x509->next;
crypto/asymmetric_keys/pkcs7_parser.c:	*ctx->ppcerts = ctx->msg->certs;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->certs = ctx->certs;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->certs = NULL;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->ppcerts = &ctx->certs;
crypto/asymmetric_keys/pkcs7_parser.c:	if (ctx->last_oid != OID_data &&
crypto/asymmetric_keys/pkcs7_parser.c:	    ctx->last_oid != OID_msIndirectData) {
crypto/asymmetric_keys/pkcs7_parser.c:		pr_warn("Unsupported data type %d\n", ctx->last_oid);
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->data_type = ctx->last_oid;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->data = value;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->data_len = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->msg->data_hdrlen = hdrlen;
crypto/asymmetric_keys/pkcs7_parser.c:	struct pkcs7_signed_info *sinfo = ctx->sinfo;
crypto/asymmetric_keys/pkcs7_parser.c:	switch (ctx->last_oid) {
crypto/asymmetric_keys/pkcs7_parser.c:		if (content_type != ctx->msg->data_type) {
crypto/asymmetric_keys/pkcs7_parser.c:				ctx->msg->data_type, sinfo->index,
crypto/asymmetric_keys/pkcs7_parser.c:		if (ctx->msg->data_type != OID_msIndirectData) {
crypto/asymmetric_keys/pkcs7_parser.c:		if (ctx->msg->data_type != OID_msIndirectData) {
crypto/asymmetric_keys/pkcs7_parser.c:	struct pkcs7_signed_info *sinfo = ctx->sinfo;
crypto/asymmetric_keys/pkcs7_parser.c:	if (ctx->msg->data_type != OID_msIndirectData &&
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_serial = value;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_serial_size = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_issuer = value;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_issuer_size = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_skid = value;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->raw_skid_size = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo->sig->s = kmemdup(value, vlen, GFP_KERNEL);
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->sinfo->sig->s)
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo->sig->s_size = vlen;
crypto/asymmetric_keys/pkcs7_parser.c:	struct pkcs7_signed_info *sinfo = ctx->sinfo;
crypto/asymmetric_keys/pkcs7_parser.c:	if (ctx->msg->data_type == OID_msIndirectData && !sinfo->authattrs) {
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->expect_skid) {
crypto/asymmetric_keys/pkcs7_parser.c:		kid = asymmetric_key_generate_id(ctx->raw_serial,
crypto/asymmetric_keys/pkcs7_parser.c:						 ctx->raw_serial_size,
crypto/asymmetric_keys/pkcs7_parser.c:						 ctx->raw_issuer,
crypto/asymmetric_keys/pkcs7_parser.c:						 ctx->raw_issuer_size);
crypto/asymmetric_keys/pkcs7_parser.c:		kid = asymmetric_key_generate_id(ctx->raw_skid,
crypto/asymmetric_keys/pkcs7_parser.c:						 ctx->raw_skid_size,
crypto/asymmetric_keys/pkcs7_parser.c:	sinfo->index = ++ctx->sinfo_index;
crypto/asymmetric_keys/pkcs7_parser.c:	*ctx->ppsinfo = sinfo;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->ppsinfo = &sinfo->next;
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo = kzalloc(sizeof(struct pkcs7_signed_info), GFP_KERNEL);
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->sinfo)
crypto/asymmetric_keys/pkcs7_parser.c:	ctx->sinfo->sig = kzalloc(sizeof(struct public_key_signature),
crypto/asymmetric_keys/pkcs7_parser.c:	if (!ctx->sinfo->sig)
crypto/asymmetric_keys/verify_pefile.c:		ctx->image_checksum_offset =
crypto/asymmetric_keys/verify_pefile.c:		ctx->header_size = pe32->header_size;
crypto/asymmetric_keys/verify_pefile.c:		ctx->n_data_dirents = pe32->data_dirs;
crypto/asymmetric_keys/verify_pefile.c:		ctx->image_checksum_offset =
crypto/asymmetric_keys/verify_pefile.c:		ctx->header_size = pe64->header_size;
crypto/asymmetric_keys/verify_pefile.c:		ctx->n_data_dirents = pe64->data_dirs;
crypto/asymmetric_keys/verify_pefile.c:	pr_debug("checksum @ %x\n", ctx->image_checksum_offset);
crypto/asymmetric_keys/verify_pefile.c:	pr_debug("header size = %x\n", ctx->header_size);
crypto/asymmetric_keys/verify_pefile.c:	if (cursor >= ctx->header_size || ctx->header_size >= datalen)
crypto/asymmetric_keys/verify_pefile.c:	if (ctx->n_data_dirents > (ctx->header_size - cursor) / sizeof(*dde))
crypto/asymmetric_keys/verify_pefile.c:	cursor += sizeof(*dde) * ctx->n_data_dirents;
crypto/asymmetric_keys/verify_pefile.c:	ctx->cert_dirent_offset =
crypto/asymmetric_keys/verify_pefile.c:	ctx->certs_size = ddir->certs.size;
crypto/asymmetric_keys/verify_pefile.c:	chkaddr(ctx->header_size, ddir->certs.virtual_address,
crypto/asymmetric_keys/verify_pefile.c:	ctx->sig_offset = ddir->certs.virtual_address;
crypto/asymmetric_keys/verify_pefile.c:	ctx->sig_len = ddir->certs.size;
crypto/asymmetric_keys/verify_pefile.c:		 ctx->sig_len, ctx->sig_offset,
crypto/asymmetric_keys/verify_pefile.c:		 ctx->sig_len, pebuf + ctx->sig_offset);
crypto/asymmetric_keys/verify_pefile.c:	ctx->n_sections = pe->sections;
crypto/asymmetric_keys/verify_pefile.c:	if (ctx->n_sections > (ctx->header_size - cursor) / sizeof(*sec))
crypto/asymmetric_keys/verify_pefile.c:	ctx->secs = secs = pebuf + cursor;
crypto/asymmetric_keys/verify_pefile.c:	if (ctx->sig_len < sizeof(wrapper)) {
crypto/asymmetric_keys/verify_pefile.c:	memcpy(&wrapper, pebuf + ctx->sig_offset, sizeof(wrapper));
crypto/asymmetric_keys/verify_pefile.c:	if (round_up(wrapper.length, 8) != ctx->sig_len) {
crypto/asymmetric_keys/verify_pefile.c:	ctx->sig_len = wrapper.length;
crypto/asymmetric_keys/verify_pefile.c:	ctx->sig_offset += sizeof(wrapper);
crypto/asymmetric_keys/verify_pefile.c:	ctx->sig_len -= sizeof(wrapper);
crypto/asymmetric_keys/verify_pefile.c:	if (ctx->sig_len < 4) {
crypto/asymmetric_keys/verify_pefile.c:	pkcs7 = pebuf + ctx->sig_offset;
crypto/asymmetric_keys/verify_pefile.c:	if (len <= ctx->sig_len) {
crypto/asymmetric_keys/verify_pefile.c:		ctx->sig_len = len;
crypto/asymmetric_keys/verify_pefile.c:	ret = crypto_shash_update(desc, pebuf, ctx->image_checksum_offset);
crypto/asymmetric_keys/verify_pefile.c:	tmp = ctx->image_checksum_offset + sizeof(uint32_t);
crypto/asymmetric_keys/verify_pefile.c:				  ctx->cert_dirent_offset - tmp);
crypto/asymmetric_keys/verify_pefile.c:	tmp = ctx->cert_dirent_offset + sizeof(struct data_dirent);
crypto/asymmetric_keys/verify_pefile.c:	ret = crypto_shash_update(desc, pebuf + tmp, ctx->header_size - tmp);
crypto/asymmetric_keys/verify_pefile.c:	canon = kcalloc(ctx->n_sections, sizeof(unsigned), GFP_KERNEL);
crypto/asymmetric_keys/verify_pefile.c:	for (loop = 1; loop < ctx->n_sections; loop++) {
crypto/asymmetric_keys/verify_pefile.c:			if (pefile_compare_shdrs(&ctx->secs[canon[i]],
crypto/asymmetric_keys/verify_pefile.c:						 &ctx->secs[loop]) > 0) {
crypto/asymmetric_keys/verify_pefile.c:	hashed_bytes = ctx->header_size;
crypto/asymmetric_keys/verify_pefile.c:	for (loop = 0; loop < ctx->n_sections; loop++) {
crypto/asymmetric_keys/verify_pefile.c:		if (ctx->secs[i].raw_data_size == 0)
crypto/asymmetric_keys/verify_pefile.c:					  pebuf + ctx->secs[i].data_addr,
crypto/asymmetric_keys/verify_pefile.c:					  ctx->secs[i].raw_data_size);
crypto/asymmetric_keys/verify_pefile.c:		hashed_bytes += ctx->secs[i].raw_data_size;
crypto/asymmetric_keys/verify_pefile.c:		tmp = hashed_bytes + ctx->certs_size;
crypto/asymmetric_keys/verify_pefile.c:	kenter(",%s", ctx->digest_algo);
crypto/asymmetric_keys/verify_pefile.c:	tfm = crypto_alloc_shash(ctx->digest_algo, 0, 0);
crypto/asymmetric_keys/verify_pefile.c:	if (digest_size != ctx->digest_len) {
crypto/asymmetric_keys/verify_pefile.c:			 digest_size, ctx->digest_len);
crypto/asymmetric_keys/verify_pefile.c:	pr_debug("Digest calc = [%*ph]\n", ctx->digest_len, digest);
crypto/asymmetric_keys/verify_pefile.c:	if (memcmp(digest, ctx->digest, ctx->digest_len) != 0) {
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert = cert;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->data = (unsigned long)data;
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->raw_akid) {
crypto/asymmetric_keys/x509_cert_parser.c:			 ctx->raw_akid_size, ctx->raw_akid_size, ctx->raw_akid);
crypto/asymmetric_keys/x509_cert_parser.c:				       ctx->raw_akid, ctx->raw_akid_size);
crypto/asymmetric_keys/x509_cert_parser.c:	cert->pub->key = kmemdup(ctx->key, ctx->key_size, GFP_KERNEL);
crypto/asymmetric_keys/x509_cert_parser.c:	cert->pub->keylen = ctx->key_size;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->last_oid = look_up_OID(value, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->last_oid == OID__NR) {
crypto/asymmetric_keys/x509_cert_parser.c:			 (unsigned long)value - ctx->data, buffer);
crypto/asymmetric_keys/x509_cert_parser.c:		 hdrlen, tag, (unsigned long)value - ctx->data, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->tbs = value - hdrlen;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->tbs_size = vlen + hdrlen;
crypto/asymmetric_keys/x509_cert_parser.c:	pr_debug("PubKey Algo: %u\n", ctx->last_oid);
crypto/asymmetric_keys/x509_cert_parser.c:	switch (ctx->last_oid) {
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "md4";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "sha1";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "sha256";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "sha384";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "sha512";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->hash_algo = "sha224";
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->sig->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->algo_oid = ctx->last_oid;
crypto/asymmetric_keys/x509_cert_parser.c:	pr_debug("Signature type: %u size %zu\n", ctx->last_oid, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->last_oid != ctx->algo_oid) {
crypto/asymmetric_keys/x509_cert_parser.c:			ctx->algo_oid, ctx->last_oid);
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_sig = value;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_sig_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_serial = value;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_serial_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	switch (ctx->last_oid) {
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cn_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cn_offset = (unsigned long)value - ctx->data;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->o_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->o_offset = (unsigned long)value - ctx->data;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->email_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->email_offset = (unsigned long)value - ctx->data;
crypto/asymmetric_keys/x509_cert_parser.c:	const void *name, *data = (const void *)ctx->data;
crypto/asymmetric_keys/x509_cert_parser.c:	if (!ctx->cn_size && !ctx->o_size && !ctx->email_size) {
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->cn_size && ctx->o_size) {
crypto/asymmetric_keys/x509_cert_parser.c:		namesize = ctx->cn_size;
crypto/asymmetric_keys/x509_cert_parser.c:		name = data + ctx->cn_offset;
crypto/asymmetric_keys/x509_cert_parser.c:		if (ctx->cn_size >= ctx->o_size &&
crypto/asymmetric_keys/x509_cert_parser.c:		    memcmp(data + ctx->cn_offset, data + ctx->o_offset,
crypto/asymmetric_keys/x509_cert_parser.c:			   ctx->o_size) == 0)
crypto/asymmetric_keys/x509_cert_parser.c:		if (ctx->cn_size >= 7 &&
crypto/asymmetric_keys/x509_cert_parser.c:		    ctx->o_size >= 7 &&
crypto/asymmetric_keys/x509_cert_parser.c:		    memcmp(data + ctx->cn_offset, data + ctx->o_offset, 7) == 0)
crypto/asymmetric_keys/x509_cert_parser.c:		buffer = kmalloc(ctx->o_size + 2 + ctx->cn_size + 1,
crypto/asymmetric_keys/x509_cert_parser.c:		       data + ctx->o_offset, ctx->o_size);
crypto/asymmetric_keys/x509_cert_parser.c:		buffer[ctx->o_size + 0] = ':';
crypto/asymmetric_keys/x509_cert_parser.c:		buffer[ctx->o_size + 1] = ' ';
crypto/asymmetric_keys/x509_cert_parser.c:		memcpy(buffer + ctx->o_size + 2,
crypto/asymmetric_keys/x509_cert_parser.c:		       data + ctx->cn_offset, ctx->cn_size);
crypto/asymmetric_keys/x509_cert_parser.c:		buffer[ctx->o_size + 2 + ctx->cn_size] = 0;
crypto/asymmetric_keys/x509_cert_parser.c:	} else if (ctx->cn_size) {
crypto/asymmetric_keys/x509_cert_parser.c:		namesize = ctx->cn_size;
crypto/asymmetric_keys/x509_cert_parser.c:		name = data + ctx->cn_offset;
crypto/asymmetric_keys/x509_cert_parser.c:	} else if (ctx->o_size) {
crypto/asymmetric_keys/x509_cert_parser.c:		namesize = ctx->o_size;
crypto/asymmetric_keys/x509_cert_parser.c:		name = data + ctx->o_offset;
crypto/asymmetric_keys/x509_cert_parser.c:		namesize = ctx->email_size;
crypto/asymmetric_keys/x509_cert_parser.c:		name = data + ctx->email_offset;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cn_size = 0;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->o_size = 0;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->email_size = 0;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_issuer = value;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_issuer_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	return x509_fabricate_name(ctx, hdrlen, tag, &ctx->cert->issuer, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_subject = value;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->raw_subject_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	return x509_fabricate_name(ctx, hdrlen, tag, &ctx->cert->subject, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->last_oid != OID_rsaEncryption)
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->pub->pkey_algo = "rsa";
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->key = value + 1;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->key_size = vlen - 1;
crypto/asymmetric_keys/x509_cert_parser.c:	pr_debug("Extension: %u\n", ctx->last_oid);
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->last_oid == OID_subjectKeyIdentifier) {
crypto/asymmetric_keys/x509_cert_parser.c:		if (ctx->cert->skid || vlen < 3)
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->raw_skid_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->raw_skid = v;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->cert->skid = kid;
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->last_oid == OID_authorityKeyIdentifier) {
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->raw_akid = v;
crypto/asymmetric_keys/x509_cert_parser.c:		ctx->raw_akid_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	return x509_decode_time(&ctx->cert->valid_from, hdrlen, tag, value, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	return x509_decode_time(&ctx->cert->valid_to, hdrlen, tag, value, vlen);
crypto/asymmetric_keys/x509_cert_parser.c:	if (ctx->cert->sig->auth_ids[1])
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->sig->auth_ids[1] = kid;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->akid_raw_issuer = value;
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->akid_raw_issuer_size = vlen;
crypto/asymmetric_keys/x509_cert_parser.c:	if (!ctx->akid_raw_issuer || ctx->cert->sig->auth_ids[0])
crypto/asymmetric_keys/x509_cert_parser.c:					 ctx->akid_raw_issuer,
crypto/asymmetric_keys/x509_cert_parser.c:					 ctx->akid_raw_issuer_size);
crypto/asymmetric_keys/x509_cert_parser.c:	ctx->cert->sig->auth_ids[0] = kid;
crypto/seqiv.c:	aead_request_set_tfm(subreq, ctx->child);
crypto/seqiv.c:		SKCIPHER_REQUEST_ON_STACK(nreq, ctx->sknull);
crypto/seqiv.c:		skcipher_request_set_tfm(nreq, ctx->sknull);
crypto/seqiv.c:	crypto_xor(info, ctx->salt, ivsize);
crypto/seqiv.c:	aead_request_set_tfm(subreq, ctx->child);
crypto/wp512.c:	const __be64 *buffer = (const __be64 *)wctx->buffer;
crypto/wp512.c:	state[0] = block[0] ^ (K[0] = wctx->hash[0]);
crypto/wp512.c:	state[1] = block[1] ^ (K[1] = wctx->hash[1]);
crypto/wp512.c:	state[2] = block[2] ^ (K[2] = wctx->hash[2]);
crypto/wp512.c:	state[3] = block[3] ^ (K[3] = wctx->hash[3]);
crypto/wp512.c:	state[4] = block[4] ^ (K[4] = wctx->hash[4]);
crypto/wp512.c:	state[5] = block[5] ^ (K[5] = wctx->hash[5]);
crypto/wp512.c:	state[6] = block[6] ^ (K[6] = wctx->hash[6]);
crypto/wp512.c:	state[7] = block[7] ^ (K[7] = wctx->hash[7]);
crypto/wp512.c:	wctx->hash[0] ^= state[0] ^ block[0];
crypto/wp512.c:	wctx->hash[1] ^= state[1] ^ block[1];
crypto/wp512.c:	wctx->hash[2] ^= state[2] ^ block[2];
crypto/wp512.c:	wctx->hash[3] ^= state[3] ^ block[3];
crypto/wp512.c:	wctx->hash[4] ^= state[4] ^ block[4];
crypto/wp512.c:	wctx->hash[5] ^= state[5] ^ block[5];
crypto/wp512.c:	wctx->hash[6] ^= state[6] ^ block[6];
crypto/wp512.c:	wctx->hash[7] ^= state[7] ^ block[7];
crypto/wp512.c:	memset(wctx->bitLength, 0, 32);
crypto/wp512.c:	wctx->bufferBits = wctx->bufferPos = 0;
crypto/wp512.c:	wctx->buffer[0] = 0;
crypto/wp512.c:		wctx->hash[i] = 0L;
crypto/wp512.c:	int bufferRem    = wctx->bufferBits & 7;
crypto/wp512.c:	u8 *buffer       = wctx->buffer;
crypto/wp512.c:	u8 *bitLength    = wctx->bitLength;
crypto/wp512.c:	int bufferBits   = wctx->bufferBits;
crypto/wp512.c:	int bufferPos    = wctx->bufferPos;
crypto/wp512.c:	wctx->bufferBits   = bufferBits;
crypto/wp512.c:	wctx->bufferPos    = bufferPos;
crypto/wp512.c:   	u8 *buffer      = wctx->buffer;
crypto/wp512.c:   	u8 *bitLength   = wctx->bitLength;
crypto/wp512.c:   	int bufferBits  = wctx->bufferBits;
crypto/wp512.c:   	int bufferPos   = wctx->bufferPos;
crypto/wp512.c:		digest[i] = cpu_to_be64(wctx->hash[i]);
crypto/wp512.c:   	wctx->bufferBits   = bufferBits;
crypto/wp512.c:   	wctx->bufferPos    = bufferPos;
crypto/authenc.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authenc.c:	struct crypto_skcipher *enc = ctx->enc;
crypto/authenc.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ictx->reqoff);
crypto/authenc.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authenc.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ictx->reqoff);
crypto/authenc.c:	u8 *hash = areq_ctx->tail;
crypto/authenc.c:	SKCIPHER_REQUEST_ON_STACK(skreq, ctx->null);
crypto/authenc.c:	skcipher_request_set_tfm(skreq, ctx->null);
crypto/authenc.c:	struct crypto_skcipher *enc = ctx->enc;
crypto/authenc.c:	struct skcipher_request *skreq = (void *)(areq_ctx->tail +
crypto/authenc.c:						  ictx->reqoff);
crypto/authenc.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, req->assoclen);
crypto/authenc.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, req->assoclen);
crypto/authenc.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ictx->reqoff);
crypto/authenc.c:	struct skcipher_request *skreq = (void *)(areq_ctx->tail +
crypto/authenc.c:						  ictx->reqoff);
crypto/authenc.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, req->assoclen);
crypto/authenc.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, req->assoclen);
crypto/authenc.c:	skcipher_request_set_tfm(skreq, ctx->enc);
crypto/authenc.c:	struct crypto_ahash *auth = ctx->auth;
crypto/authenc.c:	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ictx->reqoff);
crypto/authenc.c:	u8 *hash = areq_ctx->tail;
crypto/authenc.c:	auth = crypto_spawn_ahash(&ictx->auth);
crypto/authenc.c:	enc = crypto_spawn_skcipher2(&ictx->enc);
crypto/authenc.c:	ctx->auth = auth;
crypto/authenc.c:	ctx->enc = enc;
crypto/authenc.c:	ctx->null = null;
crypto/authenc.c:		ictx->reqoff +
crypto/authenc.c:	crypto_free_ahash(ctx->auth);
crypto/authenc.c:	crypto_free_skcipher(ctx->enc);
crypto/authenc.c:	crypto_drop_skcipher(&ctx->enc);
crypto/authenc.c:	crypto_drop_ahash(&ctx->auth);
crypto/authenc.c:	err = crypto_init_ahash_spawn(&ctx->auth, auth,
crypto/authenc.c:	crypto_set_skcipher_spawn(&ctx->enc, aead_crypto_instance(inst));
crypto/authenc.c:	err = crypto_grab_skcipher2(&ctx->enc, enc_name, 0,
crypto/authenc.c:	enc = crypto_spawn_skcipher_alg(&ctx->enc);
crypto/authenc.c:	ctx->reqoff = ALIGN(2 * auth->digestsize + auth_base->cra_alignmask,
crypto/authenc.c:	crypto_drop_skcipher(&ctx->enc);
crypto/authenc.c:	crypto_drop_ahash(&ctx->auth);
crypto/algif_aead.c:			  ctx->used, 0);
crypto/algif_aead.c:	unsigned as = crypto_aead_authsize(crypto_aead_reqtfm(&ctx->aead_req));
crypto/algif_aead.c:	return ctx->used >= ctx->aead_assoclen + (ctx->enc ? 0 : as);
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:	ctx->used = 0;
crypto/algif_aead.c:	ctx->more = 0;
crypto/algif_aead.c:	ctx->merge = 0;
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:		if (sk_wait_event(sk, &timeout, !ctx->more)) {
crypto/algif_aead.c:	if (ctx->more)
crypto/algif_aead.c:	if (!ctx->used)
crypto/algif_aead.c:		crypto_aead_ivsize(crypto_aead_reqtfm(&ctx->aead_req));
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:	if (!ctx->more && ctx->used)
crypto/algif_aead.c:		ctx->enc = enc;
crypto/algif_aead.c:			memcpy(ctx->iv, con.iv->iv, ivsize);
crypto/algif_aead.c:		ctx->aead_assoclen = con.aead_assoclen;
crypto/algif_aead.c:		if (ctx->merge) {
crypto/algif_aead.c:			ctx->merge = (sg->offset + sg->length) &
crypto/algif_aead.c:			ctx->used += len;
crypto/algif_aead.c:			ctx->used += plen;
crypto/algif_aead.c:			ctx->merge = plen & (PAGE_SIZE - 1);
crypto/algif_aead.c:	ctx->more = msg->msg_flags & MSG_MORE;
crypto/algif_aead.c:	if (!ctx->more && !aead_sufficient_data(ctx)) {
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:	if (!ctx->more && ctx->used)
crypto/algif_aead.c:	ctx->merge = 0;
crypto/algif_aead.c:	ctx->used += size;
crypto/algif_aead.c:	ctx->more = flags & MSG_MORE;
crypto/algif_aead.c:	if (!ctx->more && !aead_sufficient_data(ctx)) {
crypto/algif_aead.c:	struct crypto_aead *tfm = crypto_aead_reqtfm(&ctx->aead_req);
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:	if (ctx->more) {
crypto/algif_aead.c:	used = ctx->used;
crypto/algif_aead.c:	if (ctx->enc)
crypto/algif_aead.c:	memcpy(areq->iv, ctx->iv, crypto_aead_ivsize(tfm));
crypto/algif_aead.c:	aead_request_set_ad(req, ctx->aead_assoclen);
crypto/algif_aead.c:	used -= ctx->aead_assoclen;
crypto/algif_aead.c:	err = ctx->enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);
crypto/algif_aead.c:	unsigned as = crypto_aead_authsize(crypto_aead_reqtfm(&ctx->aead_req));
crypto/algif_aead.c:	struct aead_sg_list *sgl = &ctx->tsgl;
crypto/algif_aead.c:	if (ctx->more) {
crypto/algif_aead.c:	used = ctx->used;
crypto/algif_aead.c:	if (ctx->enc)
crypto/algif_aead.c:	used -= ctx->aead_assoclen;
crypto/algif_aead.c:		if (list_empty(&ctx->list)) {
crypto/algif_aead.c:			rsgl = &ctx->first_rsgl;
crypto/algif_aead.c:		list_add_tail(&rsgl->list, &ctx->list);
crypto/algif_aead.c:	aead_request_set_crypt(&ctx->aead_req, sgl->sg, ctx->first_rsgl.sgl.sg,
crypto/algif_aead.c:			       used, ctx->iv);
crypto/algif_aead.c:	aead_request_set_ad(&ctx->aead_req, ctx->aead_assoclen);
crypto/algif_aead.c:	err = af_alg_wait_for_completion(ctx->enc ?
crypto/algif_aead.c:					 crypto_aead_encrypt(&ctx->aead_req) :
crypto/algif_aead.c:					 crypto_aead_decrypt(&ctx->aead_req),
crypto/algif_aead.c:					 &ctx->completion);
crypto/algif_aead.c:	list_for_each_entry_safe(rsgl, tmp, &ctx->list, list) {
crypto/algif_aead.c:		if (rsgl != &ctx->first_rsgl)
crypto/algif_aead.c:	INIT_LIST_HEAD(&ctx->list);
crypto/algif_aead.c:	if (!ctx->more)
crypto/algif_aead.c:				crypto_aead_reqtfm(&ctx->aead_req));
crypto/algif_aead.c:	sock_kzfree_s(sk, ctx->iv, ivlen);
crypto/algif_aead.c:	sock_kfree_s(sk, ctx, ctx->len);
crypto/algif_aead.c:	ctx->iv = sock_kmalloc(sk, ivlen, GFP_KERNEL);
crypto/algif_aead.c:	if (!ctx->iv) {
crypto/algif_aead.c:	memset(ctx->iv, 0, ivlen);
crypto/algif_aead.c:	ctx->len = len;
crypto/algif_aead.c:	ctx->used = 0;
crypto/algif_aead.c:	ctx->more = 0;
crypto/algif_aead.c:	ctx->merge = 0;
crypto/algif_aead.c:	ctx->enc = 0;
crypto/algif_aead.c:	ctx->tsgl.cur = 0;
crypto/algif_aead.c:	ctx->aead_assoclen = 0;
crypto/algif_aead.c:	af_alg_init_completion(&ctx->completion);
crypto/algif_aead.c:	sg_init_table(ctx->tsgl.sg, ALG_MAX_PAGES);
crypto/algif_aead.c:	INIT_LIST_HEAD(&ctx->list);
crypto/algif_aead.c:	aead_request_set_tfm(&ctx->aead_req, aead);
crypto/algif_aead.c:	aead_request_set_callback(&ctx->aead_req, CRYPTO_TFM_REQ_MAY_BACKLOG,
crypto/algif_aead.c:				  af_alg_complete, &ctx->completion);
crypto/lz4.c:	ctx->lz4_comp_mem = vmalloc(LZ4_MEM_COMPRESS);
crypto/lz4.c:	if (!ctx->lz4_comp_mem)
crypto/lz4.c:	vfree(ctx->lz4_comp_mem);
crypto/lz4.c:	err = lz4_compress(src, slen, dst, &tmp_len, ctx->lz4_comp_mem);
crypto/pcrypt.c:	return crypto_aead_setkey(ctx->child, key, keylen);
crypto/pcrypt.c:	return crypto_aead_setauthsize(ctx->child, authsize);
crypto/pcrypt.c:	aead_request_set_tfm(creq, ctx->child);
crypto/pcrypt.c:	err = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pencrypt);
crypto/pcrypt.c:	aead_request_set_tfm(creq, ctx->child);
crypto/pcrypt.c:	err = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pdecrypt);
crypto/pcrypt.c:	cpu_index = (unsigned int)atomic_inc_return(&ictx->tfm_count) %
crypto/pcrypt.c:	ctx->cb_cpu = cpumask_first(cpu_online_mask);
crypto/pcrypt.c:		ctx->cb_cpu = cpumask_next(ctx->cb_cpu, cpu_online_mask);
crypto/pcrypt.c:	cipher = crypto_spawn_aead(&ictx->spawn);
crypto/pcrypt.c:	ctx->child = cipher;
crypto/pcrypt.c:	crypto_free_aead(ctx->child);
crypto/pcrypt.c:	crypto_set_aead_spawn(&ctx->spawn, aead_crypto_instance(inst));
crypto/pcrypt.c:	err = crypto_grab_aead(&ctx->spawn, name, 0, 0);
crypto/pcrypt.c:	alg = crypto_spawn_aead_alg(&ctx->spawn);
crypto/pcrypt.c:	crypto_drop_aead(&ctx->spawn);
crypto/pcrypt.c:	crypto_drop_aead(&ctx->spawn);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE) {
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE)
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE) {
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE)
drivers/md/dm-crypt.c:	ctx->bio_in = bio_in;
drivers/md/dm-crypt.c:	ctx->bio_out = bio_out;
drivers/md/dm-crypt.c:		ctx->iter_in = bio_in->bi_iter;
drivers/md/dm-crypt.c:		ctx->iter_out = bio_out->bi_iter;
drivers/md/dm-crypt.c:	ctx->cc_sector = sector + cc->iv_offset;
drivers/md/dm-crypt.c:	init_completion(&ctx->restart);
drivers/md/dm-crypt.c:	struct bio_vec bv_in = bio_iter_iovec(ctx->bio_in, ctx->iter_in);
drivers/md/dm-crypt.c:	struct bio_vec bv_out = bio_iter_iovec(ctx->bio_out, ctx->iter_out);
drivers/md/dm-crypt.c:	dmreq->iv_sector = ctx->cc_sector;
drivers/md/dm-crypt.c:	bio_advance_iter(ctx->bio_in, &ctx->iter_in, 1 << SECTOR_SHIFT);
drivers/md/dm-crypt.c:	bio_advance_iter(ctx->bio_out, &ctx->iter_out, 1 << SECTOR_SHIFT);
drivers/md/dm-crypt.c:	if (bio_data_dir(ctx->bio_in) == WRITE)
drivers/md/dm-crypt.c:	unsigned key_index = ctx->cc_sector & (cc->tfms_count - 1);
drivers/md/dm-crypt.c:	if (!ctx->req)
drivers/md/dm-crypt.c:		ctx->req = mempool_alloc(cc->req_pool, GFP_NOIO);
drivers/md/dm-crypt.c:	skcipher_request_set_tfm(ctx->req, cc->tfms[key_index]);
drivers/md/dm-crypt.c:	skcipher_request_set_callback(ctx->req,
drivers/md/dm-crypt.c:	    kcryptd_async_done, dmreq_of_req(cc, ctx->req));
drivers/md/dm-crypt.c:	atomic_set(&ctx->cc_pending, 1);
drivers/md/dm-crypt.c:	while (ctx->iter_in.bi_size && ctx->iter_out.bi_size) {
drivers/md/dm-crypt.c:		atomic_inc(&ctx->cc_pending);
drivers/md/dm-crypt.c:		r = crypt_convert_block(cc, ctx, ctx->req);
drivers/md/dm-crypt.c:			wait_for_completion(&ctx->restart);
drivers/md/dm-crypt.c:			reinit_completion(&ctx->restart);
drivers/md/dm-crypt.c:			ctx->req = NULL;
drivers/md/dm-crypt.c:			ctx->cc_sector++;
drivers/md/dm-crypt.c:			atomic_dec(&ctx->cc_pending);
drivers/md/dm-crypt.c:			ctx->cc_sector++;
drivers/md/dm-crypt.c:			atomic_dec(&ctx->cc_pending);
drivers/md/dm-crypt.c:		complete(&ctx->restart);
drivers/md/dm-crypt.c:	if (!atomic_dec_and_test(&ctx->cc_pending))
drivers/md/raid5-cache.c:	struct page *page = ctx->meta_page;
drivers/md/raid5-cache.c:	if (!sync_page_io(log->rdev, ctx->pos, PAGE_SIZE, page, REQ_OP_READ, 0,
drivers/md/raid5-cache.c:	    le64_to_cpu(mb->seq) != ctx->seq ||
drivers/md/raid5-cache.c:	    le64_to_cpu(mb->position) != ctx->pos)
drivers/md/raid5-cache.c:	ctx->meta_total_blocks = BLOCK_SECTORS;
drivers/md/raid5-cache.c:		payload = page_address(ctx->meta_page) + *offset;
drivers/md/raid5-cache.c:			ctx->meta_total_blocks += BLOCK_SECTORS;
drivers/md/raid5-cache.c:			ctx->meta_total_blocks += BLOCK_SECTORS * conf->max_degraded;
drivers/md/raid5-cache.c:	mb = page_address(ctx->meta_page);
drivers/md/raid5-cache.c:	log_offset = r5l_ring_add(log, ctx->pos, BLOCK_SECTORS);
drivers/md/raid5-cache.c:		ctx->seq++;
drivers/md/raid5-cache.c:		ctx->pos = r5l_ring_add(log, ctx->pos, ctx->meta_total_blocks);
drivers/md/dm-android-verity.h: * ctx->o_size + 2 + ctx->cn_size + 1
drivers/md/dm-switch.c:	sctx->ti = ti;
drivers/md/dm-switch.c:	sctx->region_size = region_size;
drivers/md/dm-switch.c:	if (!(sctx->region_size & (sctx->region_size - 1)))
drivers/md/dm-switch.c:		sctx->region_size_bits = __ffs(sctx->region_size);
drivers/md/dm-switch.c:		sctx->region_size_bits = -1;
drivers/md/dm-switch.c:	sctx->region_table_entry_bits = 1;
drivers/md/dm-switch.c:	while (sctx->region_table_entry_bits < sizeof(region_table_slot_t) * 8 &&
drivers/md/dm-switch.c:	       (region_table_slot_t)1 << sctx->region_table_entry_bits < nr_paths)
drivers/md/dm-switch.c:		sctx->region_table_entry_bits++;
drivers/md/dm-switch.c:	sctx->region_entries_per_slot = (sizeof(region_table_slot_t) * 8) / sctx->region_table_entry_bits;
drivers/md/dm-switch.c:	if (!(sctx->region_entries_per_slot & (sctx->region_entries_per_slot - 1)))
drivers/md/dm-switch.c:		sctx->region_entries_per_slot_bits = __ffs(sctx->region_entries_per_slot);
drivers/md/dm-switch.c:		sctx->region_entries_per_slot_bits = -1;
drivers/md/dm-switch.c:	if (sector_div(nr_regions, sctx->region_size))
drivers/md/dm-switch.c:	sctx->nr_regions = nr_regions;
drivers/md/dm-switch.c:	if (sector_div(nr_slots, sctx->region_entries_per_slot))
drivers/md/dm-switch.c:	sctx->region_table = vmalloc(nr_slots * sizeof(region_table_slot_t));
drivers/md/dm-switch.c:	if (!sctx->region_table) {
drivers/md/dm-switch.c:	if (sctx->region_entries_per_slot_bits >= 0) {
drivers/md/dm-switch.c:		*region_index = region_nr >> sctx->region_entries_per_slot_bits;
drivers/md/dm-switch.c:		*bit = region_nr & (sctx->region_entries_per_slot - 1);
drivers/md/dm-switch.c:		*region_index = region_nr / sctx->region_entries_per_slot;
drivers/md/dm-switch.c:		*bit = region_nr % sctx->region_entries_per_slot;
drivers/md/dm-switch.c:	*bit *= sctx->region_table_entry_bits;
drivers/md/dm-switch.c:	return (ACCESS_ONCE(sctx->region_table[region_index]) >> bit) &
drivers/md/dm-switch.c:		((1 << sctx->region_table_entry_bits) - 1);
drivers/md/dm-switch.c:	if (sctx->region_size_bits >= 0)
drivers/md/dm-switch.c:		p >>= sctx->region_size_bits;
drivers/md/dm-switch.c:		sector_div(p, sctx->region_size);
drivers/md/dm-switch.c:	if (unlikely(path_nr >= sctx->nr_paths))
drivers/md/dm-switch.c:	pte = sctx->region_table[region_index];
drivers/md/dm-switch.c:	pte &= ~((((region_table_slot_t)1 << sctx->region_table_entry_bits) - 1) << bit);
drivers/md/dm-switch.c:	sctx->region_table[region_index] = pte;
drivers/md/dm-switch.c:	for (region_nr = 0; region_nr < sctx->nr_regions; region_nr++) {
drivers/md/dm-switch.c:		if (++path_nr >= sctx->nr_paths)
drivers/md/dm-switch.c:			  &sctx->path_list[sctx->nr_paths].dmdev);
drivers/md/dm-switch.c:		dm_put_device(ti, sctx->path_list[sctx->nr_paths].dmdev);
drivers/md/dm-switch.c:	sctx->path_list[sctx->nr_paths].start = start;
drivers/md/dm-switch.c:	sctx->nr_paths++;
drivers/md/dm-switch.c:	while (sctx->nr_paths--)
drivers/md/dm-switch.c:		dm_put_device(ti, sctx->path_list[sctx->nr_paths].dmdev);
drivers/md/dm-switch.c:	vfree(sctx->region_table);
drivers/md/dm-switch.c:	bio->bi_bdev = sctx->path_list[path_nr].dmdev->bdev;
drivers/md/dm-switch.c:	bio->bi_iter.bi_sector = sctx->path_list[path_nr].start + offset;
drivers/md/dm-switch.c:			    unlikely(region_index + num_write >= sctx->nr_regions)) {
drivers/md/dm-switch.c:				       region_index, num_write, sctx->nr_regions);
drivers/md/dm-switch.c:		if (unlikely(region_index >= sctx->nr_regions)) {
drivers/md/dm-switch.c:			DMWARN("invalid set_region_mappings region number: %lu >= %lu", region_index, sctx->nr_regions);
drivers/md/dm-switch.c:		if (unlikely(path_nr >= sctx->nr_paths)) {
drivers/md/dm-switch.c:			DMWARN("invalid set_region_mappings device: %lu >= %u", path_nr, sctx->nr_paths);
drivers/md/dm-switch.c:		DMEMIT("%u %u 0", sctx->nr_paths, sctx->region_size);
drivers/md/dm-switch.c:		for (path_nr = 0; path_nr < sctx->nr_paths; path_nr++)
drivers/md/dm-switch.c:			DMEMIT(" %s %llu", sctx->path_list[path_nr].dmdev->name,
drivers/md/dm-switch.c:			       (unsigned long long)sctx->path_list[path_nr].start);
drivers/md/dm-switch.c:	*bdev = sctx->path_list[path_nr].dmdev->bdev;
drivers/md/dm-switch.c:	*mode = sctx->path_list[path_nr].dmdev->mode;
drivers/md/dm-switch.c:	if (ti->len + sctx->path_list[path_nr].start !=
drivers/md/dm-switch.c:	for (path_nr = 0; path_nr < sctx->nr_paths; path_nr++) {
drivers/md/dm-switch.c:		r = fn(ti, sctx->path_list[path_nr].dmdev,
drivers/md/dm-switch.c:			 sctx->path_list[path_nr].start, ti->len, data);
drivers/md/dm-rq.c:	if (unlikely(test_bit(BLK_MQ_S_STOPPED, &hctx->state)))
drivers/misc/cxl/fault.c:	unsigned int mask = (ctx->sst_size >> 7) - 1; /* SSTP0[SegTableSize] */
drivers/misc/cxl/fault.c:	primary = ctx->sstp + (hash << 3);
drivers/misc/cxl/fault.c:	ret = primary + ctx->sst_lru;
drivers/misc/cxl/fault.c:	ctx->sst_lru = (ctx->sst_lru + 1) & 0x7;
drivers/misc/cxl/fault.c:	spin_lock_irqsave(&ctx->sste_lock, flags);
drivers/misc/cxl/fault.c:			sste - ctx->sstp, slb->vsid, slb->esid);
drivers/misc/cxl/fault.c:	trace_cxl_ste_write(ctx, sste - ctx->sstp, slb->esid, slb->vsid);
drivers/misc/cxl/fault.c:	spin_unlock_irqrestore(&ctx->sste_lock, flags);
drivers/misc/cxl/fault.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/misc/cxl/fault.c:	ctx->pending_fault = true;
drivers/misc/cxl/fault.c:	ctx->fault_addr = ctx->dar;
drivers/misc/cxl/fault.c:	ctx->fault_dsisr = ctx->dsisr;
drivers/misc/cxl/fault.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/fault.c:	wake_up_all(&ctx->wq);
drivers/misc/cxl/fault.c:	pr_devel("CXL interrupt: Segment fault pe: %i ea: %#llx\n", ctx->pe, ea);
drivers/misc/cxl/fault.c:	if ((!ctx->kernel) || (REGION_ID(dar) == USER_REGION_ID))
drivers/misc/cxl/fault.c:	pr_devel("Page fault successfully handled for pe: %i!\n", ctx->pe);
drivers/misc/cxl/fault.c: * Returns the mm_struct corresponding to the context ctx via ctx->pid
drivers/misc/cxl/fault.c: * via ctx->glpid to find the next task in the thread group that has a
drivers/misc/cxl/fault.c: * is found the ctx->pid is updated to use the task struct for subsequent
drivers/misc/cxl/fault.c:	struct pid *old_pid = ctx->pid;
drivers/misc/cxl/fault.c:			 __func__, ctx->pe);
drivers/misc/cxl/fault.c:			__func__, pid_nr(old_pid), ctx->pe);
drivers/misc/cxl/fault.c:	if (unlikely(mm == NULL && ctx->glpid != NULL)) {
drivers/misc/cxl/fault.c:		task = pid_task(ctx->glpid, PIDTYPE_PID);
drivers/misc/cxl/fault.c:					ctx->pid = get_task_pid(task,
drivers/misc/cxl/fault.c:		if (ctx->pid != old_pid) {
drivers/misc/cxl/fault.c:					 __func__, ctx->pe, pid_nr(old_pid),
drivers/misc/cxl/fault.c:					 pid_nr(ctx->pid));
drivers/misc/cxl/fault.c:	u64 dsisr = ctx->dsisr;
drivers/misc/cxl/fault.c:	u64 dar = ctx->dar;
drivers/misc/cxl/fault.c:		if (cxl_p2n_read(ctx->afu, CXL_PSL_DSISR_An) != dsisr ||
drivers/misc/cxl/fault.c:		    cxl_p2n_read(ctx->afu, CXL_PSL_DAR_An) != dar ||
drivers/misc/cxl/fault.c:		    cxl_p2n_read(ctx->afu, CXL_PSL_PEHandle_An) != ctx->pe) {
drivers/misc/cxl/fault.c:			dev_notice(&ctx->afu->dev, "cxl_handle_fault: Translation fault regs changed\n");
drivers/misc/cxl/fault.c:	if (ctx->status == CLOSED) {
drivers/misc/cxl/fault.c:		"DSISR: %#llx DAR: %#llx\n", ctx->pe, dsisr, dar);
drivers/misc/cxl/fault.c:	if (!ctx->kernel) {
drivers/misc/cxl/fault.c:				 __func__, ctx->pe, pid_nr(ctx->pid));
drivers/misc/cxl/fault.c:				 ctx->pe, pid_nr(ctx->pid));
drivers/misc/cxl/fault.c:			 pid_nr(ctx->pid));
drivers/misc/cxl/fault.c:			 pid_nr(ctx->pid));
drivers/misc/cxl/fault.c:	switch (ctx->afu->prefault_mode) {
drivers/misc/cxl/api.c:	ctx->kernelapi = true;
drivers/misc/cxl/api.c:	if (ctx->status >= STARTED)
drivers/misc/cxl/api.c:		range = ctx->irqs.range[r];
drivers/misc/cxl/api.c:			return ctx->irqs.offset[r] + num;
drivers/misc/cxl/api.c:	ctx->priv = priv;
drivers/misc/cxl/api.c:	return ctx->priv;
drivers/misc/cxl/api.c:		num = ctx->afu->pp_irqs;
drivers/misc/cxl/api.c:			cxl_map_irq(ctx->afu->adapter, hwirq, cxl_ops->psl_interrupt, ctx, "psl");
drivers/misc/cxl/api.c:	if (ctx->status == STARTED) {
drivers/misc/cxl/api.c:	cxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);
drivers/misc/cxl/api.c:	return cxl_map_irq(ctx->afu->adapter, hwirq, handler, cookie, name);
drivers/misc/cxl/api.c:	pr_devel("%s: pe: %i\n", __func__, ctx->pe);
drivers/misc/cxl/api.c:	mutex_lock(&ctx->status_mutex);
drivers/misc/cxl/api.c:	if (ctx->status == STARTED)
drivers/misc/cxl/api.c:	rc = cxl_adapter_context_get(ctx->afu->adapter);
drivers/misc/cxl/api.c:		ctx->pid = get_task_pid(task, PIDTYPE_PID);
drivers/misc/cxl/api.c:		ctx->glpid = get_task_pid(task->group_leader, PIDTYPE_PID);
drivers/misc/cxl/api.c:		ctx->real_mode = false;
drivers/misc/cxl/api.c:		put_pid(ctx->glpid);
drivers/misc/cxl/api.c:		put_pid(ctx->pid);
drivers/misc/cxl/api.c:		ctx->glpid = ctx->pid = NULL;
drivers/misc/cxl/api.c:		cxl_adapter_context_put(ctx->afu->adapter);
drivers/misc/cxl/api.c:	ctx->status = STARTED;
drivers/misc/cxl/api.c:	mutex_unlock(&ctx->status_mutex);
drivers/misc/cxl/api.c:	return ctx->external_pe;
drivers/misc/cxl/api.c:	ctx->master = true;
drivers/misc/cxl/api.c:	if (ctx->status == STARTED) {
drivers/misc/cxl/api.c:	ctx->real_mode = real_mode;
drivers/misc/cxl/api.c:	file->f_mapping = ctx->mapping;
drivers/misc/cxl/api.c:	atomic_set(&ctx->afu_driver_events, 0);
drivers/misc/cxl/api.c:	ctx->afu_driver_ops = ops;
drivers/misc/cxl/api.c:	atomic_add(new_events, &ctx->afu_driver_events);
drivers/misc/cxl/api.c:	wake_up_all(&ctx->wq);
drivers/misc/cxl/api.c:		work->num_interrupts = ctx->afu->pp_irqs;
drivers/misc/cxl/api.c:	else if ((work->num_interrupts < ctx->afu->pp_irqs) ||
drivers/misc/cxl/api.c:		 (work->num_interrupts > ctx->afu->irqs_max)) {
drivers/misc/cxl/api.c:	if (ctx->status != STARTED)
drivers/misc/cxl/api.c:		__func__, ctx->psn_phys, ctx->psn_size);
drivers/misc/cxl/api.c:	return ioremap(ctx->psn_phys, ctx->psn_size);
drivers/misc/cxl/api.c:	struct cxl_afu *afu = ctx->afu;
drivers/misc/cxl/api.c:		rc = cxl_allocate_afu_irqs(ctx, min(remaining, ctx->afu->irqs_max));
drivers/misc/cxl/api.c:		remaining -= ctx->afu->irqs_max;
drivers/misc/cxl/api.c:		if (ctx != default_ctx && default_ctx->status == STARTED) {
drivers/misc/cxl/api.c:				be64_to_cpu(default_ctx->elem->common.wed),
drivers/misc/cxl/api.c:			list_add(&new_ctx->extra_irq_contexts, &ctx->extra_irq_contexts);
drivers/misc/cxl/api.c:	list_for_each_entry_safe(pos, tmp, &ctx->extra_irq_contexts, extra_irq_contexts) {
drivers/misc/cxl/file.c:	pr_devel("afu_open pe: %i\n", ctx->pe);
drivers/misc/cxl/file.c:		 __func__, ctx->pe);
drivers/misc/cxl/file.c:	if (!ctx->kernelapi) {
drivers/misc/cxl/file.c:		mutex_lock(&ctx->mapping_lock);
drivers/misc/cxl/file.c:		ctx->mapping = NULL;
drivers/misc/cxl/file.c:		mutex_unlock(&ctx->mapping_lock);
drivers/misc/cxl/file.c:	pr_devel("%s: pe: %i\n", __func__, ctx->pe);
drivers/misc/cxl/file.c:	mutex_lock(&ctx->status_mutex);
drivers/misc/cxl/file.c:	if (ctx->status != OPENED) {
drivers/misc/cxl/file.c:		work.num_interrupts = ctx->afu->pp_irqs;
drivers/misc/cxl/file.c:	else if ((work.num_interrupts < ctx->afu->pp_irqs) ||
drivers/misc/cxl/file.c:		 (work.num_interrupts > ctx->afu->irqs_max)) {
drivers/misc/cxl/file.c:	ctx->mmio_err_ff = !!(work.flags & CXL_START_WORK_ERR_FF);
drivers/misc/cxl/file.c:	rc = cxl_adapter_context_get(ctx->afu->adapter);
drivers/misc/cxl/file.c:	ctx->pid = get_task_pid(current, PIDTYPE_PID);
drivers/misc/cxl/file.c:	ctx->glpid = get_task_pid(current->group_leader, PIDTYPE_PID);
drivers/misc/cxl/file.c:		cxl_adapter_context_put(ctx->afu->adapter);
drivers/misc/cxl/file.c:		put_pid(ctx->glpid);
drivers/misc/cxl/file.c:		put_pid(ctx->pid);
drivers/misc/cxl/file.c:		ctx->glpid = ctx->pid = NULL;
drivers/misc/cxl/file.c:	ctx->status = STARTED;
drivers/misc/cxl/file.c:	mutex_unlock(&ctx->status_mutex);
drivers/misc/cxl/file.c:	pr_devel("%s: pe: %i\n", __func__, ctx->pe);
drivers/misc/cxl/file.c:	if (copy_to_user(upe, &ctx->external_pe, sizeof(__u32)))
drivers/misc/cxl/file.c:	afuid.card_id = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/file.c:	afuid.afu_offset = ctx->afu->slice;
drivers/misc/cxl/file.c:	afuid.afu_mode = ctx->afu->current_mode;
drivers/misc/cxl/file.c:	if (ctx->afu->current_mode == CXL_MODE_DIRECTED && !ctx->master)
drivers/misc/cxl/file.c:	if (ctx->status == CLOSED)
drivers/misc/cxl/file.c:	if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/file.c:	if (ctx->status != STARTED)
drivers/misc/cxl/file.c:	if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/file.c:	if (ctx->pending_irq || ctx->pending_fault || ctx->pending_afu_err)
drivers/misc/cxl/file.c:	if (ctx->afu_driver_ops && atomic_read(&ctx->afu_driver_events))
drivers/misc/cxl/file.c:	poll_wait(file, &ctx->wq, poll);
drivers/misc/cxl/file.c:	pr_devel("afu_poll wait done pe: %i\n", ctx->pe);
drivers/misc/cxl/file.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/misc/cxl/file.c:	else if (ctx->status == CLOSED)
drivers/misc/cxl/file.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/file.c:	pr_devel("afu_poll pe: %i returning %#x\n", ctx->pe, mask);
drivers/misc/cxl/file.c:		ctx->afu_driver_ops->event_delivered(ctx, pl, -EINVAL);
drivers/misc/cxl/file.c:		ctx->afu_driver_ops->event_delivered(ctx, pl, -EINVAL);
drivers/misc/cxl/file.c:		ctx->afu_driver_ops->event_delivered(ctx, pl, -EFAULT);
drivers/misc/cxl/file.c:		ctx->afu_driver_ops->event_delivered(ctx, pl, -EFAULT);
drivers/misc/cxl/file.c:	ctx->afu_driver_ops->event_delivered(ctx, pl, 0); /* Success */
drivers/misc/cxl/file.c:	if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/file.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/misc/cxl/file.c:		prepare_to_wait(&ctx->wq, &wait, TASK_INTERRUPTIBLE);
drivers/misc/cxl/file.c:		if (ctx_event_pending(ctx) || (ctx->status == CLOSED))
drivers/misc/cxl/file.c:		if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu)) {
drivers/misc/cxl/file.c:		spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/file.c:		spin_lock_irqsave(&ctx->lock, flags);
drivers/misc/cxl/file.c:	finish_wait(&ctx->wq, &wait);
drivers/misc/cxl/file.c:	event.header.process_element = ctx->pe;
drivers/misc/cxl/file.c:	if (ctx->afu_driver_ops && atomic_read(&ctx->afu_driver_events)) {
drivers/misc/cxl/file.c:		pl = ctx->afu_driver_ops->fetch_event(ctx);
drivers/misc/cxl/file.c:		atomic_dec(&ctx->afu_driver_events);
drivers/misc/cxl/file.c:	} else if (ctx->pending_irq) {
drivers/misc/cxl/file.c:		event.irq.irq = find_first_bit(ctx->irq_bitmap, ctx->irq_count) + 1;
drivers/misc/cxl/file.c:		clear_bit(event.irq.irq - 1, ctx->irq_bitmap);
drivers/misc/cxl/file.c:		if (bitmap_empty(ctx->irq_bitmap, ctx->irq_count))
drivers/misc/cxl/file.c:			ctx->pending_irq = false;
drivers/misc/cxl/file.c:	} else if (ctx->pending_fault) {
drivers/misc/cxl/file.c:		event.fault.addr = ctx->fault_addr;
drivers/misc/cxl/file.c:		event.fault.dsisr = ctx->fault_dsisr;
drivers/misc/cxl/file.c:		ctx->pending_fault = false;
drivers/misc/cxl/file.c:	} else if (ctx->pending_afu_err) {
drivers/misc/cxl/file.c:		event.afu_error.error = ctx->afu_err;
drivers/misc/cxl/file.c:		ctx->pending_afu_err = false;
drivers/misc/cxl/file.c:	} else if (ctx->status == CLOSED) {
drivers/misc/cxl/file.c:		spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/file.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/file.c:	finish_wait(&ctx->wq, &wait);
drivers/misc/cxl/file.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/misc/cxl/phb.c:		if (ctx->status == STARTED) {
drivers/misc/cxl/context.c:	spin_lock_init(&ctx->sste_lock);
drivers/misc/cxl/context.c:	ctx->afu = afu;
drivers/misc/cxl/context.c:	ctx->master = master;
drivers/misc/cxl/context.c:	ctx->pid = ctx->glpid = NULL; /* Set in start work ioctl */
drivers/misc/cxl/context.c:	mutex_init(&ctx->mapping_lock);
drivers/misc/cxl/context.c:	ctx->mapping = mapping;
drivers/misc/cxl/context.c:	INIT_WORK(&ctx->fault_work, cxl_handle_fault);
drivers/misc/cxl/context.c:	init_waitqueue_head(&ctx->wq);
drivers/misc/cxl/context.c:	spin_lock_init(&ctx->lock);
drivers/misc/cxl/context.c:	ctx->irq_bitmap = NULL;
drivers/misc/cxl/context.c:	ctx->pending_irq = false;
drivers/misc/cxl/context.c:	ctx->pending_fault = false;
drivers/misc/cxl/context.c:	ctx->pending_afu_err = false;
drivers/misc/cxl/context.c:	INIT_LIST_HEAD(&ctx->irq_names);
drivers/misc/cxl/context.c:	INIT_LIST_HEAD(&ctx->extra_irq_contexts);
drivers/misc/cxl/context.c:		ctx->irqs.range[i] = 0;
drivers/misc/cxl/context.c:	mutex_init(&ctx->status_mutex);
drivers/misc/cxl/context.c:	ctx->status = OPENED;
drivers/misc/cxl/context.c:	i = idr_alloc(&ctx->afu->contexts_idr, ctx, ctx->afu->adapter->min_pe,
drivers/misc/cxl/context.c:		      ctx->afu->num_procs, GFP_NOWAIT);
drivers/misc/cxl/context.c:	ctx->pe = i;
drivers/misc/cxl/context.c:		ctx->elem = &ctx->afu->native->spa[i];
drivers/misc/cxl/context.c:		ctx->external_pe = ctx->pe;
drivers/misc/cxl/context.c:		ctx->external_pe = -1; /* assigned when attaching */
drivers/misc/cxl/context.c:	ctx->pe_inserted = false;
drivers/misc/cxl/context.c:			__func__, ctx->pe, address, offset);
drivers/misc/cxl/context.c:	if (ctx->afu->current_mode == CXL_MODE_DEDICATED) {
drivers/misc/cxl/context.c:		area = ctx->afu->psn_phys;
drivers/misc/cxl/context.c:		if (offset >= ctx->afu->adapter->ps_size)
drivers/misc/cxl/context.c:		area = ctx->psn_phys;
drivers/misc/cxl/context.c:		if (offset >= ctx->psn_size)
drivers/misc/cxl/context.c:	mutex_lock(&ctx->status_mutex);
drivers/misc/cxl/context.c:	if (ctx->status != STARTED) {
drivers/misc/cxl/context.c:		mutex_unlock(&ctx->status_mutex);
drivers/misc/cxl/context.c:		if (ctx->mmio_err_ff) {
drivers/misc/cxl/context.c:			if (!ctx->ff_page) {
drivers/misc/cxl/context.c:				ctx->ff_page = alloc_page(GFP_USER);
drivers/misc/cxl/context.c:				if (!ctx->ff_page)
drivers/misc/cxl/context.c:				memset(page_address(ctx->ff_page), 0xff, PAGE_SIZE);
drivers/misc/cxl/context.c:			get_page(ctx->ff_page);
drivers/misc/cxl/context.c:			vmf->page = ctx->ff_page;
drivers/misc/cxl/context.c:	mutex_unlock(&ctx->status_mutex);
drivers/misc/cxl/context.c:	if (ctx->afu->current_mode == CXL_MODE_DEDICATED) {
drivers/misc/cxl/context.c:		if (start + len > ctx->afu->adapter->ps_size)
drivers/misc/cxl/context.c:		if (start + len > ctx->psn_size)
drivers/misc/cxl/context.c:	if (ctx->afu->current_mode != CXL_MODE_DEDICATED) {
drivers/misc/cxl/context.c:		if ((ctx->master && !ctx->afu->psa) || (!ctx->afu->pp_psa)) {
drivers/misc/cxl/context.c:		if (!ctx->afu->enabled)
drivers/misc/cxl/context.c:		 ctx->psn_phys, ctx->pe , ctx->master);
drivers/misc/cxl/context.c:	mutex_lock(&ctx->status_mutex);
drivers/misc/cxl/context.c:	status = ctx->status;
drivers/misc/cxl/context.c:	ctx->status = CLOSED;
drivers/misc/cxl/context.c:	mutex_unlock(&ctx->status_mutex);
drivers/misc/cxl/context.c:		cxl_ops->link_ok(ctx->afu->adapter, ctx->afu));
drivers/misc/cxl/context.c:	flush_work(&ctx->fault_work); /* Only needed for dedicated process */
drivers/misc/cxl/context.c:	put_pid(ctx->pid);
drivers/misc/cxl/context.c:	put_pid(ctx->glpid);
drivers/misc/cxl/context.c:	cxl_adapter_context_put(ctx->afu->adapter);
drivers/misc/cxl/context.c:	wake_up_all(&ctx->wq);
drivers/misc/cxl/context.c:		mutex_lock(&ctx->mapping_lock);
drivers/misc/cxl/context.c:		if (ctx->mapping)
drivers/misc/cxl/context.c:			unmap_mapping_range(ctx->mapping, 0, 0, 1);
drivers/misc/cxl/context.c:		mutex_unlock(&ctx->mapping_lock);
drivers/misc/cxl/context.c:	free_page((u64)ctx->sstp);
drivers/misc/cxl/context.c:	if (ctx->ff_page)
drivers/misc/cxl/context.c:		__free_page(ctx->ff_page);
drivers/misc/cxl/context.c:	ctx->sstp = NULL;
drivers/misc/cxl/context.c:	if (ctx->kernelapi)
drivers/misc/cxl/context.c:		kfree(ctx->mapping);
drivers/misc/cxl/context.c:	kfree(ctx->irq_bitmap);
drivers/misc/cxl/context.c:	cxl_afu_put(ctx->afu);
drivers/misc/cxl/context.c:	mutex_lock(&ctx->afu->contexts_lock);
drivers/misc/cxl/context.c:	idr_remove(&ctx->afu->contexts_idr, ctx->pe);
drivers/misc/cxl/context.c:	mutex_unlock(&ctx->afu->contexts_lock);
drivers/misc/cxl/context.c:	call_rcu(&ctx->rcu, reclaim_ctx);
drivers/misc/cxl/guest.c:	dev_crit(&ctx->afu->dev, "PSL ERROR STATUS: 0x%.16llx\n", errstat);
drivers/misc/cxl/guest.c:	return cxl_h_collect_int_info(ctx->afu->guest->handle, ctx->process_token, info);
drivers/misc/cxl/guest.c:	pr_devel("%d: received PSL interrupt %i\n", ctx->pe, irq);
drivers/misc/cxl/guest.c:	return cxl_h_control_faults(ctx->afu->guest->handle, ctx->process_token,
drivers/misc/cxl/guest.c:	pr_devel("Disabling AFU(%d) interrupts\n", ctx->afu->slice);
drivers/misc/cxl/guest.c:		hwirq = ctx->irqs.offset[r];
drivers/misc/cxl/guest.c:		for (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {
drivers/misc/cxl/guest.c:	pr_devel("Enabling AFU(%d) interrupts\n", ctx->afu->slice);
drivers/misc/cxl/guest.c:		hwirq = ctx->irqs.offset[r];
drivers/misc/cxl/guest.c:		for (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {
drivers/misc/cxl/guest.c:	struct cxl *adapter = ctx->afu->adapter;
drivers/misc/cxl/guest.c:	if (ctx->kernel) {
drivers/misc/cxl/guest.c:	elem->common.sstp0  = cpu_to_be64(ctx->sstp0);
drivers/misc/cxl/guest.c:	elem->common.sstp1  = cpu_to_be64(ctx->sstp1);
drivers/misc/cxl/guest.c:	if (ctx->irqs.range[0] == 0) {
drivers/misc/cxl/guest.c:		for (i = 0; i < ctx->irqs.range[r]; i++) {
drivers/misc/cxl/guest.c:				elem->pslVirtualIsn = cpu_to_be32(ctx->irqs.offset[0]);
drivers/misc/cxl/guest.c:				idx = ctx->irqs.offset[r] + i - adapter->guest->irq_base_offset;
drivers/misc/cxl/guest.c:	rc = cxl_h_attach_process(ctx->afu->guest->handle, elem,
drivers/misc/cxl/guest.c:				&ctx->process_token, &mmio_addr, &mmio_size);
drivers/misc/cxl/guest.c:		if (ctx->master || !ctx->afu->pp_psa) {
drivers/misc/cxl/guest.c:			ctx->psn_phys = ctx->afu->psn_phys;
drivers/misc/cxl/guest.c:			ctx->psn_size = ctx->afu->adapter->ps_size;
drivers/misc/cxl/guest.c:			ctx->psn_phys = mmio_addr;
drivers/misc/cxl/guest.c:			ctx->psn_size = mmio_size;
drivers/misc/cxl/guest.c:		if (ctx->afu->pp_psa && mmio_size &&
drivers/misc/cxl/guest.c:			ctx->afu->pp_size == 0) {
drivers/misc/cxl/guest.c:			ctx->afu->pp_size = mmio_size;
drivers/misc/cxl/guest.c:		ctx->external_pe = ctx->process_token & 0xFFFFFFFF;
drivers/misc/cxl/guest.c:			ctx->pe, ctx->external_pe, ctx->psn_size);
drivers/misc/cxl/guest.c:		ctx->pe_inserted = true;
drivers/misc/cxl/guest.c:	if (ctx->real_mode)
drivers/misc/cxl/guest.c:	ctx->kernel = kernel;
drivers/misc/cxl/guest.c:	if (ctx->afu->current_mode == CXL_MODE_DIRECTED)
drivers/misc/cxl/guest.c:	if (!ctx->pe_inserted)
drivers/misc/cxl/guest.c:	if (cxl_h_detach_process(ctx->afu->guest->handle, ctx->process_token))
drivers/misc/cxl/guest.c:	if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/guest.c:	if (ctx->afu->current_mode == CXL_MODE_DIRECTED)
drivers/misc/cxl/irq.c:	ctx->dsisr = dsisr;
drivers/misc/cxl/irq.c:	ctx->dar = dar;
drivers/misc/cxl/irq.c:	schedule_work(&ctx->fault_work);
drivers/misc/cxl/irq.c:	pr_devel("CXL interrupt %i for afu pe: %i DSISR: %#llx DAR: %#llx\n", irq, ctx->pe, dsisr, dar);
drivers/misc/cxl/irq.c:		pr_devel("Scheduling segment miss handling for later pe: %i\n", ctx->pe);
drivers/misc/cxl/irq.c:		pr_devel("Scheduling page fault handling for later pe: %i\n", ctx->pe);
drivers/misc/cxl/irq.c:		if (ctx->pending_afu_err) {
drivers/misc/cxl/irq.c:			dev_err_ratelimited(&ctx->afu->dev, "CXL AFU Error "
drivers/misc/cxl/irq.c:					    ctx->pe, irq_info->afu_err);
drivers/misc/cxl/irq.c:			spin_lock(&ctx->lock);
drivers/misc/cxl/irq.c:			ctx->afu_err = irq_info->afu_err;
drivers/misc/cxl/irq.c:			ctx->pending_afu_err = 1;
drivers/misc/cxl/irq.c:			spin_unlock(&ctx->lock);
drivers/misc/cxl/irq.c:			wake_up_all(&ctx->wq);
drivers/misc/cxl/irq.c:		irq_off = hwirq - ctx->irqs.offset[r];
drivers/misc/cxl/irq.c:		range = ctx->irqs.range[r];
drivers/misc/cxl/irq.c:		     ctx->pe, irq, hwirq);
drivers/misc/cxl/irq.c:	       afu_irq, ctx->pe, irq, hwirq);
drivers/misc/cxl/irq.c:	if (unlikely(!ctx->irq_bitmap)) {
drivers/misc/cxl/irq.c:	spin_lock(&ctx->lock);
drivers/misc/cxl/irq.c:	set_bit(afu_irq - 1, ctx->irq_bitmap);
drivers/misc/cxl/irq.c:	ctx->pending_irq = true;
drivers/misc/cxl/irq.c:	spin_unlock(&ctx->lock);
drivers/misc/cxl/irq.c:	wake_up_all(&ctx->wq);
drivers/misc/cxl/irq.c:	list_for_each_entry_safe(irq_name, tmp, &ctx->irq_names, list) {
drivers/misc/cxl/irq.c:	if ((rc = cxl_ops->alloc_irq_ranges(&ctx->irqs, ctx->afu->adapter,
drivers/misc/cxl/irq.c:		ctx->irqs.offset[0] = ctx->afu->native->psl_hwirq;
drivers/misc/cxl/irq.c:		ctx->irqs.range[0] = 1;
drivers/misc/cxl/irq.c:	ctx->irq_count = count;
drivers/misc/cxl/irq.c:	ctx->irq_bitmap = kcalloc(BITS_TO_LONGS(count),
drivers/misc/cxl/irq.c:				  sizeof(*ctx->irq_bitmap), GFP_KERNEL);
drivers/misc/cxl/irq.c:	if (!ctx->irq_bitmap)
drivers/misc/cxl/irq.c:		for (i = 0; i < ctx->irqs.range[r]; i++) {
drivers/misc/cxl/irq.c:						   dev_name(&ctx->afu->dev),
drivers/misc/cxl/irq.c:						   ctx->pe, j);
drivers/misc/cxl/irq.c:			list_add_tail(&irq_name->list, &ctx->irq_names);
drivers/misc/cxl/irq.c:	cxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);
drivers/misc/cxl/irq.c:	irq_name = list_first_entry(&ctx->irq_names, struct cxl_irq_name, list);
drivers/misc/cxl/irq.c:		hwirq = ctx->irqs.offset[r];
drivers/misc/cxl/irq.c:		for (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {
drivers/misc/cxl/irq.c:			cxl_map_irq(ctx->afu->adapter, hwirq, handler, ctx,
drivers/misc/cxl/irq.c:		hwirq = ctx->irqs.offset[r];
drivers/misc/cxl/irq.c:		for (i = 0; i < ctx->irqs.range[r]; hwirq++, i++) {
drivers/misc/cxl/irq.c:	cxl_ops->release_irq_ranges(&ctx->irqs, ctx->afu->adapter);
drivers/misc/cxl/irq.c:	ctx->irq_count = 0;
drivers/misc/cxl/main.c:	if (!(task = get_pid_task(ctx->pid, PIDTYPE_PID))) {
drivers/misc/cxl/main.c:			 __func__, pid_nr(ctx->pid));
drivers/misc/cxl/main.c:		 ctx->afu->adapter->adapter_num, ctx->afu->slice, ctx->pe);
drivers/misc/cxl/main.c:	spin_lock_irqsave(&ctx->sste_lock, flags);
drivers/misc/cxl/main.c:	memset(ctx->sstp, 0, ctx->sst_size);
drivers/misc/cxl/main.c:	spin_unlock_irqrestore(&ctx->sste_lock, flags);
drivers/misc/cxl/main.c:	cxl_afu_slbia(ctx->afu);
drivers/misc/cxl/main.c:	ctx->sst_size = PAGE_SIZE;
drivers/misc/cxl/main.c:	ctx->sst_lru = 0;
drivers/misc/cxl/main.c:	ctx->sstp = (struct cxl_sste *)get_zeroed_page(GFP_KERNEL);
drivers/misc/cxl/main.c:	if (!ctx->sstp) {
drivers/misc/cxl/main.c:	pr_devel("SSTP allocated at 0x%p\n", ctx->sstp);
drivers/misc/cxl/main.c:	vsid  = get_kernel_vsid((u64)ctx->sstp, mmu_kernel_ssize) << 12;
drivers/misc/cxl/main.c:	size = (((u64)ctx->sst_size >> 8) - 1) << CXL_SSTP0_An_SegTableSize_SHIFT;
drivers/misc/cxl/main.c:	sstp1 |= (u64)ctx->sstp & ea_mask;
drivers/misc/cxl/main.c:			(u64)ctx->sstp, (u64)ctx->sstp & ESID_MASK, mmu_kernel_ssize, vsid, sstp0, sstp1);
drivers/misc/cxl/main.c:	ctx->sstp0 = sstp0;
drivers/misc/cxl/main.c:	ctx->sstp1 = sstp1;
drivers/misc/cxl/native.c:	struct cxl *adapter = ctx->afu->adapter;
drivers/misc/cxl/native.c:	WARN_ON(!mutex_is_locked(&ctx->afu->native->spa_mutex));
drivers/misc/cxl/native.c:			((u64)be32_to_cpu(ctx->elem->common.pid) << 32) |
drivers/misc/cxl/native.c:			be32_to_cpu(ctx->elem->lpid));
drivers/misc/cxl/native.c:	WARN_ON(!ctx->afu->enabled);
drivers/misc/cxl/native.c:	ctx->elem->software_state = cpu_to_be32(pe_state);
drivers/misc/cxl/native.c:	*(ctx->afu->native->sw_command_status) = cpu_to_be64(cmd | 0 | ctx->pe);
drivers/misc/cxl/native.c:	cxl_p1n_write(ctx->afu, CXL_PSL_LLCMD_An, cmd | ctx->pe);
drivers/misc/cxl/native.c:			dev_warn(&ctx->afu->dev, "WARNING: Process Element Command timed out!\n");
drivers/misc/cxl/native.c:		if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu)) {
drivers/misc/cxl/native.c:			dev_warn(&ctx->afu->dev, "WARNING: Device link down, aborting Process Element Command!\n");
drivers/misc/cxl/native.c:		state = be64_to_cpup(ctx->afu->native->sw_command_status);
drivers/misc/cxl/native.c:		    (cmd | (cmd >> 16) | ctx->pe))
drivers/misc/cxl/native.c:	mutex_lock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	pr_devel("%s Adding pe: %i started\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:		ctx->pe_inserted = true;
drivers/misc/cxl/native.c:	pr_devel("%s Adding pe: %i finished\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:	mutex_unlock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	if (!(ctx->elem->software_state & cpu_to_be32(CXL_PE_SOFTWARE_STATE_V)))
drivers/misc/cxl/native.c:	mutex_lock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	pr_devel("%s Terminate pe: %i started\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:	if (cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/native.c:	ctx->elem->software_state = 0;	/* Remove Valid bit */
drivers/misc/cxl/native.c:	pr_devel("%s Terminate pe: %i finished\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:	mutex_unlock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	mutex_lock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	pr_devel("%s Remove pe: %i started\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:	if (cxl_ops->link_ok(ctx->afu->adapter, ctx->afu))
drivers/misc/cxl/native.c:		ctx->pe_inserted = false;
drivers/misc/cxl/native.c:	pr_devel("%s Remove pe: %i finished\n", __func__, ctx->pe);
drivers/misc/cxl/native.c:	mutex_unlock(&ctx->afu->native->spa_mutex);
drivers/misc/cxl/native.c:	if (!ctx->afu->pp_size || ctx->master) {
drivers/misc/cxl/native.c:		ctx->psn_phys = ctx->afu->psn_phys;
drivers/misc/cxl/native.c:		ctx->psn_size = ctx->afu->adapter->ps_size;
drivers/misc/cxl/native.c:		ctx->psn_phys = ctx->afu->psn_phys +
drivers/misc/cxl/native.c:			(ctx->afu->native->pp_offset + ctx->afu->pp_size * ctx->pe);
drivers/misc/cxl/native.c:		ctx->psn_size = ctx->afu->pp_size;
drivers/misc/cxl/native.c:	if (ctx->master)
drivers/misc/cxl/native.c:	if (ctx->kernel) {
drivers/misc/cxl/native.c:		if (!ctx->real_mode)
drivers/misc/cxl/native.c:	bool need_update = (ctx->status == STARTED);
drivers/misc/cxl/native.c:		ctx->elem->ivte_offsets[r] = cpu_to_be16(ctx->irqs.offset[r]);
drivers/misc/cxl/native.c:		ctx->elem->ivte_ranges[r] = cpu_to_be16(ctx->irqs.range[r]);
drivers/misc/cxl/native.c:	ctx->elem->ctxtime = 0; /* disable */
drivers/misc/cxl/native.c:	ctx->elem->lpid = cpu_to_be32(mfspr(SPRN_LPID));
drivers/misc/cxl/native.c:	ctx->elem->haurp = 0; /* disable */
drivers/misc/cxl/native.c:	ctx->elem->sdr = cpu_to_be64(mfspr(SPRN_SDR1));
drivers/misc/cxl/native.c:	if (ctx->kernel)
drivers/misc/cxl/native.c:	ctx->elem->common.tid = 0;
drivers/misc/cxl/native.c:	ctx->elem->common.pid = cpu_to_be32(pid);
drivers/misc/cxl/native.c:	ctx->elem->sr = cpu_to_be64(calculate_sr(ctx));
drivers/misc/cxl/native.c:	ctx->elem->common.csrp = 0; /* disable */
drivers/misc/cxl/native.c:	ctx->elem->common.aurp0 = 0; /* disable */
drivers/misc/cxl/native.c:	ctx->elem->common.aurp1 = 0; /* disable */
drivers/misc/cxl/native.c:	ctx->elem->common.sstp0 = cpu_to_be64(ctx->sstp0);
drivers/misc/cxl/native.c:	ctx->elem->common.sstp1 = cpu_to_be64(ctx->sstp1);
drivers/misc/cxl/native.c:	if (ctx->irqs.range[0] == 0) {
drivers/misc/cxl/native.c:		ctx->irqs.offset[0] = ctx->afu->native->psl_hwirq;
drivers/misc/cxl/native.c:		ctx->irqs.range[0] = 1;
drivers/misc/cxl/native.c:	ctx->elem->common.amr = cpu_to_be64(amr);
drivers/misc/cxl/native.c:	ctx->elem->common.wed = cpu_to_be64(wed);
drivers/misc/cxl/native.c:	if ((result = cxl_ops->afu_check_and_enable(ctx->afu)))
drivers/misc/cxl/native.c:	struct cxl_afu *afu = ctx->afu;
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.offset[0] & 0xffff) << 48) |
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.offset[1] & 0xffff) << 32) |
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.offset[2] & 0xffff) << 16) |
drivers/misc/cxl/native.c:			((u64)ctx->irqs.offset[3] & 0xffff));
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.range[0] & 0xffff) << 48) |
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.range[1] & 0xffff) << 32) |
drivers/misc/cxl/native.c:		       (((u64)ctx->irqs.range[2] & 0xffff) << 16) |
drivers/misc/cxl/native.c:			((u64)ctx->irqs.range[3] & 0xffff));
drivers/misc/cxl/native.c:	struct cxl_afu *afu = ctx->afu;
drivers/misc/cxl/native.c:	if (ctx->kernel)
drivers/misc/cxl/native.c:	if ((rc = cxl_write_sstp(afu, ctx->sstp0, ctx->sstp1)))
drivers/misc/cxl/native.c:	if (!cxl_ops->link_ok(ctx->afu->adapter, ctx->afu)) {
drivers/misc/cxl/native.c:	ctx->kernel = kernel;
drivers/misc/cxl/native.c:	if (ctx->afu->current_mode == CXL_MODE_DIRECTED)
drivers/misc/cxl/native.c:	if (ctx->afu->current_mode == CXL_MODE_DEDICATED)
drivers/misc/cxl/native.c:	cxl_ops->afu_reset(ctx->afu);
drivers/misc/cxl/native.c:	cxl_afu_disable(ctx->afu);
drivers/misc/cxl/native.c:	cxl_psl_purge(ctx->afu);
drivers/misc/cxl/native.c:	if (ctx->afu->current_mode == CXL_MODE_DIRECTED)
drivers/misc/cxl/native.c:	if (ctx->afu->current_mode == CXL_MODE_DEDICATED)
drivers/misc/cxl/native.c:	if (!ctx->pe_inserted)
drivers/misc/cxl/native.c:	if (ctx->afu->current_mode == CXL_MODE_DEDICATED)
drivers/misc/cxl/native.c:	fir1 = cxl_p1_read(ctx->afu->adapter, CXL_PSL_FIR1);
drivers/misc/cxl/native.c:	fir2 = cxl_p1_read(ctx->afu->adapter, CXL_PSL_FIR2);
drivers/misc/cxl/native.c:	fir_slice = cxl_p1n_read(ctx->afu, CXL_PSL_FIR_SLICE_An);
drivers/misc/cxl/native.c:	afu_debug = cxl_p1n_read(ctx->afu, CXL_AFU_DEBUG_An);
drivers/misc/cxl/native.c:	dev_crit(&ctx->afu->dev, "PSL_FIR1: 0x%016llx\n", fir1);
drivers/misc/cxl/native.c:	dev_crit(&ctx->afu->dev, "PSL_FIR2: 0x%016llx\n", fir2);
drivers/misc/cxl/native.c:	if (ctx->afu->adapter->native->sl_ops->register_serr_irq) {
drivers/misc/cxl/native.c:		serr = cxl_p1n_read(ctx->afu, CXL_PSL_SERR_An);
drivers/misc/cxl/native.c:		cxl_afu_decode_psl_serr(ctx->afu, serr);
drivers/misc/cxl/native.c:	dev_crit(&ctx->afu->dev, "PSL_FIR_SLICE_An: 0x%016llx\n", fir_slice);
drivers/misc/cxl/native.c:	dev_crit(&ctx->afu->dev, "CXL_PSL_AFU_DEBUG_An: 0x%016llx\n", afu_debug);
drivers/misc/cxl/native.c:	dev_crit(&ctx->afu->dev, "PSL ERROR STATUS: 0x%016llx\n", errstat);
drivers/misc/cxl/native.c:	if (ctx->afu->adapter->native->sl_ops->psl_irq_dump_registers)
drivers/misc/cxl/native.c:		ctx->afu->adapter->native->sl_ops->psl_irq_dump_registers(ctx);
drivers/misc/cxl/native.c:	if (ctx->afu->adapter->native->sl_ops->debugfs_stop_trace) {
drivers/misc/cxl/native.c:		dev_crit(&ctx->afu->dev, "STOPPING CXL TRACE\n");
drivers/misc/cxl/native.c:		ctx->afu->adapter->native->sl_ops->debugfs_stop_trace(ctx->afu->adapter);
drivers/misc/cxl/native.c:		ph = cxl_p2n_read(ctx->afu, CXL_PSL_PEHandle_An) & 0xffff;
drivers/misc/cxl/native.c:		if (ph != ctx->pe)
drivers/misc/cxl/native.c:		dsisr = cxl_p2n_read(ctx->afu, CXL_PSL_DSISR_An);
drivers/misc/cxl/native.c:	dev_warn(&ctx->afu->dev, "WARNING: waiting on DSI for PE %i"
drivers/misc/cxl/native.c:		cxl_p2n_write(ctx->afu, CXL_PSL_TFC_An, tfc);
drivers/misc/cxl/native.c:		recover_psl_err(ctx->afu, psl_reset_mask);
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->pid = pid_nr(ctx->pid);
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/cxl/trace.h:		__entry->card = ctx->afu->adapter->adapter_num;
drivers/misc/cxl/trace.h:		__entry->afu = ctx->afu->slice;
drivers/misc/cxl/trace.h:		__entry->pe = ctx->pe;
drivers/misc/vmw_vmci/vmci_context.c:		if (vmci_deny_interaction(priv_flags, sub_ctx->priv_flags))
drivers/misc/vmw_vmci/vmci_context.c:		list_for_each_entry_rcu(node, &sub_ctx->notifier_list, node) {
drivers/misc/vmw_vmci/vmci_context.c:					vmci_make_handle(sub_ctx->cid,
drivers/clk/rockchip/clk-pll.c:	struct regmap *grf = pll->ctx->grf;
drivers/clk/rockchip/clk-pll.c:	pll_mux->reg = ctx->reg_base + mode_offset;
drivers/clk/rockchip/clk-pll.c:	pll_mux->lock = &ctx->lock;
drivers/clk/rockchip/clk-pll.c:		if (!pll->rate_table || IS_ERR(ctx->grf))
drivers/clk/rockchip/clk-pll.c:		if (!pll->rate_table || IS_ERR(ctx->grf))
drivers/clk/rockchip/clk-pll.c:	pll->reg_base = ctx->reg_base + con_offset;
drivers/clk/rockchip/clk-pll.c:	pll->lock = &ctx->lock;
drivers/clk/rockchip/clk.c:	ctx->reg_base = base;
drivers/clk/rockchip/clk.c:	ctx->clk_data.clks = clk_table;
drivers/clk/rockchip/clk.c:	ctx->clk_data.clk_num = nr_clks;
drivers/clk/rockchip/clk.c:	ctx->cru_node = np;
drivers/clk/rockchip/clk.c:	ctx->grf = ERR_PTR(-EPROBE_DEFER);
drivers/clk/rockchip/clk.c:	spin_lock_init(&ctx->lock);
drivers/clk/rockchip/clk.c:	ctx->grf = syscon_regmap_lookup_by_phandle(ctx->cru_node,
drivers/clk/rockchip/clk.c:				&ctx->clk_data))
drivers/clk/rockchip/clk.c:	if (ctx->clk_data.clks && id)
drivers/clk/rockchip/clk.c:		ctx->clk_data.clks[id] = clk;
drivers/clk/rockchip/clk.c:				flags, ctx->reg_base + list->muxdiv_offset,
drivers/clk/rockchip/clk.c:				list->mux_flags, &ctx->lock);
drivers/clk/rockchip/clk.c:					ctx->reg_base + list->muxdiv_offset,
drivers/clk/rockchip/clk.c:					&ctx->lock);
drivers/clk/rockchip/clk.c:					ctx->reg_base + list->muxdiv_offset,
drivers/clk/rockchip/clk.c:					list->div_flags, &ctx->lock);
drivers/clk/rockchip/clk.c:				ctx->reg_base, list->muxdiv_offset,
drivers/clk/rockchip/clk.c:				&ctx->lock);
drivers/clk/rockchip/clk.c:				ctx->reg_base + list->gate_offset,
drivers/clk/rockchip/clk.c:				list->gate_shift, list->gate_flags, &ctx->lock);
drivers/clk/rockchip/clk.c:				ctx->reg_base, list->muxdiv_offset,
drivers/clk/rockchip/clk.c:				list->gate_flags, flags, &ctx->lock);
drivers/clk/rockchip/clk.c:				ctx->reg_base + list->muxdiv_offset,
drivers/clk/rockchip/clk.c:				ctx->reg_base + list->muxdiv_offset,
drivers/clk/rockchip/clk.c:				list->div_shift, list->div_flags, &ctx->lock);
drivers/clk/rockchip/clk.c:				list->num_parents, ctx->reg_base,
drivers/clk/rockchip/clk.c:				list->gate_flags, flags, &ctx->lock);
drivers/clk/rockchip/clk.c:				ctx->reg_base, &ctx->lock);
drivers/clk/rockchip/clk.c:					   ctx->reg_base, &ctx->lock);
drivers/clk/rockchip/clk.c:	rst_base = ctx->reg_base;
drivers/clk/samsung/clk-exynos3250.c:	exynos3_core_down_clock(ctx->reg_base);
drivers/clk/samsung/clk.c:	ctx->reg_base = base;
drivers/clk/samsung/clk.c:	ctx->clk_data.clks = clk_table;
drivers/clk/samsung/clk.c:	ctx->clk_data.clk_num = nr_clks;
drivers/clk/samsung/clk.c:	spin_lock_init(&ctx->lock);
drivers/clk/samsung/clk.c:					&ctx->clk_data))
drivers/clk/samsung/clk.c:	if (ctx->clk_data.clks && id)
drivers/clk/samsung/clk.c:		ctx->clk_data.clks[id] = clk;
drivers/clk/samsung/clk.c:	if (!ctx->clk_data.clks) {
drivers/clk/samsung/clk.c:		clk = ctx->clk_data.clks[list->id];
drivers/clk/samsung/clk.c:			ctx->reg_base + list->offset,
drivers/clk/samsung/clk.c:			list->shift, list->width, list->mux_flags, &ctx->lock);
drivers/clk/samsung/clk.c:				ctx->reg_base + list->offset,
drivers/clk/samsung/clk.c:				list->table, &ctx->lock);
drivers/clk/samsung/clk.c:				ctx->reg_base + list->offset, list->shift,
drivers/clk/samsung/clk.c:				list->width, list->div_flags, &ctx->lock);
drivers/clk/samsung/clk.c:				list->flags, ctx->reg_base + list->offset,
drivers/clk/samsung/clk.c:				list->bit_idx, list->gate_flags, &ctx->lock);
drivers/clk/samsung/clk-exynos5440.c:			ARRAY_SIZE(exynos5440_plls), ctx->reg_base);
drivers/clk/samsung/clk-cpu.c:	cpuclk->ctrl_base = ctx->reg_base + offset;
drivers/clk/samsung/clk-cpu.c:	cpuclk->lock = &ctx->lock;
drivers/acpi/apei/apei-base.c:	ctx->ins_table = ins_table;
drivers/acpi/apei/apei-base.c:	ctx->instructions = instructions;
drivers/acpi/apei/apei-base.c:	ctx->action_table = action_table;
drivers/acpi/apei/apei-base.c:	ctx->entries = entries;
drivers/acpi/apei/apei-base.c:	ctx->value = val;
drivers/acpi/apei/apei-base.c:	ctx->value = (ctx->value == entry->value);
drivers/acpi/apei/apei-base.c:	return __apei_exec_write_register(entry, ctx->value);
drivers/acpi/apei/apei-base.c:	ctx->value = entry->value;
drivers/acpi/apei/apei-base.c:	ctx->ip = 0;
drivers/acpi/apei/apei-base.c:	 * "ctx->ip" specifies the next instruction to executed,
drivers/acpi/apei/apei-base.c:	 * instruction "run" function may change the "ctx->ip" to
drivers/acpi/apei/apei-base.c:	for (i = 0; i < ctx->entries; i++) {
drivers/acpi/apei/apei-base.c:		entry = &ctx->action_table[i];
drivers/acpi/apei/apei-base.c:		if (ip == ctx->ip) {
drivers/acpi/apei/apei-base.c:			if (entry->instruction >= ctx->instructions ||
drivers/acpi/apei/apei-base.c:			    !ctx->ins_table[entry->instruction].run) {
drivers/acpi/apei/apei-base.c:			run = ctx->ins_table[entry->instruction].run;
drivers/acpi/apei/apei-base.c:				ctx->ip++;
drivers/acpi/apei/apei-base.c:		if (ctx->ip < ip)
drivers/acpi/apei/apei-base.c:	struct apei_exec_ins_type *ins_table = ctx->ins_table;
drivers/acpi/apei/apei-base.c:	for (i = 0; i < ctx->entries; i++) {
drivers/acpi/apei/apei-base.c:		entry = ctx->action_table + i;
drivers/acpi/apei/apei-base.c:		if (ins >= ctx->instructions || !ins_table[ins].run) {
drivers/acpi/apei/apei-base.c:	if (ctx->ins_table[ins].flags & APEI_EXEC_INS_ACCESS_REGISTER)
drivers/acpi/apei/apei-base.c:	if (ctx->ins_table[ins].flags & APEI_EXEC_INS_ACCESS_REGISTER)
drivers/acpi/apei/apei-base.c:	if (!(ctx->ins_table[ins].flags & APEI_EXEC_INS_ACCESS_REGISTER))
drivers/acpi/apei/erst.c:	return __apei_exec_read_register(entry, &ctx->var1);
drivers/acpi/apei/erst.c:	return __apei_exec_read_register(entry, &ctx->var2);
drivers/acpi/apei/erst.c:	return __apei_exec_write_register(entry, ctx->var1);
drivers/acpi/apei/erst.c:	ctx->var1 += ctx->var2;
drivers/acpi/apei/erst.c:	ctx->var1 -= ctx->var2;
drivers/acpi/apei/erst.c:	val += ctx->value;
drivers/acpi/apei/erst.c:	val -= ctx->value;
drivers/acpi/apei/erst.c:	if (ctx->value > FIRMWARE_MAX_STALL) {
drivers/acpi/apei/erst.c:				   ctx->value);
drivers/acpi/apei/erst.c:		stall_time = ctx->value;
drivers/acpi/apei/erst.c:	if (ctx->var1 > FIRMWARE_MAX_STALL) {
drivers/acpi/apei/erst.c:				   ctx->var1);
drivers/acpi/apei/erst.c:		stall_time = ctx->var1;
drivers/acpi/apei/erst.c:		if (val != ctx->value)
drivers/acpi/apei/erst.c:	if (val == ctx->value) {
drivers/acpi/apei/erst.c:		ctx->ip += 2;
drivers/acpi/apei/erst.c:	ctx->ip = ctx->value;
drivers/acpi/apei/erst.c:	return __apei_exec_read_register(entry, &ctx->src_base);
drivers/acpi/apei/erst.c:	return __apei_exec_read_register(entry, &ctx->dst_base);
drivers/acpi/apei/erst.c:	src = ioremap(ctx->src_base + offset, ctx->var2);
drivers/acpi/apei/erst.c:	dst = ioremap(ctx->dst_base + offset, ctx->var2);
drivers/acpi/apei/erst.c:	memmove(dst, src, ctx->var2);
drivers/acpi/apei/apei-internal.h:	ctx->value = input;
drivers/acpi/apei/apei-internal.h:	return ctx->value;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	ctx->dispc_cinfo.lck = lck;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	ctx->dispc_cinfo.pck = pck;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	ctx->fck = fck;
drivers/video/fbdev/omap2/omapfb/dss/sdi.c:	return dispc_div_calc(fck, ctx->pck_min, ctx->pck_max,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	struct omap_video_timings *t = &ctx->dispc_vm;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.lck = lck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.pck = pck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	*t = *ctx->config->timings;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	t->x_res = ctx->config->timings->x_res;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	t->y_res = ctx->config->timings->y_res;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.mX[HSDIV_DISPC] = m_dispc;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.clkout[HSDIV_DISPC] = dispc;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dispc_div_calc(dispc, ctx->req_pck_min, ctx->req_pck_max,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.n = n;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.m = m;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.fint = fint;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.clkdco = clkdco;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dss_pll_hsdiv_calc(ctx->pll, clkdco, ctx->req_pck_min,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsidev = dsi->pdev;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->pll = &dsi->pll;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->config = cfg;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_min = pck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_nom = pck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_max = pck * 3 / 2;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dss_pll_calc(ctx->pll, clkin,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	struct dsi_data *dsi = dsi_get_dsidrv_data(ctx->dsidev);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	const struct omap_dss_dsi_config *cfg = ctx->config;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	unsigned long hsclk = ctx->dsi_cinfo.clkdco / 4;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	req_pck_min = ctx->req_pck_min;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	req_pck_max = ctx->req_pck_max;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	req_pck_nom = ctx->req_pck_nom;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dispc_pck = ctx->dispc_cinfo.pck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dsi_vm = &ctx->dsi_vm;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	dispc_vm = &ctx->dispc_vm;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.lck = lck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dispc_cinfo.pck = pck;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	print_dispc_vm("dispc", &ctx->dispc_vm);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	print_dsi_vm("dsi  ", &ctx->dsi_vm);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	print_dispc_vm("req  ", ctx->config->timings);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	print_dsi_dispc_vm("act  ", &ctx->dsi_vm);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.mX[HSDIV_DISPC] = m_dispc;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.clkout[HSDIV_DISPC] = dispc;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	if (ctx->config->trans_mode == OMAP_DSS_DSI_BURST_MODE)
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		pck_max = ctx->req_pck_max + 10000000;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		pck_max = ctx->req_pck_max;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dispc_div_calc(dispc, ctx->req_pck_min, pck_max,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.n = n;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.m = m;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.fint = fint;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsi_cinfo.clkdco = clkdco;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dss_pll_hsdiv_calc(ctx->pll, clkdco, ctx->req_pck_min,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->dsidev = dsi->pdev;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->pll = &dsi->pll;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->config = cfg;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_min = t->pixelclock - 1000;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_nom = t->pixelclock;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	ctx->req_pck_max = t->pixelclock + 1000;
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	byteclk_min = div64_u64((u64)ctx->req_pck_min * bitspp, ndl * 8);
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:		byteclk_max = div64_u64((u64)ctx->req_pck_max * bitspp,
drivers/video/fbdev/omap2/omapfb/dss/dsi.c:	return dss_pll_calc(ctx->pll, clkin,
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	if (ctx->pck_min >= 100000000) {
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dispc_cinfo.lck = lck;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dispc_cinfo.pck = pck;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	if (m_dispc > 1 && m_dispc % 2 != 0 && ctx->pck_min >= 100000000)
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.mX[HSDIV_DISPC] = m_dispc;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.clkout[HSDIV_DISPC] = dispc;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	return dispc_div_calc(dispc, ctx->pck_min, ctx->pck_max,
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.n = n;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.m = m;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.fint = fint;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->dsi_cinfo.clkdco = clkdco;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	return dss_pll_hsdiv_calc(ctx->pll, clkdco,
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:		ctx->pck_min, dss_feat_get_param_max(FEAT_PARAM_DSS_FCK),
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->fck = fck;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	return dispc_div_calc(fck, ctx->pck_min, ctx->pck_max,
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->pll = dpi->pll;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->pck_min = pck - 1000;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	ctx->pck_max = pck + 1000;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	clkin = clk_get_rate(ctx->pll->clkin);
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:	return dss_pll_calc(ctx->pll, clkin,
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:			ctx->pck_min = max(pck - 1000 * i * i * i, 0lu);
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:			ctx->pck_min = 0;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:		ctx->pck_max = pck + 1000 * i * i * i;
drivers/video/fbdev/omap2/omapfb/dss/dpi.c:		ok = dss_div_calc(pck, ctx->pck_min, dpi_calc_dss_cb, ctx);
drivers/media/rc/imon.c:	struct device *dev = ictx->dev;
drivers/media/rc/imon.c:	usb_free_urb(ictx->tx_urb);
drivers/media/rc/imon.c:	usb_free_urb(ictx->rx_urb_intf0);
drivers/media/rc/imon.c:	usb_free_urb(ictx->rx_urb_intf1);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->display_supported) {
drivers/media/rc/imon.c:	} else if (ictx->display_isopen) {
drivers/media/rc/imon.c:		ictx->display_isopen = true;
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "display port opened\n");
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->display_supported) {
drivers/media/rc/imon.c:	} else if (!ictx->display_isopen) {
drivers/media/rc/imon.c:		ictx->display_isopen = false;
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "display port closed\n");
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c: * ictx->lock held, or its unlock/lock sequence while waiting for tx
drivers/media/rc/imon.c:	if (!ictx->tx_control) {
drivers/media/rc/imon.c:		pipe = usb_sndintpipe(ictx->usbdev_intf0,
drivers/media/rc/imon.c:				      ictx->tx_endpoint->bEndpointAddress);
drivers/media/rc/imon.c:		interval = ictx->tx_endpoint->bInterval;
drivers/media/rc/imon.c:		usb_fill_int_urb(ictx->tx_urb, ictx->usbdev_intf0, pipe,
drivers/media/rc/imon.c:				 ictx->usb_tx_buf,
drivers/media/rc/imon.c:				 sizeof(ictx->usb_tx_buf),
drivers/media/rc/imon.c:		ictx->tx_urb->actual_length = 0;
drivers/media/rc/imon.c:		pipe = usb_sndctrlpipe(ictx->usbdev_intf0, 0);
drivers/media/rc/imon.c:		usb_fill_control_urb(ictx->tx_urb, ictx->usbdev_intf0,
drivers/media/rc/imon.c:				     ictx->usb_tx_buf,
drivers/media/rc/imon.c:				     sizeof(ictx->usb_tx_buf),
drivers/media/rc/imon.c:		ictx->tx_urb->actual_length = 0;
drivers/media/rc/imon.c:	init_completion(&ictx->tx.finished);
drivers/media/rc/imon.c:	ictx->tx.busy = true;
drivers/media/rc/imon.c:	retval = usb_submit_urb(ictx->tx_urb, GFP_KERNEL);
drivers/media/rc/imon.c:		ictx->tx.busy = false;
drivers/media/rc/imon.c:		mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:				&ictx->tx.finished);
drivers/media/rc/imon.c:			usb_kill_urb(ictx->tx_urb);
drivers/media/rc/imon.c:		mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:		retval = ictx->tx.status;
drivers/media/rc/imon.c:	timeout = msecs_to_jiffies(ictx->send_packet_delay);
drivers/media/rc/imon.c:	if (!ictx->dev_present_intf0) {
drivers/media/rc/imon.c:	memcpy(ictx->usb_tx_buf, packet, sizeof(packet));
drivers/media/rc/imon.c:	switch (ictx->display_type) {
drivers/media/rc/imon.c:		if (ictx->product == 0xffdc) {
drivers/media/rc/imon.c:		memcpy(ictx->usb_tx_buf, clock_enable_pkt[i], 8);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (ictx->rf_isassociating)
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	ictx->rf_isassociating = true;
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->display_supported) {
drivers/media/rc/imon.c:			"%s", ictx->display_isopen ?
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->display_supported) {
drivers/media/rc/imon.c:	} else if (ictx->display_isopen) {
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->dev_present_intf0) {
drivers/media/rc/imon.c:	if (copy_from_user(ictx->tx.data_buf, buf, n_bytes)) {
drivers/media/rc/imon.c:		ictx->tx.data_buf[i] = ' ';
drivers/media/rc/imon.c:		ictx->tx.data_buf[i] = 0xFF;
drivers/media/rc/imon.c:		memcpy(ictx->usb_tx_buf, ictx->tx.data_buf + offset, 7);
drivers/media/rc/imon.c:		ictx->usb_tx_buf[7] = (unsigned char) seq;
drivers/media/rc/imon.c:	memcpy(ictx->usb_tx_buf, &vfd_packet6, sizeof(vfd_packet6));
drivers/media/rc/imon.c:	ictx->usb_tx_buf[7] = (unsigned char) seq;
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (!ictx->display_supported) {
drivers/media/rc/imon.c:	if (copy_from_user(ictx->usb_tx_buf, buf, 8)) {
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "%s: write %d bytes to LCD\n",
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	ictx->tx.status = urb->status;
drivers/media/rc/imon.c:	ictx->tx.busy = false;
drivers/media/rc/imon.c:	complete(&ictx->tx.finished);
drivers/media/rc/imon.c:	if (ictx->display_type != IMON_DISPLAY_TYPE_VGA)
drivers/media/rc/imon.c:	input_report_abs(ictx->touch, ABS_X, ictx->touch_x);
drivers/media/rc/imon.c:	input_report_abs(ictx->touch, ABS_Y, ictx->touch_y);
drivers/media/rc/imon.c:	input_report_key(ictx->touch, BTN_TOUCH, 0x00);
drivers/media/rc/imon.c:	input_sync(ictx->touch);
drivers/media/rc/imon.c:	struct device *dev = ictx->dev;
drivers/media/rc/imon.c:	memcpy(ictx->usb_tx_buf, &ir_proto_packet, sizeof(ir_proto_packet));
drivers/media/rc/imon.c:	if (!mutex_is_locked(&ictx->lock)) {
drivers/media/rc/imon.c:		mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	ictx->rc_type = *rc_type;
drivers/media/rc/imon.c:	ictx->pad_mouse = false;
drivers/media/rc/imon.c:		mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	keycode = rc_g_keycode_from_table(ictx->rdev, scancode);
drivers/media/rc/imon.c:	ictx->rc_toggle = 0x0;
drivers/media/rc/imon.c:	ictx->rc_scancode = scancode;
drivers/media/rc/imon.c:		keycode = rc_g_keycode_from_table(ictx->rdev, release);
drivers/media/rc/imon.c:	ictx->release_code = is_release_code;
drivers/media/rc/imon.c:	ictx->rc_scancode = scancode;
drivers/media/rc/imon.c:	keycode = rc_g_keycode_from_table(ictx->rdev, scancode);
drivers/media/rc/imon.c:	ictx->release_code = false;
drivers/media/rc/imon.c:	struct imon_panel_key_table *key_table = ictx->dev_descr->key_table;
drivers/media/rc/imon.c:	ictx->release_code = false;
drivers/media/rc/imon.c:	spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	if (ictx->product != 0xffdc && (buf[0] & 0x01) && len == 5) {
drivers/media/rc/imon.c:	} else if (ictx->product == 0xffdc && (buf[0] & 0x40) &&
drivers/media/rc/imon.c:	} else if (ictx->product == 0xffdc && (buf[0] == 0x68)) {
drivers/media/rc/imon.c:	} else if (ictx->kc == KEY_CHANNELUP && (buf[2] & 0x40) != 0x40) {
drivers/media/rc/imon.c:	} else if (ictx->kc == KEY_CHANNELDOWN && (buf[2] & 0x40) != 0x40) {
drivers/media/rc/imon.c:	spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "sending mouse data via input subsystem\n");
drivers/media/rc/imon.c:			input_report_rel(ictx->idev, REL_WHEEL, dir);
drivers/media/rc/imon.c:			input_report_rel(ictx->idev, REL_X, rel_x);
drivers/media/rc/imon.c:			input_report_rel(ictx->idev, REL_Y, rel_y);
drivers/media/rc/imon.c:			input_report_key(ictx->idev, BTN_LEFT, buf[1] & 0x1);
drivers/media/rc/imon.c:			input_report_key(ictx->idev, BTN_RIGHT,
drivers/media/rc/imon.c:		input_sync(ictx->idev);
drivers/media/rc/imon.c:		spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:		ictx->last_keycode = ictx->kc;
drivers/media/rc/imon.c:		spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	mod_timer(&ictx->ttimer, jiffies + TOUCH_TIMEOUT);
drivers/media/rc/imon.c:	ictx->touch_x = (buf[0] << 4) | (buf[1] >> 4);
drivers/media/rc/imon.c:	ictx->touch_y = 0xfff - ((buf[2] << 4) | (buf[1] & 0xf));
drivers/media/rc/imon.c:	input_report_abs(ictx->touch, ABS_X, ictx->touch_x);
drivers/media/rc/imon.c:	input_report_abs(ictx->touch, ABS_Y, ictx->touch_y);
drivers/media/rc/imon.c:	input_report_key(ictx->touch, BTN_TOUCH, 0x01);
drivers/media/rc/imon.c:	input_sync(ictx->touch);
drivers/media/rc/imon.c:	if (ictx->product != 0xffdc) {
drivers/media/rc/imon.c:		if (ictx->rc_type == RC_BIT_OTHER && pad_stabilize) {
drivers/media/rc/imon.c:					spin_lock_irqsave(&ictx->kc_lock,
drivers/media/rc/imon.c:					ictx->kc = KEY_UNKNOWN;
drivers/media/rc/imon.c:					spin_unlock_irqrestore(&ictx->kc_lock,
drivers/media/rc/imon.c:		if (ictx->rc_type == RC_BIT_OTHER && pad_stabilize) {
drivers/media/rc/imon.c:				spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:				ictx->kc = KEY_UNKNOWN;
drivers/media/rc/imon.c:				spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:		spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:		ictx->kc = imon_remote_key_lookup(ictx, scancode);
drivers/media/rc/imon.c:		spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	if (ictx->kc == KEY_RESERVED && buf[0] == 0x02 && buf[3] == 0x00)
drivers/media/rc/imon.c:		ictx->kc = ictx->last_keycode;
drivers/media/rc/imon.c:	else if (ictx->kc == KEY_RESERVED && buf[0] == 0x68 && buf[1] == 0x82 &&
drivers/media/rc/imon.c:		ictx->kc = ictx->last_keycode;
drivers/media/rc/imon.c:	else if (ictx->kc == KEY_RESERVED && buf[0] == 0x01 && buf[1] == 0x00 &&
drivers/media/rc/imon.c:		ictx->kc = ictx->last_keycode;
drivers/media/rc/imon.c:		ictx->rc_toggle = buf[2];
drivers/media/rc/imon.c:	} else if (ictx->kc == KEY_RESERVED)
drivers/media/rc/imon.c:	else if (ictx->release_code)
drivers/media/rc/imon.c:	spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	struct device *dev = ictx->dev;
drivers/media/rc/imon.c:		ictx->release_code = false;
drivers/media/rc/imon.c:		if (ictx->rc_type == RC_BIT_RC6_MCE) {
drivers/media/rc/imon.c:	spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	if (kc == KEY_KEYBOARD && !ictx->release_code) {
drivers/media/rc/imon.c:		ictx->last_keycode = kc;
drivers/media/rc/imon.c:			ictx->pad_mouse = !ictx->pad_mouse;
drivers/media/rc/imon.c:				ictx->pad_mouse ? "mouse" : "keyboard");
drivers/media/rc/imon.c:			spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:			ictx->pad_mouse = false;
drivers/media/rc/imon.c:	ictx->kc = kc;
drivers/media/rc/imon.c:	spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_VGA && len == 8 &&
drivers/media/rc/imon.c:	} else if (ictx->pad_mouse) {
drivers/media/rc/imon.c:			rc_keyup(ictx->rdev);
drivers/media/rc/imon.c:			if (ictx->rc_type == RC_BIT_RC6_MCE ||
drivers/media/rc/imon.c:			    ictx->rc_type == RC_BIT_OTHER)
drivers/media/rc/imon.c:				rc_keydown(ictx->rdev,
drivers/media/rc/imon.c:					   ictx->rc_type == RC_BIT_RC6_MCE ? RC_TYPE_RC6_MCE : RC_TYPE_OTHER,
drivers/media/rc/imon.c:					   ictx->rc_scancode, ictx->rc_toggle);
drivers/media/rc/imon.c:			spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:			ictx->last_keycode = ictx->kc;
drivers/media/rc/imon.c:			spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	if (ictx->kc == KEY_MUTE && ictx->kc == ictx->last_keycode) {
drivers/media/rc/imon.c:		if (msec < ictx->idev->rep[REP_DELAY]) {
drivers/media/rc/imon.c:			spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	kc = ictx->kc;
drivers/media/rc/imon.c:	spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	input_report_key(ictx->idev, kc, press_type);
drivers/media/rc/imon.c:	input_sync(ictx->idev);
drivers/media/rc/imon.c:	input_report_key(ictx->idev, kc, 0);
drivers/media/rc/imon.c:	input_sync(ictx->idev);
drivers/media/rc/imon.c:	spin_lock_irqsave(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:	ictx->last_keycode = kc;
drivers/media/rc/imon.c:	spin_unlock_irqrestore(&ictx->kc_lock, flags);
drivers/media/rc/imon.c:		ictx->rf_isassociating = false;
drivers/media/rc/imon.c:	if (!ictx->dev_present_intf0)
drivers/media/rc/imon.c:		dev_warn(ictx->dev, "imon %s: status(%d): ignored\n",
drivers/media/rc/imon.c:	usb_submit_urb(ictx->rx_urb_intf0, GFP_ATOMIC);
drivers/media/rc/imon.c:	if (!ictx->dev_present_intf1)
drivers/media/rc/imon.c:		dev_warn(ictx->dev, "imon %s: status(%d): ignored\n",
drivers/media/rc/imon.c:	usb_submit_urb(ictx->rx_urb_intf1, GFP_ATOMIC);
drivers/media/rc/imon.c:	u8 ffdc_cfg_byte = ictx->usb_rx_buf[6];
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON Knob, iMON IR");
drivers/media/rc/imon.c:		ictx->display_supported = false;
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON 2.4G LT, iMON RF");
drivers/media/rc/imon.c:		ictx->display_supported = false;
drivers/media/rc/imon.c:		ictx->rf_device = true;
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON VFD + knob, no IR");
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON VFD, iMON IR");
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON VFD, MCE IR");
drivers/media/rc/imon.c:		dev_info(ictx->dev, "0xffdc iMON LCD, MCE IR");
drivers/media/rc/imon.c:		dev_info(ictx->dev, "Unknown 0xffdc device, "
drivers/media/rc/imon.c:	ictx->display_type = detected_display_type;
drivers/media/rc/imon.c:	ictx->rc_type = allowed_protos;
drivers/media/rc/imon.c:		switch (ictx->product) {
drivers/media/rc/imon.c:			configured_display_type = ictx->display_type;
drivers/media/rc/imon.c:			ictx->display_supported = false;
drivers/media/rc/imon.c:			ictx->display_supported = false;
drivers/media/rc/imon.c:			ictx->display_supported = true;
drivers/media/rc/imon.c:		dev_info(ictx->dev, "%s: overriding display type to %d via "
drivers/media/rc/imon.c:	ictx->display_type = configured_display_type;
drivers/media/rc/imon.c:		dev_err(ictx->dev, "remote control dev allocation failed\n");
drivers/media/rc/imon.c:	snprintf(ictx->name_rdev, sizeof(ictx->name_rdev),
drivers/media/rc/imon.c:		 "iMON Remote (%04x:%04x)", ictx->vendor, ictx->product);
drivers/media/rc/imon.c:	usb_make_path(ictx->usbdev_intf0, ictx->phys_rdev,
drivers/media/rc/imon.c:		      sizeof(ictx->phys_rdev));
drivers/media/rc/imon.c:	strlcat(ictx->phys_rdev, "/input0", sizeof(ictx->phys_rdev));
drivers/media/rc/imon.c:	rdev->input_name = ictx->name_rdev;
drivers/media/rc/imon.c:	rdev->input_phys = ictx->phys_rdev;
drivers/media/rc/imon.c:	usb_to_input_id(ictx->usbdev_intf0, &rdev->input_id);
drivers/media/rc/imon.c:	rdev->dev.parent = ictx->dev;
drivers/media/rc/imon.c:	memcpy(ictx->usb_tx_buf, &fp_packet, sizeof(fp_packet));
drivers/media/rc/imon.c:		dev_info(ictx->dev, "panel buttons/knobs setup failed\n");
drivers/media/rc/imon.c:	if (ictx->product == 0xffdc) {
drivers/media/rc/imon.c:		rdev->allowed_protocols = ictx->rc_type;
drivers/media/rc/imon.c:	if (ictx->rc_type == RC_BIT_RC6_MCE)
drivers/media/rc/imon.c:		dev_err(ictx->dev, "remote input dev register failed\n");
drivers/media/rc/imon.c:	struct imon_panel_key_table *key_table = ictx->dev_descr->key_table;
drivers/media/rc/imon.c:	snprintf(ictx->name_idev, sizeof(ictx->name_idev),
drivers/media/rc/imon.c:		 ictx->vendor, ictx->product);
drivers/media/rc/imon.c:	idev->name = ictx->name_idev;
drivers/media/rc/imon.c:	usb_make_path(ictx->usbdev_intf0, ictx->phys_idev,
drivers/media/rc/imon.c:		      sizeof(ictx->phys_idev));
drivers/media/rc/imon.c:	strlcat(ictx->phys_idev, "/input1", sizeof(ictx->phys_idev));
drivers/media/rc/imon.c:	idev->phys = ictx->phys_idev;
drivers/media/rc/imon.c:	usb_to_input_id(ictx->usbdev_intf0, &idev->id);
drivers/media/rc/imon.c:	idev->dev.parent = ictx->dev;
drivers/media/rc/imon.c:		dev_err(ictx->dev, "input dev register failed\n");
drivers/media/rc/imon.c:	snprintf(ictx->name_touch, sizeof(ictx->name_touch),
drivers/media/rc/imon.c:		 ictx->vendor, ictx->product);
drivers/media/rc/imon.c:	touch->name = ictx->name_touch;
drivers/media/rc/imon.c:	usb_make_path(ictx->usbdev_intf1, ictx->phys_touch,
drivers/media/rc/imon.c:		      sizeof(ictx->phys_touch));
drivers/media/rc/imon.c:	strlcat(ictx->phys_touch, "/input2", sizeof(ictx->phys_touch));
drivers/media/rc/imon.c:	touch->phys = ictx->phys_touch;
drivers/media/rc/imon.c:	usb_to_input_id(ictx->usbdev_intf1, &touch->id);
drivers/media/rc/imon.c:	touch->dev.parent = ictx->dev;
drivers/media/rc/imon.c:		dev_info(ictx->dev, "touchscreen input dev register failed\n");
drivers/media/rc/imon.c:			dev_dbg(ictx->dev, "%s: found IR endpoint\n", __func__);
drivers/media/rc/imon.c:			dev_dbg(ictx->dev, "%s: found display endpoint\n", __func__);
drivers/media/rc/imon.c:		ictx->rx_endpoint_intf0 = rx_endpoint;
drivers/media/rc/imon.c:		ictx->tx_endpoint = tx_endpoint;
drivers/media/rc/imon.c:		ictx->rx_endpoint_intf1 = rx_endpoint;
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "%s: device uses control endpoint, not "
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_NONE) {
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "%s: device has no display\n", __func__);
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_VGA) {
drivers/media/rc/imon.c:		dev_dbg(ictx->dev, "%s: iMON Touch device found\n", __func__);
drivers/media/rc/imon.c:	ictx->tx_control = tx_control;
drivers/media/rc/imon.c:		ictx->display_supported = true;
drivers/media/rc/imon.c:	mutex_init(&ictx->lock);
drivers/media/rc/imon.c:	spin_lock_init(&ictx->kc_lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	ictx->dev = dev;
drivers/media/rc/imon.c:	ictx->usbdev_intf0 = usb_get_dev(interface_to_usbdev(intf));
drivers/media/rc/imon.c:	ictx->rx_urb_intf0 = rx_urb;
drivers/media/rc/imon.c:	ictx->tx_urb = tx_urb;
drivers/media/rc/imon.c:	ictx->rf_device = false;
drivers/media/rc/imon.c:	ictx->vendor  = le16_to_cpu(ictx->usbdev_intf0->descriptor.idVendor);
drivers/media/rc/imon.c:	ictx->product = le16_to_cpu(ictx->usbdev_intf0->descriptor.idProduct);
drivers/media/rc/imon.c:	ictx->dev_descr = (struct imon_usb_dev_descr *)id->driver_info;
drivers/media/rc/imon.c:	ictx->send_packet_delay = ictx->dev_descr->flags &
drivers/media/rc/imon.c:	usb_fill_int_urb(ictx->rx_urb_intf0, ictx->usbdev_intf0,
drivers/media/rc/imon.c:		usb_rcvintpipe(ictx->usbdev_intf0,
drivers/media/rc/imon.c:			ictx->rx_endpoint_intf0->bEndpointAddress),
drivers/media/rc/imon.c:		ictx->usb_rx_buf, sizeof(ictx->usb_rx_buf),
drivers/media/rc/imon.c:		ictx->rx_endpoint_intf0->bInterval);
drivers/media/rc/imon.c:	ret = usb_submit_urb(ictx->rx_urb_intf0, GFP_KERNEL);
drivers/media/rc/imon.c:	ictx->idev = imon_init_idev(ictx);
drivers/media/rc/imon.c:	if (!ictx->idev) {
drivers/media/rc/imon.c:	ictx->rdev = imon_init_rdev(ictx);
drivers/media/rc/imon.c:	if (!ictx->rdev) {
drivers/media/rc/imon.c:	ictx->dev_present_intf0 = true;
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	input_unregister_device(ictx->idev);
drivers/media/rc/imon.c:	usb_kill_urb(ictx->rx_urb_intf0);
drivers/media/rc/imon.c:	usb_put_dev(ictx->usbdev_intf0);
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_VGA) {
drivers/media/rc/imon.c:		init_timer(&ictx->ttimer);
drivers/media/rc/imon.c:		ictx->ttimer.data = (unsigned long)ictx;
drivers/media/rc/imon.c:		ictx->ttimer.function = imon_touch_display_timeout;
drivers/media/rc/imon.c:	ictx->usbdev_intf1 = usb_get_dev(interface_to_usbdev(intf));
drivers/media/rc/imon.c:	ictx->rx_urb_intf1 = rx_urb;
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_VGA) {
drivers/media/rc/imon.c:		ictx->touch = imon_init_touch(ictx);
drivers/media/rc/imon.c:		if (!ictx->touch)
drivers/media/rc/imon.c:		ictx->touch = NULL;
drivers/media/rc/imon.c:	usb_fill_int_urb(ictx->rx_urb_intf1, ictx->usbdev_intf1,
drivers/media/rc/imon.c:		usb_rcvintpipe(ictx->usbdev_intf1,
drivers/media/rc/imon.c:			ictx->rx_endpoint_intf1->bEndpointAddress),
drivers/media/rc/imon.c:		ictx->usb_rx_buf, sizeof(ictx->usb_rx_buf),
drivers/media/rc/imon.c:		ictx->rx_endpoint_intf1->bInterval);
drivers/media/rc/imon.c:	ret = usb_submit_urb(ictx->rx_urb_intf1, GFP_KERNEL);
drivers/media/rc/imon.c:	ictx->dev_present_intf1 = true;
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	if (ictx->touch)
drivers/media/rc/imon.c:		input_unregister_device(ictx->touch);
drivers/media/rc/imon.c:	usb_put_dev(ictx->usbdev_intf1);
drivers/media/rc/imon.c:	mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	dev_err(ictx->dev, "unable to initialize intf1, err %d\n", ret);
drivers/media/rc/imon.c:	dev_dbg(ictx->dev, "Registering iMON display with sysfs\n");
drivers/media/rc/imon.c:		dev_err(ictx->dev, "Could not create display sysfs "
drivers/media/rc/imon.c:	if (ictx->display_type == IMON_DISPLAY_TYPE_LCD)
drivers/media/rc/imon.c:		dev_info(ictx->dev, "could not get a minor number for "
drivers/media/rc/imon.c:		mutex_lock(&ictx->lock);
drivers/media/rc/imon.c:		if (product == 0xffdc && ictx->rf_device) {
drivers/media/rc/imon.c:		if (ictx->display_supported)
drivers/media/rc/imon.c:		mutex_unlock(&ictx->lock);
drivers/media/rc/imon.c:	dev = ictx->dev;
drivers/media/rc/imon.c:	if (ictx->tx.busy) {
drivers/media/rc/imon.c:		usb_kill_urb(ictx->tx_urb);
drivers/media/rc/imon.c:		complete_all(&ictx->tx.finished);
drivers/media/rc/imon.c:		ictx->dev_present_intf0 = false;
drivers/media/rc/imon.c:		usb_kill_urb(ictx->rx_urb_intf0);
drivers/media/rc/imon.c:		usb_put_dev(ictx->usbdev_intf0);
drivers/media/rc/imon.c:		input_unregister_device(ictx->idev);
drivers/media/rc/imon.c:		rc_unregister_device(ictx->rdev);
drivers/media/rc/imon.c:		if (ictx->display_supported) {
drivers/media/rc/imon.c:			if (ictx->display_type == IMON_DISPLAY_TYPE_LCD)
drivers/media/rc/imon.c:			else if (ictx->display_type == IMON_DISPLAY_TYPE_VFD)
drivers/media/rc/imon.c:		ictx->dev_present_intf1 = false;
drivers/media/rc/imon.c:		usb_kill_urb(ictx->rx_urb_intf1);
drivers/media/rc/imon.c:		usb_put_dev(ictx->usbdev_intf1);
drivers/media/rc/imon.c:		if (ictx->display_type == IMON_DISPLAY_TYPE_VGA) {
drivers/media/rc/imon.c:			input_unregister_device(ictx->touch);
drivers/media/rc/imon.c:			del_timer_sync(&ictx->ttimer);
drivers/media/rc/imon.c:	if (!ictx->dev_present_intf0 && !ictx->dev_present_intf1)
drivers/media/rc/imon.c:		usb_kill_urb(ictx->rx_urb_intf0);
drivers/media/rc/imon.c:		usb_kill_urb(ictx->rx_urb_intf1);
drivers/media/rc/imon.c:		usb_fill_int_urb(ictx->rx_urb_intf0, ictx->usbdev_intf0,
drivers/media/rc/imon.c:			usb_rcvintpipe(ictx->usbdev_intf0,
drivers/media/rc/imon.c:				ictx->rx_endpoint_intf0->bEndpointAddress),
drivers/media/rc/imon.c:			ictx->usb_rx_buf, sizeof(ictx->usb_rx_buf),
drivers/media/rc/imon.c:			ictx->rx_endpoint_intf0->bInterval);
drivers/media/rc/imon.c:		rc = usb_submit_urb(ictx->rx_urb_intf0, GFP_ATOMIC);
drivers/media/rc/imon.c:		usb_fill_int_urb(ictx->rx_urb_intf1, ictx->usbdev_intf1,
drivers/media/rc/imon.c:			usb_rcvintpipe(ictx->usbdev_intf1,
drivers/media/rc/imon.c:				ictx->rx_endpoint_intf1->bEndpointAddress),
drivers/media/rc/imon.c:			ictx->usb_rx_buf, sizeof(ictx->usb_rx_buf),
drivers/media/rc/imon.c:			ictx->rx_endpoint_intf1->bInterval);
drivers/media/rc/imon.c:		rc = usb_submit_urb(ictx->rx_urb_intf1, GFP_ATOMIC);
drivers/media/platform/vim2m.c:		return &ctx->q_data[V4L2_M2M_SRC];
drivers/media/platform/vim2m.c:		return &ctx->q_data[V4L2_M2M_DST];
drivers/media/platform/vim2m.c:	struct vim2m_dev *dev = ctx->dev;
drivers/media/platform/vim2m.c:	switch (ctx->mode) {
drivers/media/platform/vim2m.c:	if (v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx) < ctx->translen
drivers/media/platform/vim2m.c:	    || v4l2_m2m_num_dst_bufs_ready(ctx->fh.m2m_ctx) < ctx->translen) {
drivers/media/platform/vim2m.c:		dprintk(ctx->dev, "Not enough buffers available\n");
drivers/media/platform/vim2m.c:	ctx->aborting = 1;
drivers/media/platform/vim2m.c:	struct vim2m_dev *dev = ctx->dev;
drivers/media/platform/vim2m.c:	src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	schedule_irq(dev, ctx->transtime);
drivers/media/platform/vim2m.c:	src_vb = v4l2_m2m_src_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	dst_vb = v4l2_m2m_dst_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	curr_ctx->num_processed++;
drivers/media/platform/vim2m.c:	if (curr_ctx->num_processed == curr_ctx->translen
drivers/media/platform/vim2m.c:	    || curr_ctx->aborting) {
drivers/media/platform/vim2m.c:		dprintk(curr_ctx->dev, "Finishing transaction\n");
drivers/media/platform/vim2m.c:		curr_ctx->num_processed = 0;
drivers/media/platform/vim2m.c:		v4l2_m2m_job_finish(vim2m_dev->m2m_dev, curr_ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/vim2m.c:	f->fmt.pix.colorspace	= ctx->colorspace;
drivers/media/platform/vim2m.c:	f->fmt.pix.xfer_func	= ctx->xfer_func;
drivers/media/platform/vim2m.c:	f->fmt.pix.ycbcr_enc	= ctx->ycbcr_enc;
drivers/media/platform/vim2m.c:	f->fmt.pix.quantization	= ctx->quant;
drivers/media/platform/vim2m.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/vim2m.c:	f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/vim2m.c:	f->fmt.pix.xfer_func = ctx->xfer_func;
drivers/media/platform/vim2m.c:	f->fmt.pix.ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/vim2m.c:	f->fmt.pix.quantization = ctx->quant;
drivers/media/platform/vim2m.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/vim2m.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/vim2m.c:		v4l2_err(&ctx->dev->v4l2_dev, "%s queue busy\n", __func__);
drivers/media/platform/vim2m.c:	dprintk(ctx->dev,
drivers/media/platform/vim2m.c:		ctx->colorspace = f->fmt.pix.colorspace;
drivers/media/platform/vim2m.c:		ctx->xfer_func = f->fmt.pix.xfer_func;
drivers/media/platform/vim2m.c:		ctx->ycbcr_enc = f->fmt.pix.ycbcr_enc;
drivers/media/platform/vim2m.c:		ctx->quant = f->fmt.pix.quantization;
drivers/media/platform/vim2m.c:			ctx->mode |= MEM2MEM_HFLIP;
drivers/media/platform/vim2m.c:			ctx->mode &= ~MEM2MEM_HFLIP;
drivers/media/platform/vim2m.c:			ctx->mode |= MEM2MEM_VFLIP;
drivers/media/platform/vim2m.c:			ctx->mode &= ~MEM2MEM_VFLIP;
drivers/media/platform/vim2m.c:		ctx->transtime = ctrl->val;
drivers/media/platform/vim2m.c:		ctx->translen = ctrl->val;
drivers/media/platform/vim2m.c:		v4l2_err(&ctx->dev->v4l2_dev, "Invalid control\n");
drivers/media/platform/vim2m.c:	dprintk(ctx->dev, "get %d buffer(s) of size %d each.\n", count, size);
drivers/media/platform/vim2m.c:	dprintk(ctx->dev, "type: %d\n", vb->vb2_queue->type);
drivers/media/platform/vim2m.c:			dprintk(ctx->dev, "%s field isn't supported\n",
drivers/media/platform/vim2m.c:		dprintk(ctx->dev, "%s data will not fit into plane (%lu < %lu)\n",
drivers/media/platform/vim2m.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/vim2m.c:			vbuf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:			vbuf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:		spin_lock_irqsave(&ctx->dev->irqlock, flags);
drivers/media/platform/vim2m.c:		spin_unlock_irqrestore(&ctx->dev->irqlock, flags);
drivers/media/platform/vim2m.c:	src_vq->lock = &ctx->dev->dev_mutex;
drivers/media/platform/vim2m.c:	dst_vq->lock = &ctx->dev->dev_mutex;
drivers/media/platform/vim2m.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/vim2m.c:	file->private_data = &ctx->fh;
drivers/media/platform/vim2m.c:	ctx->dev = dev;
drivers/media/platform/vim2m.c:	hdl = &ctx->hdl;
drivers/media/platform/vim2m.c:	ctx->fh.ctrl_handler = hdl;
drivers/media/platform/vim2m.c:	ctx->q_data[V4L2_M2M_SRC].fmt = &formats[0];
drivers/media/platform/vim2m.c:	ctx->q_data[V4L2_M2M_SRC].width = 640;
drivers/media/platform/vim2m.c:	ctx->q_data[V4L2_M2M_SRC].height = 480;
drivers/media/platform/vim2m.c:	ctx->q_data[V4L2_M2M_SRC].sizeimage =
drivers/media/platform/vim2m.c:		ctx->q_data[V4L2_M2M_SRC].width *
drivers/media/platform/vim2m.c:		ctx->q_data[V4L2_M2M_SRC].height *
drivers/media/platform/vim2m.c:		(ctx->q_data[V4L2_M2M_SRC].fmt->depth >> 3);
drivers/media/platform/vim2m.c:	ctx->q_data[V4L2_M2M_DST] = ctx->q_data[V4L2_M2M_SRC];
drivers/media/platform/vim2m.c:	ctx->colorspace = V4L2_COLORSPACE_REC709;
drivers/media/platform/vim2m.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(dev->m2m_dev, ctx, &queue_init);
drivers/media/platform/vim2m.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/vim2m.c:		rc = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/vim2m.c:		ctx, ctx->fh.m2m_ctx);
drivers/media/platform/vim2m.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/vim2m.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/vim2m.c:	v4l2_ctrl_handler_free(&ctx->hdl);
drivers/media/platform/vim2m.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->subsampling != V4L2_JPEG_CHROMA_SUBSAMPLING_GRAY) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	switch (ctx->subsampling) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	WARN_ON(ctx->subsampling > 3);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	switch (ctx->jpeg->variant->version) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->subsampling > 2)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return ctx->subsampling;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->subsampling > 3)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return exynos3250_decoded_subsampling[ctx->subsampling];
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->subsampling > 2)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return exynos4x12_decoded_subsampling[ctx->subsampling];
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct vb2_buffer *vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		(unsigned long)vb2_plane_vaddr(vb, 0) + ctx->out_q.sos + 2;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct vb2_buffer *vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	for (j = 0; j < ctx->out_q.dht.n; ++j) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		jpeg_buffer.size = ctx->out_q.dht.len[j];
drivers/media/platform/s5p-jpeg/jpeg-core.c:				   ctx->out_q.dht.marker[j];
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct vb2_buffer *vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	jpeg_buffer.size = ctx->out_q.sof_len;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		(unsigned long)vb2_plane_vaddr(vb, 0) + ctx->out_q.sof;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct vb2_buffer *vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	for (j = 0; j < ctx->out_q.dqt.n; ++j) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		jpeg_buffer.size = ctx->out_q.dqt.len[j];
drivers/media/platform/s5p-jpeg/jpeg-core.c:				   ctx->out_q.dqt.marker[j];
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_init(&ctx->fh, vfd);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	file->private_data = &ctx->fh;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->jpeg = jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->mode = S5P_JPEG_ENCODE;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->mode = S5P_JPEG_DECODE;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->scale_factor = EXYNOS3250_DEC_SCALE_FACTOR_8_8;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(jpeg->m2m_dev, ctx, queue_init);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->out_q.fmt = out_fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->cap_q.fmt = cap_fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->subsampling = V4L2_JPEG_CHROMA_SUBSAMPLING_444;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->subsampling = V4L2_JPEG_CHROMA_SUBSAMPLING_422;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->subsampling = V4L2_JPEG_CHROMA_SUBSAMPLING_420;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->subsampling = V4L2_JPEG_CHROMA_SUBSAMPLING_GRAY;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		 dev_name(ctx->jpeg->dev));
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return &ctx->out_q;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return &ctx->cap_q;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		    fmt->flags & ctx->jpeg->variant->fmt_ver_flag) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->jpeg->variant->hw3250_compat) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		v4l2_err(&ctx->jpeg->v4l2_dev,
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (!ctx->jpeg->variant->hw_ex4_compat || ctx->mode != S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	    (fmt->subsampling < ctx->subsampling)) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ret = s5p_jpeg_adjust_fourcc_to_subsampling(ctx->subsampling,
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->subsampling == V4L2_JPEG_CHROMA_SUBSAMPLING_420 &&
drivers/media/platform/s5p-jpeg/jpeg-core.c:	    (ctx->out_q.w & 1) &&
drivers/media/platform/s5p-jpeg/jpeg-core.c:		v4l2_err(&ctx->jpeg->v4l2_dev,
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->jpeg->variant->version == SJPEG_EXYNOS4)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	w_ratio = ctx->out_q.w / r->width;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	h_ratio = ctx->out_q.h / r->height;
drivers/media/platform/s5p-jpeg/jpeg-core.c:			ctx->scale_factor = cur_ratio;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	r->width = round_down(ctx->out_q.w / ctx->scale_factor, 2);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	r->height = round_down(ctx->out_q.h / ctx->scale_factor, 2);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.width = r->width;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.height = r->height;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.left = 0;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.top = 0;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_altered = true;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	switch (ctx->cap_q.fmt->fourcc) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	base_rect.width = ctx->out_q.w;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	base_rect.height = ctx->out_q.h;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.left = r->left;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.top = r->top;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.width = r->width;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_rect.height = r->height;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctx->crop_altered = true;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.width = ctx->out_q.w;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.height = ctx->out_q.h;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.width = ctx->crop_rect.width;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.height =  ctx->crop_rect.height;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.left = ctx->crop_rect.left;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s->r.top = ctx->crop_rect.top;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->mode != S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->jpeg->variant->hw3250_compat)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->mode != S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->jpeg->variant->hw3250_compat)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	switch (ctx->jpeg->variant->version) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->out_q.fmt->fourcc == V4L2_PIX_FMT_RGB32)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->out_q.fmt->fourcc != V4L2_PIX_FMT_GREY &&
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->out_q.fmt->subsampling > *ctrl_val)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		*ctrl_val = ctx->out_q.fmt->subsampling;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_lock_irqsave(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_unlock_irqrestore(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_lock_irqsave(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->compr_quality = ctrl->val;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->restart_interval = ctrl->val;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->subsampling = ctrl->val;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_unlock_irqrestore(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, 3);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		v4l2_ctrl_new_std(&ctx->ctrl_handler, &s5p_jpeg_ctrl_ops,
drivers/media/platform/s5p-jpeg/jpeg-core.c:		v4l2_ctrl_new_std(&ctx->ctrl_handler, &s5p_jpeg_ctrl_ops,
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->jpeg->variant->version == SJPEG_S5P)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ctrl = v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &s5p_jpeg_ctrl_ops,
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ret = ctx->ctrl_handler.error;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ret = v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_lock_irqsave(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	s5p_jpeg_proc_mode(jpeg->regs, ctx->mode);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->out_q.fmt->fourcc == V4L2_PIX_FMT_RGB565)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_subsampling_mode(jpeg->regs, ctx->subsampling);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_dri(jpeg->regs, ctx->restart_interval);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_x(jpeg->regs, ctx->out_q.w);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_y(jpeg->regs, ctx->out_q.h);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_enc_stream_int(jpeg->regs, ctx->cap_q.size);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_set_qtbl_lum(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_set_qtbl_chr(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->cap_q.fmt->fourcc == V4L2_PIX_FMT_YUYV)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_unlock_irqrestore(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	pix_size = ctx->cap_q.w * ctx->cap_q.h;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		fmt = ctx->out_q.fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->out_q.w % 2 && fmt->h_align > 0)
drivers/media/platform/s5p-jpeg/jpeg-core.c:			padding_bytes = ctx->out_q.h;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		fmt = ctx->cap_q.fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	    ctx->mode == S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		jpeg_addr += ctx->out_q.sos;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos4_jpeg_set_qtbl_lum(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos4_jpeg_set_qtbl_chr(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos4_jpeg_set_stream_size(jpeg->regs, ctx->cap_q.w,
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->cap_q.h);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->jpeg->variant->version == SJPEG_EXYNOS4) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:						     ctx->subsampling);
drivers/media/platform/s5p-jpeg/jpeg-core.c:						 ctx->out_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->subsampling);
drivers/media/platform/s5p-jpeg/jpeg-core.c:						    ctx->out_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->out_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:			exynos4_jpeg_set_stream_size(jpeg->regs, ctx->cap_q.w,
drivers/media/platform/s5p-jpeg/jpeg-core.c:					ctx->cap_q.h);
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->subsampling);
drivers/media/platform/s5p-jpeg/jpeg-core.c:						    ctx->cap_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:			bitstream_size = DIV_ROUND_UP(ctx->out_q.size, 16);
drivers/media/platform/s5p-jpeg/jpeg-core.c:						 ctx->cap_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:			bitstream_size = DIV_ROUND_UP(ctx->out_q.size, 32);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	exynos4_jpeg_set_enc_dec_mode(jpeg->regs, ctx->mode);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	pix_size = ctx->cap_q.w * ctx->cap_q.h;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		fmt = ctx->out_q.fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		fmt = ctx->cap_q.fmt;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	struct s5p_jpeg *jpeg = ctx->jpeg;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_lock_irqsave(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	exynos3250_jpeg_proc_mode(jpeg->regs, ctx->mode);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:					      ctx->out_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_dri(jpeg->regs, ctx->restart_interval);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_set_qtbl_lum(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		s5p_jpeg_set_qtbl_chr(jpeg->regs, ctx->compr_quality);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_set_x(jpeg->regs, ctx->crop_rect.width);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_set_y(jpeg->regs, ctx->crop_rect.height);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_stride(jpeg->regs, ctx->out_q.fmt->fourcc,
drivers/media/platform/s5p-jpeg/jpeg-core.c:								ctx->out_q.w);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_offset(jpeg->regs, ctx->crop_rect.left,
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->crop_rect.top);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_subsampling_mode(jpeg->regs, ctx->subsampling);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_enc_stream_bound(jpeg->regs, ctx->cap_q.size);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (ctx->out_q.fmt->fourcc == V4L2_PIX_FMT_RGB565 ||
drivers/media/platform/s5p-jpeg/jpeg-core.c:		    ctx->out_q.fmt->fourcc == V4L2_PIX_FMT_RGB565X ||
drivers/media/platform/s5p-jpeg/jpeg-core.c:		    ctx->out_q.fmt->fourcc == V4L2_PIX_FMT_RGB32)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_stride(jpeg->regs, ctx->cap_q.fmt->fourcc,
drivers/media/platform/s5p-jpeg/jpeg-core.c:								ctx->cap_q.w);
drivers/media/platform/s5p-jpeg/jpeg-core.c:							ctx->scale_factor);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		exynos3250_jpeg_dec_stream_size(jpeg->regs, ctx->out_q.size);
drivers/media/platform/s5p-jpeg/jpeg-core.c:						ctx->cap_q.fmt->fourcc);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	exynos3250_jpeg_coef(jpeg->regs, ctx->mode);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	spin_unlock_irqrestore(&ctx->jpeg->slock, flags);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:		return ctx->hdr_parsed;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (ctx->mode == S5P_JPEG_DECODE &&
drivers/media/platform/s5p-jpeg/jpeg-core.c:		ctx->hdr_parsed = s5p_jpeg_parse_hdr(&tmp,
drivers/media/platform/s5p-jpeg/jpeg-core.c:		     min((unsigned long)ctx->out_q.size,
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (!ctx->hdr_parsed) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:		q_data = &ctx->out_q;
drivers/media/platform/s5p-jpeg/jpeg-core.c:		q_data = &ctx->cap_q;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	ret = pm_runtime_get_sync(ctx->jpeg->dev);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	pm_runtime_put(ctx->jpeg->dev);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_vq->lock = &ctx->jpeg->lock;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_vq->dev = ctx->jpeg->dev;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_vq->lock = &ctx->jpeg->lock;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_vq->dev = ctx->jpeg->dev;
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_buf = v4l2_m2m_src_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_buf = v4l2_m2m_dst_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (curr_ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (curr_ctx->mode == S5P_JPEG_DECODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (curr_ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_m2m_job_finish(jpeg->m2m_dev, curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	curr_ctx->subsampling = s5p_jpeg_get_subsampling_mode(jpeg->regs);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_vb = v4l2_m2m_src_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_vb = v4l2_m2m_dst_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		if (curr_ctx->mode == S5P_JPEG_ENCODE) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_m2m_job_finish(jpeg->m2m_dev, curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:		curr_ctx->subsampling = exynos4_jpeg_get_frame_fmt(jpeg->regs);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	    (curr_ctx->mode == S5P_JPEG_DECODE)) {
drivers/media/platform/s5p-jpeg/jpeg-core.c:	src_buf = v4l2_m2m_src_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	dst_buf = v4l2_m2m_dst_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	if (curr_ctx->mode == S5P_JPEG_ENCODE)
drivers/media/platform/s5p-jpeg/jpeg-core.c:	v4l2_m2m_job_finish(jpeg->m2m_dev, curr_ctx->fh.m2m_ctx);
drivers/media/platform/s5p-jpeg/jpeg-core.c:	curr_ctx->subsampling =
drivers/media/platform/omap3isp/ispcsi2.c:	ctx->ping_addr = addr;
drivers/media/platform/omap3isp/ispcsi2.c:	ctx->pong_addr = addr;
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, ctx->ping_addr,
drivers/media/platform/omap3isp/ispcsi2.c:		       csi2->regs1, ISPCSI2_CTX_DAT_PING_ADDR(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, ctx->pong_addr,
drivers/media/platform/omap3isp/ispcsi2.c:		       csi2->regs1, ISPCSI2_CTX_DAT_PONG_ADDR(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	ctx->enabled = enable;
drivers/media/platform/omap3isp/ispcsi2.c:	reg = isp_reg_readl(isp, csi2->regs1, ISPCSI2_CTX_CTRL1(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	if (ctx->eof_enabled)
drivers/media/platform/omap3isp/ispcsi2.c:	if (ctx->eol_enabled)
drivers/media/platform/omap3isp/ispcsi2.c:	if (ctx->checksum_enabled)
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, reg, csi2->regs1, ISPCSI2_CTX_CTRL1(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	reg = isp_reg_readl(isp, csi2->regs1, ISPCSI2_CTX_CTRL2(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	reg |= ctx->virtual_id << ISPCSI2_CTX_CTRL2_VIRTUAL_ID_SHIFT;
drivers/media/platform/omap3isp/ispcsi2.c:	reg |= ctx->format_id << ISPCSI2_CTX_CTRL2_FORMAT_SHIFT;
drivers/media/platform/omap3isp/ispcsi2.c:	if (ctx->dpcm_decompress) {
drivers/media/platform/omap3isp/ispcsi2.c:		if (ctx->dpcm_predictor)
drivers/media/platform/omap3isp/ispcsi2.c:	if (is_usr_def_mapping(ctx->format_id)) {
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, reg, csi2->regs1, ISPCSI2_CTX_CTRL2(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	reg = isp_reg_readl(isp, csi2->regs1, ISPCSI2_CTX_CTRL3(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	reg |= (ctx->alpha << ISPCSI2_CTX_CTRL3_ALPHA_SHIFT);
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, reg, csi2->regs1, ISPCSI2_CTX_CTRL3(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:			    ISPCSI2_CTX_DAT_OFST(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	reg |= ctx->data_offset << ISPCSI2_CTX_DAT_OFST_OFST_SHIFT;
drivers/media/platform/omap3isp/ispcsi2.c:		       ISPCSI2_CTX_DAT_OFST(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, ctx->ping_addr,
drivers/media/platform/omap3isp/ispcsi2.c:		       csi2->regs1, ISPCSI2_CTX_DAT_PING_ADDR(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	isp_reg_writel(isp, ctx->pong_addr,
drivers/media/platform/omap3isp/ispcsi2.c:		       csi2->regs1, ISPCSI2_CTX_DAT_PONG_ADDR(ctx->ctxnum));
drivers/media/platform/omap3isp/ispcsi2.c:	unsigned int n = ctx->ctxnum;
drivers/media/platform/omap3isp/ispcsi2.c:			ctx->format_id = csi2_ctx_map_format(csi2);
drivers/media/platform/rcar_jpu.c:	if (ctx->encoder)
drivers/media/platform/rcar_jpu.c:		 dev_name(ctx->jpu->dev));
drivers/media/platform/rcar_jpu.c:	return jpu_enum_fmt(f, ctx->encoder ? JPU_ENC_CAPTURE :
drivers/media/platform/rcar_jpu.c:	return jpu_enum_fmt(f, ctx->encoder ? JPU_ENC_OUTPUT : JPU_DEC_OUTPUT);
drivers/media/platform/rcar_jpu.c:		return &ctx->out_q;
drivers/media/platform/rcar_jpu.c:		return &ctx->cap_q;
drivers/media/platform/rcar_jpu.c:	fmt = jpu_find_format(ctx->encoder, pix->pixelformat, f_type);
drivers/media/platform/rcar_jpu.c:		dev_dbg(ctx->jpu->dev, "unknown format; set default format\n");
drivers/media/platform/rcar_jpu.c:		if (ctx->encoder)
drivers/media/platform/rcar_jpu.c:		fmt = jpu_find_format(ctx->encoder, pixelformat, f_type);
drivers/media/platform/rcar_jpu.c:		if (pix->plane_fmt[0].sizeimage <= 0 || ctx->encoder)
drivers/media/platform/rcar_jpu.c:	if (!v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type))
drivers/media/platform/rcar_jpu.c:	struct v4l2_m2m_ctx *m2m_ctx = ctx->fh.m2m_ctx;
drivers/media/platform/rcar_jpu.c:		v4l2_err(&ctx->jpu->v4l2_dev, "%s queue busy\n", __func__);
drivers/media/platform/rcar_jpu.c:	if (!v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type))
drivers/media/platform/rcar_jpu.c:	spin_lock_irqsave(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:		ctx->compr_quality = ctrl->val;
drivers/media/platform/rcar_jpu.c:	spin_unlock_irqrestore(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	if (ctx->encoder) {
drivers/media/platform/rcar_jpu.c:		dev_err(ctx->jpu->dev, "src and dst formats do not match.\n");
drivers/media/platform/rcar_jpu.c:	return v4l2_m2m_streamon(file, ctx->fh.m2m_ctx, type);
drivers/media/platform/rcar_jpu.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, 1);
drivers/media/platform/rcar_jpu.c:	ctrl = v4l2_ctrl_new_std(&ctx->ctrl_handler, &jpu_ctrl_ops,
drivers/media/platform/rcar_jpu.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/rcar_jpu.c:		ret = ctx->ctrl_handler.error;
drivers/media/platform/rcar_jpu.c:	if (!ctx->encoder)
drivers/media/platform/rcar_jpu.c:	ret = v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/rcar_jpu.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/rcar_jpu.c:			dev_err(ctx->jpu->dev, "%s field isn't supported\n",
drivers/media/platform/rcar_jpu.c:			dev_err(ctx->jpu->dev,
drivers/media/platform/rcar_jpu.c:		if (!ctx->encoder && !V4L2_TYPE_IS_OUTPUT(vb->vb2_queue->type))
drivers/media/platform/rcar_jpu.c:	if (!ctx->encoder && V4L2_TYPE_IS_OUTPUT(vb->vb2_queue->type)) {
drivers/media/platform/rcar_jpu.c:		q_data = &ctx->out_q;
drivers/media/platform/rcar_jpu.c:	if (ctx->fh.m2m_ctx)
drivers/media/platform/rcar_jpu.c:		v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/rcar_jpu.c:	dev_err(ctx->jpu->dev, "incompatible or corrupted JPEG data\n");
drivers/media/platform/rcar_jpu.c:	struct jpu_q_data *q_data = &ctx->out_q;
drivers/media/platform/rcar_jpu.c:	if (!ctx->encoder || vb->state != VB2_BUF_STATE_DONE ||
drivers/media/platform/rcar_jpu.c:			vb = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:			vb = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:		spin_lock_irqsave(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:		spin_unlock_irqrestore(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	src_vq->lock = &ctx->jpu->mutex;
drivers/media/platform/rcar_jpu.c:	src_vq->dev = ctx->jpu->v4l2_dev.dev;
drivers/media/platform/rcar_jpu.c:	dst_vq->lock = &ctx->jpu->mutex;
drivers/media/platform/rcar_jpu.c:	dst_vq->dev = ctx->jpu->v4l2_dev.dev;
drivers/media/platform/rcar_jpu.c:	v4l2_fh_init(&ctx->fh, vfd);
drivers/media/platform/rcar_jpu.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/rcar_jpu.c:	file->private_data = &ctx->fh;
drivers/media/platform/rcar_jpu.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/rcar_jpu.c:	ctx->jpu = jpu;
drivers/media/platform/rcar_jpu.c:	ctx->encoder = vfd == &jpu->vfd_encoder;
drivers/media/platform/rcar_jpu.c:	__jpu_try_fmt(ctx, &ctx->out_q.fmtinfo, &ctx->out_q.format,
drivers/media/platform/rcar_jpu.c:	__jpu_try_fmt(ctx, &ctx->cap_q.fmtinfo, &ctx->cap_q.format,
drivers/media/platform/rcar_jpu.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(jpu->m2m_dev, ctx, jpu_queue_init);
drivers/media/platform/rcar_jpu.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/rcar_jpu.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/rcar_jpu.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/rcar_jpu.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/rcar_jpu.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/rcar_jpu.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/rcar_jpu.c:	spin_lock_irqsave(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:		jpu_write(ctx->jpu, JCCMD_SRST, JCCMD);
drivers/media/platform/rcar_jpu.c:	spin_unlock_irqrestore(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	v4l2_m2m_job_finish(ctx->jpu->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	struct jpu *jpu = ctx->jpu;
drivers/media/platform/rcar_jpu.c:	spin_lock_irqsave(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	if (ctx->encoder) {
drivers/media/platform/rcar_jpu.c:		q_data = &ctx->out_q;
drivers/media/platform/rcar_jpu.c:		q_data = &ctx->cap_q;
drivers/media/platform/rcar_jpu.c:	if (ctx->encoder) {
drivers/media/platform/rcar_jpu.c:		jpu_buf->compr_quality = ctx->compr_quality;
drivers/media/platform/rcar_jpu.c:		jpu_set_qtbl(jpu, ctx->compr_quality);
drivers/media/platform/rcar_jpu.c:			dev_err(ctx->jpu->dev,
drivers/media/platform/rcar_jpu.c:			spin_unlock_irqrestore(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	spin_unlock_irqrestore(&ctx->jpu->lock, flags);
drivers/media/platform/rcar_jpu.c:	if (!wait_event_timeout(ctx->jpu->irq_queue, !ctx->jpu->curr,
drivers/media/platform/rcar_jpu.c:	src_buf = v4l2_m2m_src_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:	dst_buf = v4l2_m2m_dst_buf_remove(curr_ctx->fh.m2m_ctx);
drivers/media/platform/rcar_jpu.c:		if (curr_ctx->encoder) {
drivers/media/platform/rcar_jpu.c:	v4l2_m2m_job_finish(jpu->m2m_dev, curr_ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:		return &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:		return &ctx->q_data[Q_DATA_DST];
drivers/media/platform/ti-vpe/vpe.c:	((obj)->res->start - ctx->dev->res->start + reg)
drivers/media/platform/ti-vpe/vpe.c:	VPDMA_SET_MMR_ADB_HDR(ctx->mmr_adb, vpe_mmr_adb, hdr, regs, offset_a)
drivers/media/platform/ti-vpe/vpe.c:		GET_OFFSET_TOP(ctx, ctx->dev->sc, CFG_SC0));
drivers/media/platform/ti-vpe/vpe.c:		GET_OFFSET_TOP(ctx, ctx->dev->sc, CFG_SC8));
drivers/media/platform/ti-vpe/vpe.c:		GET_OFFSET_TOP(ctx, ctx->dev->sc, CFG_SC17));
drivers/media/platform/ti-vpe/vpe.c:		GET_OFFSET_TOP(ctx, ctx->dev->csc, CSC_CSC00));
drivers/media/platform/ti-vpe/vpe.c:	struct device *dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->mv_buf_size == size)
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->mv_buf[0])
drivers/media/platform/ti-vpe/vpe.c:		dma_free_coherent(dev, ctx->mv_buf_size, ctx->mv_buf[0],
drivers/media/platform/ti-vpe/vpe.c:			ctx->mv_buf_dma[0]);
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->mv_buf[1])
drivers/media/platform/ti-vpe/vpe.c:		dma_free_coherent(dev, ctx->mv_buf_size, ctx->mv_buf[1],
drivers/media/platform/ti-vpe/vpe.c:			ctx->mv_buf_dma[1]);
drivers/media/platform/ti-vpe/vpe.c:	ctx->mv_buf[0] = dma_alloc_coherent(dev, size, &ctx->mv_buf_dma[0],
drivers/media/platform/ti-vpe/vpe.c:	if (!ctx->mv_buf[0]) {
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "failed to allocate motion vector buffer\n");
drivers/media/platform/ti-vpe/vpe.c:	ctx->mv_buf[1] = dma_alloc_coherent(dev, size, &ctx->mv_buf_dma[1],
drivers/media/platform/ti-vpe/vpe.c:	if (!ctx->mv_buf[1]) {
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "failed to allocate motion vector buffer\n");
drivers/media/platform/ti-vpe/vpe.c:		dma_free_coherent(dev, size, ctx->mv_buf[0],
drivers/media/platform/ti-vpe/vpe.c:			ctx->mv_buf_dma[0]);
drivers/media/platform/ti-vpe/vpe.c:	ctx->mv_buf_size = size;
drivers/media/platform/ti-vpe/vpe.c:	ctx->src_mv_buf_selector = 0;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_dev *dev = ctx->dev;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->src_vbs[2] == NULL)
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->src_vbs[2]) {
drivers/media/platform/ti-vpe/vpe.c:		v4l2_m2m_buf_done(ctx->src_vbs[2], VB2_BUF_STATE_DONE);
drivers/media/platform/ti-vpe/vpe.c:		v4l2_m2m_buf_done(ctx->src_vbs[1], VB2_BUF_STATE_DONE);
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *s_q_data = &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_fmt *fmt = ctx->q_data[Q_DATA_SRC].fmt;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_line_mode(ctx->dev->vpdma, line_mode, VPE_CHAN_CHROMA1_IN);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_line_mode(ctx->dev->vpdma, line_mode, VPE_CHAN_CHROMA2_IN);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_line_mode(ctx->dev->vpdma, line_mode, VPE_CHAN_CHROMA3_IN);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_set_frame_start_event(ctx->dev->vpdma, VPDMA_FSEVENT_CHANNEL_ACTIVE,
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	enum v4l2_colorspace clrspc = ctx->q_data[Q_DATA_DST].colorspace;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_fmt *fmt = ctx->q_data[Q_DATA_DST].fmt;
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *s_q_data = &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:	if ((!ctx->deinterlacing && (s_q_data->flags & Q_DATA_INTERLACED)) ||
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *s_q_data =  &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *d_q_data =  &ctx->q_data[Q_DATA_DST];
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_mmr_adb *mmr_adb = ctx->mmr_adb.addr;
drivers/media/platform/ti-vpe/vpe.c:	ctx->sequence = 0;
drivers/media/platform/ti-vpe/vpe.c:	ctx->field = V4L2_FIELD_TOP;
drivers/media/platform/ti-vpe/vpe.c:		ctx->deinterlacing = true;
drivers/media/platform/ti-vpe/vpe.c:		ctx->deinterlacing = false;
drivers/media/platform/ti-vpe/vpe.c:	csc_set_coeff(ctx->dev->csc, &mmr_adb->csc_regs[0],
drivers/media/platform/ti-vpe/vpe.c:	sc_set_hs_coeffs(ctx->dev->sc, ctx->sc_coeff_h.addr, src_w, dst_w);
drivers/media/platform/ti-vpe/vpe.c:	sc_set_vs_coeffs(ctx->dev->sc, ctx->sc_coeff_v.addr, src_h, dst_h);
drivers/media/platform/ti-vpe/vpe.c:	sc_config_scaler(ctx->dev->sc, &mmr_adb->sc_regs0[0],
drivers/media/platform/ti-vpe/vpe.c:	int needed = ctx->bufs_per_job;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing && ctx->src_vbs[2] == NULL)
drivers/media/platform/ti-vpe/vpe.c:	if (v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx) < needed)
drivers/media/platform/ti-vpe/vpe.c:	if (v4l2_m2m_num_dst_bufs_ready(ctx->fh.m2m_ctx) < needed)
drivers/media/platform/ti-vpe/vpe.c:	ctx->aborting = 1;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_dev *dev = ctx->dev;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_dev *dev = ctx->dev;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *q_data = &ctx->q_data[Q_DATA_DST];
drivers/media/platform/ti-vpe/vpe.c:	struct vb2_buffer *vb = &ctx->dst_vb->vb2_buf;
drivers/media/platform/ti-vpe/vpe.c:	int mv_buf_selector = !ctx->src_mv_buf_selector;
drivers/media/platform/ti-vpe/vpe.c:		dma_addr = ctx->mv_buf_dma[mv_buf_selector];
drivers/media/platform/ti-vpe/vpe.c:			vpe_err(ctx->dev,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_add_out_dtd(&ctx->desc_list, q_data->width, &q_data->c_rect,
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *q_data = &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:	struct vb2_buffer *vb = &ctx->src_vbs[p_data->vb_index]->vb2_buf;
drivers/media/platform/ti-vpe/vpe.c:	int mv_buf_selector = ctx->src_mv_buf_selector;
drivers/media/platform/ti-vpe/vpe.c:		dma_addr = ctx->mv_buf_dma[mv_buf_selector];
drivers/media/platform/ti-vpe/vpe.c:			vpe_err(ctx->dev,
drivers/media/platform/ti-vpe/vpe.c:	vpdma_add_in_dtd(&ctx->desc_list, q_data->width, &q_data->c_rect,
drivers/media/platform/ti-vpe/vpe.c:	write_reg(ctx->dev, VPE_INT0_ENABLE0_SET, VPE_INT0_LIST0_COMPLETE);
drivers/media/platform/ti-vpe/vpe.c:	write_reg(ctx->dev, VPE_INT0_ENABLE1_SET, VPE_DEI_ERROR_INT |
drivers/media/platform/ti-vpe/vpe.c:	vpdma_enable_list_complete_irq(ctx->dev->vpdma, 0, true);
drivers/media/platform/ti-vpe/vpe.c:	write_reg(ctx->dev, VPE_INT0_ENABLE0_CLR, 0xffffffff);
drivers/media/platform/ti-vpe/vpe.c:	write_reg(ctx->dev, VPE_INT0_ENABLE1_CLR, 0xffffffff);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_enable_list_complete_irq(ctx->dev->vpdma, 0, false);
drivers/media/platform/ti-vpe/vpe.c:	struct sc_data *sc = ctx->dev->sc;
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_q_data *d_q_data = &ctx->q_data[Q_DATA_DST];
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing && ctx->src_vbs[2] == NULL) {
drivers/media/platform/ti-vpe/vpe.c:		ctx->src_vbs[2] = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:		WARN_ON(ctx->src_vbs[2] == NULL);
drivers/media/platform/ti-vpe/vpe.c:		ctx->src_vbs[1] = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:		WARN_ON(ctx->src_vbs[1] == NULL);
drivers/media/platform/ti-vpe/vpe.c:	ctx->src_vbs[0] = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:	WARN_ON(ctx->src_vbs[0] == NULL);
drivers/media/platform/ti-vpe/vpe.c:	ctx->dst_vb = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:	WARN_ON(ctx->dst_vb == NULL);
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->dev->loaded_mmrs != ctx->mmr_adb.dma_addr || ctx->load_mmrs) {
drivers/media/platform/ti-vpe/vpe.c:		vpdma_map_desc_buf(ctx->dev->vpdma, &ctx->mmr_adb);
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_cfd_adb(&ctx->desc_list, CFD_MMR_CLIENT, &ctx->mmr_adb);
drivers/media/platform/ti-vpe/vpe.c:		ctx->dev->loaded_mmrs = ctx->mmr_adb.dma_addr;
drivers/media/platform/ti-vpe/vpe.c:		ctx->load_mmrs = false;
drivers/media/platform/ti-vpe/vpe.c:	if (sc->loaded_coeff_h != ctx->sc_coeff_h.dma_addr ||
drivers/media/platform/ti-vpe/vpe.c:		vpdma_map_desc_buf(ctx->dev->vpdma, &ctx->sc_coeff_h);
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_cfd_block(&ctx->desc_list, CFD_SC_CLIENT,
drivers/media/platform/ti-vpe/vpe.c:			&ctx->sc_coeff_h, 0);
drivers/media/platform/ti-vpe/vpe.c:		sc->loaded_coeff_h = ctx->sc_coeff_h.dma_addr;
drivers/media/platform/ti-vpe/vpe.c:	if (sc->loaded_coeff_v != ctx->sc_coeff_v.dma_addr ||
drivers/media/platform/ti-vpe/vpe.c:		vpdma_map_desc_buf(ctx->dev->vpdma, &ctx->sc_coeff_v);
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_cfd_block(&ctx->desc_list, CFD_SC_CLIENT,
drivers/media/platform/ti-vpe/vpe.c:			&ctx->sc_coeff_v, SC_COEF_SRAM_SIZE >> 4);
drivers/media/platform/ti-vpe/vpe.c:		sc->loaded_coeff_v = ctx->sc_coeff_v.dma_addr;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing)
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing) {
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing)
drivers/media/platform/ti-vpe/vpe.c:	vpdma_add_sync_on_channel_ctd(&ctx->desc_list, VPE_CHAN_LUMA1_IN);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_add_sync_on_channel_ctd(&ctx->desc_list, VPE_CHAN_CHROMA1_IN);
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing) {
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list, VPE_CHAN_MV_IN);
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:			vpdma_add_sync_on_channel_ctd(&ctx->desc_list,
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing)
drivers/media/platform/ti-vpe/vpe.c:		vpdma_add_sync_on_channel_ctd(&ctx->desc_list, VPE_CHAN_MV_OUT);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_map_desc_buf(ctx->dev->vpdma, &ctx->desc_list.buf);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_submit_descs(ctx->dev->vpdma, &ctx->desc_list);
drivers/media/platform/ti-vpe/vpe.c:	dev_warn(ctx->dev->v4l2_dev.dev,
drivers/media/platform/ti-vpe/vpe.c:	dev_warn(ctx->dev->v4l2_dev.dev,
drivers/media/platform/ti-vpe/vpe.c:			vpdma_clear_list_stat(ctx->dev->vpdma);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_unmap_desc_buf(dev->vpdma, &ctx->desc_list.buf);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_unmap_desc_buf(dev->vpdma, &ctx->mmr_adb);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_unmap_desc_buf(dev->vpdma, &ctx->sc_coeff_h);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_unmap_desc_buf(dev->vpdma, &ctx->sc_coeff_v);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_reset_desc_list(&ctx->desc_list);
drivers/media/platform/ti-vpe/vpe.c:	ctx->src_mv_buf_selector = !ctx->src_mv_buf_selector;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->aborting)
drivers/media/platform/ti-vpe/vpe.c:	s_vb = ctx->src_vbs[0];
drivers/media/platform/ti-vpe/vpe.c:	d_vb = ctx->dst_vb;
drivers/media/platform/ti-vpe/vpe.c:	d_vb->sequence = ctx->sequence;
drivers/media/platform/ti-vpe/vpe.c:	d_q_data = &ctx->q_data[Q_DATA_DST];
drivers/media/platform/ti-vpe/vpe.c:		d_vb->field = ctx->field;
drivers/media/platform/ti-vpe/vpe.c:		if (ctx->field == V4L2_FIELD_BOTTOM) {
drivers/media/platform/ti-vpe/vpe.c:			ctx->sequence++;
drivers/media/platform/ti-vpe/vpe.c:			ctx->field = V4L2_FIELD_TOP;
drivers/media/platform/ti-vpe/vpe.c:			WARN_ON(ctx->field != V4L2_FIELD_TOP);
drivers/media/platform/ti-vpe/vpe.c:			ctx->field = V4L2_FIELD_BOTTOM;
drivers/media/platform/ti-vpe/vpe.c:		ctx->sequence++;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing)
drivers/media/platform/ti-vpe/vpe.c:		s_vb = ctx->src_vbs[2];
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->deinterlacing) {
drivers/media/platform/ti-vpe/vpe.c:		ctx->src_vbs[2] = ctx->src_vbs[1];
drivers/media/platform/ti-vpe/vpe.c:		ctx->src_vbs[1] = ctx->src_vbs[0];
drivers/media/platform/ti-vpe/vpe.c:	ctx->bufs_completed++;
drivers/media/platform/ti-vpe/vpe.c:	if (ctx->bufs_completed < ctx->bufs_per_job) {
drivers/media/platform/ti-vpe/vpe.c:	vpe_dbg(ctx->dev, "finishing transaction\n");
drivers/media/platform/ti-vpe/vpe.c:	ctx->bufs_completed = 0;
drivers/media/platform/ti-vpe/vpe.c:	v4l2_m2m_job_finish(dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "Fourcc format (0x%08x) invalid.\n",
drivers/media/platform/ti-vpe/vpe.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "queue busy\n");
drivers/media/platform/ti-vpe/vpe.c:	vpe_dbg(ctx->dev, "Setting format for type %d, wxh: %dx%d, fmt: %d bpl_y %d",
drivers/media/platform/ti-vpe/vpe.c:		vpe_dbg(ctx->dev, " bpl_uv %d\n",
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "negative values for top and left\n");
drivers/media/platform/ti-vpe/vpe.c:		vpe_dbg(ctx->dev,
drivers/media/platform/ti-vpe/vpe.c:		ctx->bufs_per_job = ctrl->val;
drivers/media/platform/ti-vpe/vpe.c:		vpe_err(ctx->dev, "Invalid control\n");
drivers/media/platform/ti-vpe/vpe.c:	vpe_dbg(ctx->dev, "get %d buffer(s) of size %d", *nbuffers,
drivers/media/platform/ti-vpe/vpe.c:		vpe_dbg(ctx->dev, " and %d\n", sizes[VPE_CHROMA]);
drivers/media/platform/ti-vpe/vpe.c:	vpe_dbg(ctx->dev, "type: %d\n", vb->vb2_queue->type);
drivers/media/platform/ti-vpe/vpe.c:			vpe_err(ctx->dev,
drivers/media/platform/ti-vpe/vpe.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/ti-vpe/vpe.c:	vpe_dump_regs(ctx->dev);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_dump_regs(ctx->dev->vpdma);
drivers/media/platform/ti-vpe/vpe.c:	struct vpe_dev *dev = ctx->dev;
drivers/media/platform/ti-vpe/vpe.c:	ctx->dev = dev;
drivers/media/platform/ti-vpe/vpe.c:	ret = vpdma_create_desc_list(&ctx->desc_list, VPE_DESC_LIST_SIZE,
drivers/media/platform/ti-vpe/vpe.c:	ret = vpdma_alloc_desc_buf(&ctx->mmr_adb, sizeof(struct vpe_mmr_adb));
drivers/media/platform/ti-vpe/vpe.c:	ret = vpdma_alloc_desc_buf(&ctx->sc_coeff_h, SC_COEF_SRAM_SIZE);
drivers/media/platform/ti-vpe/vpe.c:	ret = vpdma_alloc_desc_buf(&ctx->sc_coeff_v, SC_COEF_SRAM_SIZE);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/ti-vpe/vpe.c:	file->private_data = &ctx->fh;
drivers/media/platform/ti-vpe/vpe.c:	hdl = &ctx->hdl;
drivers/media/platform/ti-vpe/vpe.c:	ctx->fh.ctrl_handler = hdl;
drivers/media/platform/ti-vpe/vpe.c:	s_q_data = &ctx->q_data[Q_DATA_SRC];
drivers/media/platform/ti-vpe/vpe.c:	ctx->q_data[Q_DATA_DST] = *s_q_data;
drivers/media/platform/ti-vpe/vpe.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(dev->m2m_dev, ctx, &queue_init);
drivers/media/platform/ti-vpe/vpe.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/ti-vpe/vpe.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/ti-vpe/vpe.c:	ctx->bufs_per_job = VPE_DEF_BUFS_PER_JOB;
drivers/media/platform/ti-vpe/vpe.c:	ctx->load_mmrs = true;
drivers/media/platform/ti-vpe/vpe.c:		ctx, ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_buf(&ctx->sc_coeff_v);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_buf(&ctx->sc_coeff_h);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_buf(&ctx->mmr_adb);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_list(&ctx->desc_list);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_list(&ctx->desc_list);
drivers/media/platform/ti-vpe/vpe.c:	vpdma_free_desc_buf(&ctx->mmr_adb);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_ctrl_handler_free(&ctx->hdl);
drivers/media/platform/ti-vpe/vpe.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/ti-vpe/cal.c:		v4l2_dbg(level, debug, &ctx->v4l2_dev, fmt, ##arg)
drivers/media/platform/ti-vpe/cal.c:		v4l2_info(&ctx->v4l2_dev, fmt, ##arg)
drivers/media/platform/ti-vpe/cal.c:		v4l2_err(&ctx->v4l2_dev, fmt, ##arg)
drivers/media/platform/ti-vpe/cal.c:	for (k = 0; k < ctx->num_active_fmt; k++) {
drivers/media/platform/ti-vpe/cal.c:		fmt = ctx->active_fmt[k];
drivers/media/platform/ti-vpe/cal.c:	for (k = 0; k < ctx->num_active_fmt; k++) {
drivers/media/platform/ti-vpe/cal.c:		fmt = ctx->active_fmt[k];
drivers/media/platform/ti-vpe/cal.c:	if (!ctx->dev->cm->base) {
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev->cm, CM_CTRL_CORE_CAMERRX_CONTROL);
drivers/media/platform/ti-vpe/cal.c:	if (ctx->csi2_port == 1) {
drivers/media/platform/ti-vpe/cal.c:	} else if (ctx->csi2_port == 2) {
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev->cm, CM_CTRL_CORE_CAMERRX_CONTROL, val);
drivers/media/platform/ti-vpe/cal.c:	if (!ctx->dev->cm->base) {
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev->cm, CM_CTRL_CORE_CAMERRX_CONTROL);
drivers/media/platform/ti-vpe/cal.c:	if (ctx->csi2_port == 1)
drivers/media/platform/ti-vpe/cal.c:	else if (ctx->csi2_port == 2)
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev->cm, CM_CTRL_CORE_CAMERRX_CONTROL, val);
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:			CAL_HL_IRQ_MASK(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:			CAL_HL_IRQ_MASK(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_VC_IRQENABLE(1), 0xFF000000);
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:			CAL_HL_IRQ_MASK(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:			CAL_HL_IRQ_MASK(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_VC_IRQENABLE(1), 0);
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_CSI2_TIMING(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_TIMING(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_CSI2_TIMING(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_CSI2_TIMING(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:		if (reg_read_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:				   CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port),
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_CSI2_COMPLEXIO_CFG(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_CTRL);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CTRL, val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_CTRL = 0x%08x\n", reg_read(ctx->dev, CAL_CTRL));
drivers/media/platform/ti-vpe/cal.c:	u32 val = reg_read(ctx->dev, CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	struct v4l2_of_bus_mipi_csi2 *mipi_csi2 = &ctx->endpoint.bus.mipi_csi2;
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_COMPLEXIO_CFG(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:		ctx->csi2_port, val);
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev, CAL_CSI2_PPI_CTRL(ctx->csi2_port),
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev, CAL_CSI2_PPI_CTRL(ctx->csi2_port),
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_CSI2_CTX0(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	set_field(&val, ctx->csi2_port, CAL_CSI2_CTX_CPORT_MASK);
drivers/media/platform/ti-vpe/cal.c:	set_field(&val, ctx->virtual_channel, CAL_CSI2_CTX_VC_MASK);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_CSI2_CTX0(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_CSI2_CTX0(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_CSI2_CTX0(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_PIX_PROC(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	set_field(&val, ctx->csi2_port, CAL_PIX_PROC_CPORT_MASK);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_PIX_PROC(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_PIX_PROC(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_PIX_PROC(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_WR_DMA_CTRL(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	set_field(&val, ctx->csi2_port, CAL_WR_DMA_CTRL_CPORT_MASK);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_WR_DMA_CTRL(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_WR_DMA_CTRL(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_WR_DMA_CTRL(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	reg_write_field(ctx->dev,
drivers/media/platform/ti-vpe/cal.c:			CAL_WR_DMA_OFST(ctx->csi2_port),
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_WR_DMA_OFST(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_WR_DMA_OFST(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	val = reg_read(ctx->dev, CAL_WR_DMA_XSIZE(ctx->csi2_port));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_WR_DMA_XSIZE(ctx->csi2_port), val);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "CAL_WR_DMA_XSIZE(%d) = 0x%08x\n", ctx->csi2_port,
drivers/media/platform/ti-vpe/cal.c:		reg_read(ctx->dev, CAL_WR_DMA_XSIZE(ctx->csi2_port)));
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->dev, CAL_WR_DMA_ADDR(ctx->csi2_port), dmaaddr);
drivers/media/platform/ti-vpe/cal.c:	ddrclkperiod_us = ctx->external_rate / 2000000;
drivers/media/platform/ti-vpe/cal.c:	reg0 = reg_read(ctx->cc, CAL_CSI2_PHY_REG0);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(1, ctx, "CSI2_%d_REG0 = 0x%08x\n", (ctx->csi2_port - 1), reg0);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->cc, CAL_CSI2_PHY_REG0, reg0);
drivers/media/platform/ti-vpe/cal.c:	reg1 = reg_read(ctx->cc, CAL_CSI2_PHY_REG1);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(1, ctx, "CSI2_%d_REG1 = 0x%08x\n", (ctx->csi2_port - 1), reg1);
drivers/media/platform/ti-vpe/cal.c:	reg_write(ctx->cc, CAL_CSI2_PHY_REG1, reg1);
drivers/media/platform/ti-vpe/cal.c:	if (!ctx->sensor)
drivers/media/platform/ti-vpe/cal.c:	ctrl = v4l2_ctrl_find(ctx->sensor->ctrl_handler, V4L2_CID_PIXEL_RATE);
drivers/media/platform/ti-vpe/cal.c:			ctx->sensor->name);
drivers/media/platform/ti-vpe/cal.c:	ctx->external_rate = v4l2_ctrl_g_ctrl_int64(ctrl);
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "sensor Pixel Rate: %d\n", ctx->external_rate);
drivers/media/platform/ti-vpe/cal.c:	struct cal_dmaqueue *dma_q = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:	ctx->next_frm = buf;
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm->vb.vb2_buf.timestamp = ktime_get_ns();
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm->vb.field = ctx->m_fmt.field;
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm->vb.sequence = ctx->sequence++;
drivers/media/platform/ti-vpe/cal.c:	vb2_buffer_done(&ctx->cur_frm->vb.vb2_buf, VB2_BUF_STATE_DONE);
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm = ctx->next_frm;
drivers/media/platform/ti-vpe/cal.c:			if (ctx->cur_frm != ctx->next_frm)
drivers/media/platform/ti-vpe/cal.c:			if (ctx->cur_frm != ctx->next_frm)
drivers/media/platform/ti-vpe/cal.c:			dma_q = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:			spin_lock(&ctx->slock);
drivers/media/platform/ti-vpe/cal.c:			    ctx->cur_frm == ctx->next_frm)
drivers/media/platform/ti-vpe/cal.c:			spin_unlock(&ctx->slock);
drivers/media/platform/ti-vpe/cal.c:			dma_q = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:			spin_lock(&ctx->slock);
drivers/media/platform/ti-vpe/cal.c:			    ctx->cur_frm == ctx->next_frm)
drivers/media/platform/ti-vpe/cal.c:			spin_unlock(&ctx->slock);
drivers/media/platform/ti-vpe/cal.c:		 "platform:%s", ctx->v4l2_dev.name);
drivers/media/platform/ti-vpe/cal.c:	if (f->index >= ctx->num_active_fmt)
drivers/media/platform/ti-vpe/cal.c:	fmt = ctx->active_fmt[f->index];
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_subdev_call(ctx->sensor, pad, get_fmt, NULL, &sd_fmt);
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_subdev_call(ctx->sensor, pad, set_fmt, NULL, &sd_fmt);
drivers/media/platform/ti-vpe/cal.c:	*f = ctx->v_fmt;
drivers/media/platform/ti-vpe/cal.c:		fmt = ctx->active_fmt[0];
drivers/media/platform/ti-vpe/cal.c:	f->fmt.pix.field = ctx->v_fmt.fmt.pix.field;
drivers/media/platform/ti-vpe/cal.c:		ret = v4l2_subdev_call(ctx->sensor, pad, enum_frame_size,
drivers/media/platform/ti-vpe/cal.c:		f->fmt.pix.width = ctx->v_fmt.fmt.pix.width;
drivers/media/platform/ti-vpe/cal.c:		f->fmt.pix.height =  ctx->v_fmt.fmt.pix.height;
drivers/media/platform/ti-vpe/cal.c:	f->fmt.pix.colorspace = ctx->v_fmt.fmt.pix.colorspace;
drivers/media/platform/ti-vpe/cal.c:	struct vb2_queue *q = &ctx->vb_vidq;
drivers/media/platform/ti-vpe/cal.c:	v4l2_fill_pix_format(&ctx->v_fmt.fmt.pix, &mbus_fmt);
drivers/media/platform/ti-vpe/cal.c:	ctx->v_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
drivers/media/platform/ti-vpe/cal.c:	ctx->v_fmt.fmt.pix.pixelformat  = fmt->fourcc;
drivers/media/platform/ti-vpe/cal.c:	cal_calc_format_size(ctx, fmt, &ctx->v_fmt);
drivers/media/platform/ti-vpe/cal.c:	ctx->fmt = fmt;
drivers/media/platform/ti-vpe/cal.c:	ctx->m_fmt = mbus_fmt;
drivers/media/platform/ti-vpe/cal.c:	*f = ctx->v_fmt;
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_subdev_call(ctx->sensor, pad, enum_frame_size, NULL, &fse);
drivers/media/platform/ti-vpe/cal.c:	*i = ctx->input;
drivers/media/platform/ti-vpe/cal.c:	ctx->input = i;
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_subdev_call(ctx->sensor, pad, enum_frame_interval,
drivers/media/platform/ti-vpe/cal.c:	unsigned size = ctx->v_fmt.fmt.pix.sizeimage;
drivers/media/platform/ti-vpe/cal.c:	if (WARN_ON(!ctx->fmt))
drivers/media/platform/ti-vpe/cal.c:	size = ctx->v_fmt.fmt.pix.sizeimage;
drivers/media/platform/ti-vpe/cal.c:	struct cal_dmaqueue *vidq = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:	spin_lock_irqsave(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	spin_unlock_irqrestore(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	struct cal_dmaqueue *dma_q = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:	spin_lock_irqsave(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:		spin_unlock_irqrestore(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm = buf;
drivers/media/platform/ti-vpe/cal.c:	ctx->next_frm = buf;
drivers/media/platform/ti-vpe/cal.c:	spin_unlock_irqrestore(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	addr = vb2_dma_contig_plane_dma_addr(&ctx->cur_frm->vb.vb2_buf, 0);
drivers/media/platform/ti-vpe/cal.c:	ctx->sequence = 0;
drivers/media/platform/ti-vpe/cal.c:	cal_runtime_get(ctx->dev);
drivers/media/platform/ti-vpe/cal.c:	cal_wr_dma_config(ctx, ctx->v_fmt.fmt.pix.bytesperline);
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_subdev_call(ctx->sensor, video, s_stream, 1);
drivers/media/platform/ti-vpe/cal.c:		cal_runtime_put(ctx->dev);
drivers/media/platform/ti-vpe/cal.c:		cal_quickdump_regs(ctx->dev);
drivers/media/platform/ti-vpe/cal.c:	struct cal_dmaqueue *dma_q = &ctx->vidq;
drivers/media/platform/ti-vpe/cal.c:	if (v4l2_subdev_call(ctx->sensor, video, s_stream, 0))
drivers/media/platform/ti-vpe/cal.c:	spin_lock_irqsave(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	if (ctx->cur_frm == ctx->next_frm) {
drivers/media/platform/ti-vpe/cal.c:		vb2_buffer_done(&ctx->cur_frm->vb.vb2_buf, VB2_BUF_STATE_ERROR);
drivers/media/platform/ti-vpe/cal.c:		vb2_buffer_done(&ctx->cur_frm->vb.vb2_buf, VB2_BUF_STATE_ERROR);
drivers/media/platform/ti-vpe/cal.c:		vb2_buffer_done(&ctx->next_frm->vb.vb2_buf,
drivers/media/platform/ti-vpe/cal.c:	ctx->cur_frm = NULL;
drivers/media/platform/ti-vpe/cal.c:	ctx->next_frm = NULL;
drivers/media/platform/ti-vpe/cal.c:	spin_unlock_irqrestore(&ctx->slock, flags);
drivers/media/platform/ti-vpe/cal.c:	cal_runtime_put(ctx->dev);
drivers/media/platform/ti-vpe/cal.c:	if (ctx->sensor) {
drivers/media/platform/ti-vpe/cal.c:	ctx->sensor = subdev;
drivers/media/platform/ti-vpe/cal.c:	ctx->num_active_fmt = 0;
drivers/media/platform/ti-vpe/cal.c:				ctx->active_fmt[i] = fmt;
drivers/media/platform/ti-vpe/cal.c:				ctx->num_active_fmt = ++i;
drivers/media/platform/ti-vpe/cal.c:	v4l2_fill_pix_format(&ctx->v_fmt.fmt.pix, &mbus_fmt);
drivers/media/platform/ti-vpe/cal.c:	ctx->v_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
drivers/media/platform/ti-vpe/cal.c:	ctx->v_fmt.fmt.pix.pixelformat  = fmt->fourcc;
drivers/media/platform/ti-vpe/cal.c:	cal_calc_format_size(ctx, fmt, &ctx->v_fmt);
drivers/media/platform/ti-vpe/cal.c:	ctx->fmt = fmt;
drivers/media/platform/ti-vpe/cal.c:	ctx->m_fmt = mbus_fmt;
drivers/media/platform/ti-vpe/cal.c:	ctx->timeperframe = tpf_default;
drivers/media/platform/ti-vpe/cal.c:	ctx->external_rate = 192000000;
drivers/media/platform/ti-vpe/cal.c:	spin_lock_init(&ctx->slock);
drivers/media/platform/ti-vpe/cal.c:	mutex_init(&ctx->mutex);
drivers/media/platform/ti-vpe/cal.c:	q = &ctx->vb_vidq;
drivers/media/platform/ti-vpe/cal.c:	q->lock = &ctx->mutex;
drivers/media/platform/ti-vpe/cal.c:	q->dev = ctx->v4l2_dev.dev;
drivers/media/platform/ti-vpe/cal.c:	INIT_LIST_HEAD(&ctx->vidq.active);
drivers/media/platform/ti-vpe/cal.c:	vfd = &ctx->vdev;
drivers/media/platform/ti-vpe/cal.c:	vfd->v4l2_dev = &ctx->v4l2_dev;
drivers/media/platform/ti-vpe/cal.c:	vfd->lock = &ctx->mutex;
drivers/media/platform/ti-vpe/cal.c:	v4l2_info(&ctx->v4l2_dev, "V4L2 device registered as %s\n",
drivers/media/platform/ti-vpe/cal.c:	struct platform_device *pdev = ctx->dev->pdev;
drivers/media/platform/ti-vpe/cal.c:	asd = &ctx->asd;
drivers/media/platform/ti-vpe/cal.c:	endpoint = &ctx->endpoint;
drivers/media/platform/ti-vpe/cal.c:	ctx->virtual_channel = endpoint->base.id;
drivers/media/platform/ti-vpe/cal.c:	ctx_dbg(3, ctx, "Virtual Channel=%d\n", ctx->virtual_channel);
drivers/media/platform/ti-vpe/cal.c:	ctx->asd_list[0] = asd;
drivers/media/platform/ti-vpe/cal.c:	ctx->notifier.subdevs = ctx->asd_list;
drivers/media/platform/ti-vpe/cal.c:	ctx->notifier.num_subdevs = 1;
drivers/media/platform/ti-vpe/cal.c:	ctx->notifier.bound = cal_async_bound;
drivers/media/platform/ti-vpe/cal.c:	ctx->notifier.complete = cal_async_complete;
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_async_notifier_register(&ctx->v4l2_dev,
drivers/media/platform/ti-vpe/cal.c:					   &ctx->notifier);
drivers/media/platform/ti-vpe/cal.c:	ctx->dev = dev;
drivers/media/platform/ti-vpe/cal.c:	snprintf(ctx->v4l2_dev.name, sizeof(ctx->v4l2_dev.name),
drivers/media/platform/ti-vpe/cal.c:	ret = v4l2_device_register(&dev->pdev->dev, &ctx->v4l2_dev);
drivers/media/platform/ti-vpe/cal.c:	hdl = &ctx->ctrl_handler;
drivers/media/platform/ti-vpe/cal.c:	ctx->v4l2_dev.ctrl_handler = hdl;
drivers/media/platform/ti-vpe/cal.c:	ctx->cc = dev->cc[inst];
drivers/media/platform/ti-vpe/cal.c:	ctx->csi2_port = inst + 1;
drivers/media/platform/ti-vpe/cal.c:	v4l2_device_unregister(&ctx->v4l2_dev);
drivers/media/platform/ti-vpe/cal.c:				video_device_node_name(&ctx->vdev));
drivers/media/platform/ti-vpe/cal.c:			v4l2_async_notifier_unregister(&ctx->notifier);
drivers/media/platform/ti-vpe/cal.c:			v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/ti-vpe/cal.c:			v4l2_device_unregister(&ctx->v4l2_dev);
drivers/media/platform/ti-vpe/cal.c:			video_unregister_device(&ctx->vdev);
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:		ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:	ctx->base = ctx_base;
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:		ctx->req_base[i].req_priv = ctx;
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:		NULL, hw_intf, ctx->req_base, CAM_CTX_REQ_MAX);
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:	if (!ctx || !ctx->base) {
drivers/media/platform/msm/camera/cam_jpeg/cam_jpeg_context.c:	cam_context_deinit(ctx->base);
drivers/media/platform/msm/camera/cam_icp/icp_hw/icp_hw_mgr/cam_icp_hw_mgr.c:		if (ctx->state == CAM_ICP_CTX_STATE_ACQUIRED &&
drivers/media/platform/msm/camera/cam_icp/icp_hw/icp_hw_mgr/cam_icp_hw_mgr.c:			ctx->icp_dev_acquire_info->dev_type) ==
drivers/media/platform/msm/camera/cam_icp/icp_hw/icp_hw_mgr/cam_icp_hw_mgr.c:				ctx->clk_info.uncompressed_bw;
drivers/media/platform/msm/camera/cam_icp/icp_hw/icp_hw_mgr/cam_icp_hw_mgr.c:				ctx->clk_info.compressed_bw;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:		ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:		ctx->state = CAM_CTX_READY;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	if ((!ctx) || (!ctx->base) || (!hw_intf)) {
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	rc = cam_context_init(ctx->base, icp_dev_name, CAM_ICP, ctx_id,
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:		NULL, hw_intf, ctx->req_base, CAM_CTX_REQ_MAX);
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	ctx->base->state_machine = cam_icp_ctx_state_machine;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	ctx->base->ctx_priv = ctx;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	ctx->ctxt_to_hw_map = NULL;
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	if ((!ctx) || (!ctx->base)) {
drivers/media/platform/msm/camera/cam_icp/cam_icp_context.c:	cam_context_deinit(ctx->base);
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	uint64_t ctxt_to_hw_map = (uint64_t)ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	struct cam_lrme_context *lrme_ctx = ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctxt_to_hw_map |= (lrme_ctx->index << CAM_LRME_CTX_INDEX_SHIFT);
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->ctxt_to_hw_map = (void *)ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->state = CAM_CTX_ACTIVATED;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:		NULL, hw_intf, lrme_ctx->req_base, CAM_CTX_REQ_MAX);
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	lrme_ctx->base = base_ctx;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	lrme_ctx->index = index;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	base_ctx->ctx_priv = lrme_ctx;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	base_ctx->state_machine = cam_lrme_ctx_state_machine;
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_context.c:	rc = cam_context_deinit(lrme_ctx->base);
drivers/media/platform/msm/camera/cam_lrme/cam_lrme_dev.c:	rc = ctx->irq_cb_intf(ctx, evt_id, evt_data);
drivers/media/platform/msm/camera/cam_utils/cam_trace.h:		__entry->state = ctx->state;
drivers/media/platform/msm/camera/cam_utils/cam_trace.h:		__entry->state = ctx->state;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	ctx->state = CAM_CTX_ACTIVATED;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:		NULL, hw_intf, fd_ctx->req_base, CAM_CTX_REQ_MAX);
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	fd_ctx->base = base_ctx;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	base_ctx->ctx_priv = fd_ctx;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	base_ctx->state_machine = cam_fd_ctx_state_machine;
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	if (!fd_ctx || !fd_ctx->base) {
drivers/media/platform/msm/camera/cam_fd/cam_fd_context.c:	rc = cam_context_deinit(fd_ctx->base);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if ((hw_ctx->device_index < 0) ||
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		(hw_ctx->device_index >= CAM_FD_HW_MAX)) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		CAM_ERR(CAM_FD, "Invalid device indx %d", hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx_index=%u, hw_ctx=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	*hw_device = &hw_mgr->hw_device[hw_ctx->device_index];
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_release_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->device_index = -1;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->ctx_hw_private = hw_reserve_args.ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->device_index = i;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx index=%u, device_index=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		start_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		stop_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:			frame_req->hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (frame_req->hw_ctx->event_cb) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		rc = frame_req->hw_ctx->event_cb(frame_req->hw_ctx->cb_priv,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->ctx_in_use = true;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->hw_mgr = hw_mgr;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->get_raw_results = fd_acquire_args.get_raw_results;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->mode = fd_acquire_args.mode;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->cb_priv = acquire_args->context_data;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->event_cb = acquire_args->event_cb;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	list_del_init(&hw_ctx->list);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	hw_ctx->ctx_in_use = false;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	list_del_init(&hw_ctx->list);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx index=%u, device_index=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_init_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx index=%u, hw_ctx=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx index=%u, hw_ctx=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	CAM_DBG(CAM_FD, "ctx index=%u, hw_ctx=%d", hw_ctx->ctx_index,
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_ctx->device_index);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_deinit_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	prestart_args.ctx_hw_private = hw_ctx->ctx_hw_private;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (!hw_ctx || !hw_ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (hw_ctx->priority == CAM_FD_PRIORITY_HIGH) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:	if (hw_ctx->priority == CAM_FD_PRIORITY_HIGH) {
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		INIT_LIST_HEAD(&hw_mgr_ctx->list);
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_mgr_ctx->ctx_index = i;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_mgr_ctx->device_index = -1;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		hw_mgr_ctx->hw_mgr = &g_fd_hw_mgr;
drivers/media/platform/msm/camera/cam_fd/fd_hw_mgr/cam_fd_hw_mgr.c:		list_add_tail(&hw_mgr_ctx->list, &g_fd_hw_mgr.free_ctx_list);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				ctx->is_rdi_only_context;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_free_hw_res(&ife_ctx->res_list_ife_out[i]);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_put_res(&ife_ctx->free_res_list, &hw_mgr_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_put_res(&ife_ctx->free_res_list, &hw_mgr_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_ctx->res_list_ife_cid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_put_res(&ife_ctx->free_res_list, &hw_mgr_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (ife_ctx->res_list_ife_in.res_type != CAM_IFE_HW_MGR_RES_UNINIT)
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_free_hw_res(&ife_ctx->res_list_ife_in);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->common.cb_priv = NULL;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	memset(ife_ctx->common.event_cb, 0, sizeof(ife_ctx->common.event_cb));
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx->num_base) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->base[0].split_id = split_id;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->base[0].idx      = base_idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->num_base++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			split_id, base_idx, ctx->num_base);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (ctx->base[i].idx == base_idx) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ctx->base[i].split_id ==
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ctx->base[i].split_id = split_id;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[ctx->num_base].split_id = split_id;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[ctx->num_base].idx      = base_idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->num_base++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				 split_id, base_idx, ctx->num_base);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (list_empty(&ctx->res_list_ife_src)) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "ctx base num = %d", ctx->num_base);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	vfe_acquire.tasklet = ife_ctx->common.tasklet_info;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_out_res = &ife_ctx->res_list_ife_out[vfe_out_res_id & 0xFF];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.vfe_out.cdm_ops = ife_ctx->cdm_ops;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.vfe_out.unique_id = ife_ctx->ctx_index;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_out_res = &ife_ctx->res_list_ife_out[k];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.tasklet = ife_ctx->common.tasklet_info;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.vfe_out.cdm_ops = ife_ctx->cdm_ops;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.vfe_out.unique_id     = ife_ctx->ctx_index;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(ife_src_res, &ife_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hw_mgr = ife_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(csid_res, &ife_ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_ife_hw_mgr_get_res(&ife_ctx->free_res_list,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_put_res(&ife_ctx->res_list_ife_src,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.tasklet = ife_ctx->common.tasklet_info;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		vfe_acquire.vfe_in.cdm_ops = ife_ctx->cdm_ops;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hw_mgr = ife_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	rc = cam_ife_hw_mgr_get_res(&ife_ctx->free_res_list, &cid_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_hw_mgr_put_res(&ife_ctx->res_list_ife_cid, &cid_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cid_res->parent = &ife_ctx->res_list_ife_in;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->res_list_ife_in.child[
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->res_list_ife_in.num_children++] = cid_res;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hw_mgr = ife_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	rc = cam_ife_hw_mgr_get_res(&ife_ctx->free_res_list, &csid_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_hw_mgr_put_res(&ife_ctx->res_list_ife_csid, &csid_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(cid_res, &ife_ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hw_mgr = ife_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_ife_hw_mgr_get_res(&ife_ctx->free_res_list,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_put_res(&ife_ctx->res_list_ife_csid, &csid_res);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		list_for_each_entry(cid_res, &ife_ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (ife_ctx->res_list_ife_in.res_type == CAM_IFE_HW_MGR_RES_UNINIT) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->res_list_ife_in.res_type = CAM_IFE_HW_MGR_RES_ROOT;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->res_list_ife_in.res_id = in_port->res_type;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->res_list_ife_in.is_dual_vfe = in_port->usage_type;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	} else if (ife_ctx->res_list_ife_in.res_id != in_port->res_type) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hw_mgr = ife_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		complete(&ctx->config_done_complete);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->common.cb_priv = acquire_args->context_data;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->common.event_cb[i] = acquire_args->event_cb;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->hw_mgr = ife_hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->cdm_handle = cdm_acquire.handle;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->cdm_ops = cdm_acquire.ops;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_ctx->is_rdi_only_context = 1;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_ctx->ctx_in_use = 1;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_cdm_release(ife_ctx->cdm_handle);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx->ctx_in_use || !ctx->cdm_cmd) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (atomic_read(&ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index, cfg->num_hw_update_entries);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cdm_cmd = ctx->cdm_cmd;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			init_completion(&ctx->config_done_complete);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_cdm_submit_bls(ctx->cdm_handle, cdm_cmd);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			init_completion(&ctx->config_done_complete);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				&ctx->config_done_complete,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx->num_base) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (ctx->base[i].split_id == CAM_ISP_HW_SPLIT_LEFT) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			master_base_idx = ctx->base[i].idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (i == ctx->num_base)
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		master_base_idx = ctx->base[0].idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, CAM_CSID_HALT_IMMEDIATELY);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_csid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_csid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, CAM_CSID_HALT_IMMEDIATELY);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_stop_hw_res(&ctx->res_list_ife_out[i]);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_tasklet_stop(ctx->common.tasklet_info);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "Enter...ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, " Enter...ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx->num_base) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (cam_cdm_stream_off(ctx->cdm_handle))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->cdm_handle);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_stop_hw_res(&ctx->res_list_ife_out[i]);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (ctx->base[i].split_id == CAM_ISP_HW_SPLIT_LEFT) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			master_base_idx = ctx->base[i].idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_tasklet_stop(ctx->common.tasklet_info);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (i == ctx->num_base)
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		master_base_idx = ctx->base[0].idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_cid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, csid_halt_type);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_csid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_mgr_csid_stop_hw(ctx, &ctx->res_list_ife_csid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, csid_halt_type);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_cid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		cam_ife_hw_mgr_deinit_hw_res(&ctx->res_list_ife_out[i]);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "Exit...ctx id:%d rc :%d", ctx->ctx_index, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "START IFE OUT ... in ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_tasklet_start(ctx->common.tasklet_info);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			&ctx->res_list_ife_out[i], ctx);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "START IFE SRC ... in ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "START CSID HW ... in ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	CAM_DBG(CAM_ISP, "START CID SRC ... in ctx id:%d", ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_tasklet_start(ctx->common.tasklet_info);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_cid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_ife_hw_mgr_init_hw_res(&ctx->res_list_ife_out[i]);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				 ctx->res_list_ife_out[i].res_id);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	rc = cam_cdm_stream_on(ctx->cdm_handle);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			 ctx->cdm_handle);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			&ctx->res_list_ife_out[i], ctx);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_cid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ctx->num_base = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	memset(ctx->base, 0, sizeof(ctx->base));
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	cam_cdm_release(ctx->cdm_handle);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_del_init(&ctx->list);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ctx->ctx_in_use = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ctx->is_rdi_only_context = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ctx->cdm_handle = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ctx->cdm_ops = NULL;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	atomic_set(&ctx->overflow_pending, 0);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->sof_cnt[i] = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->eof_cnt[i] = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->epoch_cnt[i] = 0;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ctx->ctx_index);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		hw_mgr_res = &ctx->res_list_ife_out[res_id_out];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_isp_add_change_base(prepare, &ctx->res_list_ife_src,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, &kmd_buf);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				i, ctx->base[i].idx, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (ctx->base[i].split_id != CAM_ISP_HW_SPLIT_MAX) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				&ctx->base[i],
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				ctx->res_list_ife_out, CAM_IFE_HW_OUT_RES_MAX);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					i, ctx->base[i].split_id, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			prepare, ctx->base[i].idx,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			&kmd_buf, ctx->res_list_ife_out,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	for (i = 0; i < ctx->num_base; i++) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_isp_add_change_base(prepare, &ctx->res_list_ife_src,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, &kmd_buf);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				i, ctx->base[i].idx, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		rc = cam_isp_add_reg_update(prepare, &ctx->res_list_ife_src,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx->base[i].idx, &kmd_buf);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				i, ctx->base[i].idx, rc);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (!ctx || !ctx->ctx_in_use) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (ctx->is_rdi_only_context)
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	list_for_each_entry(hw_mgr_res, &ife_ctx->res_list_ife_csid, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			list_for_each_entry(hw_mgr_res, &ctx->res_list_ife_csid,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			atomic_set(&ctx->overflow_pending, 0);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	uint32_t max_idx =  ife_hwr_mgr_ctx->num_base;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (affected_core[ife_hwr_mgr_ctx->base[i].idx])
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			ctx_affected_core_idx[j] = ife_hwr_mgr_ctx->base[i].idx;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	ife_hwr_mgr = curr_ife_hwr_mgr_ctx->hw_mgr;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		atomic_set(&ife_hwr_mgr_ctx->overflow_pending, 1);
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_ERROR];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_irq_err_cb(ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_hwr_mgr_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:	if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_REG_UPDATE];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			&ife_hwr_mgr_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (!ife_hwr_mgr_ctx->is_rdi_only_context)
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		event_cnt = ife_hw_mgr_ctx->sof_cnt;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		event_cnt = ife_hw_mgr_ctx->epoch_cnt;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		event_cnt = ife_hw_mgr_ctx->eof_cnt;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_EPOCH];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_hwr_mgr_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:						ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->epoch_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->epoch_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				ife_hwr_mgr_ctx->sof_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:				ife_hwr_mgr_ctx->sof_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hw_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_SOF];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_hw_mgr_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (ife_hw_mgr_ctx->is_rdi_only_context) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:						ife_hw_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hw_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_EOF];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		&ife_hwr_mgr_ctx->res_list_ife_src, list) {
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:						ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->eof_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->eof_cnt[core_idx]++;
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		ife_hwr_mgr_ctx->common.event_cb[CAM_ISP_HW_EVENT_DONE];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:		isp_ife_out_res = &ife_hwr_mgr_ctx->res_list_ife_out[i];
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:			if (atomic_read(&ife_hwr_mgr_ctx->overflow_pending))
drivers/media/platform/msm/camera/cam_isp/isp_hw_mgr/cam_ife_hw_mgr.c:					ife_hwr_mgr_ctx->common.cb_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			req_current, req_prev, &ctx->pending_req_list, list) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:					&ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req_old = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->active_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_trigger &&
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			ctx->ctx_crm_intf->notify_trigger(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_for_each_entry(req, &ctx->active_req_list, list) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_trigger) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_trigger(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->state != CAM_CTX_ACTIVATED) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->pending_req_list, struct cam_ctx_request,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (req_isp->bubble_report && ctx->ctx_crm_intf &&
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->active_req_list))
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->pending_req_list, struct cam_ctx_request,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (req_isp->bubble_report && ctx->ctx_crm_intf &&
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			&ctx->active_req_list, list) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:				list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			&ctx->active_req_list, list) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_err) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx_isp = (struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->pending_req_list, struct cam_ctx_request,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		if (!list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			active_req = list_first_entry(&ctx->active_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_config(ctx->hw_mgr_intf->hw_mgr_priv, &cfg);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = __cam_isp_ctx_flush_req(ctx, &ctx->pending_req_list, flush_req);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		 ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx_isp = (struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	CAM_DBG(CAM_ISP, "Flush request in state %d", ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = __cam_isp_ctx_flush_req(ctx, &ctx->pending_req_list, flush_req);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = __cam_isp_ctx_flush_req(ctx, &ctx->pending_req_list, flush_req);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list))
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		 ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_trigger &&
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_trigger(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->active_req_list))
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req = list_first_entry(&ctx->pending_req_list, struct cam_ctx_request,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (req_isp->bubble_report && ctx->ctx_crm_intf &&
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_err(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	while (!list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->active_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_trigger) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_trigger(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->ctx_crm_intf && ctx->ctx_crm_intf->notify_trigger) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		notify.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->ctx_crm_intf->notify_trigger(&notify);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->hw_mgr_intf->hw_release(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->session_hdl = -1;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->dev_hdl = -1;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->link_hdl = -1;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->ctx_crm_intf = NULL;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!list_empty(&ctx->active_req_list))
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	flush_req.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	flush_req.dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = __cam_isp_ctx_flush_req(ctx, &ctx->pending_req_list, &flush_req);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	CAM_DBG(CAM_ISP, "next state %d", ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!list_empty(&ctx->free_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->free_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_prepare_update(
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->hw_mgr_intf->hw_mgr_priv, &cfg);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		if (ctx->state < CAM_CTX_ACTIVATED) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		if (ctx->state >= CAM_CTX_READY && ctx->ctx_crm_intf->add_req) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			add_req.link_hdl = ctx->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			add_req.dev_hdl  = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:			rc = ctx->ctx_crm_intf->add_req(&add_req);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	param.event_cb = ctx->irq_cb_intf;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_acquire(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_cmd(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	req_hdl_param.ops = ctx->crm_ctx_intf;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->dev_hdl = cam_create_device_hdl(&req_hdl_param);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->dev_hdl <= 0) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	cmd->dev_handle = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->session_hdl = cmd->session_handle;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->hw_mgr_intf->hw_release(ctx->hw_mgr_intf->hw_mgr_priv, &release);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!rc && (ctx->link_hdl >= 0)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->state = CAM_CTX_READY;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	CAM_DBG(CAM_ISP, "next state %d", ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->link_hdl = link->link_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->ctx_crm_intf = link->crm_cb;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (!list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->state = CAM_CTX_READY;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	CAM_DBG(CAM_ISP, "next state %d", ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->link_hdl = -1;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->ctx_crm_intf = NULL;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	dev_info->dev_hdl = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (cmd->session_handle != ctx->session_hdl ||
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		cmd->dev_handle != ctx->dev_hdl) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->state = CAM_CTX_ACTIVATED;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_start(ctx->hw_mgr_intf->hw_mgr_priv, &arg);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->state = CAM_CTX_READY;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->link_hdl = -1;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->ctx_crm_intf = NULL;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->hw_mgr_intf->hw_stop(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	while (!list_empty(&ctx->pending_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->pending_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	while (!list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		req = list_first_entry(&ctx->active_req_list,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	CAM_DBG(CAM_ISP, "next state %d", ctx->state);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->state = CAM_CTX_ACQUIRED;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_cmd(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	rc = ctx->hw_mgr_intf->hw_cmd(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *) ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		(struct cam_isp_context *)ctx->ctx_priv;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_lock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		 ctx->state, ctx_isp->substate_activated, evt_id);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		 ctx->state, ctx_isp->substate_activated);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	spin_unlock_bh(&ctx->lock);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->base = ctx_base;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->frame_id = 0;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->active_req_cnt = 0;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->reported_req_id = 0;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->hw_ctx = NULL;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->substate_activated = CAM_ISP_CTX_ACTIVATED_SOF;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->substate_machine = cam_isp_ctx_activated_state_machine;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	ctx->substate_machine_irq = cam_isp_ctx_activated_state_machine_irq;
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->req_base[i].req_priv = &ctx->req_isp[i];
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		ctx->req_isp[i].base = &ctx->req_base[i];
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		crm_node_intf, hw_intf, ctx->req_base, CAM_CTX_REQ_MAX);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->base)
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:		cam_context_deinit(ctx->base);
drivers/media/platform/msm/camera/cam_isp/cam_isp_context.c:	if (ctx->substate_activated != CAM_ISP_CTX_ACTIVATED_SOF)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (list_empty(&ctx->active_req_list)) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	req = list_first_entry(&ctx->active_req_list,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_add_tail(&req->list, &ctx->active_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	cfg.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	rc = ctx->hw_mgr_intf->hw_config(ctx->hw_mgr_intf->hw_mgr_priv, &cfg);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		mutex_lock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			mutex_unlock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			mutex_unlock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:					ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if ((!ctx->hw_mgr_intf) || (!ctx->hw_mgr_intf->hw_release)) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	arg.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->hw_mgr_intf->hw_release(ctx->hw_mgr_intf->hw_mgr_priv, &arg);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->ctxt_to_hw_map = NULL;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->session_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->dev_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->link_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!list_empty(&ctx->free_req_list)) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		req = list_first_entry(&ctx->free_req_list,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	cfg.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	rc = ctx->hw_mgr_intf->hw_prepare_update(
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		ctx->hw_mgr_intf->hw_mgr_priv, &cfg);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		list_add_tail(&req->list, &ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:					ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:						ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	param.event_cb = ctx->irq_cb_intf;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	rc = ctx->hw_mgr_intf->hw_acquire(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->ctxt_to_hw_map = param.ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	req_hdl_param.ops = ctx->crm_ctx_intf;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->dev_hdl = cam_create_device_hdl(&req_hdl_param);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (ctx->dev_hdl <= 0) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	cmd->dev_handle = ctx->dev_hdl;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->session_hdl = cmd->session_handle;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	release.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->hw_mgr_intf->hw_release(ctx->hw_mgr_intf->hw_mgr_priv, &release);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	ctx->ctxt_to_hw_map = NULL;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	CAM_DBG(CAM_CTXT, "[%s] E: NRT flush ctx", ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	mutex_lock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_splice_init(&ctx->pending_req_list, &temp_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	mutex_unlock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (ctx->hw_mgr_intf->hw_flush) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		list_for_each_entry(req, &ctx->active_req_list, list) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			flush_args.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->hw_mgr_intf->hw_flush(
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->hw_mgr_intf->hw_mgr_priv, &flush_args);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_splice_init(&ctx->active_req_list, &temp_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	INIT_LIST_HEAD(&ctx->active_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:						req->ctx->dev_name,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:						req->ctx->dev_hdl,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:						req->ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	CAM_DBG(CAM_CTXT, "[%s] X: NRT flush ctx", ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	CAM_DBG(CAM_CTXT, "[%s] E: NRT flush req", ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	mutex_lock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	list_for_each_entry(req, &ctx->pending_req_list, list) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id, req->request_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	mutex_unlock(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (ctx->hw_mgr_intf->hw_flush) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			list_for_each_entry(req, &ctx->active_req_list, list) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			flush_args.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->hw_mgr_intf->hw_flush(
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->hw_mgr_intf->hw_mgr_priv, &flush_args);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				spin_lock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				list_add_tail(&req->list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				spin_unlock(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				if (cam_debug_ctx_req_list & ctx->dev_id)
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:						ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	CAM_DBG(CAM_CTXT, "[%s] X: NRT flush req", ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id, cmd->flush_type);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if ((cmd->session_handle != ctx->session_hdl) ||
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		(cmd->dev_handle != ctx->dev_hdl)) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (ctx->hw_mgr_intf->hw_start) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		arg.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		rc = ctx->hw_mgr_intf->hw_start(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:				ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (!ctx->hw_mgr_intf) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:			ctx->dev_name, ctx->ctx_id);
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:	if (ctx->hw_mgr_intf->hw_stop) {
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		stop.ctxt_to_hw_map = ctx->ctxt_to_hw_map;
drivers/media/platform/msm/camera/cam_core/cam_context_utils.c:		ctx->hw_mgr_intf->hw_stop(ctx->hw_mgr_intf->hw_mgr_priv,
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx || !ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].irq_ops)
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].irq_ops(ctx, evt_id,
drivers/media/platform/msm/camera/cam_core/cam_context.c:			evt_id, ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.stop_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.stop_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.release_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.release_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.get_dev_info) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.get_dev_info(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.link) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.link(ctx, link);
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.unlink) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.unlink(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->dev_name, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.apply_req) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.apply_req(ctx,
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.flush_req) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.flush_req(ctx,
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].crm_ops.process_evt) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].crm_ops.process_evt(ctx,
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.acquire_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.acquire_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			cmd->dev_handle, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->active_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->wait_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	for (i = 0; i < ctx->req_size; i++) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		INIT_LIST_HEAD(&ctx->req_list[i].list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:		list_add_tail(&ctx->req_list[i].list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.release_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.release_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.flush_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.flush_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.config_dev) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.config_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.start_dev)
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.start_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (!ctx->state_machine) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_lock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state_machine[ctx->state].ioctl_ops.stop_dev)
drivers/media/platform/msm/camera/cam_core/cam_context.c:		rc = ctx->state_machine[ctx->state].ioctl_ops.stop_dev(
drivers/media/platform/msm/camera/cam_core/cam_context.c:			ctx->dev_hdl, ctx->dev_name, ctx->state);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_unlock(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->dev_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->link_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->session_hdl = -1;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_init(&ctx->ctx_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	mutex_init(&ctx->sync_mutex);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	spin_lock_init(&ctx->lock);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->dev_name = dev_name;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->dev_id = dev_id;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->ctx_id = ctx_id;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->ctx_crm_intf = NULL;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->crm_ctx_intf = crm_node_intf;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->hw_mgr_intf = hw_mgr_intf;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->irq_cb_intf = cam_context_handle_hw_event;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->active_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->wait_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->pending_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	INIT_LIST_HEAD(&ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->req_list = req_list;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->req_size = req_size;
drivers/media/platform/msm/camera/cam_core/cam_context.c:		INIT_LIST_HEAD(&ctx->req_list[i].list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:		list_add_tail(&ctx->req_list[i].list, &ctx->free_req_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:		ctx->req_list[i].ctx = ctx;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->state = CAM_CTX_AVAILABLE;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->state_machine = NULL;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	ctx->ctx_priv = NULL;
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (ctx->state != CAM_CTX_AVAILABLE)
drivers/media/platform/msm/camera/cam_core/cam_context.c:	kref_put(&ctx->refcount, cam_node_put_ctxt_to_free_list);
drivers/media/platform/msm/camera/cam_core/cam_context.c:		ctx->dev_hdl, atomic_read(&(ctx->refcount.refcount)),
drivers/media/platform/msm/camera/cam_core/cam_context.c:		ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_context.c:	if (kref_get_unless_zero(&ctx->refcount) == 0) {
drivers/media/platform/msm/camera/cam_core/cam_context.c:		ctx->dev_hdl, atomic_read(&(ctx->refcount.refcount)),
drivers/media/platform/msm/camera/cam_core/cam_context.c:		ctx->dev_name);
drivers/media/platform/msm/camera/cam_core/cam_node.c:		list_del_init(&ctx->list);
drivers/media/platform/msm/camera/cam_core/cam_node.c:		kref_init(&ctx->refcount);
drivers/media/platform/msm/camera/cam_core/cam_node.c:	struct cam_node *node = ctx->node;
drivers/media/platform/msm/camera/cam_core/cam_node.c:	list_add_tail(&ctx->list, &node->free_ctx_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->rotate == SDE_ROTATOR_DEGREE_270)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	else if (ctx->rotate == SDE_ROTATOR_DEGREE_180)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	else if (ctx->rotate == SDE_ROTATOR_DEGREE_90)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->hflip)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->vflip)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->secure)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->secure_camera)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->format_out.fmt.pix.field == V4L2_FIELD_INTERLACED &&
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_cap.fmt.pix.field == V4L2_FIELD_NONE)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->frame_rate = (ctx->timeperframe.numerator) ?
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->timeperframe.denominator
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					/ ctx->timeperframe.numerator :	0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->session_id = ctx->session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->input.width = ctx->crop_out.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->input.height = ctx->crop_out.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->input.format = ctx->format_out.fmt.pix.pixelformat;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->output.width = ctx->crop_cap.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->output.height = ctx->crop_cap.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	config->output.format = ctx->format_cap.fmt.pix.pixelformat;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->vbinfo_out)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		config->input.comp_ratio = ctx->vbinfo_out[0].comp_ratio;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->vbinfo_cap)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		config->output.comp_ratio = ctx->vbinfo_cap[0].comp_ratio;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "config s:%d out_cr:%u/%u cap_cr:%u/%u\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->session_id = ctx->session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->wb_idx = (ctx->fh.prio >= V4L2_PRIORITY_DEFAULT) ? 0 : 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->src_rect.x = ctx->crop_out.left;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->src_rect.y = ctx->crop_out.top;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->src_rect.w = ctx->crop_out.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->src_rect.h = ctx->crop_out.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->input.width = ctx->format_out.fmt.pix.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->input.height = ctx->format_out.fmt.pix.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->input.format = ctx->format_out.fmt.pix.pixelformat;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->input.planes[0].stride = ctx->format_out.fmt.pix.bytesperline;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->dst_rect.x = ctx->crop_cap.left;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->dst_rect.y = ctx->crop_cap.top;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->dst_rect.w = ctx->crop_cap.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->dst_rect.h = ctx->crop_cap.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->output.width = ctx->format_cap.fmt.pix.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->output.height = ctx->format_cap.fmt.pix.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->output.format = ctx->format_cap.fmt.pix.pixelformat;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item->output.planes[0].stride = ctx->format_cap.fmt.pix.bytesperline;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	req = sde_rotator_req_init(rot_dev->mgr, ctx->private, item, 1, 0);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = sde_rotator_validate_request(rot_dev->mgr, ctx->private, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sizes[0] = ctx->format_out.fmt.pix.sizeimage;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sizes[0] = ctx->format_cap.fmt.pix.sizeimage;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->nbuf_out = *num_buffers;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		kfree(ctx->vbinfo_out);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_out = kzalloc(sizeof(struct sde_rotator_vbinfo) *
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->nbuf_out, GFP_KERNEL);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (!ctx->vbinfo_out)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		for (i = 0; i < ctx->nbuf_out; i++) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_out[i].fd = -1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_out[i].comp_ratio.numer = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_out[i].comp_ratio.denom = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->nbuf_cap = *num_buffers;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		kfree(ctx->vbinfo_cap);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap = kzalloc(sizeof(struct sde_rotator_vbinfo) *
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->nbuf_cap, GFP_KERNEL);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (!ctx->vbinfo_cap)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		for (i = 0; i < ctx->nbuf_cap; i++) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_cap[i].fd = -1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_cap[i].comp_ratio.numer = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->vbinfo_cap[i].comp_ratio.denom = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		while ((buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx))) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		while ((buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx))) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, q->type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!list_empty(&ctx->pending_list)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, q->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				!list_empty(&ctx->pending_list));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->abort_pending = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, q->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			!list_empty(&ctx->pending_list));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->abort_pending = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = wait_event_timeout(ctx->wait_queue,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			list_empty(&ctx->pending_list),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, q->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				!list_empty(&ctx->pending_list));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEROT_EVTLOG(ctx->session_id, q->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				!list_empty(&ctx->pending_list),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sde_rotator_cancel_all_requests(rot_dev->mgr, ctx->private);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		list_for_each_safe(curr, next, &ctx->pending_list) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			spin_lock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			list_add_tail(&request->list, &ctx->retired_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			spin_unlock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_resync_timeline(ctx->work_queue.timeline);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		for (i = 0; i < ctx->nbuf_cap; i++) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					&ctx->vbinfo_cap[i];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:						ctx->session_id, q->type, i);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		for (i = 0; i < ctx->nbuf_out; i++) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					&ctx->vbinfo_out[i];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:						ctx->session_id, q->type, i);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	buf->secure = ctx->secure || ctx->secure_camera;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->secure_camera) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				buf->ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				buf->ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			buf->ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_s_ctx_ctrl(ctx, &ctx->hflip, ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_s_ctx_ctrl(ctx, &ctx->vflip, ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_s_ctx_ctrl(ctx, &ctx->rotate, ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_s_ctx_ctrl(ctx, &ctx->secure, ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_s_ctx_ctrl(ctx, &ctx->secure_camera, ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("rotate=%d\n", ctx->rotate);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("hflip=%d\n", ctx->hflip);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("vflip=%d\n", ctx->vflip);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("priority=%d\n", ctx->fh.prio);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("secure=%d\n", ctx->secure);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("timeperframe=%u %u\n", ctx->timeperframe.numerator,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->timeperframe.denominator);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("nbuf_out=%d\n", ctx->nbuf_out);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("nbuf_cap=%d\n", ctx->nbuf_cap);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->crop_out.left, ctx->crop_out.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->crop_out.width, ctx->crop_out.height);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->crop_cap.left, ctx->crop_cap.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->crop_cap.width, ctx->crop_cap.height);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_out.fmt.pix.pixelformat>>0)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_out.fmt.pix.pixelformat>>8)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_out.fmt.pix.pixelformat>>16)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_out.fmt.pix.pixelformat>>24)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_out.fmt.pix.width,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_out.fmt.pix.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_out.fmt.pix.bytesperline,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_out.fmt.pix.sizeimage);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_cap.fmt.pix.pixelformat>>0)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_cap.fmt.pix.pixelformat>>8)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_cap.fmt.pix.pixelformat>>16)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->format_cap.fmt.pix.pixelformat>>24)&0xff,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_cap.fmt.pix.width,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_cap.fmt.pix.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_cap.fmt.pix.bytesperline,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->format_cap.fmt.pix.sizeimage);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("abort_pending=%d\n", ctx->abort_pending);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SPRINT("command_pending=%d\n", !list_empty(&ctx->pending_list));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sde_rotator_get_timeline_commit_ts(ctx->work_queue.timeline));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sde_rotator_get_timeline_retire_ts(ctx->work_queue.timeline));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	src_vq->lock = &ctx->rot_dev->lock;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	src_vq->dev = ctx->rot_dev->dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	dst_vq->lock = &ctx->rot_dev->lock;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	src_vq->dev = ctx->rot_dev->dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->rot_dev = rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->file = file;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->session_id = rot_dev->session_id++;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "open %d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->timeperframe.numerator = 1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->timeperframe.denominator = SDE_ROTATOR_DEFAULT_FPS;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->hflip = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->vflip = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->rotate = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->secure = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->abort_pending = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_cap.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_cap.fmt.pix.pixelformat = SDE_PIX_FMT_Y_CBCR_H2V2;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_cap.fmt.pix.width = 640;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_cap.fmt.pix.height = 480;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.width = 640;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.height = 480;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_out.type = V4L2_BUF_TYPE_VIDEO_OUTPUT;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_out.fmt.pix.pixelformat = SDE_PIX_FMT_Y_CBCR_H2V2;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_out.fmt.pix.width = 640;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_out.fmt.pix.height = 480;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.width = 640;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.height = 480;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	init_waitqueue_head(&ctx->wait_queue);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	spin_lock_init(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	INIT_LIST_HEAD(&ctx->pending_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	INIT_LIST_HEAD(&ctx->retired_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	for (i = 0 ; i < ARRAY_SIZE(ctx->requests); i++) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		struct sde_rotator_request *request = &ctx->requests[i];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		list_add_tail(&request->list, &ctx->retired_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_init(&ctx->fh, video);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		file->private_data = &ctx->fh;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_add(&ctx->fh);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(rot_dev->m2m_dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (IS_ERR_OR_NULL(ctx->fh.m2m_ctx)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = kobject_init_and_add(&ctx->kobj, &sde_rotator_fs_ktype,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&rot_dev->dev->kobj, "session_%d", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = sysfs_create_group(&ctx->kobj, &sde_rotator_fs_attr_group);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kthread_init_worker(&ctx->work_queue.rot_kw);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->work_queue.rot_thread = kthread_run(kthread_worker_fn,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&ctx->work_queue.rot_kw, name);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (IS_ERR(ctx->work_queue.rot_thread)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail allocate kthread\n");
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->work_queue.rot_thread = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "kthread name=%s\n", name);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->work_queue.timeline = sde_rotator_create_timeline(name);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx->work_queue.timeline)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_DBG(ctx->rot_dev->dev, "timeline is not available\n");
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = sde_rotator_session_open(rot_dev->mgr, &ctx->private,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, &ctx->work_queue);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail open session\n");
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->fh.ctrl_handler = ctrl_handler;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEROT_EVTLOG(ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "SDE v4l2 rotator open success\n");
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ATRACE_BEGIN(ctx->kobj.name);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_destroy_timeline(ctx->work_queue.timeline);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kthread_flush_worker(&ctx->work_queue.rot_kw);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kthread_stop(ctx->work_queue.rot_thread);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sysfs_remove_group(&ctx->kobj, &sde_rotator_fs_attr_group);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kobject_put(&ctx->kobj);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_del(&ctx->fh);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_exit(&ctx->fh);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	u32 session_id = ctx->session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ATRACE_END(ctx->kobj.name);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_streamoff(file, ctx->fh.m2m_ctx,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_streamoff(file, ctx->fh.m2m_ctx,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	list_for_each_safe(curr, next, &ctx->pending_list) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_session_close(rot_dev->mgr, ctx->private, session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	list_for_each_safe(curr, next, &ctx->pending_list) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_destroy_timeline(ctx->work_queue.timeline);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kthread_flush_worker(&ctx->work_queue.rot_kw);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kthread_stop(ctx->work_queue.rot_thread);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sysfs_remove_group(&ctx->kobj, &sde_rotator_fs_attr_group);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kobject_put(&ctx->kobj);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_del(&ctx->fh);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_fh_exit(&ctx->fh);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kfree(ctx->vbinfo_out);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	kfree(ctx->vbinfo_cap);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->retired_sequence_id = request->sequence_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	wake_up(&ctx->wait_queue);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, ctx->retired_sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	spin_lock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	list_add_tail(&request->list, &ctx->retired_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	spin_unlock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	wake_up(&ctx->wait_queue);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, ctx->retired_sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	retire_delta = (s32) (ctx->retired_sequence_id - sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEROT_DBG("sequence:%u/%u\n", sequence_id, ctx->retired_sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->slice = llcc_slice_getd(rot_dev->dev, "rotator");
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (IS_ERR(ctx->slice)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		rc = PTR_ERR(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		rc = llcc_slice_activate(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				llcc_get_slice_id(ctx->slice),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				llcc_get_slice_size(ctx->slice));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEROT_EVTLOG(ctx->session_id, llcc_get_slice_id(ctx->slice),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			llcc_get_slice_size(ctx->slice),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	llcc_slice_putd(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->slice = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->slice) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			llcc_slice_deactivate(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		llcc_slice_putd(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->slice = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEROT_EVTLOG(ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = wait_event_timeout(ctx->wait_queue,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEROT_EVTLOG(ctx->session_id, SDE_ROT_EVTLOG_ERROR);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->private, request->req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEROT_ERR("timeout w/ retire s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEROT_EVTLOG(ctx->session_id, SDE_ROT_EVTLOG_ERROR);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_req_finish(rot_dev->mgr, ctx->private, request->req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->session_id, cmd->sequence_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEROT_EVTLOG(ctx->session_id, cmd->sequence_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		int scid = llcc_get_slice_id(ctx->slice);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		item.session_id = ctx->session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		item.sequence_id = ++(ctx->commit_sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		req = sde_rotator_req_init(rot_dev->mgr, ctx->private,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		rotcfg.session_id = ctx->session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->private, &rotcfg);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (memcmp(&rotcfg, &ctx->rotcfg, sizeof(rotcfg))) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->private, &rotcfg);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:						ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->rotcfg = rotcfg;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		request = list_first_entry_or_null(&ctx->retired_list,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEROT_ERR("no free request s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		spin_lock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		list_add_tail(&request->list, &ctx->pending_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		spin_unlock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		req->retire_kw = &ctx->work_queue.rot_kw;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, cmd->sequence_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				rot_dev->mgr, ctx->private, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		sde_rotator_queue_request(rot_dev->mgr, ctx->private, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->private, request->req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = v4l2_m2m_poll(file, ctx->fh.m2m_ctx, wait);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	*f = ctx->format_cap;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	*f = ctx->format_out;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_WARN(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEDEV_WARN(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_WARN(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEDEV_WARN(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.top = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.left = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.width = f->fmt.pix.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_cap.height = f->fmt.pix.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_cap = *f;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->session_id, f->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.top = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.left = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.width = f->fmt.pix.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->crop_out.height = f->fmt.pix.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->format_out = *f;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->session_id, f->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	return v4l2_m2m_reqbufs(file, ctx->fh.m2m_ctx, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&& (buf->index < ctx->nbuf_cap)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].fd = -1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].fence = sde_rotator_get_sync_fence(
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->work_queue.timeline, NULL,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				&ctx->vbinfo_cap[idx].fence_ts);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].qbuf_ts = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].dqbuf_ts = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_DBG(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->vbinfo_cap[idx].fence_ts,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->vbinfo_cap[idx].fence);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&& (buf->index < ctx->nbuf_out)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_out[idx].qbuf_ts = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_out[idx].dqbuf_ts = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = v4l2_m2m_qbuf(file, ctx->fh.m2m_ctx, buf);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail qbuf s:%d t:%d r:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf->type, ret);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = v4l2_m2m_dqbuf(file, ctx->fh.m2m_ctx, buf);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf->type, buf->index, ret);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&& (buf->index < ctx->nbuf_cap)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (ctx->vbinfo_cap[idx].fence) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEDEV_DBG(ctx->rot_dev->dev, "put fence s:%d i:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id, idx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			sde_rotator_put_sync_fence(ctx->vbinfo_cap[idx].fence);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].fence = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_cap[idx].fd = -1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (ctx->vbinfo_cap[idx].dqbuf_ts)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			*(ctx->vbinfo_cap[idx].dqbuf_ts) = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			&& (buf->index < ctx->nbuf_out)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_out[idx].fence = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->vbinfo_out[idx].fd = -1;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (ctx->vbinfo_out[idx].dqbuf_ts)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			*(ctx->vbinfo_out[idx].dqbuf_ts) = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_WARN(ctx->rot_dev->dev, "invalid dq s:%d t:%d i:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf->type, buf->index);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	return v4l2_m2m_querybuf(file, ctx->fh.m2m_ctx, buf);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "stream on s:%d t:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail to get vq on s:%d t:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ret = sde_rotator_session_config(rot_dev->mgr, ctx->private,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf_type, ret);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->rotcfg = config;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = v4l2_m2m_streamon(file, ctx->fh.m2m_ctx, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail stream on s:%d t:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(ctx->rot_dev->dev, "stream off s:%d t:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ret = v4l2_m2m_streamoff(file, ctx->fh.m2m_ctx, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "fail stream off s:%d t:%d\n",
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, buf_type);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		format = &ctx->format_out;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		crop = &ctx->crop_out;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		format = &ctx->format_cap;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		crop = &ctx->crop_cap;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		crop->c = ctx->crop_out;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		crop->c = ctx->crop_cap;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->format_out.fmt.pix.width - 1);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->format_out.fmt.pix.height - 1);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				(ctx->format_out.fmt.pix.width - rect.left));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				(ctx->format_out.fmt.pix.height - rect.top));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, crop->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.left = item.src_rect.x;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.top = item.src_rect.y;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.width = item.src_rect.w;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.height = item.src_rect.h;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->format_cap.fmt.pix.width - 1);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->format_cap.fmt.pix.height - 1);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				(ctx->format_cap.fmt.pix.width - rect.left));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				(ctx->format_cap.fmt.pix.height - rect.top));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, crop->type,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.left = item.dst_rect.x;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.top = item.dst_rect.y;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.width = item.dst_rect.w;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.height = item.dst_rect.h;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	a->parm.output.timeperframe = ctx->timeperframe;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	ctx->timeperframe = a->parm.output.timeperframe;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (fence->index >= ctx->nbuf_out)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, fence->index,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		vbinfo = &ctx->vbinfo_out[fence->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:						ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id, vbinfo->fd);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		if (fence->index >= ctx->nbuf_cap)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		vbinfo = &ctx->vbinfo_cap[fence->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:						ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, fence->index,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				comp_ratio->index < ctx->nbuf_out)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			vbinfo = &ctx->vbinfo_out[comp_ratio->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				comp_ratio->index < ctx->nbuf_cap)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			vbinfo = &ctx->vbinfo_cap[comp_ratio->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, comp_ratio->index,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				comp_ratio->index < ctx->nbuf_out)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			vbinfo = &ctx->vbinfo_out[comp_ratio->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				comp_ratio->index < ctx->nbuf_cap)
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			vbinfo = &ctx->vbinfo_cap[comp_ratio->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id, comp_ratio->index,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		SDEDEV_ERR(ctx->rot_dev->dev, "invalid ioctl32 type:%x\n", cmd);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_ERR(ctx->rot_dev->dev, "error handling ioctl32 cmd:%x\n", cmd);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx || !ctx->rot_dev) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(rot_dev->dev, "retire handler s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->abort_pending) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx->file) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_try_schedule(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_job_finish(rot_dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	struct sde_rotator_device *rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	vbinfo_out = &ctx->vbinfo_out[src_buf->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	vbinfo_cap = &ctx->vbinfo_cap[dst_buf->index];
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->session_id, vbinfo_cap->fence_ts,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.left, ctx->crop_out.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.width, ctx->crop_out.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.left, ctx->crop_cap.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.width, ctx->crop_cap.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->rotate, ctx->hflip, ctx->vflip, ctx->secure,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->session_id, vbinfo_cap->fence_ts,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->fh.prio,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		(ctx->rotate << 0) | (ctx->hflip << 8) |
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			(ctx->hflip << 9) | (ctx->secure << 10),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_out.fmt.pix.pixelformat,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_out.fmt.pix.width,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_out.fmt.pix.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.left, ctx->crop_out.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_out.width, ctx->crop_out.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_cap.fmt.pix.pixelformat,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_cap.fmt.pix.width,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->format_cap.fmt.pix.height,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.left, ctx->crop_cap.top,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		ctx->crop_cap.width, ctx->crop_cap.height);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id, vbinfo_cap->fence_ts, vbinfo_out->fd);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			SDEROT_EVTLOG(ctx->session_id, vbinfo_cap->fence_ts,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item.input.planes[0].stride = ctx->format_out.fmt.pix.bytesperline;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	item.output.planes[0].stride = ctx->format_cap.fmt.pix.bytesperline;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	req = sde_rotator_req_init(rot_dev->mgr, ctx->private, &item, 1, 0);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	req->retire_kw = &ctx->work_queue.rot_kw;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			rot_dev->mgr, ctx->private, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_queue_request(rot_dev->mgr, ctx->private, req);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx || !ctx->rot_dev) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(rot_dev->dev, "submit handler s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (ctx->abort_pending) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		v4l2_m2m_try_schedule(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx || !ctx->rot_dev) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(rot_dev->dev, "device run s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		request = list_first_entry_or_null(&ctx->pending_list,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			sde_rotator_req_finish(rot_dev->mgr, ctx->private,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			v4l2_m2m_job_finish(rot_dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			sde_rotator_req_finish(rot_dev->mgr, ctx->private,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		request = list_first_entry_or_null(&ctx->retired_list,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		spin_lock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		list_add_tail(&request->list, &ctx->pending_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		spin_unlock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	sde_rotator_resync_timeline(ctx->work_queue.timeline);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	v4l2_m2m_job_finish(rot_dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx || !ctx->rot_dev) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(rot_dev->dev, "job abort s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	v4l2_m2m_job_finish(rot_dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	if (!ctx || !ctx->rot_dev) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	rot_dev = ctx->rot_dev;
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	SDEDEV_DBG(rot_dev->dev, "job ready s:%d\n", ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	request = list_first_entry_or_null(&ctx->pending_list,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:	} else if (list_empty(&ctx->pending_list)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				v4l2_m2m_num_dst_bufs_ready(ctx->fh.m2m_ctx),
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				!list_empty(&ctx->pending_list));
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:		request = list_first_entry_or_null(&ctx->retired_list,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:					ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			spin_lock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			list_add_tail(&request->list, &ctx->pending_list);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			spin_unlock(&ctx->list_lock);
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:			kthread_queue_work(&ctx->work_queue.rot_kw,
drivers/media/platform/msm/sde/rotator/sde_rotator_dev.c:				ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	SDEROT_DBG("wb%d:%6.6x:%8.8x\n", ctx->wb_num, ctx->offset + reg, val);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	writel_relaxed(val, ctx->base + reg);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	SDEROT_DBG("wb_num=%d addr=0x%pa\n", ctx->wb_num, &data.p[0].addr);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ret = sde_mdp_data_check(&data, &ctx->dst_planes, ctx->dst_fmt);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	sde_rot_data_calc_offset(&data, ctx->dst_rect.x, ctx->dst_rect.y,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:			&ctx->dst_planes, ctx->dst_fmt);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if ((ctx->dst_fmt->fetch_planes == SDE_MDP_PLANE_PLANAR) &&
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:			(ctx->dst_fmt->element[0] == C1_B_Cb))
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	u32 opmode = ctx->opmode;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	SDEROT_DBG("wb_num=%d format=%d\n", ctx->wb_num, format);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->rot90)
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	sde_mdp_get_plane_sizes(fmt, ctx->img_width, ctx->img_height,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:				 &ctx->dst_planes,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:				 ctx->opmode & SDE_MDP_OP_BWC_EN, rotation);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->dst_fmt = fmt;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ystride0 = (ctx->dst_planes.ystride[0]) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		   (ctx->dst_planes.ystride[1] << 16);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ystride1 = (ctx->dst_planes.ystride[2]) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		   (ctx->dst_planes.ystride[3] << 16);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	outsize = (ctx->dst_rect.h << 16) | ctx->dst_rect.w;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->type == SDE_MDP_WRITEBACK_TYPE_ROTATOR) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		dnsc_factor = (ctx->dnsc_factor_h) | (ctx->dnsc_factor_w << 16);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	SDEROT_DBG("rot setup wb_num=%d\n", ctx->wb_num);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->opmode = BIT(6); /* ROT EN */
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->opmode |= BIT(4); /* block size 128 */
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->bwc_mode = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->opmode |= ctx->bwc_mode;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->img_width = item->output.width;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->img_height = item->output.height;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->width = ctx->dst_rect.w = item->dst_rect.w;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->height = ctx->dst_rect.h = item->dst_rect.h;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->dst_rect.x = item->dst_rect.x;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->dst_rect.y = item->dst_rect.y;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->dnsc_factor_w = entry->dnsc_factor_w;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->dnsc_factor_h = entry->dnsc_factor_h;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->rot90 = !!(item->flags & SDE_ROTATION_90);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->rot90)
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->opmode |= BIT(5); /* ROT 90 */
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		sde_mdp_set_intr_callback(ctx->intr_type, ctx->intf_num,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		complete_all(&ctx->wb_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->ref_cnt--;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	SDEROT_DBG("intr wb_num=%d\n", ctx->wb_num);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	complete_all(&ctx->wb_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->comp_cnt == 0)
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		rc = wait_for_completion_timeout(&ctx->wb_comp,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		sde_mdp_set_intr_callback(ctx->intr_type, ctx->intf_num,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:			mask = BIT(ctx->intr_type + ctx->intf_num);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->end_time = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->comp_cnt--;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		rot_time = (u64)ktime_to_us(ctx->end_time) -
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:				(u64)ktime_to_us(ctx->start_time);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:			ctx->wb_num, ctx->type, ctx->xin_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:				ctx->intf_num, rot_time);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:			(rc)?"Timeout":"Done", rot_time, ctx->comp_cnt);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.xin_id = ctx->xin_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.num = ctx->wb_num;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.width = ctx->width;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.height = ctx->height;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.reg_off_mdp_clk_ctrl = ctx->clk_ctrl.reg_off;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.bit_off_mdp_clk_ctrl = ctx->clk_ctrl.bit_off;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ot_params.fmt = (ctx->dst_fmt) ? ctx->dst_fmt->format : 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->comp_cnt) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	sde_mdp_set_intr_callback(ctx->intr_type, ctx->intf_num,
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	reinit_completion(&ctx->wb_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->start_time = ktime_get();
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->wb_num, ctx->type, ctx->xin_id, ctx->intf_num);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->comp_cnt++;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		if (ctx->ref_cnt) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:		ctx->ref_cnt++;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->wb_num = wb->num;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->base = wb->base;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	ctx->offset = wb->offset;
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	init_completion(&ctx->wb_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r1_wb.c:	if (ctx->type == SDE_MDP_WRITEBACK_TYPE_ROTATOR)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	if (ctx->rot->mode == ROT_REGDMA_OFF)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:		return ctx->timestamp & SDE_HW_ROT_REGDMA_SEG_MASK;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:			ctx->regdma_base);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	return ctx->regdma_base;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	char __iomem *addr = ctx->regdma_wrptr;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	ctx->regdma_wrptr = wrptr;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	rot->rotCtx[ctx->q_id][idx] = ctx;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	if (ctx->sbuf_mode)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:		list_add_tail(&ctx->list, &rot->sbuf_ctx[ctx->q_id]);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:			 ctx->q_id, idx, ctx, ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	rot->rotCtx[ctx->q_id][idx] = NULL;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:	if (ctx->sbuf_mode)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:		list_del_init(&ctx->list);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3_internal.h:			 ctx->q_id, idx, ctx->session_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->last_regdma_timestamp == SDE_REGDMA_SWTS_INVALID)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		swts = ctx->last_regdma_timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->q_id == ROT_QUEUE_LOW_PRIORITY)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ts_diff = sde_hw_rotator_elapsed_swts(ctx->timestamp, swts);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->timestamp, ctx->q_id, swts, pending);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(ctx->timestamp, swts, ctx->q_id, ts_diff);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->q_id == ROT_QUEUE_LOW_PRIORITY) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->q_id >= ROT_QUEUE_MAX) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		SDEROT_ERR("context q_id out of range: %d\n", ctx->q_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	last_ts[ctx->q_id] = ctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	sde_hw_rotator_update_swts(rot, ctx, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				rctx->last_regdma_isr_status = int_mask;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				rctx->last_regdma_timestamp  = rctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:							rctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					last_ts[i] = rctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:						i, j, rctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				SDEROT_EVTLOG(i, j, rctx->timestamp,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				wake_up_all(&rctx->regdma_waitq);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		if (ctx && (ctx->session_id == session_id) &&
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				(ctx->sequence_id == sequence_id)) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				q_id, i, ctx, ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->sequence_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_BLKWRITE_DATA(wrptr, ctx->ts_addr);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_BLKWRITE_DATA(wrptr, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->is_secure) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_BLKWRITE_DATA(wrptr, ctx->ts_addr);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			(ctx->rot->highest_bank & 0x3) << 8);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->rot->mode == ROT_REGDMA_ON) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		if (ctx->sbuf_mode)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					ctx->start_ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->ubwc_malsize & 0x3) << 8) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->highest_bank & 0x3) << 4) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->ubwc_swizzle & 0x1) << 0));
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->is_secure = true;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->is_secure = false;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (((!ctx->sbuf_mode)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->is_traffic_shaping = true;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->is_traffic_shaping = false;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			(ctx->rot->highest_bank & 0x3) << 8);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->ubwc_malsize & 0x3) << 8) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->highest_bank & 0x3) << 4) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->ubwc_swizzle & 0x1) << 0));
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->sys_cache_mode);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_WRITE(wrptr, ROTTOP_OP_MODE, ctx->op_mode |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (ctx->is_traffic_shaping || cfg->prefill_bw) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		reinit_completion(&ctx->rot_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_WRITE(wrptr, ROTTOP_START_CTRL, ctx->start_ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_DBG("BEGIN %d\n", ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_DBG("END %d\n", ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	return ctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDE_REGDMA_WRITE(wrptr, ROTTOP_START_CTRL, ctx->start_ctrl);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	length = (wrptr - ctx->regdma_base) / 4;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	offset = (ctx->regdma_base - (rot->mdss_base +
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	enableInt = ((ctx->timestamp & 1) + 1) << 30;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	trig_sel = ctx->sbuf_mode ? REGDMA_CMD_TRIG_SEL_MDP_FLUSH :
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				(ctx->sbuf_mode ? enableInt : 0) | trig_sel |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		swts = ctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				(ctx->sbuf_mode ? enableInt : 0) | trig_sel |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		swts = ctx->timestamp << SDE_REGDMA_SWTS_SHIFT;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(ctx->timestamp, queue_id, length, offset, ctx->sbuf_mode);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	return ctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		rc = wait_for_completion_timeout(&ctx->rot_comp,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->sbuf_mode ?
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	struct sde_hw_rotator *rot = ctx->rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		rc = wait_event_timeout(ctx->regdma_waitq,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->sbuf_mode ?
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		last_isr = ctx->last_regdma_isr_status;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		last_ts  = ctx->last_regdma_timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		abort    = ctx->abort;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->timestamp, swts, pending, abort);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					ctx->timestamp, swts);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->timestamp, swts, last_isr);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->timestamp, swts, last_isr);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->rot        = rot;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->q_id       = hw->wb_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->session_id = session_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->sequence_id = sequence_id;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->hwres      = hw;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->timestamp  = atomic_add_return(1, &rot->timestamp[ctx->q_id]);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->timestamp &= SDE_REGDMA_SWTS_MASK;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->is_secure  = false;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->sbuf_mode  = sbuf_mode;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	INIT_LIST_HEAD(&ctx->list);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->regdma_base  = rot->cmd_wr_ptr[ctx->q_id]
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->regdma_wrptr = ctx->regdma_base;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->ts_addr      = (dma_addr_t)((u32 *)rot->swts_buf.addr +
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->q_id * SDE_HW_ROT_REGDMA_TOTAL_CTX +
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->last_regdma_timestamp = SDE_REGDMA_SWTS_INVALID;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	init_completion(&ctx->rot_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	init_waitqueue_head(&ctx->regdma_waitq);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx, sde_hw_rotator_get_regdma_ctxidx(ctx), ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->q_id, ctx->timestamp,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		atomic_read(&ctx->hwres->num_active),
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->sbuf_mode);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx, sde_hw_rotator_get_regdma_ctxidx(ctx), ctx->session_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->q_id, ctx->timestamp,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		atomic_read(&ctx->hwres->num_active),
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->sbuf_mode);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->last_entry = entry;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->start_ctrl = (rot->cmd_trigger << 4);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->start_ctrl = (rot->vid_trigger << 4);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ctx->start_ctrl = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->sys_cache_mode = BIT(15) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->op_mode = BIT(4) |
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				((ctx->rot->sbuf_headroom & 0xff) << 8);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->start_ctrl = BIT(0);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->sys_cache_mode = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->op_mode = 0;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ctx->start_ctrl = BIT(0);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(ctx->start_ctrl, ctx->sys_cache_mode, ctx->op_mode);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		if (ctx->q_id == ROT_QUEUE_HIGH_PRIORITY)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	rot->ops.setup_rotator_fetchengine(ctx, ctx->q_id,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	rot->ops.setup_rotator_wbengine(ctx, ctx->q_id, &wb_cfg, flags);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_map_vaddr(&ctx->src_dbgbuf,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_map_vaddr(&ctx->dst_dbgbuf,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(ctx->timestamp, flags,
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode && mdata->default_ot_rd_limit) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ot_params.fmt = ctx->is_traffic_shaping ?
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode && mdata->default_ot_wr_limit) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		ot_params.fmt = ctx->is_traffic_shaping ?
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	if (!ctx->sbuf_mode)
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	sde_hw_rotator_update_swts(rot, ctx, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(entry->item.session_id, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_unmap_vaddr(&ctx->src_dbgbuf);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_unmap_vaddr(&ctx->dst_dbgbuf);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	rot->ops.start_rotator(ctx, ctx->q_id);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	sde_hw_rotator_update_swts(rot, ctx, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ctx->abort = true;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	wake_up_all(&ctx->regdma_waitq);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	SDEROT_EVTLOG(entry->item.session_id, ctx->timestamp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:	ret = rot->ops.wait_rotator_done(ctx, ctx->q_id, 0);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_unmap_vaddr(&ctx->src_dbgbuf);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		sde_hw_rotator_unmap_vaddr(&ctx->dst_dbgbuf);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:		complete_all(&ctx->rot_comp);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				ts = ctx->timestamp;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			sde_hw_rotator_elapsed_swts(ctx->timestamp, ts) >= 0) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->last_regdma_isr_status = isr;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			ctx->last_regdma_timestamp  = ts;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:			wake_up_all(&ctx->regdma_waitq);
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:				if (ctx && ctx->last_regdma_isr_status == 0) {
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					ctx->last_regdma_isr_status = isr;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					ctx->last_regdma_timestamp  = ts;
drivers/media/platform/msm/sde/rotator/sde_rotator_r3.c:					wake_up_all(&ctx->regdma_waitq);
drivers/media/platform/exynos4-is/fimc-core.h:	spin_lock_irqsave(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.h:	ctx->state |= state;
drivers/media/platform/exynos4-is/fimc-core.h:	spin_unlock_irqrestore(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.h:	spin_lock_irqsave(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.h:	ret = (ctx->state & mask) == mask;
drivers/media/platform/exynos4-is/fimc-core.h:	spin_unlock_irqrestore(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.h:			frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-core.h:		frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-core.h:		v4l2_err(ctx->fimc_dev->v4l2_dev,
drivers/media/platform/exynos4-is/fimc-m2m.c:	if (!ctx || !ctx->fh.m2m_ctx)
drivers/media/platform/exynos4-is/fimc-m2m.c:	src_vb = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	dst_vb = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:		v4l2_m2m_job_finish(ctx->fimc_dev->m2m.m2m_dev,
drivers/media/platform/exynos4-is/fimc-m2m.c:				    ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ret = pm_runtime_get_sync(&ctx->fimc_dev->pdev->dev);
drivers/media/platform/exynos4-is/fimc-m2m.c:	pm_runtime_put(&ctx->fimc_dev->pdev->dev);
drivers/media/platform/exynos4-is/fimc-m2m.c:	fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	sf = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:	df = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:	if (ctx->state & FIMC_PARAMS) {
drivers/media/platform/exynos4-is/fimc-m2m.c:	src_vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	dst_vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:		ctx->state |= FIMC_PARAMS;
drivers/media/platform/exynos4-is/fimc-m2m.c:	if (ctx->state & FIMC_PARAMS) {
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->state &= (FIMC_CTX_M2M | FIMC_CTX_CAP);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/exynos4-is/fimc-m2m.c:		frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:		frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:		f = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:	min_size = (f == &ctx->s_frame) ?
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:		&ctx->s_frame : &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-m2m.c:				cr.c.height, ctx->d_frame.width,
drivers/media/platform/exynos4-is/fimc-m2m.c:				ctx->d_frame.height, ctx->rotation);
drivers/media/platform/exynos4-is/fimc-m2m.c:		ret = fimc_check_scaler_ratio(ctx, ctx->s_frame.width,
drivers/media/platform/exynos4-is/fimc-m2m.c:				ctx->s_frame.height, cr.c.width,
drivers/media/platform/exynos4-is/fimc-m2m.c:				cr.c.height, ctx->rotation);
drivers/media/platform/exynos4-is/fimc-m2m.c:	src_vq->lock = &ctx->fimc_dev->lock;
drivers/media/platform/exynos4-is/fimc-m2m.c:	src_vq->dev = &ctx->fimc_dev->pdev->dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	dst_vq->lock = &ctx->fimc_dev->lock;
drivers/media/platform/exynos4-is/fimc-m2m.c:	dst_vq->dev = &ctx->fimc_dev->pdev->dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	__set_frame_format(&ctx->s_frame, fmt, &pixm);
drivers/media/platform/exynos4-is/fimc-m2m.c:	__set_frame_format(&ctx->d_frame, fmt, &pixm);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_init(&ctx->fh, &fimc->m2m.vfd);
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->fimc_dev = fimc;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->s_frame.fmt = fimc_get_format(0);
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->d_frame.fmt = fimc_get_format(0);
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->fh.ctrl_handler = &ctx->ctrls.handler;
drivers/media/platform/exynos4-is/fimc-m2m.c:	file->private_data = &ctx->fh;
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->state = FIMC_CTX_M2M;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->flags = 0;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->in_path = FIMC_IO_DMA;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->out_path = FIMC_IO_DMA;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->scaler.enabled = 1;
drivers/media/platform/exynos4-is/fimc-m2m.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(fimc->m2m.m2m_dev, ctx, queue_init);
drivers/media/platform/exynos4-is/fimc-m2m.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/exynos4-is/fimc-m2m.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/exynos4-is/fimc-m2m.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/exynos4-is/fimc-m2m.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/exynos4-is/fimc-core.c:	if (!ctx->scaler.enabled)
drivers/media/platform/exynos4-is/fimc-core.c:	const struct fimc_variant *variant = ctx->fimc_dev->variant;
drivers/media/platform/exynos4-is/fimc-core.c:	struct device *dev = &ctx->fimc_dev->pdev->dev;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_frame *s_frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_frame *d_frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-core.c:	if (ctx->rotation == 90 || ctx->rotation == 270) {
drivers/media/platform/exynos4-is/fimc-core.c:			if (ctx->state & FIMC_CTX_SHUT) {
drivers/media/platform/exynos4-is/fimc-core.c:				ctx->state &= ~FIMC_CTX_SHUT;
drivers/media/platform/exynos4-is/fimc-core.c:	ctx->in_order_2p = FIMC_REG_CIOCTRL_ORDER422_2P_LSB_CRCB;
drivers/media/platform/exynos4-is/fimc-core.c:	ctx->out_order_2p = FIMC_REG_CIOCTRL_ORDER422_2P_LSB_CRCB;
drivers/media/platform/exynos4-is/fimc-core.c:	switch (ctx->s_frame.fmt->color) {
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->in_order_1p = FIMC_REG_MSCTRL_ORDER422_YCRYCB;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->in_order_1p = FIMC_REG_MSCTRL_ORDER422_CBYCRY;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->in_order_1p = FIMC_REG_MSCTRL_ORDER422_CRYCBY;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->in_order_1p = FIMC_REG_MSCTRL_ORDER422_YCBYCR;
drivers/media/platform/exynos4-is/fimc-core.c:	dbg("ctx->in_order_1p= %d", ctx->in_order_1p);
drivers/media/platform/exynos4-is/fimc-core.c:	switch (ctx->d_frame.fmt->color) {
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->out_order_1p = FIMC_REG_CIOCTRL_ORDER422_YCRYCB;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->out_order_1p = FIMC_REG_CIOCTRL_ORDER422_CBYCRY;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->out_order_1p = FIMC_REG_CIOCTRL_ORDER422_CRYCBY;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->out_order_1p = FIMC_REG_CIOCTRL_ORDER422_YCBYCR;
drivers/media/platform/exynos4-is/fimc-core.c:	dbg("ctx->out_order_1p= %d", ctx->out_order_1p);
drivers/media/platform/exynos4-is/fimc-core.c:	bool pix_hoff = ctx->fimc_dev->drv_data->dma_pix_hoff;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_effect *effect = &ctx->effect;
drivers/media/platform/exynos4-is/fimc-core.c:		effect->pat_cb = ctx->ctrls.colorfx_cbcr->val >> 8;
drivers/media/platform/exynos4-is/fimc-core.c:		effect->pat_cr = ctx->ctrls.colorfx_cbcr->val & 0xff;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->hflip = ctrl->val;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->vflip = ctrl->val;
drivers/media/platform/exynos4-is/fimc-core.c:			ret = fimc_check_scaler_ratio(ctx, ctx->s_frame.width,
drivers/media/platform/exynos4-is/fimc-core.c:					ctx->s_frame.height, ctx->d_frame.width,
drivers/media/platform/exynos4-is/fimc-core.c:					ctx->d_frame.height, ctrl->val);
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->rotation = ctrl->val;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->d_frame.alpha = ctrl->val;
drivers/media/platform/exynos4-is/fimc-core.c:	ctx->state |= FIMC_PARAMS;
drivers/media/platform/exynos4-is/fimc-core.c:	spin_lock_irqsave(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.c:	spin_unlock_irqrestore(&ctx->fimc_dev->slock, flags);
drivers/media/platform/exynos4-is/fimc-core.c:	unsigned int max_alpha = fimc_get_alpha_mask(ctx->d_frame.fmt);
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_ctrls *ctrls = &ctx->ctrls;
drivers/media/platform/exynos4-is/fimc-core.c:	if (ctx->ctrls.ready)
drivers/media/platform/exynos4-is/fimc-core.c:	if (ctx->fimc_dev->drv_data->alpha_color)
drivers/media/platform/exynos4-is/fimc-core.c:	ctx->effect.type = FIMC_REG_CIIMGEFF_FIN_BYPASS;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_ctrls *ctrls = &ctx->ctrls;
drivers/media/platform/exynos4-is/fimc-core.c:	unsigned int has_alpha = ctx->d_frame.fmt->flags & FMT_HAS_ALPHA;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_ctrls *ctrls = &ctx->ctrls;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->rotation = ctrls->rotate->val;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->hflip    = ctrls->hflip->val;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->vflip    = ctrls->vflip->val;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->effect.type = FIMC_REG_CIIMGEFF_FIN_BYPASS;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->rotation = 0;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->hflip    = 0;
drivers/media/platform/exynos4-is/fimc-core.c:		ctx->vflip    = 0;
drivers/media/platform/exynos4-is/fimc-core.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-core.c:	struct v4l2_ctrl *ctrl = ctx->ctrls.alpha;
drivers/media/platform/exynos4-is/fimc-core.c:	ctrl->maximum = fimc_get_alpha_mask(ctx->d_frame.fmt);
drivers/media/platform/exynos4-is/fimc-capture.c:	if (ctx == NULL || ctx->s_frame.fmt == NULL)
drivers/media/platform/exynos4-is/fimc-capture.c:	fimc_prepare_dma_offset(ctx, &ctx->d_frame);
drivers/media/platform/exynos4-is/fimc-capture.c:	fimc_hw_set_camera_offset(fimc, &ctx->s_frame);
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	fimc_hw_set_camera_offset(fimc, &ctx->s_frame);
drivers/media/platform/exynos4-is/fimc-capture.c:	fimc_prepare_dma_offset(ctx, &ctx->d_frame);
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *f = &cap->ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (ctx->d_frame.fmt == NULL)
drivers/media/platform/exynos4-is/fimc-capture.c:	for (i = 0; i < ctx->d_frame.fmt->memplanes; i++) {
drivers/media/platform/exynos4-is/fimc-capture.c:		unsigned long size = ctx->d_frame.payload[i];
drivers/media/platform/exynos4-is/fimc-capture.c:			v4l2_err(&ctx->fimc_dev->vid_cap.ve.vdev,
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	fimc_prepare_addr(ctx, &buf->vb.vb2_buf, &ctx->d_frame, &buf->paddr);
drivers/media/platform/exynos4-is/fimc-capture.c:	bool rotation = ctx->rotation == 90 || ctx->rotation == 270;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *dst = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (code && ctx->s_frame.fmt && pad == FIMC_SD_PAD_SOURCE &&
drivers/media/platform/exynos4-is/fimc-capture.c:	    fimc_fmt_is_user_defined(ctx->s_frame.fmt->color))
drivers/media/platform/exynos4-is/fimc-capture.c:		*code = ctx->s_frame.fmt->mbus_code;
drivers/media/platform/exynos4-is/fimc-capture.c:		*width  = ctx->s_frame.f_width;
drivers/media/platform/exynos4-is/fimc-capture.c:		*height = ctx->s_frame.f_height;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (ctx->state & FIMC_COMPOSE) {
drivers/media/platform/exynos4-is/fimc-capture.c:	bool rotate = ctx->rotation == 90 || ctx->rotation == 270;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *sink = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (fimc_fmt_is_user_defined(ctx->d_frame.fmt->color)) {
drivers/media/platform/exynos4-is/fimc-capture.c:		if (ctx->rotation != 90 && ctx->rotation != 270)
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_dev *fimc = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-capture.c:	__fimc_get_format(&fimc->vid_cap.ctx->d_frame, f);
drivers/media/platform/exynos4-is/fimc-capture.c:			ctx->s_frame.f_width = pix->width;
drivers/media/platform/exynos4-is/fimc-capture.c:			ctx->s_frame.f_height = pix->height;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->scaler.enabled = !jpeg;
drivers/media/platform/exynos4-is/fimc-capture.c:		set_bit(ST_CAPT_JPEG, &ctx->fimc_dev->state);
drivers/media/platform/exynos4-is/fimc-capture.c:		clear_bit(ST_CAPT_JPEG, &ctx->fimc_dev->state);
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *ff = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (!(ctx->state & FIMC_COMPOSE))
drivers/media/platform/exynos4-is/fimc-capture.c:		ctx->s_frame.fmt = inp_fmt;
drivers/media/platform/exynos4-is/fimc-capture.c:		set_frame_bounds(&ctx->s_frame, pix->width, pix->height);
drivers/media/platform/exynos4-is/fimc-capture.c:		set_frame_crop(&ctx->s_frame, 0, 0, pix->width, pix->height);
drivers/media/platform/exynos4-is/fimc-capture.c:			struct fimc_frame *ff = &vc->ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:			struct fimc_frame *frame = &vc->ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *f = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	return v4l2_ctrl_add_handler(&vc->ctx->ctrls.handler,
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *ff = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		ff = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		mf->width = ctx->s_frame.width;
drivers/media/platform/exynos4-is/fimc-capture.c:		mf->height = ctx->s_frame.height;
drivers/media/platform/exynos4-is/fimc-capture.c:		ff = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	if (!(fmt->pad == FIMC_SD_PAD_SOURCE && (ctx->state & FIMC_COMPOSE)))
drivers/media/platform/exynos4-is/fimc-capture.c:		ctx->state &= ~FIMC_COMPOSE;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *f = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:	struct fimc_frame *f = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:		f = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-capture.c:			ctx->state |= FIMC_COMPOSE;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->fimc_dev	 = fimc;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->in_path	 = FIMC_IO_CAMERA;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->out_path	 = FIMC_IO_DMA;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->state	 = FIMC_CTX_CAP;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->s_frame.fmt = fimc_find_format(NULL, NULL, FMT_FLAGS_CAM, 0);
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->d_frame.fmt = ctx->s_frame.fmt;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->s_frame.width = FIMC_DEFAULT_WIDTH;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->s_frame.height = FIMC_DEFAULT_HEIGHT;
drivers/media/platform/exynos4-is/fimc-capture.c:	ctx->s_frame.fmt = fmt;
drivers/media/platform/exynos4-is/fimc-capture.c:	vfd->ctrl_handler = &ctx->ctrls.handler;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->hflip)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->vflip)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->rotation <= 90)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->hflip)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->vflip)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->rotation <= 90)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->rotation == 90 || ctx->rotation == 270) {
drivers/media/platform/exynos4-is/fimc-reg.c:		if (ctx->out_path == FIMC_IO_LCDFIFO)
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->out_path == FIMC_IO_DMA) {
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->rotation == 90 || ctx->rotation == 270)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:		cfg |= ctx->out_order_1p;
drivers/media/platform/exynos4-is/fimc-reg.c:		cfg |= ctx->out_order_2p | FIMC_REG_CIOCTRL_YCBCR_2PLANE;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev =  ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *src_frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *dst_frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (!(ctx->flags & FIMC_COLOR_RANGE_NARROW))
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->in_path == FIMC_IO_DMA) {
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->out_path == FIMC_IO_DMA) {
drivers/media/platform/exynos4-is/fimc-reg.c:		if (ctx->flags & FIMC_SCAN_MODE_INTERLACED)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->scaler.enabled)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_effect *effect = &ctx->effect;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (FIMC_IO_LCDFIFO == ctx->out_path)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *frame = &ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	fimc_hw_en_autoload(dev, ctx->out_path == FIMC_IO_LCDFIFO);
drivers/media/platform/exynos4-is/fimc-reg.c:			cfg |= ctx->in_order_2p | FIMC_REG_MSCTRL_C_INT_IN_2PLANE;
drivers/media/platform/exynos4-is/fimc-reg.c:			cfg |= ctx->in_order_1p
drivers/media/platform/exynos4-is/fimc-reg.c:				cfg |= ctx->in_order_2p
drivers/media/platform/exynos4-is/fimc-reg.c:	if (tiled_fmt(ctx->s_frame.fmt))
drivers/media/platform/exynos4-is/fimc-reg.c:	if (tiled_fmt(ctx->d_frame.fmt))
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->in_path == FIMC_IO_DMA)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_dev *dev = ctx->fimc_dev;
drivers/media/platform/exynos4-is/fimc-reg.c:	if (ctx->out_path == FIMC_IO_LCDFIFO)
drivers/media/platform/exynos4-is/fimc-reg.c:	struct fimc_frame *f = &vc->ctx->s_frame;
drivers/media/platform/exynos4-is/fimc-reg.c:	fimc_hw_enable_scaler(ctx->fimc_dev, ctx->scaler.enabled);
drivers/media/platform/sti/bdisp/bdisp-hw.c:	if (ctx && ctx->node[0])
drivers/media/platform/sti/bdisp/bdisp-hw.c:		dma_free_attrs(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-hw.c:			       ctx->node[0], ctx->node_paddr[0],
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct device *dev = ctx->bdisp_dev->dev;
drivers/media/platform/sti/bdisp/bdisp-hw.c:		ctx->node[i] = base;
drivers/media/platform/sti/bdisp/bdisp-hw.c:		ctx->node_paddr[i] = paddr;
drivers/media/platform/sti/bdisp/bdisp-hw.c:		dev_dbg(dev, "node[%d]=0x%p (paddr=%pad)\n", i, ctx->node[i],
drivers/media/platform/sti/bdisp/bdisp-hw.c:	src_w = ctx->src.crop.width;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	src_h = ctx->src.crop.height;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	dst_w = ctx->dst.crop.width;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	dst_h = ctx->dst.crop.height;
drivers/media/platform/sti/bdisp/bdisp-hw.c:		dev_err(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct device *dev = ctx->bdisp_dev->dev;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_frame *src = &ctx->src;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_frame *dst = &ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	c->hflip = ctx->hflip;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	c->vflip = ctx->vflip;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_frame *src = &ctx->src;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_frame *dst = &ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	dev_dbg(ctx->bdisp_dev->dev, "%s\n", __func__);
drivers/media/platform/sti/bdisp/bdisp-hw.c:	dst_x_offset = (src_x_offset * dst_width) / ctx->src.crop.width;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	dst_rect.width = (src_rect.width * dst_width) / ctx->src.crop.width;
drivers/media/platform/sti/bdisp/bdisp-hw.c:		if (!ctx->node[i]) {
drivers/media/platform/sti/bdisp/bdisp-hw.c:			dev_err(ctx->bdisp_dev->dev, "node %d is null\n", i);
drivers/media/platform/sti/bdisp/bdisp-hw.c:		bdisp_hw_build_node(ctx, &cfg, ctx->node[nid],
drivers/media/platform/sti/bdisp/bdisp-hw.c:			ctx->node[nid - 1]->nip = ctx->node_paddr[nid];
drivers/media/platform/sti/bdisp/bdisp-hw.c:			bdisp_hw_build_node(ctx, &cfg, ctx->node[nid],
drivers/media/platform/sti/bdisp/bdisp-hw.c:			ctx->node[nid - 1]->nip = ctx->node_paddr[nid];
drivers/media/platform/sti/bdisp/bdisp-hw.c:		if (src_x_offset >= ctx->src.crop.width)
drivers/media/platform/sti/bdisp/bdisp-hw.c:	ctx->node[nid - 1]->nip = 0;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_node **copy_node = ctx->bdisp_dev->dbg.copy_node;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_request *request = &ctx->bdisp_dev->dbg.copy_request;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_node **node = ctx->node;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	request->src = ctx->src;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	request->dst = ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	request->hflip = ctx->hflip;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	request->vflip = ctx->vflip;
drivers/media/platform/sti/bdisp/bdisp-hw.c:			copy_node[i] = devm_kzalloc(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-hw.c:	struct bdisp_dev *bdisp = ctx->bdisp_dev;
drivers/media/platform/sti/bdisp/bdisp-hw.c:	writel(ctx->node_paddr[0], bdisp->regs + BLT_AQ1_IP);
drivers/media/platform/sti/bdisp/bdisp-hw.c:		if (!ctx->node[node_id]->nip)
drivers/media/platform/sti/bdisp/bdisp-hw.c:	writel(ctx->node_paddr[node_id], bdisp->regs + BLT_AQ1_LNA);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_lock_irqsave(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->state |= state;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_unlock_irqrestore(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_lock_irqsave(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->state &= ~state;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_unlock_irqrestore(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_lock_irqsave(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ret = (ctx->state & mask) == mask;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_unlock_irqrestore(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		return &ctx->src;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		return &ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (WARN(!ctx || !ctx->fh.m2m_ctx, "Null hardware context\n"))
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dev_dbg(ctx->bdisp_dev->dev, "%s\n", __func__);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	src_vb = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dst_vb = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		v4l2_m2m_job_finish(ctx->bdisp_dev->m2m.m2m_dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:				    ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	struct bdisp_dev *bdisp = ctx->bdisp_dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dev_dbg(ctx->bdisp_dev->dev, "%s\n", __func__);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "%s IRQ timeout\n", __func__);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if ((ret == -ETIMEDOUT) || (ctx->state & BDISP_CTX_ABORT)) {
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev, "ignoring some planes\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dev_dbg(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	src = &ctx->src;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dst = &ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	src_vb = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dst_vb = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	bdisp = ctx->bdisp_dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->state |= BDISP_PARAMS;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (ctx->state & BDISP_CTX_STOP_REQ) {
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->state &= ~BDISP_CTX_STOP_REQ;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->state |= BDISP_CTX_ABORT;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->state &= ~BDISP_PARAMS;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->hflip = ctrl->val;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->vflip = ctrl->val;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "unknown control %d\n", ctrl->id);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->state |= BDISP_PARAMS;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_lock_irqsave(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	spin_unlock_irqrestore(&ctx->bdisp_dev->slock, flags);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (ctx->ctrls_rdy)
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, BDISP_MAX_CTRL_NUM);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->bdisp_ctrls.hflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->bdisp_ctrls.vflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		int err = ctx->ctrl_handler.error;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->ctrls_rdy = true;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (ctx->ctrls_rdy) {
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ctx->ctrls_rdy = false;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid frame (%p)\n", frame);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid format\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid frame (%p)\n", frame);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev, "0 data buffer, skip it\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (ctx->fh.m2m_ctx)
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	int ret = pm_runtime_get_sync(ctx->bdisp_dev->dev);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "failed to set runtime PM\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:			while ((buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:			while ((buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	pm_runtime_put(ctx->bdisp_dev->dev);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	src_vq->lock = &ctx->bdisp_dev->lock;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	src_vq->dev = ctx->bdisp_dev->v4l2_dev.dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dst_vq->lock = &ctx->bdisp_dev->lock;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dst_vq->dev = ctx->bdisp_dev->v4l2_dev.dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->bdisp_dev = bdisp;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_init(&ctx->fh, bdisp->m2m.vdev);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	file->private_data = &ctx->fh;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->src = bdisp_dflt_fmt;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->dst = bdisp_dflt_fmt;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(bdisp->m2m.m2m_dev, ctx,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	struct bdisp_dev *bdisp = ctx->bdisp_dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	struct bdisp_dev *bdisp = ctx->bdisp_dev;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev, "No YU12 on capture\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid frame (%p)\n", frame);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev, "Unknown format 0x%x\n",
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev, "No YU12 on capture\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Cannot set format\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "queue (%d) busy\n", f->type);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:			&ctx->src : &ctx->dst;
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Unknown format 0x%x\n",
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid frame (%p)\n", frame);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:			dev_err(ctx->bdisp_dev->dev, "Invalid target\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:			dev_err(ctx->bdisp_dev->dev, "Invalid target\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid type\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid type / target\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "Invalid frame (%p)\n", frame);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_dbg(ctx->bdisp_dev->dev,
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "src not defined\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:		dev_err(ctx->bdisp_dev->dev, "dst not defined\n");
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	return v4l2_m2m_streamon(file, ctx->fh.m2m_ctx, type);
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	if (!ctx || !ctx->fh.m2m_ctx)
drivers/media/platform/sti/bdisp/bdisp-v4l2.c:	dev_err(ctx->bdisp_dev->dev, "Device work timeout\n");
drivers/media/platform/sti/hva/hva-mem.c:			ctx->name, __func__, name, size);
drivers/media/platform/sti/hva/hva-mem.c:		ctx->name, size, b->vaddr, &b->paddr, b->name);
drivers/media/platform/sti/hva/hva-mem.c:		ctx->name, buf->size, buf->vaddr, &buf->paddr, buf->name);
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__, ctx_id);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = false;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = false;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = false;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, __func__);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, hva->lmi_err_reg);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, hva->emi_err_reg);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:			ctx->name, hva->hec_mif_err_reg);
drivers/media/platform/sti/hva/hva-hw.c:		ctx->hw_err = true;
drivers/media/platform/sti/hva/hva-hw.c:	u8 client_id = ctx->id;
drivers/media/platform/sti/hva/hva-hw.c:		dev_err(dev, "%s     failed to get pm_runtime\n", ctx->name);
drivers/media/platform/sti/hva/hva-hw.c:		dev_dbg(dev, "%s     unknown command 0x%x\n", ctx->name, cmd);
drivers/media/platform/sti/hva/hva-hw.c:	dev_dbg(dev, "%s     %s: write configuration registers\n", ctx->name,
drivers/media/platform/sti/hva/hva-hw.c:		ctx->name, __func__, cmd + (client_id << 8), &task->paddr);
drivers/media/platform/sti/hva/hva-hw.c:		dev_err(dev, "%s     %s: time out on completion\n", ctx->name,
drivers/media/platform/sti/hva/hva-hw.c:	ret = ctx->hw_err ? -EFAULT : 0;
drivers/media/platform/sti/hva/hva-hw.c:		dev_dbg(dev, "%s     unknown command 0x%x\n", ctx->name, cmd);
drivers/media/platform/sti/hva/hva-v4l2.c:	struct hva_frameinfo *frameinfo = &ctx->frameinfo;
drivers/media/platform/sti/hva/hva-v4l2.c:	struct hva_streaminfo *streaminfo = &ctx->streaminfo;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->colorspace = V4L2_COLORSPACE_REC709;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->xfer_func = V4L2_XFER_FUNC_DEFAULT;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->ycbcr_enc = V4L2_YCBCR_ENC_DEFAULT;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->quantization = V4L2_QUANTIZATION_DEFAULT;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->max_stream_size = estimated_stream_size(streaminfo->width,
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, (char *)&pixelformat, (char *)&streamformat);
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->name, (char *)&pixelformat, (char *)&streamformat);
drivers/media/platform/sti/hva/hva-v4l2.c:	snprintf(ctx->name, sizeof(ctx->name), "[%3d:%4.4s]",
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, ret);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s %s encoder opened\n", ctx->name, enc->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	struct hva_streaminfo *streaminfo = &ctx->streaminfo;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.xfer_func = ctx->xfer_func;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.quantization = ctx->quantization;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.sizeimage = ctx->max_stream_size;
drivers/media/platform/sti/hva/hva-v4l2.c:	struct hva_frameinfo *frameinfo = &ctx->frameinfo;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.xfer_func = ctx->xfer_func;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	f->fmt.pix.quantization = ctx->quantization;
drivers/media/platform/sti/hva/hva-v4l2.c:	enc = hva_find_encoder(ctx, ctx->frameinfo.pixelformat, streamformat);
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, (char *)&pix->pixelformat);
drivers/media/platform/sti/hva/hva-v4l2.c:	if (ctx->flags & HVA_FLAG_FRAMEINFO) {
drivers/media/platform/sti/hva/hva-v4l2.c:		pix->width = ctx->frameinfo.width;
drivers/media/platform/sti/hva/hva-v4l2.c:		pix->height = ctx->frameinfo.height;
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, width, height,
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, width, height,
drivers/media/platform/sti/hva/hva-v4l2.c:	pix->colorspace = ctx->colorspace;
drivers/media/platform/sti/hva/hva-v4l2.c:	pix->xfer_func = ctx->xfer_func;
drivers/media/platform/sti/hva/hva-v4l2.c:	pix->ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	pix->quantization = ctx->quantization;
drivers/media/platform/sti/hva/hva-v4l2.c:	enc = hva_find_encoder(ctx, pixelformat, ctx->streaminfo.streamformat);
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, (char *)&pixelformat);
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, width, height, pix->width, pix->height);
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, (char *)&f->fmt.pix.pixelformat);
drivers/media/platform/sti/hva/hva-v4l2.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->max_stream_size = f->fmt.pix.sizeimage;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->streaminfo.width = f->fmt.pix.width;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->streaminfo.height = f->fmt.pix.height;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->streaminfo.streamformat = f->fmt.pix.pixelformat;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->flags |= HVA_FLAG_STREAMINFO;
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, (char *)&pix->pixelformat);
drivers/media/platform/sti/hva/hva-v4l2.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/sti/hva/hva-v4l2.c:		dev_dbg(dev, "%s V4L2 S_FMT (OUTPUT): queue busy\n", ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->colorspace = pix->colorspace;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->xfer_func = pix->xfer_func;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->ycbcr_enc = pix->ycbcr_enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->quantization = pix->quantization;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.aligned_width = ALIGN(pix->width, HVA_WIDTH_ALIGNMENT);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.aligned_height = ALIGN(pix->height,
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.size = pix->sizeimage;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.pixelformat = pix->pixelformat;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.width = pix->width;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->frameinfo.height = pix->height;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->flags |= HVA_FLAG_FRAMEINFO;
drivers/media/platform/sti/hva/hva-v4l2.c:	struct v4l2_fract *time_per_frame = &ctx->ctrls.time_per_frame;
drivers/media/platform/sti/hva/hva-v4l2.c:	struct v4l2_fract *time_per_frame = &ctx->ctrls.time_per_frame;
drivers/media/platform/sti/hva/hva-v4l2.c:		vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, buf->type);
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, buf->index, vq->num_buffers);
drivers/media/platform/sti/hva/hva-v4l2.c:	return v4l2_m2m_qbuf(file, ctx->fh.m2m_ctx, buf);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s S_CTRL: id = %d, val = %d\n", ctx->name,
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.bitrate_mode = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.gop_size = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.bitrate = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.aspect = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.profile = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		if (ctx->flags & HVA_FLAG_STREAMINFO)
drivers/media/platform/sti/hva/hva-v4l2.c:			snprintf(ctx->streaminfo.profile,
drivers/media/platform/sti/hva/hva-v4l2.c:				 sizeof(ctx->streaminfo.profile),
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.level = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		if (ctx->flags & HVA_FLAG_STREAMINFO)
drivers/media/platform/sti/hva/hva-v4l2.c:			snprintf(ctx->streaminfo.level,
drivers/media/platform/sti/hva/hva-v4l2.c:				 sizeof(ctx->streaminfo.level),
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.entropy_mode = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.cpb_size = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.dct8x8 = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.qpmin = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.qpmax = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.vui_sar = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.vui_sar_idc = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.sei_fp = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->ctrls.sei_fp_type = ctrl->val;
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, ctrl->id);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, 15);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_new_std_menu(&ctx->ctrl_handler, &hva_ctrl_ops,
drivers/media/platform/sti/hva/hva-v4l2.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/sti/hva/hva-v4l2.c:		int err = ctx->ctrl_handler.error;
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, err);
drivers/media/platform/sti/hva/hva-v4l2.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->ctrls.time_per_frame.numerator = HVA_DEFAULT_FRAME_NUM;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->ctrls.time_per_frame.denominator = HVA_DEFAULT_FRAME_DEN;
drivers/media/platform/sti/hva/hva-v4l2.c:	const struct hva_enc *enc = ctx->enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	mutex_lock(&ctx->lock);
drivers/media/platform/sti/hva/hva-v4l2.c:	src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/sti/hva/hva-v4l2.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/sti/hva/hva-v4l2.c:	frame->vbuf.sequence = ctx->frame_num++;
drivers/media/platform/sti/hva/hva-v4l2.c:		dst_buf->sequence = ctx->stream_num - 1;
drivers/media/platform/sti/hva/hva-v4l2.c:	mutex_unlock(&ctx->lock);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_m2m_job_finish(ctx->hva_dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/sti/hva/hva-v4l2.c:	queue_work(hva->work_queue, &ctx->run_work);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s aborting job\n", ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->aborting = true;
drivers/media/platform/sti/hva/hva-v4l2.c:	if (!v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx)) {
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	if (!v4l2_m2m_num_dst_bufs_ready(ctx->fh.m2m_ctx)) {
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	if (ctx->aborting) {
drivers/media/platform/sti/hva/hva-v4l2.c:		dev_dbg(dev, "%s job not ready: aborting\n", ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s %s queue setup: num_buffers %d\n", ctx->name,
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->frameinfo.size : ctx->max_stream_size;
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, vb->index, vbuf->field);
drivers/media/platform/sti/hva/hva-v4l2.c:			frame->info = ctx->frameinfo;
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, vb->index,
drivers/media/platform/sti/hva/hva-v4l2.c:				ctx->name, vb->index,
drivers/media/platform/sti/hva/hva-v4l2.c:	if (ctx->fh.m2m_ctx)
drivers/media/platform/sti/hva/hva-v4l2.c:		v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s %s start streaming\n", ctx->name,
drivers/media/platform/sti/hva/hva-v4l2.c:		if (!vb2_start_streaming_called(&ctx->fh.m2m_ctx->cap_q_ctx.q))
drivers/media/platform/sti/hva/hva-v4l2.c:		if (!vb2_start_streaming_called(&ctx->fh.m2m_ctx->out_q_ctx.q))
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->id = i;
drivers/media/platform/sti/hva/hva-v4l2.c:		dev_err(dev, "%s maximum instances reached\n", ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	if (!ctx->enc) {
drivers/media/platform/sti/hva/hva-v4l2.c:				       ctx->streaminfo.streamformat,
drivers/media/platform/sti/hva/hva-v4l2.c:				       ctx->frameinfo.pixelformat,
drivers/media/platform/sti/hva/hva-v4l2.c:				       &ctx->enc);
drivers/media/platform/sti/hva/hva-v4l2.c:	hva->instances[ctx->id] = NULL;
drivers/media/platform/sti/hva/hva-v4l2.c:		while ((vbuf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/hva/hva-v4l2.c:		while ((vbuf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/hva/hva-v4l2.c:	const struct hva_enc *enc = ctx->enc;
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_dbg(dev, "%s %s stop streaming\n", ctx->name,
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->frame_num = 0;
drivers/media/platform/sti/hva/hva-v4l2.c:		while ((vbuf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->stream_num = 0;
drivers/media/platform/sti/hva/hva-v4l2.c:		while ((vbuf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/sti/hva/hva-v4l2.c:	     vb2_is_streaming(&ctx->fh.m2m_ctx->cap_q_ctx.q)) ||
drivers/media/platform/sti/hva/hva-v4l2.c:	     vb2_is_streaming(&ctx->fh.m2m_ctx->out_q_ctx.q))) {
drivers/media/platform/sti/hva/hva-v4l2.c:			ctx->name, to_type_str(vq->type),
drivers/media/platform/sti/hva/hva-v4l2.c:			vb2_is_streaming(&ctx->fh.m2m_ctx->out_q_ctx.q),
drivers/media/platform/sti/hva/hva-v4l2.c:			vb2_is_streaming(&ctx->fh.m2m_ctx->cap_q_ctx.q));
drivers/media/platform/sti/hva/hva-v4l2.c:		dev_dbg(dev, "%s %s encoder closed\n", ctx->name, enc->name);
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->enc = NULL;
drivers/media/platform/sti/hva/hva-v4l2.c:		hva->instances[ctx->id] = NULL;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->aborting = false;
drivers/media/platform/sti/hva/hva-v4l2.c:	vq->lock = &ctx->hva_dev->lock;
drivers/media/platform/sti/hva/hva-v4l2.c:	src_vq->dev = ctx->hva_dev->dev;
drivers/media/platform/sti/hva/hva-v4l2.c:	dst_vq->dev = ctx->hva_dev->dev;
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->hva_dev = hva;
drivers/media/platform/sti/hva/hva-v4l2.c:	INIT_WORK(&ctx->run_work, hva_run_work);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/sti/hva/hva-v4l2.c:	file->private_data = &ctx->fh;
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/sti/hva/hva-v4l2.c:	mutex_init(&ctx->lock);
drivers/media/platform/sti/hva/hva-v4l2.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(hva->m2m_dev, ctx,
drivers/media/platform/sti/hva/hva-v4l2.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/sti/hva/hva-v4l2.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/sti/hva/hva-v4l2.c:	snprintf(ctx->name, sizeof(ctx->name), "[%3d:----]",
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_info(dev, "%s encoder instance created\n", ctx->name);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/sti/hva/hva-v4l2.c:	const struct hva_enc *enc = ctx->enc;
drivers/media/platform/sti/hva/hva-v4l2.c:		dev_dbg(dev, "%s %s encoder closed\n", ctx->name, enc->name);
drivers/media/platform/sti/hva/hva-v4l2.c:		ctx->enc = NULL;
drivers/media/platform/sti/hva/hva-v4l2.c:		hva->instances[ctx->id] = NULL;
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/sti/hva/hva-v4l2.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/sti/hva/hva-v4l2.c:	dev_info(dev, "%s encoder instance released\n", ctx->name);
drivers/media/platform/sti/hva/hva-h264.c:		pctx->name, __func__, frame_order, idr_pic_id, *header_size);
drivers/media/platform/sti/hva/hva-h264.c:	dev_dbg(dev, "%s   %s stuffing bytes %d\n", pctx->name, __func__,
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, __func__, stuffing_bytes);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, type);
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_h264_ctx *ctx = (struct hva_h264_ctx *)pctx->priv;
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_buffer *seq_info = ctx->seq_info;
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_buffer *fwd_ref_frame = ctx->ref_frame;
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_buffer *loc_rec_frame = ctx->rec_frame;
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_controls *ctrls = &pctx->ctrls;
drivers/media/platform/sti/hva/hva-h264.c:	struct v4l2_fract *time_per_frame = &pctx->ctrls.time_per_frame;
drivers/media/platform/sti/hva/hva-h264.c:	u32 frame_num = pctx->stream_num;
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, frame_width, frame_height,
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, td->bit_rate, max_bitrate);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, td->cpb_buffer_size, max_cpb_buffer_size);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:		dev_err(dev, "%s   invalid framerate\n", pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:	td->addr_param_out = (u32)ctx->task->paddr +
drivers/media/platform/sti/hva/hva-h264.c:		dev_err(dev, "%s   invalid sps/pps size %d\n", pctx->name,
drivers/media/platform/sti/hva/hva-h264.c:		dev_err(dev, "%s   fail to get SEI nal\n", pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:	u32 frame_width = pctx->frameinfo.aligned_width;
drivers/media/platform/sti/hva/hva-h264.c:	u32 frame_height = pctx->frameinfo.aligned_height;
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name, hva->esram_size, size);
drivers/media/platform/sti/hva/hva-h264.c:			    &ctx->seq_info);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:			    &ctx->ref_frame);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:			    &ctx->rec_frame);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:			    &ctx->task);
drivers/media/platform/sti/hva/hva-h264.c:			pctx->name);
drivers/media/platform/sti/hva/hva-h264.c:	pctx->priv = (void *)ctx;
drivers/media/platform/sti/hva/hva-h264.c:	hva_mem_free(pctx, ctx->rec_frame);
drivers/media/platform/sti/hva/hva-h264.c:	hva_mem_free(pctx, ctx->ref_frame);
drivers/media/platform/sti/hva/hva-h264.c:	hva_mem_free(pctx, ctx->seq_info);
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_h264_ctx *ctx = (struct hva_h264_ctx *)pctx->priv;
drivers/media/platform/sti/hva/hva-h264.c:	if (ctx->seq_info)
drivers/media/platform/sti/hva/hva-h264.c:		hva_mem_free(pctx, ctx->seq_info);
drivers/media/platform/sti/hva/hva-h264.c:	if (ctx->ref_frame)
drivers/media/platform/sti/hva/hva-h264.c:		hva_mem_free(pctx, ctx->ref_frame);
drivers/media/platform/sti/hva/hva-h264.c:	if (ctx->rec_frame)
drivers/media/platform/sti/hva/hva-h264.c:		hva_mem_free(pctx, ctx->rec_frame);
drivers/media/platform/sti/hva/hva-h264.c:	if (ctx->task)
drivers/media/platform/sti/hva/hva-h264.c:		hva_mem_free(pctx, ctx->task);
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_h264_ctx *ctx = (struct hva_h264_ctx *)pctx->priv;
drivers/media/platform/sti/hva/hva-h264.c:	struct hva_h264_task *task = (struct hva_h264_task *)ctx->task->vaddr;
drivers/media/platform/sti/hva/hva-h264.c:	ret = hva_hw_execute_task(pctx, H264_ENC, ctx->task);
drivers/media/platform/sti/hva/hva-h264.c:	pctx->stream_num++;
drivers/media/platform/sti/hva/hva-h264.c:	tmp_frame = ctx->ref_frame;
drivers/media/platform/sti/hva/hva-h264.c:	ctx->ref_frame = ctx->rec_frame;
drivers/media/platform/sti/hva/hva-h264.c:	ctx->rec_frame = tmp_frame;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	mfc_debug(2, "Requested codec mode: %d\n", ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	mfc_write(dev, ctx->ctx.dma, S5P_FIMV_CONTEXT_MEM_ADDR_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	mfc_write(dev, ctx->ctx.size, S5P_FIMV_CONTEXT_MEM_SIZE_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:	if (ctx->state != MFCINST_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v6.c:		mfc_write(dev, ctx->inst_no, S5P_FIMV_INSTANCE_ID_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:		ret = wait_event_interruptible_timeout(ctx->queue,
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:				(ctx->int_cond && (ctx->int_type == command
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:			|| ctx->int_type == S5P_MFC_R2H_CMD_ERR_RET)),
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:		ret = wait_event_timeout(ctx->queue,
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:				(ctx->int_cond && (ctx->int_type == command
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:			|| ctx->int_type == S5P_MFC_R2H_CMD_ERR_RET)),
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:		mfc_err("Interrupt (ctx->int_type:%d, command:%d) timed out\n",
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:							ctx->int_type, command);
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:	mfc_debug(1, "Finished waiting (ctx->int_type:%d, command: %d)\n",
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:							ctx->int_type, command);
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:	if (ctx->int_type == S5P_MFC_R2H_CMD_ERR_RET)
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:	ctx->int_cond = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:	ctx->int_type = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_intr.c:	ctx->int_err = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->src_queue_cnt >= 1 && ctx->state == MFCINST_GOT_INST)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->src_queue_cnt >= 1 &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state == MFCINST_RUNNING &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->dst_queue_cnt >= ctx->pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_FINISHING &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->dst_queue_cnt >= ctx->pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->src_queue_cnt >= 1 &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state == MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->capture_state == QUEUE_BUFS_MMAPED)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if ((ctx->state == MFCINST_RES_CHANGE_INIT ||
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state == MFCINST_RES_CHANGE_FLUSH) &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_queue_cnt >= ctx->pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_RES_CHANGE_END &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_queue_cnt >= 1)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    (ctx->state == MFCINST_GOT_INST || ctx->state ==
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state >= MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state < MFCINST_ABORT) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->width = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->height = ctx->buf_height;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->pixelformat = ctx->dst_fmt->fourcc;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[0].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[0].sizeimage = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[1].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[1].sizeimage = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[0].bytesperline = ctx->dec_src_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->plane_fmt[0].sizeimage = ctx->dec_src_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->pixelformat = ctx->src_fmt->fourcc;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		pix_mp->num_planes = ctx->src_fmt->num_planes;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (vb2_is_streaming(&ctx->vq_src) || vb2_is_streaming(&ctx->vq_dst)) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_fmt = find_format(f, MFC_FMT_RAW);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_fmt = find_format(f, MFC_FMT_DEC);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->codec_mode = ctx->src_fmt->codec_mode;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		mfc_debug(2, "The codec number is: %d\n", ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			pix_mp->plane_fmt[0].sizeimage = ctx->dec_src_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->dec_src_buf_size = buf_size->cpb;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->dec_src_buf_size = pix_mp->plane_fmt[0].sizeimage;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state = MFCINST_INIT;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_reqbufs(&ctx->vq_src, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_bufs_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->output_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	} else if (ctx->output_state == QUEUE_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		WARN_ON(ctx->src_bufs_cnt != 0);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->state != MFCINST_INIT) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_reqbufs(&ctx->vq_src, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			vb2_reqbufs(&ctx->vq_src, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->output_state = QUEUE_BUFS_REQUESTED;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_bufs_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	} else if (ctx->capture_state == QUEUE_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		WARN_ON(ctx->dst_bufs_cnt != 0);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->capture_state = QUEUE_BUFS_REQUESTED;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->total_dpb_count = reqbufs->count;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->capture_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		WARN_ON(ctx->dst_bufs_cnt != ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->capture_state = QUEUE_BUFS_MMAPED;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	mfc_debug(2, "State: %d, buf->type: %d\n", ctx->state, buf->type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_GOT_INST &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_querybuf(&ctx->vq_src, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	} else if (ctx->state == MFCINST_RUNNING &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_querybuf(&ctx->vq_dst, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_ERROR) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_qbuf(&ctx->vq_src, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_qbuf(&ctx->vq_dst, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_ERROR) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_dqbuf(&ctx->vq_src, buf, file->f_flags & O_NONBLOCK);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_dqbuf(&ctx->vq_dst, buf, file->f_flags & O_NONBLOCK);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->state == MFCINST_FINISHED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		    (ctx->dst_bufs[buf->index].flags & MFC_BUF_FLAG_EOS))
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			v4l2_event_queue_fh(&ctx->fh, &ev);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_expbuf(&ctx->vq_src, eb);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_expbuf(&ctx->vq_dst, eb);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_streamon(&ctx->vq_src, type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ret = vb2_streamon(&ctx->vq_dst, type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_streamoff(&ctx->vq_src, type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return vb2_streamoff(&ctx->vq_dst, type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->display_delay = ctrl->val;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->display_delay_enable = ctrl->val;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->loop_filter_mpeg4 = ctrl->val;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->slice_interface = ctrl->val;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->state >= MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		    ctx->state < MFCINST_ABORT) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctrl->val = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		} else if (ctx->state != MFCINST_INIT &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:				ctx->state != MFCINST_RES_CHANGE_END) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->state >= MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		    ctx->state < MFCINST_ABORT) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctrl->val = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state != MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state != MFCINST_RUNNING &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state != MFCINST_FINISHING &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	    ctx->state != MFCINST_FINISHED) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_H264) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		cr->c.width = ctx->img_width - left - right;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		cr->c.height = ctx->img_height - top - bottom;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->buf_width, ctx->buf_height);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		cr->c.width = ctx->img_width;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		cr->c.height = ctx->img_height;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			"fh=%d\n", cr->c.width,	cr->c.height, ctx->buf_width,
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:							ctx->buf_height);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (!vb2_is_streaming(&ctx->vq_src))
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			buf = list_entry(ctx->src_queue.prev,
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:				ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_INIT &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	} else if (ctx->state == MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (*buf_count < ctx->pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			*buf_count = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (*buf_count > ctx->pb_count + MFC_MAX_EXTRA_DPB)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			*buf_count = ctx->pb_count + MFC_MAX_EXTRA_DPB;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:							ctx->state, vq->type);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		psize[0] = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		psize[1] = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			alloc_devs[0] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			alloc_devs[0] = ctx->dev->mem_dev_r;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		alloc_devs[1] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		   ctx->state == MFCINST_INIT) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		psize[0] = ctx->dec_src_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		alloc_devs[0] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->capture_state == QUEUE_BUFS_MMAPED)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		for (i = 0; i < ctx->dst_fmt->num_planes; i++) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (vb2_plane_size(vb, 0) < ctx->luma_size ||
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			vb2_plane_size(vb, 1) < ctx->chroma_size) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_bufs[i].b = vbuf;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_bufs[i].cookie.raw.luma =
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_bufs[i].cookie.raw.chroma =
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_bufs_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (vb2_plane_size(vb, 0) < ctx->dec_src_buf_size) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_bufs[i].b = vbuf;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_bufs[i].cookie.stream =
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_bufs_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->state == MFCINST_FINISHING ||
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state == MFCINST_FINISHED)
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state = MFCINST_RUNNING;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if ((ctx->state == MFCINST_FINISHING ||
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state ==  MFCINST_RUNNING) &&
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		dev->curr_ctx == ctx->num && dev->hw_lock) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state = MFCINST_ABORT;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		s5p_mfc_cleanup_queue(&ctx->dst_queue, &ctx->vq_dst);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		INIT_LIST_HEAD(&ctx->dst_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dpb_flush_flag = 1;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dec_dst_flag = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (IS_MFCV6_PLUS(dev) && (ctx->state == MFCINST_RUNNING)) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->state = MFCINST_FLUSH;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		s5p_mfc_cleanup_queue(&ctx->src_queue, &ctx->vq_src);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		INIT_LIST_HEAD(&ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->state = MFCINST_RUNNING;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		mfc_buf = &ctx->src_bufs[vb->index];
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		list_add_tail(&mfc_buf->list, &ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->src_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		mfc_buf = &ctx->dst_bufs[vb->index];
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		set_bit(vb->index, &ctx->dec_dst_flag);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		list_add_tail(&mfc_buf->list, &ctx->dst_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->dst_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, NUM_CTRLS);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		return ctx->ctrl_handler.error;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->ctrls[i] = v4l2_ctrl_new_custom(&ctx->ctrl_handler,
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->ctrls[i] = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			return ctx->ctrl_handler.error;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		if (controls[i].is_volatile && ctx->ctrls[i])
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->ctrls[i]->flags |= V4L2_CTRL_FLAG_VOLATILE;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:		ctx->ctrls[i] = NULL;
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	ctx->src_fmt = find_format(&f, MFC_FMT_DEC);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	if (IS_MFCV8(ctx->dev))
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	else if (IS_MFCV6_PLUS(ctx->dev))
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:	ctx->dst_fmt = find_format(&f, MFC_FMT_RAW);
drivers/media/platform/s5p-mfc/s5p_mfc_dec.c:			ctx->src_fmt, ctx->dst_fmt);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		  ctx->src_queue_cnt, ctx->dst_queue_cnt, ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->state == MFCINST_GOT_INST && ctx->dst_queue_cnt >= 1)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if ((ctx->state == MFCINST_RUNNING ||
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state == MFCINST_HEAD_PRODUCED) &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_queue_cnt >= 1 && ctx->dst_queue_cnt >= 1)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->state == MFCINST_FINISHING &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_queue_cnt >= 1)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	while (!list_empty(&ctx->ref_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mb_entry = list_entry((&ctx->ref_queue)->next,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->ref_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		list_add_tail(&mb_entry->list, &ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		  ctx->src_queue_cnt, ctx->ref_queue_cnt);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	INIT_LIST_HEAD(&ctx->ref_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	ctx->ref_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (!list_empty(&ctx->dst_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			dst_mb = list_entry(ctx->dst_queue.next,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->dst_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state = MFCINST_RUNNING;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->pb_count < enc_pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->pb_count = enc_pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state = MFCINST_HEAD_PRODUCED;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	src_mb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		list_for_each_entry(mb_entry, &ctx->src_queue, list) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->src_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		list_for_each_entry(mb_entry, &ctx->ref_queue, list) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->ref_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if ((ctx->src_queue_cnt > 0) && (ctx->state == MFCINST_RUNNING)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mb_entry = list_entry(ctx->src_queue.next, struct s5p_mfc_buf,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->src_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			list_add_tail(&mb_entry->list, &ctx->ref_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->ref_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		  ctx->src_queue_cnt, ctx->ref_queue_cnt);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if ((ctx->dst_queue_cnt > 0) && (strm_size > 0)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mb_entry = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if ((ctx->src_queue_cnt == 0) || (ctx->dst_queue_cnt == 0))
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	mfc_debug(2, "f->type = %d ctx->state = %d\n", f->type, ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->pixelformat = ctx->dst_fmt->fourcc;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->num_planes = ctx->dst_fmt->num_planes;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].bytesperline = ctx->enc_dst_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].sizeimage = ctx->enc_dst_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->width = ctx->img_width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->height = ctx->img_height;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->pixelformat = ctx->src_fmt->fourcc;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->num_planes = ctx->src_fmt->num_planes;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].sizeimage = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[1].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[1].sizeimage = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->vq_src.streaming || ctx->vq_dst.streaming) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_fmt = find_format(f, MFC_FMT_ENC);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state = MFCINST_INIT;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->codec_mode = ctx->dst_fmt->codec_mode;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->enc_dst_buf_size =	pix_fmt_mp->plane_fmt[0].sizeimage;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_bufs_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->capture_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_fmt = find_format(f, MFC_FMT_RAW);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->img_width = pix_fmt_mp->width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->img_height = pix_fmt_mp->height;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mfc_debug(2, "codec number: %d\n", ctx->src_fmt->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->img_width, ctx->img_height);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].sizeimage = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[0].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[1].sizeimage = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		pix_fmt_mp->plane_fmt[1].bytesperline = ctx->buf_width;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_bufs_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->output_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ret = vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->capture_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->capture_state != QUEUE_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:							ctx->capture_state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->capture_state = QUEUE_BUFS_REQUESTED;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = s5p_mfc_hw_call(ctx->dev->mfc_ops,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ret = vb2_reqbufs(&ctx->vq_dst, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ret = vb2_reqbufs(&ctx->vq_src, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->output_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->output_state != QUEUE_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:							ctx->output_state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			if (ctx->pb_count &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				(reqbufs->count < ctx->pb_count)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				reqbufs->count = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:						ctx->pb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->pb_count = reqbufs->count;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_reqbufs(&ctx->vq_src, reqbufs);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->output_state = QUEUE_BUFS_REQUESTED;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->state != MFCINST_GOT_INST) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			mfc_err("invalid context state: %d\n", ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_querybuf(&ctx->vq_dst, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_querybuf(&ctx->vq_src, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->state == MFCINST_ERROR) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->state == MFCINST_FINISHING) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_qbuf(&ctx->vq_src, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_qbuf(&ctx->vq_dst, buf);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->state == MFCINST_ERROR) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_dqbuf(&ctx->vq_src, buf, file->f_flags & O_NONBLOCK);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = vb2_dqbuf(&ctx->vq_dst, buf, file->f_flags & O_NONBLOCK);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ret == 0 && ctx->state == MFCINST_FINISHED
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					&& list_empty(&ctx->vq_dst.done_list))
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			v4l2_event_queue_fh(&ctx->fh, &ev);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_expbuf(&ctx->vq_src, eb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_expbuf(&ctx->vq_dst, eb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_streamon(&ctx->vq_src, type);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_streamon(&ctx->vq_dst, type);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_streamoff(&ctx->vq_src, type);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return vb2_streamoff(&ctx->vq_dst, type);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->force_frame_type = ctrl->val;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->force_frame_type =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->state >= MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		    ctx->state < MFCINST_ABORT) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctrl->val = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		} else if (ctx->state != MFCINST_INIT) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->state >= MFCINST_HEAD_PARSED &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		    ctx->state < MFCINST_ABORT) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctrl->val = ctx->pb_count;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->enc_params.rc_framerate_num =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->enc_params.rc_framerate_denom =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					ctx->enc_params.rc_framerate_num;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					ctx->enc_params.rc_framerate_denom;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (!ctx->vq_src.streaming)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			buf = list_entry(ctx->src_queue.prev,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->state != MFCINST_GOT_INST) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			mfc_err("invalid state: %d\n", ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->dst_fmt)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			*plane_count = ctx->dst_fmt->num_planes;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		psize[0] = ctx->enc_dst_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		alloc_devs[0] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->src_fmt)
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			*plane_count = ctx->src_fmt->num_planes;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		psize[0] = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		psize[1] = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			alloc_devs[0] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			alloc_devs[1] = ctx->dev->mem_dev_l;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			alloc_devs[0] = ctx->dev->mem_dev_r;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			alloc_devs[1] = ctx->dev->mem_dev_r;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = check_vb_with_fmt(ctx->dst_fmt, vb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_bufs[i].b = vbuf;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_bufs[i].cookie.stream =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_bufs_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = check_vb_with_fmt(ctx->src_fmt, vb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_bufs[i].b = vbuf;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_bufs[i].cookie.raw.luma =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_bufs[i].cookie.raw.chroma =
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_bufs_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = check_vb_with_fmt(ctx->dst_fmt, vb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			vb2_plane_size(vb, 0), ctx->enc_dst_buf_size);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (vb2_plane_size(vb, 0) < ctx->enc_dst_buf_size) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ret = check_vb_with_fmt(ctx->src_fmt, vb);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			vb2_plane_size(vb, 0), ctx->luma_size);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			vb2_plane_size(vb, 1), ctx->chroma_size);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (vb2_plane_size(vb, 0) < ctx->luma_size ||
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		    vb2_plane_size(vb, 1) < ctx->chroma_size) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if ((ctx->state == MFCINST_GOT_INST) &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			(dev->curr_ctx == ctx->num) && dev->hw_lock) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->src_bufs_cnt < ctx->pb_count) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					ctx->pb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if ((ctx->state == MFCINST_FINISHING ||
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state == MFCINST_RUNNING) &&
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		dev->curr_ctx == ctx->num && dev->hw_lock) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->state = MFCINST_ABORT;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	ctx->state = MFCINST_FINISHED;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		s5p_mfc_cleanup_queue(&ctx->dst_queue, &ctx->vq_dst);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		INIT_LIST_HEAD(&ctx->dst_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		s5p_mfc_cleanup_queue(&ctx->src_queue, &ctx->vq_src);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		INIT_LIST_HEAD(&ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->state == MFCINST_ERROR) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mfc_buf = &ctx->dst_bufs[vb->index];
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		list_add_tail(&mfc_buf->list, &ctx->dst_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->dst_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		mfc_buf = &ctx->src_bufs[vb->index];
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		list_add_tail(&mfc_buf->list, &ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->src_queue_cnt++;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, NUM_CTRLS);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		return ctx->ctrl_handler.error;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->ctrls[i] = v4l2_ctrl_new_custom(&ctx->ctrl_handler,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->ctrls[i] = v4l2_ctrl_new_std_menu(
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					&ctx->ctrl_handler,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:				ctx->ctrls[i] = v4l2_ctrl_new_std(
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:					&ctx->ctrl_handler,
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			return ctx->ctrl_handler.error;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		if (controls[i].is_volatile && ctx->ctrls[i])
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:			ctx->ctrls[i]->flags |= V4L2_CTRL_FLAG_VOLATILE;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:		ctx->ctrls[i] = NULL;
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	ctx->src_fmt = find_format(&f, MFC_FMT_RAW);
drivers/media/platform/s5p-mfc/s5p_mfc_enc.c:	ctx->dst_fmt = find_format(&f, MFC_FMT_ENC);
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	if (ctx->type == MFCINST_DECODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	mfc_debug(2, "Got instance number: %d\n", ctx->inst_no);
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	if (ctx->type == MFCINST_DECODER)
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	ctx->state = MFCINST_RETURN_INST;
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	if (ctx->type == MFCINST_DECODER)
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	ctx->inst_no = MFC_NO_INSTANCE_SET;
drivers/media/platform/s5p-mfc/s5p_mfc_ctrl.c:	ctx->state = MFCINST_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	__clear_bit(ctx->num, &dev->ctx_work_bits);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	__set_bit(ctx->num, &dev->ctx_work_bits);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	__clear_bit(ctx->num, &dev->ctx_work_bits);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	__set_bit(ctx->num, &dev->ctx_work_bits);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_cond = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_type = reason;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_err = err;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	wake_up(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		s5p_mfc_cleanup_queue(&ctx->dst_queue, &ctx->vq_dst);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		s5p_mfc_cleanup_queue(&ctx->src_queue, &ctx->vq_src);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->state = MFCINST_FINISHED;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->sequence++;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	while (!list_empty(&ctx->dst_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		dst_buf = list_entry(ctx->dst_queue.next,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->dst_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		dst_buf->b->sequence = (ctx->sequence++);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->dec_dst_flag &= ~(1 << dst_buf->b->vb2_buf.index);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	src_buf = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	list_for_each_entry(dst_buf, &ctx->dst_queue, list) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (!ctx->after_packed_pb)
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->sequence++;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->after_packed_pb = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->sequence++;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	list_for_each_entry(dst_buf, &ctx->dst_queue, list) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->dst_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			dst_buf->b->sequence = ctx->sequence;
drivers/media/platform/s5p-mfc/s5p_mfc.c:						ctx->luma_size);
drivers/media/platform/s5p-mfc/s5p_mfc.c:						ctx->chroma_size);
drivers/media/platform/s5p-mfc/s5p_mfc.c:							&ctx->dec_dst_flag);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if (ctx->state == MFCINST_RES_CHANGE_INIT)
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_RES_CHANGE_FLUSH;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_RES_CHANGE_INIT;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if (ctx->dpb_flush_flag)
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->dpb_flush_flag = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->state == MFCINST_RES_CHANGE_FLUSH) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->state = MFCINST_RES_CHANGE_END;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			v4l2_event_queue_fh(&ctx->fh, &ev_src_ch);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		&& !list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		src_buf = list_entry(ctx->src_queue.next, struct s5p_mfc_buf,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->consumed_stream += s5p_mfc_hw_call(dev->mfc_ops,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->codec_mode != S5P_MFC_CODEC_H264_DEC &&
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->codec_mode != S5P_MFC_CODEC_VP8_DEC &&
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->consumed_stream + STUFF_BYTE <
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->after_packed_pb = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->consumed_stream = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:				ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->src_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if ((ctx->src_queue_cnt == 0 && ctx->state != MFCINST_FINISHING)
drivers/media/platform/s5p-mfc/s5p_mfc.c:				    || ctx->dst_queue_cnt < ctx->pb_count)
drivers/media/platform/s5p-mfc/s5p_mfc.c:		switch (ctx->state) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			s5p_mfc_cleanup_queue(&ctx->dst_queue, &ctx->vq_dst);
drivers/media/platform/s5p-mfc/s5p_mfc.c:			s5p_mfc_cleanup_queue(&ctx->src_queue, &ctx->vq_src);
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if (ctx->c_ops->post_seq_start) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->c_ops->post_seq_start(ctx))
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->img_width = s5p_mfc_hw_call(dev->mfc_ops, get_img_width,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->img_height = s5p_mfc_hw_call(dev->mfc_ops, get_img_height,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->pb_count = s5p_mfc_hw_call(dev->mfc_ops, get_dpb_count,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->mv_count = s5p_mfc_hw_call(dev->mfc_ops, get_mv_count,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->img_width == 0 || ctx->img_height == 0)
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->state = MFCINST_HEAD_PARSED;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if ((ctx->codec_mode == S5P_MFC_CODEC_H264_DEC ||
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->codec_mode == S5P_MFC_CODEC_H264_MVC_DEC) &&
drivers/media/platform/s5p-mfc/s5p_mfc.c:				!list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			src_buf = list_entry(ctx->src_queue.next,
drivers/media/platform/s5p-mfc/s5p_mfc.c:				ctx->head_processed = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:				ctx->head_processed = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->head_processed = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_type = reason;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_err = err;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_cond = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_RUNNING;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (!ctx->dpb_flush_flag && ctx->head_processed) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			if (!list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:				src_buf = list_entry(ctx->src_queue.next,
drivers/media/platform/s5p-mfc/s5p_mfc.c:				ctx->src_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc.c:			ctx->dpb_flush_flag = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		wake_up(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		wake_up(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->state = MFCINST_FINISHED;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if (!list_empty(&ctx->dst_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		mb_entry = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf,
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->dst_queue_cnt--;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	wake_up(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->state == MFCINST_RUNNING &&
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->c_ops->post_frame_start) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:			if (ctx->c_ops->post_frame_start(ctx))
drivers/media/platform/s5p-mfc/s5p_mfc.c:			if (ctx->state == MFCINST_FINISHING &&
drivers/media/platform/s5p-mfc/s5p_mfc.c:						list_empty(&ctx->ref_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->inst_no = s5p_mfc_hw_call(dev->mfc_ops, get_inst_no, dev);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_GOT_INST;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->inst_no = MFC_NO_INSTANCE_SET;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->int_type = reason;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->int_err = err;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->state = MFCINST_RUNNING;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_type = reason;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_err = err;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->int_cond = 1;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	wake_up(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	v4l2_fh_init(&ctx->fh, vdev);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	file->private_data = &ctx->fh;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->dev = dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	INIT_LIST_HEAD(&ctx->src_queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	INIT_LIST_HEAD(&ctx->dst_queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->src_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->dst_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->num = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	while (dev->ctx[ctx->num]) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->num++;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->num >= MFC_NUM_CONTEXTS) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:	dev->ctx[ctx->num] = ctx;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->type = MFCINST_DECODER;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->c_ops = get_dec_codec_ops();
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->type = MFCINST_ENCODER;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->c_ops = get_enc_codec_ops();
drivers/media/platform/s5p-mfc/s5p_mfc.c:		INIT_LIST_HEAD(&ctx->ref_queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->ref_queue_cnt = 0;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	ctx->inst_no = MFC_NO_INSTANCE_SET;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	q = &ctx->vq_dst;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	q->drv_priv = &ctx->fh;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	q = &ctx->vq_src;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	q->drv_priv = &ctx->fh;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	init_waitqueue_head(&ctx->queue);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	dev->ctx[ctx->num] = NULL;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	vb2_queue_release(&ctx->vq_src);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	vb2_queue_release(&ctx->vq_dst);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (ctx->state != MFCINST_FREE && ctx->state != MFCINST_INIT) {
drivers/media/platform/s5p-mfc/s5p_mfc.c:		if (dev->curr_ctx == ctx->num)
drivers/media/platform/s5p-mfc/s5p_mfc.c:		dev->ctx[ctx->num] = NULL;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		v4l2_fh_exit(&ctx->fh);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	src_q = &ctx->vq_src;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	dst_q = &ctx->vq_dst;
drivers/media/platform/s5p-mfc/s5p_mfc.c:	poll_wait(file, &ctx->fh.wait, wait);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	if (v4l2_event_pending(&ctx->fh))
drivers/media/platform/s5p-mfc/s5p_mfc.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ret = vb2_mmap(&ctx->vq_src, vma);
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ret = vb2_mmap(&ctx->vq_dst, vma);
drivers/media/platform/s5p-mfc/s5p_mfc.c:	 * and s5p_mfc_release() and s5p_mfc_release() accessing ctx->dev
drivers/media/platform/s5p-mfc/s5p_mfc.c:		/* clear ctx->dev */
drivers/media/platform/s5p-mfc/s5p_mfc.c:		ctx->dev = NULL;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->dsc.size = buf_size->dsc;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ret =  s5p_mfc_alloc_priv_buf(dev->mem_dev_l, dev->bank1, &ctx->dsc);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	BUG_ON(ctx->dsc.dma & ((1 << MFC_BANK1_ALIGN_ORDER) - 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	memset(ctx->dsc.virt, 0, ctx->dsc.size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->dsc);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->type == MFCINST_DECODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			  ctx->luma_size, ctx->chroma_size, ctx->mv_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_debug(2, "Totals bufs: %d\n", ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	} else if (ctx->type == MFCINST_ENCODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		enc_ref_y_size = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN(ctx->img_height, S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		if (ctx->codec_mode == S5P_MFC_CODEC_H264_ENC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			enc_ref_c_size = ALIGN(ctx->img_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:						* ALIGN(ctx->img_height >> 1,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			guard_width = ALIGN(ctx->img_width + 16,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			guard_height = ALIGN((ctx->img_height >> 1) + 4,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = ctx->total_dpb_count * ctx->mv_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank1.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->bank2.size = (enc_ref_y_size * 2) +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->bank1.size > 0) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:					     &ctx->bank1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		BUG_ON(ctx->bank1.dma & ((1 << MFC_BANK1_ALIGN_ORDER) - 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->bank2.size > 0) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:					     &ctx->bank2);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->bank1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		BUG_ON(ctx->bank2.dma & ((1 << MFC_BANK2_ALIGN_ORDER) - 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->bank1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_r, &ctx->bank2);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC ||
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->codec_mode == S5P_MFC_CODEC_H264_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->ctx.size = buf_size->h264_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->ctx.size = buf_size->non_h264_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ret = s5p_mfc_alloc_priv_buf(dev->mem_dev_l, dev->bank1, &ctx->ctx);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->ctx.ofs = OFFSETA(ctx->ctx.dma);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	memset(ctx->ctx.virt, 0, ctx->ctx.size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->shm.size = buf_size->shm;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ret = s5p_mfc_alloc_priv_buf(dev->mem_dev_l, dev->bank1, &ctx->shm);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		s5p_mfc_release_priv_buf(dev->mem_dev_l, &ctx->ctx);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->shm.ofs = ctx->shm.dma - dev->bank1;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	BUG_ON(ctx->shm.ofs & ((1 << MFC_BANK1_ALIGN_ORDER) - 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	memset(ctx->shm.virt, 0, buf_size->shm);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->ctx);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->shm);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	*(u32 *)(ctx->shm.virt + ofs) = data;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	return *(u32 *)(ctx->shm.virt + ofs);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->buf_width = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	ctx->buf_height = ALIGN(ctx->img_height, S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->img_width,	ctx->img_height, ctx->buf_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->buf_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(ctx->buf_width * ctx->buf_height,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size = ALIGN(ctx->buf_width *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:				ALIGN((ctx->img_height >> 1),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->mv_size = ALIGN(ctx->buf_width *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:				ALIGN((ctx->buf_height >> 2),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->img_width + 24, S5P_FIMV_NV12MT_HALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->img_height + 16, S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(guard_width * guard_height,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->img_width + 16, S5P_FIMV_NV12MT_HALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN((ctx->img_height >> 1) + 4,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size = ALIGN(guard_width * guard_height,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->mv_size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12M) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->buf_width = ALIGN(ctx->img_width, S5P_FIMV_NV12M_HALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(ctx->img_width, S5P_FIMV_NV12M_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN(ctx->img_height, S5P_FIMV_NV12M_LVALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size = ALIGN(ctx->img_width, S5P_FIMV_NV12M_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN((ctx->img_height >> 1), S5P_FIMV_NV12M_CVALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(ctx->luma_size, S5P_FIMV_NV12M_SALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->chroma_size, S5P_FIMV_NV12M_SALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	} else if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12MT) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->buf_width = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN(ctx->img_height, S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN((ctx->img_height >> 1), S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->luma_size = ALIGN(ctx->luma_size, S5P_FIMV_NV12MT_SALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->chroma_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ALIGN(ctx->chroma_size, S5P_FIMV_NV12MT_SALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, OFFSETA(ctx->dsc.dma), S5P_FIMV_SI_CH0_DESC_ADR);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->shm.ofs, S5P_FIMV_SI_CH0_HOST_WR_ADR);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->dec_src_buf_size, S5P_FIMV_SI_CH0_CPB_SIZE);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_addr1 = ctx->bank1.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_size1 = ctx->bank1.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_addr2 = ctx->bank2.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_size2 = ctx->bank2.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->total_dpb_count | dpb,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	frame_size_lu = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	frame_size_ch = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	frame_size_mv = ctx->mv_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	for (i = 0; i < ctx->total_dpb_count; i++) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:					ctx->dst_bufs[i].cookie.raw.luma);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_write(dev, OFFSETB(ctx->dst_bufs[i].cookie.raw.luma),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:					ctx->dst_bufs[i].cookie.raw.chroma);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_write(dev, OFFSETA(ctx->dst_bufs[i].cookie.raw.chroma),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			buf_size1,  buf_size2, ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:					<< S5P_FIMV_CH_SHIFT) | (ctx->inst_no),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_addr1 = ctx->bank1.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_size1 = ctx->bank1.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_addr2 = ctx->bank2.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	buf_size2 = ctx->bank2.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	enc_ref_y_size = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		* ALIGN(ctx->img_height, S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_ENC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		enc_ref_c_size = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			* ALIGN((ctx->img_height >> 1), S5P_FIMV_NV12MT_VALIGN);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		guard_width = ALIGN(ctx->img_width + 16,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		guard_height = ALIGN((ctx->img_height >> 1) + 4,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->img_width, S5P_FIMV_ENC_HSIZE_PX);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->img_height, S5P_FIMV_ENC_VSIZE_PX);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12M)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	else if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12MT)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_write(dev, ctx->img_height >> 1, S5P_FIMV_ENC_VSIZE_PX);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_MPEG4_DEC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_write(dev, ctx->loop_filter_mpeg4, S5P_FIMV_ENC_LF_CTRL);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ((ctx->slice_interface & S5P_FIMV_SLICE_INT_MASK) <<
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		S5P_FIMV_SLICE_INT_SHIFT) | (ctx->display_delay_enable <<
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		S5P_FIMV_DDELAY_ENA_SHIFT) | ((ctx->display_delay &
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:				| (ctx->inst_no), S5P_FIMV_SI_CH0_INST_ID);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	mfc_write(dev, ctx->dec_dst_flag, S5P_FIMV_SI_CH0_RELEASE_BUF);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	s5p_mfc_set_flush(ctx, ctx->dpb_flush_flag);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		S5P_FIMV_CH_SHIFT) | (ctx->inst_no), S5P_FIMV_SI_CH0_INST_ID);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		S5P_FIMV_CH_SHIFT) | (ctx->inst_no), S5P_FIMV_SI_CH0_INST_ID);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		S5P_FIMV_CH_MASK) << S5P_FIMV_CH_SHIFT) | (ctx->inst_no),
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	else if (ctx->codec_mode == S5P_MFC_CODEC_MPEG4_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	else if (ctx->codec_mode == S5P_MFC_CODEC_H263_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		(ctx->inst_no), S5P_FIMV_SI_CH0_INST_ID);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12M)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	else if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12MT)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->state == MFCINST_FINISHING)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:				| (ctx->inst_no), S5P_FIMV_SI_CH0_INST_ID);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->state == MFCINST_FINISHING) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	temp_vb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->consumed_stream, temp_vb->b->vb2_buf.planes[0].bytesused);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_debug(2, "Setting ctx->state to FINISHING\n");
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (list_empty(&ctx->src_queue) && ctx->state != MFCINST_FINISHING) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (list_empty(&ctx->dst_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		src_mb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:				ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		  src_mb ? src_mb->b->vb2_buf.index : -1, ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	temp_vb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->capture_state != QUEUE_BUFS_MMAPED) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	temp_vb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	if (ctx->type == MFCINST_DECODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		switch (ctx->state) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:			ctx->capture_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:	} else if (ctx->type == MFCINST_ENCODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		switch (ctx->state) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v5.c:		mfc_err("Invalid context type: %d\n", ctx->type);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mb_width = MB_WIDTH(ctx->img_width);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mb_height = MB_HEIGHT(ctx->img_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->type == MFCINST_DECODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			  ctx->luma_size, ctx->chroma_size, ctx->mv_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		mfc_debug(2, "Totals bufs: %d\n", ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	} else if (ctx->type == MFCINST_ENCODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->tmv_buffer_size = S5P_FIMV_NUM_TMV_BUFFERS_V6 *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->tmv_buffer_size = S5P_FIMV_NUM_TMV_BUFFERS_V6 *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->luma_dpb_size = ALIGN((mb_width * mb_height) *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->chroma_dpb_size = ALIGN((mb_width * mb_height) *
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->me_buffer_size = ALIGN(S5P_FIMV_ME_BUFFER_SIZE_V8(
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:						ctx->img_width, ctx->img_height,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->me_buffer_size = ALIGN(S5P_FIMV_ME_BUFFER_SIZE_V6(
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:						ctx->img_width, ctx->img_height,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			  ctx->luma_dpb_size, ctx->chroma_dpb_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			(ctx->mv_count * ctx->mv_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size = ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size = ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size = ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size = ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size + ctx->tmv_buffer_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			(ctx->pb_count * (ctx->luma_dpb_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->chroma_dpb_size + ctx->me_buffer_size));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size + ctx->tmv_buffer_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			(ctx->pb_count * (ctx->luma_dpb_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->chroma_dpb_size + ctx->me_buffer_size));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->scratch_buf_size = ALIGN(ctx->scratch_buf_size,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank1.size =
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->scratch_buf_size + ctx->tmv_buffer_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			(ctx->pb_count * (ctx->luma_dpb_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->chroma_dpb_size + ctx->me_buffer_size));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->bank2.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->bank1.size > 0) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:					     &ctx->bank1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		BUG_ON(ctx->bank1.dma & ((1 << MFC_BANK1_ALIGN_ORDER) - 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->bank1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->ctx.size = buf_size->h264_dec_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->ctx.size = buf_size->other_dec_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->ctx.size = buf_size->h264_enc_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->ctx.size = buf_size->other_enc_ctx;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->ctx.size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		mfc_err("Codec type(%d) should be checked!\n", ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ret = s5p_mfc_alloc_priv_buf(dev->mem_dev_l, dev->bank1, &ctx->ctx);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	memset(ctx->ctx.virt, 0, ctx->ctx.size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	s5p_mfc_release_priv_buf(ctx->dev->mem_dev_l, &ctx->ctx);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->buf_width = ALIGN(ctx->img_width, S5P_FIMV_NV12MT_HALIGN_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->buf_height = ALIGN(ctx->img_height, S5P_FIMV_NV12MT_VALIGN_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			"buffer dimensions: %dx%d\n", ctx->img_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->img_height, ctx->buf_width, ctx->buf_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->luma_size = calc_plane(ctx->img_width, ctx->img_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->chroma_size = calc_plane(ctx->img_width, (ctx->img_height >> 1));
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (IS_MFCV8(ctx->dev)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->luma_size += S5P_FIMV_D_ALIGN_PLANE_SIZE_V8;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->chroma_size += S5P_FIMV_D_ALIGN_PLANE_SIZE_V8;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC ||
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->codec_mode == S5P_MFC_CODEC_H264_MVC_DEC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->mv_size = S5P_MFC_DEC_MV_SIZE_V6(ctx->img_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:				ctx->img_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->mv_size = ALIGN(ctx->mv_size, 16);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->mv_size = 0;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mb_width = MB_WIDTH(ctx->img_width);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mb_height = MB_HEIGHT(ctx->img_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->buf_width = ALIGN(ctx->img_width, S5P_FIMV_NV12M_HALIGN_V6);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->luma_size = ALIGN((mb_width * mb_height) * 256, 256);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->chroma_size = ALIGN((mb_width * mb_height) * 128, 256);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (IS_MFCV7_PLUS(ctx->dev)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->luma_size += MFC_LUMA_PAD_BYTES_V7;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->chroma_size += MFC_CHROMA_PAD_BYTES_V7;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->inst_no, buf_addr, strm_size, strm_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 = ctx->bank1.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_size1 = ctx->bank1.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mfc_debug(2, "Total DPB COUNT: %d\n", ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mfc_debug(2, "Setting display delay to %d\n", ctx->display_delay);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->total_dpb_count, mfc_regs->d_num_dpb);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->luma_size, mfc_regs->d_first_plane_dpb_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->chroma_size, mfc_regs->d_second_plane_dpb_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->scratch_buf_size, mfc_regs->d_scratch_buffer_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_width,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 += ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_size1 -= ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_FIMV_CODEC_H264_DEC ||
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->codec_mode == S5P_FIMV_CODEC_H264_MVC_DEC){
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->mv_size, mfc_regs->d_mv_buffer_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->mv_count, mfc_regs->d_num_mv);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	frame_size = ctx->luma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	frame_size_ch = ctx->chroma_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	frame_size_mv = ctx->mv_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	for (i = 0; i < ctx->total_dpb_count; i++) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:					ctx->dst_bufs[i].cookie.raw.luma);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->dst_bufs[i].cookie.raw.luma,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:					ctx->dst_bufs[i].cookie.raw.chroma);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->dst_bufs[i].cookie.raw.chroma,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_DEC ||
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->codec_mode == S5P_MFC_CODEC_H264_MVC_DEC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		for (i = 0; i < ctx->mv_count; i++) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			buf_addr1, buf_size1, ctx->total_dpb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 = ctx->bank1.dma;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_size1 = ctx->bank1.size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	for (i = 0; i < ctx->pb_count; i++) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		buf_addr1 += ctx->luma_dpb_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		buf_addr1 += ctx->chroma_dpb_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		buf_addr1 += ctx->me_buffer_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		buf_size1 -= (ctx->luma_dpb_size + ctx->chroma_dpb_size +
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->me_buffer_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->scratch_buf_size, mfc_regs->e_scratch_buffer_size);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 += ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_size1 -= ctx->scratch_buf_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 += ctx->tmv_buffer_size >> 1;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_addr1 += ctx->tmv_buffer_size >> 1;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	buf_size1 -= ctx->tmv_buffer_size;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			buf_addr1, buf_size1, ctx->pb_count);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->slice_mode, mfc_regs->e_mslice_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->slice_mode == V4L2_MPEG_VIDEO_MULTI_SICE_MODE_MAX_MB) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->slice_size.mb, mfc_regs->e_mslice_size_mb);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	} else if (ctx->slice_mode ==
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->slice_size.bits, mfc_regs->e_mslice_size_bits);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->img_width, mfc_regs->e_frame_width); /* 16 align */
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->img_height, mfc_regs->e_frame_height); /* 16 align */
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->img_width, mfc_regs->e_cropped_frame_width);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->img_height, mfc_regs->e_cropped_frame_height);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	ctx->slice_mode = p->slice_mode;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->slice_size.mb = p->slice_mb;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->slice_size.bits = p->slice_bit;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12M) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	} else if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV21M) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	} else if (ctx->src_fmt->fourcc == V4L2_PIX_FMT_NV12MT_16X16) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_height >> 1,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_height >> 1,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mfc_debug(2, "InstNo: %d/%d\n", ctx->inst_no,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->display_delay_enable) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->display_delay, mfc_regs->d_display_delay);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_MFC_CODEC_MPEG4_DEC) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:				ctx->loop_filter_mpeg4);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		reg |= (ctx->loop_filter_mpeg4 <<
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->dst_fmt->fourcc == V4L2_PIX_FMT_NV12MT_16X16)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->dst_fmt->fourcc == V4L2_PIX_FMT_NV21M)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->sei_fp_parse & 0x1, mfc_regs->d_sei_enable);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->dec_dst_flag, mfc_regs->d_available_dpb_flag_lower);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->slice_interface & 0x1, mfc_regs->d_slice_if_enable);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	else if (ctx->codec_mode == S5P_MFC_CODEC_MPEG4_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	else if (ctx->codec_mode == S5P_MFC_CODEC_H263_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	else if (ctx->codec_mode == S5P_MFC_CODEC_VP8_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_width, mfc_regs->e_source_first_plane_stride);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		writel(ctx->img_width, mfc_regs->e_source_second_plane_stride);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_enc_params *p = &ctx->enc_params;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->codec_mode == S5P_MFC_CODEC_H264_ENC)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->state != MFCINST_FINISHING)
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	writel(ctx->inst_no, mfc_regs->instance_id);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->state == MFCINST_FINISHING) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	temp_vb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->consumed_stream,
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		mfc_debug(2, "Setting ctx->state to FINISHING\n");
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (list_empty(&ctx->src_queue) && ctx->state != MFCINST_FINISHING) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (list_empty(&ctx->dst_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (list_empty(&ctx->src_queue)) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		src_mb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:				ctx->state = MFCINST_FINISHING;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	temp_vb = list_entry(ctx->src_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dst_mb = list_entry(ctx->dst_queue.next, struct s5p_mfc_buf, list);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->capture_state != QUEUE_BUFS_MMAPED) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mfc_debug(1, "ctx->dst_queue_cnt=%d ctx->dpb_count=%d ctx->src_queue_cnt=%d\n",
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		ctx->dst_queue_cnt, ctx->pb_count, ctx->src_queue_cnt);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	mfc_debug(1, "ctx->state=%d\n", ctx->state);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	if (ctx->type == MFCINST_DECODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		switch (ctx->state) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			s5p_mfc_set_flush(ctx, ctx->dpb_flush_flag);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:			ctx->capture_state = QUEUE_FREE;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	} else if (ctx->type == MFCINST_ENCODER) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		switch (ctx->state) {
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		mfc_err("invalid context type: %d\n", ctx->type);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		(__force unsigned long) ctx->dev->mfc_regs->d_ret_picture_tag_top);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		(__force unsigned long) ctx->dev->mfc_regs->d_ret_picture_tag_bot);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		(__force unsigned long) ctx->dev->mfc_regs->d_display_crop_info1);
drivers/media/platform/s5p-mfc/s5p_mfc_opr_v6.c:		(__force unsigned long) ctx->dev->mfc_regs->d_display_crop_info2);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	mfc_debug(2, "Getting instance number (codec: %d)\n", ctx->codec_mode);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	switch (ctx->codec_mode) {
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	h2r_args.arg[2] = ctx->ctx.ofs;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	h2r_args.arg[3] = ctx->ctx.size;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	struct s5p_mfc_dev *dev = ctx->dev;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	if (ctx->state == MFCINST_FREE) {
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	mfc_debug(2, "Returning instance number %d\n", ctx->inst_no);
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	dev->curr_ctx = ctx->num;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:	h2r_args.arg[0] = ctx->inst_no;
drivers/media/platform/s5p-mfc/s5p_mfc_cmd_v5.c:		ctx->state = MFCINST_ERROR;
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	if ((v4l2_m2m_num_src_bufs_ready(ctx->m2m_ctx) > 0)
drivers/media/platform/m2m-deinterlace.c:	    && (v4l2_m2m_num_dst_bufs_ready(ctx->m2m_ctx) > 0)
drivers/media/platform/m2m-deinterlace.c:	    && (atomic_read(&ctx->dev->busy) == 0)) {
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	ctx->aborting = 1;
drivers/media/platform/m2m-deinterlace.c:	v4l2_m2m_job_finish(pcdev->m2m_dev, ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = curr_ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	src_vb = v4l2_m2m_src_buf_remove(curr_ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	dst_vb = v4l2_m2m_dst_buf_remove(curr_ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	v4l2_m2m_job_finish(pcdev->m2m_dev, curr_ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	struct deinterlace_dev *pcdev = ctx->dev;
drivers/media/platform/m2m-deinterlace.c:	src_buf = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + s_size / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + s_size;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_size;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + (9 * s_size) / 8;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_size + s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + (5 * s_size) / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + (5 * s_size) / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + (11 * s_size) / 8;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + (5 * s_size) / 4 + s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_width;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + s_size;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_size + s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + (5 * s_size) / 4;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + (5 * s_size) / 4 + s_width / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in + s_size;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->numf = s_height / 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].size = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->sgl[0].icg = s_width * 2;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->src_start = p_in;
drivers/media/platform/m2m-deinterlace.c:		ctx->xt->dst_start = p_out + s_width * 2;
drivers/media/platform/m2m-deinterlace.c:	ctx->xt->frame_size = 1;
drivers/media/platform/m2m-deinterlace.c:	ctx->xt->dir = DMA_MEM_TO_MEM;
drivers/media/platform/m2m-deinterlace.c:	ctx->xt->src_sgl = false;
drivers/media/platform/m2m-deinterlace.c:	ctx->xt->dst_sgl = true;
drivers/media/platform/m2m-deinterlace.c:	tx = dmadev->device_prep_interleaved_dma(chan, ctx->xt, flags);
drivers/media/platform/m2m-deinterlace.c:	ctx->cookie = dmaengine_submit(tx);
drivers/media/platform/m2m-deinterlace.c:	if (dma_submit_error(ctx->cookie)) {
drivers/media/platform/m2m-deinterlace.c:			  ctx->cookie, (unsigned)p_in, (unsigned)p_out,
drivers/media/platform/m2m-deinterlace.c:	atomic_set(&ctx->dev->busy, 1);
drivers/media/platform/m2m-deinterlace.c:	dprintk(ctx->dev, "%s: DMA try issue.\n", __func__);
drivers/media/platform/m2m-deinterlace.c:			dprintk(ctx->dev, "%s: yuv420 interlaced tb.\n",
drivers/media/platform/m2m-deinterlace.c:			dprintk(ctx->dev, "%s: yuv420 interlaced line doubling.\n",
drivers/media/platform/m2m-deinterlace.c:			dprintk(ctx->dev, "%s: yuyv interlaced_tb.\n",
drivers/media/platform/m2m-deinterlace.c:			dprintk(ctx->dev, "%s: yuyv interlaced line doubling.\n",
drivers/media/platform/m2m-deinterlace.c:	dprintk(ctx->dev, "%s: DMA issue done.\n", __func__);
drivers/media/platform/m2m-deinterlace.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/m2m-deinterlace.c:	f->fmt.pix.colorspace	= ctx->colorspace;
drivers/media/platform/m2m-deinterlace.c:	f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/m2m-deinterlace.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/m2m-deinterlace.c:		v4l2_err(&ctx->dev->v4l2_dev, "%s queue busy\n", __func__);
drivers/media/platform/m2m-deinterlace.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/m2m-deinterlace.c:	dprintk(ctx->dev,
drivers/media/platform/m2m-deinterlace.c:		ctx->colorspace = f->fmt.pix.colorspace;
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_reqbufs(file, ctx->m2m_ctx, reqbufs);
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_querybuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_qbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_dqbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/m2m-deinterlace.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/m2m-deinterlace.c:			v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/m2m-deinterlace.c:			v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_streamon(file, ctx->m2m_ctx, type);
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_streamoff(file, ctx->m2m_ctx, type);
drivers/media/platform/m2m-deinterlace.c:	dprintk(ctx->dev, "get %d buffer(s) of size %d each.\n", count, size);
drivers/media/platform/m2m-deinterlace.c:	dprintk(ctx->dev, "type: %d\n", vb->vb2_queue->type);
drivers/media/platform/m2m-deinterlace.c:		dprintk(ctx->dev, "%s data will not fit into plane (%lu < %lu)\n",
drivers/media/platform/m2m-deinterlace.c:	v4l2_m2m_buf_queue(ctx->m2m_ctx, vbuf);
drivers/media/platform/m2m-deinterlace.c:	src_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/m2m-deinterlace.c:	dst_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/m2m-deinterlace.c:	ctx->dev = pcdev;
drivers/media/platform/m2m-deinterlace.c:	ctx->m2m_ctx = v4l2_m2m_ctx_init(pcdev->m2m_dev, ctx, &queue_init);
drivers/media/platform/m2m-deinterlace.c:	if (IS_ERR(ctx->m2m_ctx)) {
drivers/media/platform/m2m-deinterlace.c:		int ret = PTR_ERR(ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	ctx->xt = kzalloc(sizeof(struct dma_interleaved_template) +
drivers/media/platform/m2m-deinterlace.c:	if (!ctx->xt) {
drivers/media/platform/m2m-deinterlace.c:	ctx->colorspace = V4L2_COLORSPACE_REC709;
drivers/media/platform/m2m-deinterlace.c:	dprintk(pcdev, "Created instance %p, m2m_ctx: %p\n", ctx, ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	v4l2_m2m_ctx_release(ctx->m2m_ctx);
drivers/media/platform/m2m-deinterlace.c:	kfree(ctx->xt);
drivers/media/platform/m2m-deinterlace.c:	ret = v4l2_m2m_poll(file, ctx->m2m_ctx, wait);
drivers/media/platform/m2m-deinterlace.c:	return v4l2_m2m_mmap(file, ctx->m2m_ctx, vma);
drivers/media/platform/s5p-g2d/g2d.c:		return &ctx->in;
drivers/media/platform/s5p-g2d/g2d.c:		return &ctx->out;
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/s5p-g2d/g2d.c:	src_vq->lock = &ctx->dev->mutex;
drivers/media/platform/s5p-g2d/g2d.c:	src_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/s5p-g2d/g2d.c:	dst_vq->lock = &ctx->dev->mutex;
drivers/media/platform/s5p-g2d/g2d.c:	dst_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/s5p-g2d/g2d.c:	spin_lock_irqsave(&ctx->dev->ctrl_lock, flags);
drivers/media/platform/s5p-g2d/g2d.c:			ctx->rop = ROP4_INVERT;
drivers/media/platform/s5p-g2d/g2d.c:			ctx->rop = ROP4_COPY;
drivers/media/platform/s5p-g2d/g2d.c:		ctx->flip = ctx->ctrl_hflip->val | (ctx->ctrl_vflip->val << 1);
drivers/media/platform/s5p-g2d/g2d.c:	spin_unlock_irqrestore(&ctx->dev->ctrl_lock, flags);
drivers/media/platform/s5p-g2d/g2d.c:	struct g2d_dev *dev = ctx->dev;
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, 3);
drivers/media/platform/s5p-g2d/g2d.c:	ctx->ctrl_hflip = v4l2_ctrl_new_std(&ctx->ctrl_handler, &g2d_ctrl_ops,
drivers/media/platform/s5p-g2d/g2d.c:	ctx->ctrl_vflip = v4l2_ctrl_new_std(&ctx->ctrl_handler, &g2d_ctrl_ops,
drivers/media/platform/s5p-g2d/g2d.c:		&ctx->ctrl_handler,
drivers/media/platform/s5p-g2d/g2d.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/s5p-g2d/g2d.c:		int err = ctx->ctrl_handler.error;
drivers/media/platform/s5p-g2d/g2d.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_ctrl_cluster(2, &ctx->ctrl_hflip);
drivers/media/platform/s5p-g2d/g2d.c:	ctx->dev = dev;
drivers/media/platform/s5p-g2d/g2d.c:	ctx->in		= def_frame;
drivers/media/platform/s5p-g2d/g2d.c:	ctx->out	= def_frame;
drivers/media/platform/s5p-g2d/g2d.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(dev->m2m_dev, ctx, &queue_init);
drivers/media/platform/s5p-g2d/g2d.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/s5p-g2d/g2d.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/s5p-g2d/g2d.c:	file->private_data = &ctx->fh;
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_ctrl_handler_setup(&ctx->ctrl_handler);
drivers/media/platform/s5p-g2d/g2d.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/s5p-g2d/g2d.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/s5p-g2d/g2d.c:	struct g2d_dev *dev = ctx->dev;
drivers/media/platform/s5p-g2d/g2d.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/s5p-g2d/g2d.c:	struct g2d_dev *dev = ctx->dev;
drivers/media/platform/s5p-g2d/g2d.c:	struct g2d_dev *dev = ctx->dev;
drivers/media/platform/s5p-g2d/g2d.c:	struct g2d_dev *dev = ctx->dev;
drivers/media/platform/s5p-g2d/g2d.c:	src = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-g2d/g2d.c:	dst = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-g2d/g2d.c:	g2d_set_src_size(dev, &ctx->in);
drivers/media/platform/s5p-g2d/g2d.c:	g2d_set_dst_size(dev, &ctx->out);
drivers/media/platform/s5p-g2d/g2d.c:	g2d_set_rop4(dev, ctx->rop);
drivers/media/platform/s5p-g2d/g2d.c:	g2d_set_flip(dev, ctx->flip);
drivers/media/platform/s5p-g2d/g2d.c:	if (ctx->in.c_width != ctx->out.c_width ||
drivers/media/platform/s5p-g2d/g2d.c:		ctx->in.c_height != ctx->out.c_height) {
drivers/media/platform/s5p-g2d/g2d.c:			g2d_set_v41_stretch(dev, &ctx->in, &ctx->out);
drivers/media/platform/s5p-g2d/g2d.c:	src = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-g2d/g2d.c:	dst = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/s5p-g2d/g2d.c:	v4l2_m2m_job_finish(dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:		return &(ctx->q_data[V4L2_M2M_SRC]);
drivers/media/platform/mx2_emmaprp.c:		return &(ctx->q_data[V4L2_M2M_DST]);
drivers/media/platform/mx2_emmaprp.c:	struct emmaprp_dev *pcdev = ctx->dev;
drivers/media/platform/mx2_emmaprp.c:	ctx->aborting = 1;
drivers/media/platform/mx2_emmaprp.c:	v4l2_m2m_job_finish(pcdev->m2m_dev, ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	struct emmaprp_dev *pcdev = ctx->dev;
drivers/media/platform/mx2_emmaprp.c:	struct emmaprp_dev *pcdev = ctx->dev;
drivers/media/platform/mx2_emmaprp.c:	struct emmaprp_dev *pcdev = ctx->dev;
drivers/media/platform/mx2_emmaprp.c:	src_buf = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	if (!curr_ctx->aborting) {
drivers/media/platform/mx2_emmaprp.c:			src_vb = v4l2_m2m_src_buf_remove(curr_ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:			dst_vb = v4l2_m2m_dst_buf_remove(curr_ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	v4l2_m2m_job_finish(pcdev->m2m_dev, curr_ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/mx2_emmaprp.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/mx2_emmaprp.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/mx2_emmaprp.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/mx2_emmaprp.c:		v4l2_err(&ctx->dev->v4l2_dev, "%s queue busy\n", __func__);
drivers/media/platform/mx2_emmaprp.c:	dprintk(ctx->dev,
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_reqbufs(file, ctx->m2m_ctx, reqbufs);
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_querybuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_qbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_dqbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_streamon(file, ctx->m2m_ctx, type);
drivers/media/platform/mx2_emmaprp.c:	return v4l2_m2m_streamoff(file, ctx->m2m_ctx, type);
drivers/media/platform/mx2_emmaprp.c:	dprintk(ctx->dev, "get %d buffer(s) of size %d each.\n", count, size);
drivers/media/platform/mx2_emmaprp.c:	dprintk(ctx->dev, "type: %d\n", vb->vb2_queue->type);
drivers/media/platform/mx2_emmaprp.c:		dprintk(ctx->dev, "%s data will not fit into plane"
drivers/media/platform/mx2_emmaprp.c:	v4l2_m2m_buf_queue(ctx->m2m_ctx, vbuf);
drivers/media/platform/mx2_emmaprp.c:	src_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/mx2_emmaprp.c:	dst_vq->dev = ctx->dev->v4l2_dev.dev;
drivers/media/platform/mx2_emmaprp.c:	ctx->dev = pcdev;
drivers/media/platform/mx2_emmaprp.c:	ctx->m2m_ctx = v4l2_m2m_ctx_init(pcdev->m2m_dev, ctx, &queue_init);
drivers/media/platform/mx2_emmaprp.c:	if (IS_ERR(ctx->m2m_ctx)) {
drivers/media/platform/mx2_emmaprp.c:		int ret = PTR_ERR(ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	ctx->q_data[V4L2_M2M_SRC].fmt = &formats[1];
drivers/media/platform/mx2_emmaprp.c:	ctx->q_data[V4L2_M2M_DST].fmt = &formats[0];
drivers/media/platform/mx2_emmaprp.c:	dprintk(pcdev, "Created instance %p, m2m_ctx: %p\n", ctx, ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	v4l2_m2m_ctx_release(ctx->m2m_ctx);
drivers/media/platform/mx2_emmaprp.c:	res = v4l2_m2m_poll(file, ctx->m2m_ctx, wait);
drivers/media/platform/mx2_emmaprp.c:	ret = v4l2_m2m_mmap(file, ctx->m2m_ctx, vma);
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-core.c:		f = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-core.c:		f = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-core.c:		if (ctx->gsc_ctrls.rotate->val == 90 ||
drivers/media/platform/exynos-gsc/gsc-core.c:		    ctx->gsc_ctrls.rotate->val == 270) {
drivers/media/platform/exynos-gsc/gsc-core.c:		(ctx->gsc_ctrls.rotate->val == 90 ||
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->gsc_ctrls.rotate->val == 270))
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_frame *s_frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_frame *d_frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_variant *variant = ctx->gsc_dev->variant;
drivers/media/platform/exynos-gsc/gsc-core.c:	struct device *dev = &ctx->gsc_dev->pdev->dev;
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->gsc_ctrls.rotate->val, ctx->out_path);
drivers/media/platform/exynos-gsc/gsc-core.c:	if (ctx->gsc_ctrls.rotate->val == 90 ||
drivers/media/platform/exynos-gsc/gsc-core.c:	    ctx->gsc_ctrls.rotate->val == 270) {
drivers/media/platform/exynos-gsc/gsc-core.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->hflip = ctrl->val;
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->vflip = ctrl->val;
drivers/media/platform/exynos-gsc/gsc-core.c:		if ((ctx->state & flags) == flags) {
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->s_frame.crop.width,
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->s_frame.crop.height,
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->d_frame.crop.width,
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->d_frame.crop.height,
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->gsc_ctrls.rotate->val,
drivers/media/platform/exynos-gsc/gsc-core.c:					ctx->out_path);
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->rotation = ctrl->val;
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->d_frame.alpha = ctrl->val;
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->state |= GSC_PARAMS;
drivers/media/platform/exynos-gsc/gsc-core.c:	spin_lock_irqsave(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.c:	spin_unlock_irqrestore(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.c:	if (ctx->ctrls_rdy) {
drivers/media/platform/exynos-gsc/gsc-core.c:	v4l2_ctrl_handler_init(&ctx->ctrl_handler, GSC_MAX_CTRL_NUM);
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->gsc_ctrls.rotate = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->gsc_ctrls.hflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->gsc_ctrls.vflip = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->gsc_ctrls.global_alpha = v4l2_ctrl_new_std(&ctx->ctrl_handler,
drivers/media/platform/exynos-gsc/gsc-core.c:	ctx->ctrls_rdy = ctx->ctrl_handler.error == 0;
drivers/media/platform/exynos-gsc/gsc-core.c:	if (ctx->ctrl_handler.error) {
drivers/media/platform/exynos-gsc/gsc-core.c:		int err = ctx->ctrl_handler.error;
drivers/media/platform/exynos-gsc/gsc-core.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/exynos-gsc/gsc-core.c:	if (ctx->ctrls_rdy) {
drivers/media/platform/exynos-gsc/gsc-core.c:		v4l2_ctrl_handler_free(&ctx->ctrl_handler);
drivers/media/platform/exynos-gsc/gsc-core.c:		ctx->ctrls_rdy = false;
drivers/media/platform/exynos-gsc/gsc-core.c:		if (!ctx || !ctx->m2m_ctx)
drivers/media/platform/exynos-gsc/gsc-core.c:		if (ctx->state & GSC_CTX_STOP_REQ) {
drivers/media/platform/exynos-gsc/gsc-core.c:			ctx->state &= ~GSC_CTX_STOP_REQ;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	if (ctx->in_path == GSC_DMA)
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	if (ctx->out_path == GSC_DMA)
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	if (ctx->out_path == GSC_DMA) {
drivers/media/platform/exynos-gsc/gsc-regs.c:	if (ctx->gsc_ctrls.rotate->val == 90 ||
drivers/media/platform/exynos-gsc/gsc-regs.c:	    ctx->gsc_ctrls.rotate->val == 270) {
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	if (ctx->out_path != GSC_DMA) {
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_scaler *sc = &ctx->scaler;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	switch (ctx->gsc_ctrls.rotate->val) {
drivers/media/platform/exynos-gsc/gsc-regs.c:		if (ctx->gsc_ctrls.hflip->val)
drivers/media/platform/exynos-gsc/gsc-regs.c:		else if (ctx->gsc_ctrls.vflip->val)
drivers/media/platform/exynos-gsc/gsc-regs.c:		if (ctx->gsc_ctrls.hflip->val)
drivers/media/platform/exynos-gsc/gsc-regs.c:		else if (ctx->gsc_ctrls.vflip->val)
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_frame *frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-regs.c:	cfg |= GSC_OUT_GLOBAL_ALPHA(ctx->gsc_ctrls.global_alpha->val);
drivers/media/platform/exynos-gsc/gsc-regs.c:	struct gsc_dev *dev = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_lock_irqsave(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:	ctx->state |= state;
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_unlock_irqrestore(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_lock_irqsave(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:	ctx->state &= ~state;
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_unlock_irqrestore(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_lock_irqsave(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:	ret = (ctx->state & mask) == mask;
drivers/media/platform/exynos-gsc/gsc-core.h:	spin_unlock_irqrestore(&ctx->gsc_dev->slock, flags);
drivers/media/platform/exynos-gsc/gsc-core.h:		frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-core.h:		frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	if ((ret == -ETIMEDOUT) || (ctx->state & GSC_CTX_ABORT)) {
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ret = pm_runtime_get_sync(&ctx->gsc_dev->pdev->dev);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	pm_runtime_put(&ctx->gsc_dev->pdev->dev);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	if (!ctx || !ctx->m2m_ctx)
drivers/media/platform/exynos-gsc/gsc-m2m.c:	src_vb = v4l2_m2m_src_buf_remove(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	dst_vb = v4l2_m2m_dst_buf_remove(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:		v4l2_m2m_job_finish(ctx->gsc_dev->m2m.m2m_dev,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				    ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	s_frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	d_frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	src_vb = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	dst_vb = v4l2_m2m_next_dst_buf(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		ctx->state |= GSC_PARAMS;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	is_set = ctx->state & GSC_CTX_STOP_REQ;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		ctx->state &= ~GSC_CTX_STOP_REQ;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		ctx->state |= GSC_CTX_ABORT;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	gsc_set_prefbuf(gsc, &ctx->s_frame);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	gsc_hw_set_input_addr(gsc, &ctx->s_frame.addr, GSC_M2M_BUF_NUM);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	gsc_hw_set_output_addr(gsc, &ctx->d_frame.addr, GSC_M2M_BUF_NUM);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	if (ctx->state & GSC_PARAMS) {
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->state &= ~GSC_PARAMS;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->state &= ~GSC_PARAMS;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	pr_debug("ctx: %p, ctx->state: 0x%x", ctx, ctx->state);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	if (ctx->m2m_ctx)
drivers/media/platform/exynos-gsc/gsc-m2m.c:		v4l2_m2m_buf_queue(ctx->m2m_ctx, vbuf);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/exynos-gsc/gsc-m2m.c:		frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_reqbufs(file, ctx->m2m_ctx, reqbufs);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_expbuf(file, ctx->m2m_ctx, eb);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_querybuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_qbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_dqbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_streamon(file, ctx->m2m_ctx, type);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	return v4l2_m2m_streamoff(file, ctx->m2m_ctx, type);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_variant *variant = ctx->gsc_dev->variant;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		frame = &ctx->s_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:		frame = &ctx->d_frame;
drivers/media/platform/exynos-gsc/gsc-m2m.c:				cr.c.height, ctx->d_frame.crop.width,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				ctx->d_frame.crop.height,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				ctx->gsc_ctrls.rotate->val, ctx->out_path);
drivers/media/platform/exynos-gsc/gsc-m2m.c:				ctx->s_frame.crop.width,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				ctx->s_frame.crop.height, cr.c.width,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				cr.c.height, ctx->gsc_ctrls.rotate->val,
drivers/media/platform/exynos-gsc/gsc-m2m.c:				ctx->out_path);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	src_vq->lock = &ctx->gsc_dev->lock;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	src_vq->dev = &ctx->gsc_dev->pdev->dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	dst_vq->lock = &ctx->gsc_dev->lock;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	dst_vq->dev = &ctx->gsc_dev->pdev->dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_init(&ctx->fh, gsc->m2m.vfd);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->fh.ctrl_handler = &ctx->ctrl_handler;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	file->private_data = &ctx->fh;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->gsc_dev = gsc;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->s_frame.fmt = get_format(0);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->d_frame.fmt = get_format(0);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->state = GSC_CTX_M2M;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->flags = 0;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->in_path = GSC_DMA;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->out_path = GSC_DMA;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ctx->m2m_ctx = v4l2_m2m_ctx_init(gsc->m2m.m2m_dev, ctx, queue_init);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	if (IS_ERR(ctx->m2m_ctx)) {
drivers/media/platform/exynos-gsc/gsc-m2m.c:		ret = PTR_ERR(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_m2m_ctx_release(ctx->m2m_ctx);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ret = v4l2_m2m_poll(file, ctx->m2m_ctx, wait);
drivers/media/platform/exynos-gsc/gsc-m2m.c:	struct gsc_dev *gsc = ctx->gsc_dev;
drivers/media/platform/exynos-gsc/gsc-m2m.c:	ret = v4l2_m2m_mmap(file, ctx->m2m_ctx, vma);
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	return ctx->dev->reg_base[reg_idx];
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	struct device *dev = &ctx->dev->plat_dev->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]  - va      = %p", ctx->id, mem->va);
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]  - dma     = 0x%lx", ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]    size = 0x%lx", ctx->id, size);
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	struct device *dev = &ctx->dev->plat_dev->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]  - va      = %p", ctx->id, mem->va);
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]  - dma     = 0x%lx", ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_util.c:	mtk_v4l2_debug(3, "[%d]    size = 0x%lx", ctx->id, size);
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:	waitqueue = (wait_queue_head_t *)&ctx->queue;
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				(ctx->int_cond &&
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				(ctx->int_type == command)),
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:		mtk_v4l2_err("[%d] cmd=%d, ctx->type=%d, wait_event_interruptible_timeout time=%ums out %d %d!",
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				ctx->id, ctx->type, command, timeout_ms,
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				ctx->int_cond, ctx->int_type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:		mtk_v4l2_err("[%d] cmd=%d, ctx->type=%d, wait_event_interruptible_timeout interrupted by a signal %d %d",
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				ctx->id, ctx->type, command, ctx->int_cond,
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:				ctx->int_type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:	ctx->int_cond = 0;
drivers/media/platform/mtk-vcodec/mtk_vcodec_intr.c:	ctx->int_type = 0;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct mtk_enc_params *p = &ctx->enc_params;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->param_change |= MTK_ENCODE_PARAM_BITRATE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->param_change |= MTK_ENCODE_PARAM_INTRA_PERIOD;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->param_change |= MTK_ENCODE_PARAM_GOP_SIZE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->param_change |= MTK_ENCODE_PARAM_FORCE_INTRA;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->enc_params.framerate_num =
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->enc_params.framerate_denom =
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->param_change |= MTK_ENCODE_PARAM_FRAMERATE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			ctx->enc_params.framerate_num;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			ctx->enc_params.framerate_denom;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		return &ctx->q_data[MTK_Q_DATA_SRC];
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	return &ctx->q_data[MTK_Q_DATA_DST];
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct mtk_q_data *q_data_src = &ctx->q_data[MTK_Q_DATA_SRC];
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct mtk_enc_params *enc_params = &ctx->enc_params;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if (ctx->state == MTK_STATE_FREE) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->state = MTK_STATE_INIT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->colorspace = f->fmt.pix_mp.colorspace;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->ycbcr_enc = f->fmt.pix_mp.ycbcr_enc;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->quantization = f->fmt.pix_mp.quantization;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->xfer_func = f->fmt.pix_mp.xfer_func;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	vq = v4l2_m2m_get_vq(ctx->m2m_ctx, f->type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	pix->colorspace = ctx->colorspace;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	pix->ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	pix->quantization = ctx->quantization;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	pix->xfer_func = ctx->xfer_func;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	f->fmt.pix_mp.colorspace = ctx->colorspace;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	f->fmt.pix_mp.ycbcr_enc = ctx->ycbcr_enc;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	f->fmt.pix_mp.quantization = ctx->quantization;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	f->fmt.pix_mp.xfer_func = ctx->xfer_func;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if (ctx->state == MTK_STATE_ABORT) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:				ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	return v4l2_m2m_qbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if (ctx->state == MTK_STATE_ABORT) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:				ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	return v4l2_m2m_dqbuf(file, ctx->m2m_ctx, buf);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	    (ctx->param_change != MTK_ENCODE_PARAM_NONE)) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       ctx->param_change);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		mtk_buf->param_change = ctx->param_change;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		mtk_buf->enc_params = ctx->enc_params;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->param_change = MTK_ENCODE_PARAM_NONE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	v4l2_m2m_buf_queue(ctx->m2m_ctx, to_vb2_v4l2_buffer(vb));
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if ((ctx->state == MTK_STATE_ABORT) || (ctx->state == MTK_STATE_FREE)) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		if (!vb2_start_streaming_called(&ctx->m2m_ctx->cap_q_ctx.q))
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		if (!vb2_start_streaming_called(&ctx->m2m_ctx->out_q_ctx.q))
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->param_change = MTK_ENCODE_PARAM_NONE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if ((ctx->q_data[MTK_Q_DATA_DST].fmt->fourcc == V4L2_PIX_FMT_H264) &&
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	    (ctx->enc_params.seq_hdr_mode !=
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->state = MTK_STATE_HEADER;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:					ctx->id, i, q->type,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	mtk_v4l2_debug(2, "[%d]-> type=%d", ctx->id, q->type);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		while ((dst_buf = v4l2_m2m_dst_buf_remove(ctx->m2m_ctx))) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		while ((src_buf = v4l2_m2m_src_buf_remove(ctx->m2m_ctx)))
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	     vb2_is_streaming(&ctx->m2m_ctx->out_q_ctx.q)) ||
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	     vb2_is_streaming(&ctx->m2m_ctx->cap_q_ctx.q))) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       ctx->id, q->type,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       vb2_is_streaming(&ctx->m2m_ctx->out_q_ctx.q),
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       vb2_is_streaming(&ctx->m2m_ctx->cap_q_ctx.q));
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->state = MTK_STATE_FREE;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	src_buf = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->state = MTK_STATE_HEADER;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct vb2_buffer *vb = v4l2_m2m_next_src_buf(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:				ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:				ctx->id,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		v4l2_m2m_job_finish(ctx->dev->m2m_dev_enc, ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	src_buf = v4l2_m2m_src_buf_remove(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	v4l2_m2m_job_finish(ctx->dev->m2m_dev_enc, ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if ((ctx->q_data[MTK_Q_DATA_DST].fmt->fourcc == V4L2_PIX_FMT_H264) &&
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	    (ctx->state != MTK_STATE_HEADER)) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:		queue_work(ctx->dev->encode_workqueue, &ctx->encode_work);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	queue_work(ctx->dev->encode_workqueue, &ctx->encode_work);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	if (ctx->state == MTK_STATE_ABORT || ctx->state == MTK_STATE_FREE) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:			       ctx->id, ctx->state);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	mutex_lock(&ctx->dev->dev_mutex);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	mutex_unlock(&ctx->dev->dev_mutex);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->m2m_ctx->q_lock = &ctx->dev->dev_mutex;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->fh.m2m_ctx = ctx->m2m_ctx;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->fh.ctrl_handler = &ctx->ctrl_hdl;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	INIT_WORK(&ctx->encode_work, mtk_venc_worker);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->colorspace = V4L2_COLORSPACE_REC709;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->ycbcr_enc = V4L2_YCBCR_ENC_DEFAULT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->quantization = V4L2_QUANTIZATION_DEFAULT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->xfer_func = V4L2_XFER_FUNC_DEFAULT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	q_data = &ctx->q_data[MTK_Q_DATA_SRC];
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	q_data = &ctx->q_data[MTK_Q_DATA_DST];
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->q_data[MTK_Q_DATA_DST].sizeimage[0] =
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->q_data[MTK_Q_DATA_DST].bytesperline[0] = 0;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct v4l2_ctrl_handler *handler = &ctx->ctrl_hdl;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	v4l2_ctrl_handler_setup(&ctx->ctrl_hdl);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	src_vq->lock		= &ctx->dev->dev_mutex;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	src_vq->dev		= &ctx->dev->plat_dev->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	dst_vq->lock		= &ctx->dev->dev_mutex;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	dst_vq->dev		= &ctx->dev->plat_dev->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct mtk_vcodec_dev *dev = ctx->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	struct mtk_vcodec_dev *dev = ctx->dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc.c:	ctx->state = MTK_STATE_FREE;
drivers/media/platform/mtk-vcodec/venc/venc_vp8_if.c:		irq_status = ctx->irq_status;
drivers/media/platform/mtk-vcodec/venc/venc_vp8_if.c:	inst->vpu_inst.dev = ctx->dev->vpu_plat_dev;
drivers/media/platform/mtk-vcodec/venc/venc_vp8_if.c:	enable_irq(ctx->dev->enc_lt_irq);
drivers/media/platform/mtk-vcodec/venc/venc_vp8_if.c:	disable_irq(ctx->dev->enc_lt_irq);
drivers/media/platform/mtk-vcodec/venc/venc_h264_if.c:		irq_status = ctx->irq_status;
drivers/media/platform/mtk-vcodec/venc/venc_h264_if.c:	inst->vpu_inst.dev = ctx->dev->vpu_plat_dev;
drivers/media/platform/mtk-vcodec/venc/venc_h264_if.c:	enable_irq(ctx->dev->enc_irq);
drivers/media/platform/mtk-vcodec/venc/venc_h264_if.c:	disable_irq(ctx->dev->enc_irq);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:		ctx->enc_if = get_vp8_enc_comm_if();
drivers/media/platform/mtk-vcodec/venc_drv_if.c:		ctx->enc_if = get_h264_enc_comm_if();
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_on(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ret = ctx->enc_if->init(ctx, (unsigned long *)&ctx->drv_handle);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_off(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_on(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ret = ctx->enc_if->set_param(ctx->drv_handle, type, in);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_off(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	spin_lock_irqsave(&ctx->dev->irqlock, flags);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ctx->dev->curr_ctx = ctx;
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	spin_unlock_irqrestore(&ctx->dev->irqlock, flags);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_on(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ret = ctx->enc_if->encode(ctx->drv_handle, opt, frm_buf,
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_off(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	spin_lock_irqsave(&ctx->dev->irqlock, flags);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ctx->dev->curr_ctx = NULL;
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	spin_unlock_irqrestore(&ctx->dev->irqlock, flags);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	if (ctx->drv_handle == 0)
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_on(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ret = ctx->enc_if->deinit(ctx->drv_handle);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	mtk_vcodec_enc_clock_off(&ctx->dev->pm);
drivers/media/platform/mtk-vcodec/venc_drv_if.c:	ctx->drv_handle = 0;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->int_cond = 1;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->int_type = reason;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	wake_up_interruptible(&ctx->queue);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	mtk_v4l2_debug(1, "id=%d", ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->irq_status = readl(dev->reg_base[VENC_SYS] +
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	clean_irq_status(ctx->irq_status, addr);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	mtk_v4l2_debug(1, "id=%d", ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->irq_status = readl(dev->reg_base[VENC_LT_SYS] +
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	clean_irq_status(ctx->irq_status, addr);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:		ctx->state = MTK_STATE_ABORT;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:				ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->id = dev->id_counter++;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	file->private_data = &ctx->fh;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	INIT_LIST_HEAD(&ctx->list);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->dev = dev;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	init_waitqueue_head(&ctx->queue);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->type = MTK_INST_ENCODER;
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	ctx->m2m_ctx = v4l2_m2m_ctx_init(dev->m2m_dev_enc, ctx,
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	if (IS_ERR((__force void *)ctx->m2m_ctx)) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:		ret = PTR_ERR((__force void *)ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	if (v4l2_fh_is_singular(&ctx->fh)) {
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:			ctx->id, ctx, ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	list_add(&ctx->list, &dev->ctx_list);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:			ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_m2m_ctx_release(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_ctrl_handler_free(&ctx->ctrl_hdl);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	mtk_v4l2_debug(1, "[%d] encoder", ctx->id);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_m2m_ctx_release(ctx->m2m_ctx);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	v4l2_ctrl_handler_free(&ctx->ctrl_hdl);
drivers/media/platform/mtk-vcodec/mtk_vcodec_enc_drv.c:	list_del_init(&ctx->list);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->bit_stream_param,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->frm_dis_flg,
drivers/media/platform/coda/coda-bit.c:				CODA_REG_BIT_FRM_DIS_FLG(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->frame_mem_ctrl,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->workbuf.paddr, CODA_REG_BIT_WORK_BUF_ADDR);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->idx, CODA_REG_BIT_RUN_INDEX);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->params.codec_mode, CODA_REG_BIT_RUN_COD_STD);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->params.codec_mode_aux, CODA7_REG_BIT_RUN_AUX_STD);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	struct __kfifo *kfifo = &ctx->bitstream_fifo.kfifo;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	rd_ptr = coda_read(dev, CODA_REG_BIT_RD_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:		      (rd_ptr - ctx->bitstream.paddr);
drivers/media/platform/coda/coda-bit.c:	struct __kfifo *kfifo = &ctx->bitstream_fifo.kfifo;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	rd_ptr = ctx->bitstream.paddr + (kfifo->out & kfifo->mask);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, rd_ptr, CODA_REG_BIT_RD_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	wr_ptr = ctx->bitstream.paddr + (kfifo->in & kfifo->mask);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, wr_ptr, CODA_REG_BIT_WR_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	struct __kfifo *kfifo = &ctx->bitstream_fifo.kfifo;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	wr_ptr = ctx->bitstream.paddr + (kfifo->in & kfifo->mask);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, wr_ptr, CODA_REG_BIT_WR_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	n = kfifo_in(&ctx->bitstream_fifo,
drivers/media/platform/coda/coda-bit.c:	src_buf->sequence = ctx->qsequence++;
drivers/media/platform/coda/coda-bit.c:	    ctx->bitstream.size)
drivers/media/platform/coda/coda-bit.c:		v4l2_err(&ctx->dev->v4l2_dev, "trying to queue empty buffer\n");
drivers/media/platform/coda/coda-bit.c:		v4l2_err(&ctx->dev->v4l2_dev, "bitstream buffer overflow\n");
drivers/media/platform/coda/coda-bit.c:	if (ctx == v4l2_m2m_get_curr_priv(ctx->dev->m2m_dev))
drivers/media/platform/coda/coda-bit.c:	ctx->hold = false;
drivers/media/platform/coda/coda-bit.c:	if (ctx->bit_stream_param & CODA_BIT_STREAM_END_FLAG)
drivers/media/platform/coda/coda-bit.c:	while (v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx) > 0) {
drivers/media/platform/coda/coda-bit.c:		if (ctx->codec->src_fourcc == V4L2_PIX_FMT_JPEG &&
drivers/media/platform/coda/coda-bit.c:		    (coda_get_bitstream_payload(ctx) >= 512) && !ctx->hold)
drivers/media/platform/coda/coda-bit.c:		src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:		if (ctx->codec->src_fourcc == V4L2_PIX_FMT_JPEG &&
drivers/media/platform/coda/coda-bit.c:			v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:				 ctx->qsequence);
drivers/media/platform/coda/coda-bit.c:			src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:			src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:		start = ctx->bitstream_fifo.kfifo.in &
drivers/media/platform/coda/coda-bit.c:			ctx->bitstream_fifo.kfifo.mask;
drivers/media/platform/coda/coda-bit.c:			src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:				meta->end = ctx->bitstream_fifo.kfifo.in &
drivers/media/platform/coda/coda-bit.c:					    ctx->bitstream_fifo.kfifo.mask;
drivers/media/platform/coda/coda-bit.c:				spin_lock_irqsave(&ctx->buffer_meta_lock,
drivers/media/platform/coda/coda-bit.c:					      &ctx->buffer_meta_list);
drivers/media/platform/coda/coda-bit.c:				ctx->num_metas++;
drivers/media/platform/coda/coda-bit.c:				spin_unlock_irqrestore(&ctx->buffer_meta_lock,
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	ctx->bit_stream_param |= CODA_BIT_STREAM_END_FLAG;
drivers/media/platform/coda/coda-bit.c:	    (ctx->idx == coda_read(dev, CODA_REG_BIT_RUN_INDEX))) {
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->bit_stream_param,
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	u32 *p = ctx->parabuf.vaddr;
drivers/media/platform/coda/coda-bit.c:	return coda_alloc_aux_buf(ctx->dev, buf, size, name, ctx->debugfs_entry);
drivers/media/platform/coda/coda-bit.c:		coda_free_aux_buf(ctx->dev, &ctx->internal_frames[i]);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	if (ctx->codec && (ctx->codec->src_fourcc == V4L2_PIX_FMT_H264 ||
drivers/media/platform/coda/coda-bit.c:	     ctx->codec->dst_fourcc == V4L2_PIX_FMT_H264)) {
drivers/media/platform/coda/coda-bit.c:	for (i = 0; i < ctx->num_internal_frames; i++) {
drivers/media/platform/coda/coda-bit.c:		if (ctx->tiled_map_type == GDI_TILED_FRAME_MB_RASTER_MAP)
drivers/media/platform/coda/coda-bit.c:		if (ctx->codec->src_fourcc == V4L2_PIX_FMT_H264 &&
drivers/media/platform/coda/coda-bit.c:		ret = coda_alloc_context_buf(ctx, &ctx->internal_frames[i],
drivers/media/platform/coda/coda-bit.c:	for (i = 0; i < ctx->num_internal_frames; i++) {
drivers/media/platform/coda/coda-bit.c:		y = ctx->internal_frames[i].paddr;
drivers/media/platform/coda/coda-bit.c:		if (ctx->tiled_map_type == GDI_TILED_FRAME_MB_RASTER_MAP) {
drivers/media/platform/coda/coda-bit.c:		if (ctx->codec->src_fourcc == V4L2_PIX_FMT_H264 &&
drivers/media/platform/coda/coda-bit.c:					   ctx->internal_frames[i].paddr +
drivers/media/platform/coda/coda-bit.c:	    (ctx->codec->src_fourcc == V4L2_PIX_FMT_MPEG4))
drivers/media/platform/coda/coda-bit.c:		coda_parabuf_write(ctx, 97, ctx->internal_frames[0].paddr +
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	coda_free_aux_buf(dev, &ctx->slicebuf);
drivers/media/platform/coda/coda-bit.c:	coda_free_aux_buf(dev, &ctx->psbuf);
drivers/media/platform/coda/coda-bit.c:		coda_free_aux_buf(dev, &ctx->workbuf);
drivers/media/platform/coda/coda-bit.c:	coda_free_aux_buf(dev, &ctx->parabuf);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	if (!ctx->parabuf.vaddr) {
drivers/media/platform/coda/coda-bit.c:		ret = coda_alloc_context_buf(ctx, &ctx->parabuf,
drivers/media/platform/coda/coda-bit.c:	if (!ctx->slicebuf.vaddr && q_data->fourcc == V4L2_PIX_FMT_H264) {
drivers/media/platform/coda/coda-bit.c:		ret = coda_alloc_context_buf(ctx, &ctx->slicebuf, size,
drivers/media/platform/coda/coda-bit.c:	if (!ctx->psbuf.vaddr && dev->devtype->product == CODA_7541) {
drivers/media/platform/coda/coda-bit.c:		ret = coda_alloc_context_buf(ctx, &ctx->psbuf,
drivers/media/platform/coda/coda-bit.c:	if (!ctx->workbuf.vaddr) {
drivers/media/platform/coda/coda-bit.c:		ret = coda_alloc_context_buf(ctx, &ctx->workbuf, size,
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:		*size = coda_read(dev, CODA_REG_BIT_WR_PTR(ctx->reg_idx)) -
drivers/media/platform/coda/coda-bit.c:	struct coda_iram_info *iram_info = &ctx->iram_info;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	if (ctx->inst_type == CODA_INST_ENCODER) {
drivers/media/platform/coda/coda-bit.c:	} else if (ctx->inst_type == CODA_INST_DECODER) {
drivers/media/platform/coda/coda-bit.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:		if (ctx->inst_type == CODA_INST_DECODER) {
drivers/media/platform/coda/coda-bit.c:	if (ctx->tiled_map_type == GDI_LINEAR_FRAME_MAP) {
drivers/media/platform/coda/coda-bit.c:	coda_write(ctx->dev, cache_size, CODA9_CMD_SET_FRAME_CACHE_SIZE);
drivers/media/platform/coda/coda-bit.c:	coda_write(ctx->dev, cache_config, CODA9_CMD_SET_FRAME_CACHE_CONFIG);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:		if (!ctx->params.jpeg_qmat_tab[0])
drivers/media/platform/coda/coda-bit.c:			ctx->params.jpeg_qmat_tab[0] = kmalloc(64, GFP_KERNEL);
drivers/media/platform/coda/coda-bit.c:		if (!ctx->params.jpeg_qmat_tab[1])
drivers/media/platform/coda/coda-bit.c:			ctx->params.jpeg_qmat_tab[1] = kmalloc(64, GFP_KERNEL);
drivers/media/platform/coda/coda-bit.c:		coda_set_jpeg_compression_quality(ctx, ctx->params.jpeg_quality);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->parabuf.paddr, CODA_REG_BIT_PARA_BUF_ADDR);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, bitstream_buf, CODA_REG_BIT_RD_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, bitstream_buf, CODA_REG_BIT_WR_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	ctx->frame_mem_ctrl &= ~(CODA_FRAME_CHROMA_INTERLEAVE | (0x3 << 9) |
drivers/media/platform/coda/coda-bit.c:		ctx->frame_mem_ctrl |= CODA_FRAME_CHROMA_INTERLEAVE;
drivers/media/platform/coda/coda-bit.c:	if (ctx->tiled_map_type == GDI_TILED_FRAME_MB_RASTER_MAP)
drivers/media/platform/coda/coda-bit.c:		ctx->frame_mem_ctrl |= (0x3 << 9) | CODA9_FRAME_TILED2LINEAR;
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->frame_mem_ctrl, CODA_REG_BIT_FRAME_MEM_CTRL);
drivers/media/platform/coda/coda-bit.c:		ctx->params.framerate = 0;
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->params.framerate,
drivers/media/platform/coda/coda-bit.c:	ctx->params.codec_mode = ctx->codec->mode;
drivers/media/platform/coda/coda-bit.c:		if (ctx->params.h264_deblk_enabled) {
drivers/media/platform/coda/coda-bit.c:			value = ((ctx->params.h264_deblk_alpha &
drivers/media/platform/coda/coda-bit.c:				((ctx->params.h264_deblk_beta &
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->params.jpeg_restart_interval,
drivers/media/platform/coda/coda-bit.c:		switch (ctx->params.slice_mode) {
drivers/media/platform/coda/coda-bit.c:			value  = (ctx->params.slice_max_mb &
drivers/media/platform/coda/coda-bit.c:			value  = (ctx->params.slice_max_bits &
drivers/media/platform/coda/coda-bit.c:		value = ctx->params.gop_size & CODA_GOP_SIZE_MASK;
drivers/media/platform/coda/coda-bit.c:	if (ctx->params.bitrate) {
drivers/media/platform/coda/coda-bit.c:		value = (ctx->params.bitrate & CODA_RATECONTROL_BITRATE_MASK)
drivers/media/platform/coda/coda-bit.c:		value |= (ctx->params.vbv_delay &
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->params.vbv_size, CODA_CMD_ENC_SEQ_RC_BUF_SIZE);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->params.intra_refresh,
drivers/media/platform/coda/coda-bit.c:	if (ctx->params.h264_min_qp || ctx->params.h264_max_qp) {
drivers/media/platform/coda/coda-bit.c:			   ctx->params.h264_min_qp << CODA_QPMIN_OFFSET |
drivers/media/platform/coda/coda-bit.c:			   ctx->params.h264_max_qp << CODA_QPMAX_OFFSET,
drivers/media/platform/coda/coda-bit.c:		if (ctx->params.h264_max_qp)
drivers/media/platform/coda/coda-bit.c:		if (ctx->params.h264_min_qp)
drivers/media/platform/coda/coda-bit.c:		if (ctx->params.h264_max_qp)
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->iram_info.search_ram_paddr,
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->iram_info.search_ram_size,
drivers/media/platform/coda/coda-bit.c:	ctx->initialized = 1;
drivers/media/platform/coda/coda-bit.c:			ctx->num_internal_frames = 4;
drivers/media/platform/coda/coda-bit.c:			ctx->num_internal_frames = 2;
drivers/media/platform/coda/coda-bit.c:		ctx->num_internal_frames = 0;
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_bit_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_ip_ac_dc_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_dbk_y_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_dbk_c_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_ovl_use,
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->iram_info.buf_btp_use,
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->internal_frames[2].paddr,
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->internal_frames[3].paddr,
drivers/media/platform/coda/coda-bit.c:	buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header[0][0],
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header_size[0]);
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header[1][0],
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header_size[1]);
drivers/media/platform/coda/coda-bit.c:		ctx->vpu_header_size[2] = coda_h264_padding(
drivers/media/platform/coda/coda-bit.c:					(ctx->vpu_header_size[0] +
drivers/media/platform/coda/coda-bit.c:					 ctx->vpu_header_size[1]),
drivers/media/platform/coda/coda-bit.c:					 ctx->vpu_header[2]);
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header[0][0],
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header_size[0]);
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header[1][0],
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header_size[1]);
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header[2][0],
drivers/media/platform/coda/coda-bit.c:					 &ctx->vpu_header_size[2]);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	src_buf = v4l2_m2m_next_src_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	src_buf->sequence = ctx->osequence;
drivers/media/platform/coda/coda-bit.c:	dst_buf->sequence = ctx->osequence;
drivers/media/platform/coda/coda-bit.c:	ctx->osequence++;
drivers/media/platform/coda/coda-bit.c:	if (src_buf->sequence % ctx->params.gop_size) {
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[0] +
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[1] +
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[2];
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[0] -
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[1] -
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[2];
drivers/media/platform/coda/coda-bit.c:		       &ctx->vpu_header[0][0], ctx->vpu_header_size[0]);
drivers/media/platform/coda/coda-bit.c:			+ ctx->vpu_header_size[0], &ctx->vpu_header[1][0],
drivers/media/platform/coda/coda-bit.c:			ctx->vpu_header_size[1]);
drivers/media/platform/coda/coda-bit.c:			+ ctx->vpu_header_size[0] + ctx->vpu_header_size[1],
drivers/media/platform/coda/coda-bit.c:			&ctx->vpu_header[2][0], ctx->vpu_header_size[2]);
drivers/media/platform/coda/coda-bit.c:			quant_param = ctx->params.h264_intra_qp;
drivers/media/platform/coda/coda-bit.c:			quant_param = ctx->params.mpeg4_intra_qp;
drivers/media/platform/coda/coda-bit.c:			v4l2_warn(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:			quant_param = ctx->params.h264_inter_qp;
drivers/media/platform/coda/coda-bit.c:			quant_param = ctx->params.mpeg4_inter_qp;
drivers/media/platform/coda/coda-bit.c:			v4l2_warn(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:	if (ctx->params.rot_mode)
drivers/media/platform/coda/coda-bit.c:		rot_mode = CODA_ROT_MIR_ENABLE | ctx->params.rot_mode;
drivers/media/platform/coda/coda-bit.c:	if (!ctx->streamon_out) {
drivers/media/platform/coda/coda-bit.c:		ctx->bit_stream_param |= CODA_BIT_STREAM_END_FLAG;
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->bit_stream_param,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.axi_sram_use,
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	src_buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	wr_ptr = coda_read(dev, CODA_REG_BIT_WR_PTR(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:					ctx->vpu_header_size[0] +
drivers/media/platform/coda/coda-bit.c:					ctx->vpu_header_size[1] +
drivers/media/platform/coda/coda-bit.c:					ctx->vpu_header_size[2]);
drivers/media/platform/coda/coda-bit.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev, "frame size = %u\n",
drivers/media/platform/coda/coda-bit.c:	dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	ctx->gopcounter--;
drivers/media/platform/coda/coda-bit.c:	if (ctx->gopcounter < 0)
drivers/media/platform/coda/coda-bit.c:		ctx->gopcounter = ctx->params.gop_size - 1;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	mutex_lock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-bit.c:	if (ctx->initialized == 0)
drivers/media/platform/coda/coda-bit.c:		 "%d: %s: sent command 'SEQ_END' to coda\n", ctx->idx,
drivers/media/platform/coda/coda-bit.c:	kfifo_init(&ctx->bitstream_fifo,
drivers/media/platform/coda/coda-bit.c:		ctx->bitstream.vaddr, ctx->bitstream.size);
drivers/media/platform/coda/coda-bit.c:	ctx->initialized = 0;
drivers/media/platform/coda/coda-bit.c:	mutex_unlock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-bit.c:	mutex_lock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-bit.c:	mutex_unlock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-bit.c:	if (ctx->bitstream.vaddr)
drivers/media/platform/coda/coda-bit.c:	ctx->bitstream.size = roundup_pow_of_two(q_data->sizeimage * 2);
drivers/media/platform/coda/coda-bit.c:	ctx->bitstream.vaddr = dma_alloc_wc(&ctx->dev->plat_dev->dev,
drivers/media/platform/coda/coda-bit.c:					    ctx->bitstream.size,
drivers/media/platform/coda/coda-bit.c:					    &ctx->bitstream.paddr, GFP_KERNEL);
drivers/media/platform/coda/coda-bit.c:	if (!ctx->bitstream.vaddr) {
drivers/media/platform/coda/coda-bit.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:	kfifo_init(&ctx->bitstream_fifo,
drivers/media/platform/coda/coda-bit.c:		   ctx->bitstream.vaddr, ctx->bitstream.size);
drivers/media/platform/coda/coda-bit.c:	if (ctx->bitstream.vaddr == NULL)
drivers/media/platform/coda/coda-bit.c:	dma_free_wc(&ctx->dev->plat_dev->dev, ctx->bitstream.size,
drivers/media/platform/coda/coda-bit.c:		    ctx->bitstream.vaddr, ctx->bitstream.paddr);
drivers/media/platform/coda/coda-bit.c:	ctx->bitstream.vaddr = NULL;
drivers/media/platform/coda/coda-bit.c:	kfifo_init(&ctx->bitstream_fifo, NULL, 0);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	bitstream_buf = ctx->bitstream.paddr;
drivers/media/platform/coda/coda-bit.c:	bitstream_size = ctx->bitstream.size;
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->parabuf.paddr, CODA_REG_BIT_PARA_BUF_ADDR);
drivers/media/platform/coda/coda-bit.c:	ctx->frame_mem_ctrl &= ~(CODA_FRAME_CHROMA_INTERLEAVE | (0x3 << 9) |
drivers/media/platform/coda/coda-bit.c:		ctx->frame_mem_ctrl |= CODA_FRAME_CHROMA_INTERLEAVE;
drivers/media/platform/coda/coda-bit.c:	if (ctx->tiled_map_type == GDI_TILED_FRAME_MB_RASTER_MAP)
drivers/media/platform/coda/coda-bit.c:		ctx->frame_mem_ctrl |= (0x3 << 9) | CODA9_FRAME_TILED2LINEAR;
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->frame_mem_ctrl, CODA_REG_BIT_FRAME_MEM_CTRL);
drivers/media/platform/coda/coda-bit.c:	ctx->display_idx = -1;
drivers/media/platform/coda/coda-bit.c:	ctx->frm_dis_flg = 0;
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, 0, CODA_REG_BIT_FRM_DIS_FLG(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	if (ctx->codec->src_fourcc == V4L2_PIX_FMT_JPEG)
drivers/media/platform/coda/coda-bit.c:	ctx->params.codec_mode = ctx->codec->mode;
drivers/media/platform/coda/coda-bit.c:		ctx->params.codec_mode_aux = CODA_MP4_AUX_MPEG4;
drivers/media/platform/coda/coda-bit.c:		ctx->params.codec_mode_aux = 0;
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->psbuf.paddr,
drivers/media/platform/coda/coda-bit.c:	ctx->initialized = 1;
drivers/media/platform/coda/coda-bit.c:		 __func__, ctx->idx, width, height);
drivers/media/platform/coda/coda-bit.c:	ctx->num_internal_frames = coda_read(dev, CODA_RET_DEC_SEQ_FRAME_NEED);
drivers/media/platform/coda/coda-bit.c:	if (ctx->num_internal_frames > CODA_MAX_FRAMEBUFFERS) {
drivers/media/platform/coda/coda-bit.c:			 CODA_MAX_FRAMEBUFFERS, ctx->num_internal_frames);
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, ctx->num_internal_frames, CODA_CMD_SET_FRAME_BUF_NUM);
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_bit_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_ip_ac_dc_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_dbk_y_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_dbk_c_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.buf_ovl_use,
drivers/media/platform/coda/coda-bit.c:			coda_write(dev, ctx->iram_info.buf_btp_use,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->slicebuf.paddr,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->slicebuf.size / 1024,
drivers/media/platform/coda/coda-bit.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	dst_buf = v4l2_m2m_next_dst_buf(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	mutex_lock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-bit.c:	mutex_unlock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-bit.c:	    (!(ctx->bit_stream_param & CODA_BIT_STREAM_END_FLAG))) {
drivers/media/platform/coda/coda-bit.c:		v4l2_m2m_job_finish(ctx->dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:	if (!ctx->initialized) {
drivers/media/platform/coda/coda-bit.c:			v4l2_m2m_job_finish(ctx->dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:			ctx->initialized = 1;
drivers/media/platform/coda/coda-bit.c:		 * ROT_INDEX needs to be < 0x40, but > ctx->num_internal_frames.
drivers/media/platform/coda/coda-bit.c:	coda_write(dev, CODA_ROT_MIR_ENABLE | ctx->params.rot_mode,
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->iram_info.axi_sram_use,
drivers/media/platform/coda/coda-bit.c:	spin_lock_irqsave(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-bit.c:	meta = list_first_entry_or_null(&ctx->buffer_meta_list,
drivers/media/platform/coda/coda-bit.c:	if (meta && ctx->codec->src_fourcc == V4L2_PIX_FMT_JPEG) {
drivers/media/platform/coda/coda-bit.c:		if (meta->end == (ctx->bitstream_fifo.kfifo.in &
drivers/media/platform/coda/coda-bit.c:				  ctx->bitstream_fifo.kfifo.mask)) {
drivers/media/platform/coda/coda-bit.c:			kfifo_in(&ctx->bitstream_fifo, buf, pad);
drivers/media/platform/coda/coda-bit.c:	spin_unlock_irqrestore(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-bit.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-bit.c:	if (ctx->bit_stream_param & CODA_BIT_STREAM_END_FLAG) {
drivers/media/platform/coda/coda-bit.c:		if (coda_get_bitstream_payload(ctx) >= ctx->bitstream.size - 512)
drivers/media/platform/coda/coda-bit.c:			kfifo_init(&ctx->bitstream_fifo,
drivers/media/platform/coda/coda-bit.c:				ctx->bitstream.vaddr, ctx->bitstream.size);
drivers/media/platform/coda/coda-bit.c:				 ctx->psbuf.size);
drivers/media/platform/coda/coda-bit.c:				 ctx->slicebuf.size);
drivers/media/platform/coda/coda-bit.c:			ctx->hold = true;
drivers/media/platform/coda/coda-bit.c:	ctx->frm_dis_flg = coda_read(dev,
drivers/media/platform/coda/coda-bit.c:				     CODA_REG_BIT_FRM_DIS_FLG(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:	if (ctx->display_idx >= 0 &&
drivers/media/platform/coda/coda-bit.c:	    ctx->display_idx < ctx->num_internal_frames) {
drivers/media/platform/coda/coda-bit.c:		ctx->frm_dis_flg &= ~(1 << ctx->display_idx);
drivers/media/platform/coda/coda-bit.c:		coda_write(dev, ctx->frm_dis_flg,
drivers/media/platform/coda/coda-bit.c:				CODA_REG_BIT_FRM_DIS_FLG(ctx->reg_idx));
drivers/media/platform/coda/coda-bit.c:		if (display_idx >= 0 && display_idx < ctx->num_internal_frames)
drivers/media/platform/coda/coda-bit.c:			ctx->sequence_offset++;
drivers/media/platform/coda/coda-bit.c:		else if (ctx->display_idx < 0)
drivers/media/platform/coda/coda-bit.c:			ctx->hold = true;
drivers/media/platform/coda/coda-bit.c:	} else if (decoded_idx < 0 || decoded_idx >= ctx->num_internal_frames) {
drivers/media/platform/coda/coda-bit.c:		val -= ctx->sequence_offset;
drivers/media/platform/coda/coda-bit.c:		spin_lock_irqsave(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-bit.c:		if (!list_empty(&ctx->buffer_meta_list)) {
drivers/media/platform/coda/coda-bit.c:			meta = list_first_entry(&ctx->buffer_meta_list,
drivers/media/platform/coda/coda-bit.c:			ctx->num_metas--;
drivers/media/platform/coda/coda-bit.c:			spin_unlock_irqrestore(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-bit.c:					 val, ctx->sequence_offset,
drivers/media/platform/coda/coda-bit.c:			ctx->frame_metas[decoded_idx] = *meta;
drivers/media/platform/coda/coda-bit.c:			spin_unlock_irqrestore(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-bit.c:			memset(&ctx->frame_metas[decoded_idx], 0,
drivers/media/platform/coda/coda-bit.c:			ctx->frame_metas[decoded_idx].sequence = val;
drivers/media/platform/coda/coda-bit.c:			ctx->sequence_offset++;
drivers/media/platform/coda/coda-bit.c:		trace_coda_dec_pic_done(ctx, &ctx->frame_metas[decoded_idx]);
drivers/media/platform/coda/coda-bit.c:			ctx->frame_types[decoded_idx] = V4L2_BUF_FLAG_KEYFRAME;
drivers/media/platform/coda/coda-bit.c:			ctx->frame_types[decoded_idx] = V4L2_BUF_FLAG_PFRAME;
drivers/media/platform/coda/coda-bit.c:			ctx->frame_types[decoded_idx] = V4L2_BUF_FLAG_BFRAME;
drivers/media/platform/coda/coda-bit.c:		ctx->frame_errors[decoded_idx] = err_mb;
drivers/media/platform/coda/coda-bit.c:		ctx->hold = true;
drivers/media/platform/coda/coda-bit.c:	} else if (display_idx < 0 || display_idx >= ctx->num_internal_frames) {
drivers/media/platform/coda/coda-bit.c:	if (ctx->display_idx >= 0 &&
drivers/media/platform/coda/coda-bit.c:	    ctx->display_idx < ctx->num_internal_frames) {
drivers/media/platform/coda/coda-bit.c:		dst_buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-bit.c:		dst_buf->sequence = ctx->osequence++;
drivers/media/platform/coda/coda-bit.c:		dst_buf->flags |= ctx->frame_types[ctx->display_idx];
drivers/media/platform/coda/coda-bit.c:		meta = &ctx->frame_metas[ctx->display_idx];
drivers/media/platform/coda/coda-bit.c:		coda_m2m_buf_done(ctx, dst_buf, ctx->frame_errors[display_idx] ?
drivers/media/platform/coda/coda-bit.c:	ctx->display_idx = display_idx;
drivers/media/platform/coda/coda-bit.c:	if (ctx->aborting) {
drivers/media/platform/coda/coda-bit.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:	if (coda_isbusy(ctx->dev)) {
drivers/media/platform/coda/coda-bit.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-bit.c:	complete(&ctx->completion);
drivers/media/platform/coda/coda-common.c:	coda_write(ctx->dev, base_y, reg_y);
drivers/media/platform/coda/coda-common.c:	coda_write(ctx->dev, base_cb, reg_y + 4);
drivers/media/platform/coda/coda-common.c:	coda_write(ctx->dev, base_cr, reg_y + 8);
drivers/media/platform/coda/coda-common.c:	strlcpy(cap->card, coda_product_name(ctx->dev->devtype->product),
drivers/media/platform/coda/coda-common.c:		f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/coda/coda-common.c:		formats = ctx->cvd->src_formats;
drivers/media/platform/coda/coda-common.c:		formats = ctx->cvd->dst_formats;
drivers/media/platform/coda/coda-common.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	src_vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, V4L2_BUF_TYPE_VIDEO_OUTPUT);
drivers/media/platform/coda/coda-common.c:	f->fmt.pix.colorspace = ctx->colorspace;
drivers/media/platform/coda/coda-common.c:	codec = coda_find_codec(ctx->dev, q_data_src->fourcc,
drivers/media/platform/coda/coda-common.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, f->type);
drivers/media/platform/coda/coda-common.c:		v4l2_err(&ctx->dev->v4l2_dev, "%s queue busy\n", __func__);
drivers/media/platform/coda/coda-common.c:			ctx->tiled_map_type = GDI_TILED_FRAME_MB_RASTER_MAP;
drivers/media/platform/coda/coda-common.c:		ctx->tiled_map_type = GDI_LINEAR_FRAME_MAP;
drivers/media/platform/coda/coda-common.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	ctx->colorspace = f->fmt.pix.colorspace;
drivers/media/platform/coda/coda-common.c:	ret = v4l2_m2m_reqbufs(file, ctx->fh.m2m_ctx, rb);
drivers/media/platform/coda/coda-common.c:	if (rb->type == V4L2_BUF_TYPE_VIDEO_OUTPUT && ctx->ops->reqbufs)
drivers/media/platform/coda/coda-common.c:		return ctx->ops->reqbufs(ctx, rb);
drivers/media/platform/coda/coda-common.c:	return v4l2_m2m_qbuf(file, ctx->fh.m2m_ctx, buf);
drivers/media/platform/coda/coda-common.c:	src_vq = v4l2_m2m_get_vq(ctx->fh.m2m_ctx, V4L2_BUF_TYPE_VIDEO_OUTPUT);
drivers/media/platform/coda/coda-common.c:	return ((ctx->bit_stream_param & CODA_BIT_STREAM_END_FLAG) &&
drivers/media/platform/coda/coda-common.c:		(buf->sequence == (ctx->qsequence - 1)));
drivers/media/platform/coda/coda-common.c:		v4l2_event_queue_fh(&ctx->fh, &eos_event);
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type != CODA_INST_DECODER)
drivers/media/platform/coda/coda-common.c:	ctx->hold = false;
drivers/media/platform/coda/coda-common.c:	v4l2_m2m_try_schedule(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	tpf->denominator = ctx->params.framerate & CODA_FRATE_RES_MASK;
drivers/media/platform/coda/coda-common.c:	tpf->numerator = 1 + (ctx->params.framerate >>
drivers/media/platform/coda/coda-common.c:	ctx->params.framerate = coda_timeperframe_to_frate(tpf);
drivers/media/platform/coda/coda-common.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	queue_work(dev->workqueue, &ctx->pic_run_work);
drivers/media/platform/coda/coda-common.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	mutex_lock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-common.c:	ret = ctx->ops->prepare_run(ctx);
drivers/media/platform/coda/coda-common.c:	if (ret < 0 && ctx->inst_type == CODA_INST_DECODER) {
drivers/media/platform/coda/coda-common.c:		mutex_unlock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-common.c:	if (!wait_for_completion_timeout(&ctx->completion,
drivers/media/platform/coda/coda-common.c:		ctx->hold = true;
drivers/media/platform/coda/coda-common.c:	} else if (!ctx->aborting) {
drivers/media/platform/coda/coda-common.c:		ctx->ops->finish_run(ctx);
drivers/media/platform/coda/coda-common.c:	if ((ctx->aborting || (!ctx->streamon_cap && !ctx->streamon_out)) &&
drivers/media/platform/coda/coda-common.c:	    ctx->ops->seq_end_work)
drivers/media/platform/coda/coda-common.c:		queue_work(dev->workqueue, &ctx->seq_end_work);
drivers/media/platform/coda/coda-common.c:	mutex_unlock(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-common.c:	v4l2_m2m_job_finish(ctx->dev->m2m_dev, ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	int src_bufs = v4l2_m2m_num_src_bufs_ready(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	if (!src_bufs && ctx->inst_type != CODA_INST_DECODER) {
drivers/media/platform/coda/coda-common.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	if (!v4l2_m2m_num_dst_bufs_ready(ctx->fh.m2m_ctx)) {
drivers/media/platform/coda/coda-common.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type == CODA_INST_DECODER && ctx->use_bit) {
drivers/media/platform/coda/coda-common.c:		bool stream_end = ctx->bit_stream_param &
drivers/media/platform/coda/coda-common.c:		int num_metas = ctx->num_metas;
drivers/media/platform/coda/coda-common.c:		if (ctx->hold && !src_bufs) {
drivers/media/platform/coda/coda-common.c:			v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:				 ctx->idx);
drivers/media/platform/coda/coda-common.c:			v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:				 ctx->idx, num_metas, src_bufs);
drivers/media/platform/coda/coda-common.c:			v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:				 ctx->idx, coda_get_bitstream_payload(ctx));
drivers/media/platform/coda/coda-common.c:	if (ctx->aborting) {
drivers/media/platform/coda/coda-common.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	ctx->aborting = 1;
drivers/media/platform/coda/coda-common.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	struct coda_dev *pcdev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	struct coda_dev *pcdev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	ctx->codec = coda_find_codec(ctx->dev, ctx->cvd->src_formats[0],
drivers/media/platform/coda/coda-common.c:				     ctx->cvd->dst_formats[0]);
drivers/media/platform/coda/coda-common.c:	max_w = min(ctx->codec->max_w, 1920U);
drivers/media/platform/coda/coda-common.c:	max_h = min(ctx->codec->max_h, 1088U);
drivers/media/platform/coda/coda-common.c:	ctx->params.codec_mode = ctx->codec->mode;
drivers/media/platform/coda/coda-common.c:	ctx->colorspace = V4L2_COLORSPACE_REC709;
drivers/media/platform/coda/coda-common.c:	ctx->params.framerate = 30;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_SRC].fourcc = ctx->cvd->src_formats[0];
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_DST].fourcc = ctx->cvd->dst_formats[0];
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_SRC].width = max_w;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_SRC].height = max_h;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_DST].width = max_w;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_DST].height = max_h;
drivers/media/platform/coda/coda-common.c:	if (ctx->codec->src_fourcc == V4L2_PIX_FMT_YUV420) {
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_SRC].bytesperline = max_w;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_SRC].sizeimage = usize;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_DST].bytesperline = 0;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_DST].sizeimage = csize;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_SRC].bytesperline = 0;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_SRC].sizeimage = csize;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_DST].bytesperline = max_w;
drivers/media/platform/coda/coda-common.c:		ctx->q_data[V4L2_M2M_DST].sizeimage = usize;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_SRC].rect.width = max_w;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_SRC].rect.height = max_h;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_DST].rect.width = max_w;
drivers/media/platform/coda/coda-common.c:	ctx->q_data[V4L2_M2M_DST].rect.height = max_h;
drivers/media/platform/coda/coda-common.c:	ctx->tiled_map_type = GDI_LINEAR_FRAME_MAP;
drivers/media/platform/coda/coda-common.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:		v4l2_warn(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	if (ctx->bitstream.size && vq->type == V4L2_BUF_TYPE_VIDEO_OUTPUT) {
drivers/media/platform/coda/coda-common.c:		mutex_lock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-common.c:		v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/coda/coda-common.c:		mutex_unlock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-common.c:		v4l2_m2m_buf_queue(ctx->fh.m2m_ctx, vbuf);
drivers/media/platform/coda/coda-common.c:	struct v4l2_device *v4l2_dev = &ctx->dev->v4l2_dev;
drivers/media/platform/coda/coda-common.c:		if (ctx->inst_type == CODA_INST_DECODER && ctx->use_bit) {
drivers/media/platform/coda/coda-common.c:			mutex_lock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-common.c:			mutex_unlock(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-common.c:		ctx->streamon_out = 1;
drivers/media/platform/coda/coda-common.c:		ctx->streamon_cap = 1;
drivers/media/platform/coda/coda-common.c:	if (!(ctx->streamon_out & ctx->streamon_cap))
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type == CODA_INST_DECODER && ctx->use_bit)
drivers/media/platform/coda/coda-common.c:		v4l2_m2m_set_src_buffered(ctx->fh.m2m_ctx, true);
drivers/media/platform/coda/coda-common.c:	ctx->gopcounter = ctx->params.gop_size - 1;
drivers/media/platform/coda/coda-common.c:	ctx->codec = coda_find_codec(ctx->dev, q_data_src->fourcc,
drivers/media/platform/coda/coda-common.c:	if (!ctx->codec) {
drivers/media/platform/coda/coda-common.c:		ctx->params.gop_size = 1;
drivers/media/platform/coda/coda-common.c:	ctx->gopcounter = ctx->params.gop_size - 1;
drivers/media/platform/coda/coda-common.c:	ret = ctx->ops->start_streaming(ctx);
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type == CODA_INST_DECODER) {
drivers/media/platform/coda/coda-common.c:		while ((buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/coda/coda-common.c:		while ((buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/coda/coda-common.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-common.c:	stop = ctx->streamon_out && ctx->streamon_cap;
drivers/media/platform/coda/coda-common.c:		ctx->streamon_out = 0;
drivers/media/platform/coda/coda-common.c:		ctx->qsequence = 0;
drivers/media/platform/coda/coda-common.c:		while ((buf = v4l2_m2m_src_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/coda/coda-common.c:		ctx->streamon_cap = 0;
drivers/media/platform/coda/coda-common.c:		ctx->osequence = 0;
drivers/media/platform/coda/coda-common.c:		ctx->sequence_offset = 0;
drivers/media/platform/coda/coda-common.c:		while ((buf = v4l2_m2m_dst_buf_remove(ctx->fh.m2m_ctx)))
drivers/media/platform/coda/coda-common.c:		if (ctx->ops->seq_end_work) {
drivers/media/platform/coda/coda-common.c:			queue_work(dev->workqueue, &ctx->seq_end_work);
drivers/media/platform/coda/coda-common.c:			flush_work(&ctx->seq_end_work);
drivers/media/platform/coda/coda-common.c:		spin_lock_irqsave(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-common.c:		while (!list_empty(&ctx->buffer_meta_list)) {
drivers/media/platform/coda/coda-common.c:			meta = list_first_entry(&ctx->buffer_meta_list,
drivers/media/platform/coda/coda-common.c:		ctx->num_metas = 0;
drivers/media/platform/coda/coda-common.c:		spin_unlock_irqrestore(&ctx->buffer_meta_lock, flags);
drivers/media/platform/coda/coda-common.c:		kfifo_init(&ctx->bitstream_fifo,
drivers/media/platform/coda/coda-common.c:			ctx->bitstream.vaddr, ctx->bitstream.size);
drivers/media/platform/coda/coda-common.c:		ctx->runcounter = 0;
drivers/media/platform/coda/coda-common.c:		ctx->aborting = 0;
drivers/media/platform/coda/coda-common.c:	if (!ctx->streamon_out && !ctx->streamon_cap)
drivers/media/platform/coda/coda-common.c:		ctx->bit_stream_param &= ~CODA_BIT_STREAM_END_FLAG;
drivers/media/platform/coda/coda-common.c:	v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:			ctx->params.rot_mode |= CODA_MIR_HOR;
drivers/media/platform/coda/coda-common.c:			ctx->params.rot_mode &= ~CODA_MIR_HOR;
drivers/media/platform/coda/coda-common.c:			ctx->params.rot_mode |= CODA_MIR_VER;
drivers/media/platform/coda/coda-common.c:			ctx->params.rot_mode &= ~CODA_MIR_VER;
drivers/media/platform/coda/coda-common.c:		ctx->params.bitrate = ctrl->val / 1000;
drivers/media/platform/coda/coda-common.c:		ctx->params.gop_size = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_intra_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_inter_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_min_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_max_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_deblk_alpha = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_deblk_beta = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.h264_deblk_enabled = (ctrl->val ==
drivers/media/platform/coda/coda-common.c:		ctx->params.mpeg4_intra_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.mpeg4_inter_qp = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.slice_mode = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.slice_max_mb = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.slice_max_bits = ctrl->val * 8;
drivers/media/platform/coda/coda-common.c:		ctx->params.intra_refresh = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.jpeg_restart_interval = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.vbv_delay = ctrl->val;
drivers/media/platform/coda/coda-common.c:		ctx->params.vbv_size = min(ctrl->val * 8192, 0x7fffffff);
drivers/media/platform/coda/coda-common.c:		v4l2_dbg(1, coda_debug, &ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	if (ctx->dev->devtype->product != CODA_960) {
drivers/media/platform/coda/coda-common.c:		v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std_menu(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std_menu(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std_menu(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_handler_init(&ctx->ctrls, 2);
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_new_std(&ctx->ctrls, &coda_ctrl_ops,
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type == CODA_INST_ENCODER) {
drivers/media/platform/coda/coda-common.c:		if (ctx->cvd->dst_formats[0] == V4L2_PIX_FMT_JPEG)
drivers/media/platform/coda/coda-common.c:	if (ctx->ctrls.error) {
drivers/media/platform/coda/coda-common.c:		v4l2_err(&ctx->dev->v4l2_dev,
drivers/media/platform/coda/coda-common.c:			ctx->ctrls.error);
drivers/media/platform/coda/coda-common.c:	return v4l2_ctrl_handler_setup(&ctx->ctrls);
drivers/media/platform/coda/coda-common.c:	vq->lock = &ctx->dev->dev_mutex;
drivers/media/platform/coda/coda-common.c:	vq->dev = &ctx->dev->plat_dev->dev;
drivers/media/platform/coda/coda-common.c:	ctx->debugfs_entry = debugfs_create_dir(name, dev->debugfs_root);
drivers/media/platform/coda/coda-common.c:	ctx->cvd = to_coda_video_device(vdev);
drivers/media/platform/coda/coda-common.c:	ctx->inst_type = ctx->cvd->type;
drivers/media/platform/coda/coda-common.c:	ctx->ops = ctx->cvd->ops;
drivers/media/platform/coda/coda-common.c:	ctx->use_bit = !ctx->cvd->direct;
drivers/media/platform/coda/coda-common.c:	init_completion(&ctx->completion);
drivers/media/platform/coda/coda-common.c:	INIT_WORK(&ctx->pic_run_work, coda_pic_run_work);
drivers/media/platform/coda/coda-common.c:	if (ctx->ops->seq_end_work)
drivers/media/platform/coda/coda-common.c:		INIT_WORK(&ctx->seq_end_work, ctx->ops->seq_end_work);
drivers/media/platform/coda/coda-common.c:	v4l2_fh_init(&ctx->fh, video_devdata(file));
drivers/media/platform/coda/coda-common.c:	file->private_data = &ctx->fh;
drivers/media/platform/coda/coda-common.c:	v4l2_fh_add(&ctx->fh);
drivers/media/platform/coda/coda-common.c:	ctx->dev = dev;
drivers/media/platform/coda/coda-common.c:	ctx->idx = idx;
drivers/media/platform/coda/coda-common.c:		ctx->frame_mem_ctrl = 1 << 12;
drivers/media/platform/coda/coda-common.c:		ctx->reg_idx = 0;
drivers/media/platform/coda/coda-common.c:		ctx->reg_idx = idx;
drivers/media/platform/coda/coda-common.c:	ctx->fh.m2m_ctx = v4l2_m2m_ctx_init(dev->m2m_dev, ctx,
drivers/media/platform/coda/coda-common.c:					    ctx->ops->queue_init);
drivers/media/platform/coda/coda-common.c:	if (IS_ERR(ctx->fh.m2m_ctx)) {
drivers/media/platform/coda/coda-common.c:		ret = PTR_ERR(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	ctx->fh.ctrl_handler = &ctx->ctrls;
drivers/media/platform/coda/coda-common.c:	mutex_init(&ctx->bitstream_mutex);
drivers/media/platform/coda/coda-common.c:	mutex_init(&ctx->buffer_mutex);
drivers/media/platform/coda/coda-common.c:	INIT_LIST_HEAD(&ctx->buffer_meta_list);
drivers/media/platform/coda/coda-common.c:	spin_lock_init(&ctx->buffer_meta_lock);
drivers/media/platform/coda/coda-common.c:	list_add(&ctx->list, &dev->instances);
drivers/media/platform/coda/coda-common.c:		 ctx->idx, ctx);
drivers/media/platform/coda/coda-common.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/coda/coda-common.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/coda/coda-common.c:	clear_bit(ctx->idx, &dev->instance_mask);
drivers/media/platform/coda/coda-common.c:	if (ctx->inst_type == CODA_INST_DECODER && ctx->use_bit)
drivers/media/platform/coda/coda-common.c:	v4l2_m2m_ctx_release(ctx->fh.m2m_ctx);
drivers/media/platform/coda/coda-common.c:	if (ctx->ops->seq_end_work) {
drivers/media/platform/coda/coda-common.c:		queue_work(dev->workqueue, &ctx->seq_end_work);
drivers/media/platform/coda/coda-common.c:		flush_work(&ctx->seq_end_work);
drivers/media/platform/coda/coda-common.c:	list_del(&ctx->list);
drivers/media/platform/coda/coda-common.c:	if (ctx->dev->devtype->product == CODA_DX6)
drivers/media/platform/coda/coda-common.c:		coda_free_aux_buf(dev, &ctx->workbuf);
drivers/media/platform/coda/coda-common.c:	v4l2_ctrl_handler_free(&ctx->ctrls);
drivers/media/platform/coda/coda-common.c:	v4l2_fh_del(&ctx->fh);
drivers/media/platform/coda/coda-common.c:	v4l2_fh_exit(&ctx->fh);
drivers/media/platform/coda/coda-common.c:	clear_bit(ctx->idx, &dev->instance_mask);
drivers/media/platform/coda/coda-common.c:	if (ctx->ops->release)
drivers/media/platform/coda/coda-common.c:		ctx->ops->release(ctx);
drivers/media/platform/coda/coda-common.c:	debugfs_remove_recursive(ctx->debugfs_entry);
drivers/media/platform/coda/coda-jpeg.c:		{ 512, ctx->params.jpeg_qmat_tab[0], 64 },
drivers/media/platform/coda/coda-jpeg.c:		{ 576, ctx->params.jpeg_qmat_tab[1], 64 },
drivers/media/platform/coda/coda-jpeg.c:		{ 640, ctx->params.jpeg_qmat_tab[1], 64 },
drivers/media/platform/coda/coda-jpeg.c:		coda_memcpy_parabuf(ctx->parabuf.vaddr, huff + i);
drivers/media/platform/coda/coda-jpeg.c:		coda_memcpy_parabuf(ctx->parabuf.vaddr, qmat + i);
drivers/media/platform/coda/coda-jpeg.c:	ctx->params.jpeg_quality = quality;
drivers/media/platform/coda/coda-jpeg.c:	if (ctx->params.jpeg_qmat_tab[0]) {
drivers/media/platform/coda/coda-jpeg.c:		memcpy(ctx->params.jpeg_qmat_tab[0], luma_q, 64);
drivers/media/platform/coda/coda-jpeg.c:		coda_scale_quant_table(ctx->params.jpeg_qmat_tab[0], scale);
drivers/media/platform/coda/coda-jpeg.c:	if (ctx->params.jpeg_qmat_tab[1]) {
drivers/media/platform/coda/coda-jpeg.c:		memcpy(ctx->params.jpeg_qmat_tab[1], chroma_q, 64);
drivers/media/platform/coda/coda-jpeg.c:		coda_scale_quant_table(ctx->params.jpeg_qmat_tab[1], scale);
drivers/media/platform/coda/coda.h:		return &(ctx->q_data[V4L2_M2M_SRC]);
drivers/media/platform/coda/coda.h:		return &(ctx->q_data[V4L2_M2M_DST]);
drivers/media/platform/coda/coda.h:	return kfifo_len(&ctx->bitstream_fifo);
drivers/media/platform/coda/coda-gdi.c:	struct coda_dev *dev = ctx->dev;
drivers/media/platform/coda/coda-gdi.c:	switch (ctx->tiled_map_type) {
drivers/media/platform/coda/trace.h:		__entry->minor = ctx->fh.vdev->minor;
drivers/media/platform/coda/trace.h:		__entry->ctx = ctx->idx;
drivers/media/platform/coda/trace.h:		__entry->minor = ctx->fh.vdev->minor;
drivers/media/platform/coda/trace.h:		__entry->ctx = ctx->idx;
drivers/media/platform/coda/trace.h:		__entry->minor = ctx->fh.vdev->minor;
drivers/media/platform/coda/trace.h:		__entry->ctx = ctx->idx;
drivers/media/platform/coda/trace.h:		__entry->minor = ctx->fh.vdev->minor;
drivers/media/platform/coda/trace.h:		__entry->ctx = ctx->idx;
drivers/media/platform/coda/trace.h:		__entry->minor = ctx->fh.vdev->minor;
drivers/media/platform/coda/trace.h:		__entry->ctx = ctx->idx;
drivers/media/firewire/firedtv-fw.c:	p.interrupt = !(++ctx->interrupt_packet & (IRQ_INTERVAL - 1));
drivers/media/firewire/firedtv-fw.c:	return fw_iso_context_queue(ctx->context, &p, &ctx->buffer,
drivers/media/firewire/firedtv-fw.c:	int length, err, i = ctx->current_packet;
drivers/media/firewire/firedtv-fw.c:		p = ctx->pages[i / PACKETS_PER_PAGE]
drivers/media/firewire/firedtv-fw.c:	fw_iso_context_queue_flush(ctx->context);
drivers/media/firewire/firedtv-fw.c:	ctx->current_packet = i;
drivers/media/firewire/firedtv-fw.c:	ctx->context = fw_iso_context_create(device->card,
drivers/media/firewire/firedtv-fw.c:	if (IS_ERR(ctx->context)) {
drivers/media/firewire/firedtv-fw.c:		err = PTR_ERR(ctx->context);
drivers/media/firewire/firedtv-fw.c:	err = fw_iso_buffer_init(&ctx->buffer, device->card,
drivers/media/firewire/firedtv-fw.c:	ctx->interrupt_packet = 0;
drivers/media/firewire/firedtv-fw.c:	ctx->current_packet = 0;
drivers/media/firewire/firedtv-fw.c:		ctx->pages[i] = page_address(ctx->buffer.pages[i]);
drivers/media/firewire/firedtv-fw.c:	err = fw_iso_context_start(ctx->context, -1, 0,
drivers/media/firewire/firedtv-fw.c:	fw_iso_buffer_destroy(&ctx->buffer, device->card);
drivers/media/firewire/firedtv-fw.c:	fw_iso_context_destroy(ctx->context);
drivers/media/firewire/firedtv-fw.c:	fw_iso_context_stop(ctx->context);
drivers/media/firewire/firedtv-fw.c:	fw_iso_buffer_destroy(&ctx->buffer, device_of(fdtv)->card);
drivers/media/firewire/firedtv-fw.c:	fw_iso_context_destroy(ctx->context);
drivers/media/v4l2-core/v4l2-mem2mem.c:		return &m2m_ctx->out_q_ctx;
drivers/media/v4l2-core/v4l2-mem2mem.c:		return &m2m_ctx->cap_q_ctx;
drivers/media/v4l2-core/v4l2-mem2mem.c:	return &q_ctx->q;
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (list_empty(&q_ctx->rdy_queue)) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	b = list_first_entry(&q_ctx->rdy_queue, struct v4l2_m2m_buffer, list);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (list_empty(&q_ctx->rdy_queue)) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	b = list_first_entry(&q_ctx->rdy_queue, struct v4l2_m2m_buffer, list);
drivers/media/v4l2-core/v4l2-mem2mem.c:	q_ctx->num_rdy--;
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:		ret = m2m_dev->curr_ctx->priv;
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev->curr_ctx->job_flags |= TRANS_RUNNING;
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev->m2m_ops->device_run(m2m_dev->curr_ctx->priv);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev = m2m_ctx->m2m_dev;
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (!m2m_ctx->out_q_ctx.q.streaming
drivers/media/v4l2-core/v4l2-mem2mem.c:	    || !m2m_ctx->cap_q_ctx.q.streaming) {
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->job_flags & TRANS_ABORT) {
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->job_flags & TRANS_QUEUED) {
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&m2m_ctx->out_q_ctx.rdy_spinlock, flags_out);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (list_empty(&m2m_ctx->out_q_ctx.rdy_queue)
drivers/media/v4l2-core/v4l2-mem2mem.c:	    && !m2m_ctx->out_q_ctx.buffered) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		spin_unlock_irqrestore(&m2m_ctx->out_q_ctx.rdy_spinlock,
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&m2m_ctx->cap_q_ctx.rdy_spinlock, flags_cap);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (list_empty(&m2m_ctx->cap_q_ctx.rdy_queue)
drivers/media/v4l2-core/v4l2-mem2mem.c:	    && !m2m_ctx->cap_q_ctx.buffered) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		spin_unlock_irqrestore(&m2m_ctx->cap_q_ctx.rdy_spinlock,
drivers/media/v4l2-core/v4l2-mem2mem.c:		spin_unlock_irqrestore(&m2m_ctx->out_q_ctx.rdy_spinlock,
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&m2m_ctx->cap_q_ctx.rdy_spinlock, flags_cap);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&m2m_ctx->out_q_ctx.rdy_spinlock, flags_out);
drivers/media/v4l2-core/v4l2-mem2mem.c:		&& (!m2m_dev->m2m_ops->job_ready(m2m_ctx->priv))) {
drivers/media/v4l2-core/v4l2-mem2mem.c:	list_add_tail(&m2m_ctx->queue, &m2m_dev->job_queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_ctx->job_flags |= TRANS_QUEUED;
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev = m2m_ctx->m2m_dev;
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_ctx->job_flags |= TRANS_ABORT;
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->job_flags & TRANS_RUNNING) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		m2m_dev->m2m_ops->job_abort(m2m_ctx->priv);
drivers/media/v4l2-core/v4l2-mem2mem.c:		wait_event(m2m_ctx->finished,
drivers/media/v4l2-core/v4l2-mem2mem.c:				!(m2m_ctx->job_flags & TRANS_RUNNING));
drivers/media/v4l2-core/v4l2-mem2mem.c:	} else if (m2m_ctx->job_flags & TRANS_QUEUED) {
drivers/media/v4l2-core/v4l2-mem2mem.c:		list_del(&m2m_ctx->queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:		m2m_ctx->job_flags &= ~(TRANS_QUEUED | TRANS_RUNNING);
drivers/media/v4l2-core/v4l2-mem2mem.c:	list_del(&m2m_dev->curr_ctx->queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev->curr_ctx->job_flags &= ~(TRANS_QUEUED | TRANS_RUNNING);
drivers/media/v4l2-core/v4l2-mem2mem.c:	wake_up(&m2m_dev->curr_ctx->finished);
drivers/media/v4l2-core/v4l2-mem2mem.c:	ret = vb2_streamoff(&q_ctx->q, type);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_dev = m2m_ctx->m2m_dev;
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->job_flags & TRANS_QUEUED)
drivers/media/v4l2-core/v4l2-mem2mem.c:		list_del(&m2m_ctx->queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_ctx->job_flags = 0;
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	INIT_LIST_HEAD(&q_ctx->rdy_queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	q_ctx->num_rdy = 0;
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:		wake_up(&m2m_ctx->finished);
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_ctx->priv = drv_priv;
drivers/media/v4l2-core/v4l2-mem2mem.c:	m2m_ctx->m2m_dev = m2m_dev;
drivers/media/v4l2-core/v4l2-mem2mem.c:	init_waitqueue_head(&m2m_ctx->finished);
drivers/media/v4l2-core/v4l2-mem2mem.c:	out_q_ctx = &m2m_ctx->out_q_ctx;
drivers/media/v4l2-core/v4l2-mem2mem.c:	cap_q_ctx = &m2m_ctx->cap_q_ctx;
drivers/media/v4l2-core/v4l2-mem2mem.c:	INIT_LIST_HEAD(&out_q_ctx->rdy_queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	INIT_LIST_HEAD(&cap_q_ctx->rdy_queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_init(&out_q_ctx->rdy_spinlock);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_init(&cap_q_ctx->rdy_spinlock);
drivers/media/v4l2-core/v4l2-mem2mem.c:	INIT_LIST_HEAD(&m2m_ctx->queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	ret = queue_init(drv_priv, &out_q_ctx->q, &cap_q_ctx->q);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (out_q_ctx->q.lock == cap_q_ctx->q.lock)
drivers/media/v4l2-core/v4l2-mem2mem.c:		m2m_ctx->q_lock = out_q_ctx->q.lock;
drivers/media/v4l2-core/v4l2-mem2mem.c:	vb2_queue_release(&m2m_ctx->cap_q_ctx.q);
drivers/media/v4l2-core/v4l2-mem2mem.c:	vb2_queue_release(&m2m_ctx->out_q_ctx.q);
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_lock_irqsave(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	list_add_tail(&b->list, &q_ctx->rdy_queue);
drivers/media/v4l2-core/v4l2-mem2mem.c:	q_ctx->num_rdy++;
drivers/media/v4l2-core/v4l2-mem2mem.c:	spin_unlock_irqrestore(&q_ctx->rdy_spinlock, flags);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->q_lock)
drivers/media/v4l2-core/v4l2-mem2mem.c:		mutex_lock(m2m_ctx->q_lock);
drivers/media/v4l2-core/v4l2-mem2mem.c:	if (m2m_ctx->q_lock)
drivers/media/v4l2-core/v4l2-mem2mem.c:		mutex_unlock(m2m_ctx->q_lock);
drivers/media/i2c/mt9m111.c:	return reg_write(CONTEXT_CONTROL, ctx->control);
drivers/media/i2c/mt9m111.c:	int ret = mt9m111_reg_write(client, ctx->reducer_xzoom, rect->width);
drivers/media/i2c/mt9m111.c:		ret = mt9m111_reg_write(client, ctx->reducer_yzoom, rect->height);
drivers/media/i2c/mt9m111.c:		ret = mt9m111_reg_write(client, ctx->reducer_xsize, width);
drivers/media/i2c/mt9m111.c:		ret = mt9m111_reg_write(client, ctx->reducer_ysize, height);
drivers/media/i2c/mt9m111.c:		ret = mt9m111_reg_set(client, mt9m111->ctx->read_mode, mask);
drivers/media/i2c/mt9m111.c:		ret = mt9m111_reg_clear(client, mt9m111->ctx->read_mode, mask);
drivers/edac/xgene_edac.c:		       ctx->mcu_csr + MCUESRRA0 + i * MCU_RANK_STRIDE);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, PCPHPERRINTSTS, &pcp_hp_stat);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, PCPLPERRINTSTS, &pcp_lp_stat);
drivers/edac/xgene_edac.c:		reg = readl(ctx->mcu_csr + MCUESRR0 + rank * MCU_RANK_STRIDE);
drivers/edac/xgene_edac.c:			bank = readl(ctx->mcu_csr + MCUEBLRR0 +
drivers/edac/xgene_edac.c:			col_row = readl(ctx->mcu_csr + MCUERCRR0 +
drivers/edac/xgene_edac.c:			count = readl(ctx->mcu_csr + MCUSBECNT0 +
drivers/edac/xgene_edac.c:		writel(0x0, ctx->mcu_csr + MCUEBLRR0 + rank * MCU_RANK_STRIDE);
drivers/edac/xgene_edac.c:		writel(0x0, ctx->mcu_csr + MCUERCRR0 + rank * MCU_RANK_STRIDE);
drivers/edac/xgene_edac.c:		writel(0x0, ctx->mcu_csr + MCUSBECNT0 +
drivers/edac/xgene_edac.c:		writel(reg, ctx->mcu_csr + MCUESRR0 + rank * MCU_RANK_STRIDE);
drivers/edac/xgene_edac.c:	reg = readl(ctx->mcu_csr + MCUGESR);
drivers/edac/xgene_edac.c:		writel(reg, ctx->mcu_csr + MCUGESR);
drivers/edac/xgene_edac.c:	mutex_lock(&ctx->edac->mc_lock);
drivers/edac/xgene_edac.c:		ctx->edac->mc_registered_mask |= 1 << ctx->mcu_id;
drivers/edac/xgene_edac.c:		if (ctx->edac->mc_registered_mask ==
drivers/edac/xgene_edac.c:		    ctx->edac->mc_active_mask) {
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:		val = readl(ctx->mcu_csr + MCUGECR);
drivers/edac/xgene_edac.c:		writel(val, ctx->mcu_csr + MCUGECR);
drivers/edac/xgene_edac.c:		val = readl(ctx->mcu_csr + MCUGECR);
drivers/edac/xgene_edac.c:		writel(val, ctx->mcu_csr + MCUGECR);
drivers/edac/xgene_edac.c:		xgene_edac_pcp_setbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:		xgene_edac_pcp_setbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:		ctx->edac->mc_registered_mask &= ~(1 << ctx->mcu_id);
drivers/edac/xgene_edac.c:	mutex_unlock(&ctx->edac->mc_lock);
drivers/edac/xgene_edac.c:	if (regmap_read(ctx->edac->csw_map, CSW_CSWCR, &reg))
drivers/edac/xgene_edac.c:		if (regmap_read(ctx->edac->mcbb_map, MCBADDRMR, &reg))
drivers/edac/xgene_edac.c:		if (regmap_read(ctx->edac->mcba_map, MCBADDRMR, &reg))
drivers/edac/xgene_edac.c:	if (!ctx->edac->mc_active_mask)
drivers/edac/xgene_edac.c:		ctx->edac->mc_active_mask = mcu_mask;
drivers/edac/xgene_edac.c:	ctx->name = "xgene_edac_mc_err";
drivers/edac/xgene_edac.c:	ctx->mci = mci;
drivers/edac/xgene_edac.c:	mci->ctl_name = ctx->name;
drivers/edac/xgene_edac.c:	mci->dev_name = ctx->name;
drivers/edac/xgene_edac.c:	list_add(&ctx->next, &edac->mcus);
drivers/edac/xgene_edac.c:	pg_f = ctx->pmd_csr + cpu_idx * CPU_CSR_STRIDE + CPU_MEMERR_CPU_PAGE;
drivers/edac/xgene_edac.c:		ctx->pmd * MAX_CPU_PER_PMD + cpu_idx, val,
drivers/edac/xgene_edac.c:		ctx->pmd * MAX_CPU_PER_PMD + cpu_idx, val,
drivers/edac/xgene_edac.c:		ctx->pmd * MAX_CPU_PER_PMD + cpu_idx, val,
drivers/edac/xgene_edac.c:	pg_e = ctx->pmd_csr + CPU_MEMERR_L2C_PAGE;
drivers/edac/xgene_edac.c:		ctx->pmd, val, val_hi, val_lo);
drivers/edac/xgene_edac.c:	pg_d = ctx->pmd_csr + CPU_L2C_PAGE;
drivers/edac/xgene_edac.c:			ctx->pmd, val, val_hi, val_lo);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, PCPHPERRINTSTS, &pcp_hp_stat);
drivers/edac/xgene_edac.c:	if (!((PMD0_MERR_MASK << ctx->pmd) & pcp_hp_stat))
drivers/edac/xgene_edac.c:	void __iomem *pg_f = ctx->pmd_csr + cpu * CPU_CSR_STRIDE +
drivers/edac/xgene_edac.c:	void __iomem *pg_d = ctx->pmd_csr + CPU_L2C_PAGE;
drivers/edac/xgene_edac.c:	void __iomem *pg_e = ctx->pmd_csr + CPU_MEMERR_L2C_PAGE;
drivers/edac/xgene_edac.c:	if (ctx->version > 1)
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:					       PMD0_MERR_MASK << ctx->pmd);
drivers/edac/xgene_edac.c:			xgene_edac_pcp_setbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:					       PMD0_MERR_MASK << ctx->pmd);
drivers/edac/xgene_edac.c:		cpux_pg_f = ctx->pmd_csr + i * CPU_CSR_STRIDE +
drivers/edac/xgene_edac.c:	void __iomem *pg_e = ctx->pmd_csr + CPU_MEMERR_L2C_PAGE;
drivers/edac/xgene_edac.c:	if (!IS_ENABLED(CONFIG_EDAC_DEBUG) || !ctx->edac->dfs)
drivers/edac/xgene_edac.c:	snprintf(name, sizeof(name), "PMD%d", ctx->pmd);
drivers/edac/xgene_edac.c:	dbgfs_dir = edac_debugfs_create_dir_at(name, ctx->edac->dfs);
drivers/edac/xgene_edac.c:	ctx->name = "xgene_pmd_err";
drivers/edac/xgene_edac.c:	ctx->pmd = pmd;
drivers/edac/xgene_edac.c:	ctx->edac = edac;
drivers/edac/xgene_edac.c:	ctx->edac_dev = edac_dev;
drivers/edac/xgene_edac.c:	ctx->ddev = *edac->dev;
drivers/edac/xgene_edac.c:	ctx->version = version;
drivers/edac/xgene_edac.c:	edac_dev->dev = &ctx->ddev;
drivers/edac/xgene_edac.c:	edac_dev->ctl_name = ctx->name;
drivers/edac/xgene_edac.c:	edac_dev->dev_name = ctx->name;
drivers/edac/xgene_edac.c:	ctx->pmd_csr = devm_ioremap_resource(edac->dev, &res);
drivers/edac/xgene_edac.c:	if (IS_ERR(ctx->pmd_csr)) {
drivers/edac/xgene_edac.c:		rc = PTR_ERR(ctx->pmd_csr);
drivers/edac/xgene_edac.c:	list_add(&ctx->next, &edac->pmds);
drivers/edac/xgene_edac.c:	dev_info(edac->dev, "X-Gene EDAC PMD%d registered\n", ctx->pmd);
drivers/edac/xgene_edac.c:	l3cesr = readl(ctx->dev_csr + L3C_ESR);
drivers/edac/xgene_edac.c:	l3celr = readl(ctx->dev_csr + L3C_ELR);
drivers/edac/xgene_edac.c:	l3caelr = readl(ctx->dev_csr + L3C_AELR);
drivers/edac/xgene_edac.c:	l3cbelr = readl(ctx->dev_csr + L3C_BELR);
drivers/edac/xgene_edac.c:	writel(0, ctx->dev_csr + L3C_ESR);
drivers/edac/xgene_edac.c:	if (ctx->version <= 1 &&
drivers/edac/xgene_edac.c:	val = readl(ctx->dev_csr + L3C_ECR);
drivers/edac/xgene_edac.c:	writel(val, ctx->dev_csr + L3C_ECR);
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_setbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_setbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:	writel(0xFFFFFFFF, ctx->dev_csr + L3C_ESR);
drivers/edac/xgene_edac.c:	if (!IS_ENABLED(CONFIG_EDAC_DEBUG) || !ctx->edac->dfs)
drivers/edac/xgene_edac.c:	snprintf(name, sizeof(name), "l3c%d", ctx->edac_idx);
drivers/edac/xgene_edac.c:	dbgfs_dir = edac_debugfs_create_dir_at(name, ctx->edac->dfs);
drivers/edac/xgene_edac.c:	ctx->dev_csr = dev_csr;
drivers/edac/xgene_edac.c:	ctx->name = "xgene_l3_err";
drivers/edac/xgene_edac.c:	ctx->edac_idx = edac_idx;
drivers/edac/xgene_edac.c:	ctx->edac = edac;
drivers/edac/xgene_edac.c:	ctx->edac_dev = edac_dev;
drivers/edac/xgene_edac.c:	ctx->ddev = *edac->dev;
drivers/edac/xgene_edac.c:	ctx->version = version;
drivers/edac/xgene_edac.c:	edac_dev->dev = &ctx->ddev;
drivers/edac/xgene_edac.c:	edac_dev->ctl_name = ctx->name;
drivers/edac/xgene_edac.c:	edac_dev->dev_name = ctx->name;
drivers/edac/xgene_edac.c:	list_add(&ctx->next, &edac->l3s);
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + XGICTRANSERRINTSTS);
drivers/edac/xgene_edac.c:	info = readl(ctx->dev_csr + XGICTRANSERRREQINFO);
drivers/edac/xgene_edac.c:	writel(reg, ctx->dev_csr + XGICTRANSERRINTSTS);
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + GLBL_ERR_STS);
drivers/edac/xgene_edac.c:		err_addr_lo = readl(ctx->dev_csr + GLBL_SEC_ERRL);
drivers/edac/xgene_edac.c:		err_addr_hi = readl(ctx->dev_csr + GLBL_SEC_ERRH);
drivers/edac/xgene_edac.c:		writel(err_addr_lo, ctx->dev_csr + GLBL_SEC_ERRL);
drivers/edac/xgene_edac.c:		writel(err_addr_hi, ctx->dev_csr + GLBL_SEC_ERRH);
drivers/edac/xgene_edac.c:		err_addr_lo = readl(ctx->dev_csr + GLBL_MSEC_ERRL);
drivers/edac/xgene_edac.c:		err_addr_hi = readl(ctx->dev_csr + GLBL_MSEC_ERRH);
drivers/edac/xgene_edac.c:		writel(err_addr_lo, ctx->dev_csr + GLBL_MSEC_ERRL);
drivers/edac/xgene_edac.c:		writel(err_addr_hi, ctx->dev_csr + GLBL_MSEC_ERRH);
drivers/edac/xgene_edac.c:		err_addr_lo = readl(ctx->dev_csr + GLBL_DED_ERRL);
drivers/edac/xgene_edac.c:		err_addr_hi = readl(ctx->dev_csr + GLBL_DED_ERRH);
drivers/edac/xgene_edac.c:		writel(err_addr_lo, ctx->dev_csr + GLBL_DED_ERRL);
drivers/edac/xgene_edac.c:		writel(err_addr_hi, ctx->dev_csr + GLBL_DED_ERRH);
drivers/edac/xgene_edac.c:		err_addr_lo = readl(ctx->dev_csr + GLBL_MDED_ERRL);
drivers/edac/xgene_edac.c:		err_addr_hi = readl(ctx->dev_csr + GLBL_MDED_ERRH);
drivers/edac/xgene_edac.c:		writel(err_addr_lo, ctx->dev_csr + GLBL_MDED_ERRL);
drivers/edac/xgene_edac.c:		writel(err_addr_hi, ctx->dev_csr + GLBL_MDED_ERRH);
drivers/edac/xgene_edac.c:	if (!ctx->edac->rb_map)
drivers/edac/xgene_edac.c:	if (regmap_read(ctx->edac->rb_map, RBCSR, &reg))
drivers/edac/xgene_edac.c:		if (regmap_read(ctx->edac->rb_map, RBEIR, &reg))
drivers/edac/xgene_edac.c:		if (regmap_write(ctx->edac->rb_map, RBEIR, 0))
drivers/edac/xgene_edac.c:		if (regmap_write(ctx->edac->rb_map, RBCSR, 0))
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + IOBBATRANSERRINTSTS);
drivers/edac/xgene_edac.c:	err_addr_lo = readl(ctx->dev_csr + IOBBATRANSERRREQINFOL);
drivers/edac/xgene_edac.c:	err_addr_hi = readl(ctx->dev_csr + IOBBATRANSERRREQINFOH);
drivers/edac/xgene_edac.c:			readl(ctx->dev_csr + IOBBATRANSERRCSWREQID));
drivers/edac/xgene_edac.c:	writel(reg, ctx->dev_csr + IOBBATRANSERRINTSTS);
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + IOBPATRANSERRINTSTS);
drivers/edac/xgene_edac.c:	writel(reg, ctx->dev_csr + IOBPATRANSERRINTSTS);
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + IOBAXIS0TRANSERRINTSTS);
drivers/edac/xgene_edac.c:	err_addr_lo = readl(ctx->dev_csr + IOBAXIS0TRANSERRREQINFOL);
drivers/edac/xgene_edac.c:	err_addr_hi = readl(ctx->dev_csr + IOBAXIS0TRANSERRREQINFOH);
drivers/edac/xgene_edac.c:	writel(reg, ctx->dev_csr + IOBAXIS0TRANSERRINTSTS);
drivers/edac/xgene_edac.c:	reg = readl(ctx->dev_csr + IOBAXIS1TRANSERRINTSTS);
drivers/edac/xgene_edac.c:	err_addr_lo = readl(ctx->dev_csr + IOBAXIS1TRANSERRREQINFOL);
drivers/edac/xgene_edac.c:	err_addr_hi = readl(ctx->dev_csr + IOBAXIS1TRANSERRREQINFOH);
drivers/edac/xgene_edac.c:	writel(reg, ctx->dev_csr + IOBAXIS1TRANSERRINTSTS);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, PCPHPERRINTSTS, &pcp_hp_stat);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, PCPLPERRINTSTS, &pcp_lp_stat);
drivers/edac/xgene_edac.c:	xgene_edac_pcp_rd(ctx->edac, MEMERRINTSTS, &reg);
drivers/edac/xgene_edac.c:	if (ctx->version == 1)
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_clrbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_setbits(ctx->edac, PCPHPERRINTMSK,
drivers/edac/xgene_edac.c:			xgene_edac_pcp_setbits(ctx->edac, PCPLPERRINTMSK,
drivers/edac/xgene_edac.c:		       ctx->dev_csr + IOBAXIS0TRANSERRINTMSK);
drivers/edac/xgene_edac.c:		       ctx->dev_csr + IOBAXIS1TRANSERRINTMSK);
drivers/edac/xgene_edac.c:		       ctx->dev_csr + XGICTRANSERRINTMSK);
drivers/edac/xgene_edac.c:		xgene_edac_pcp_setbits(ctx->edac, MEMERRINTMSK,
drivers/edac/xgene_edac.c:	ctx->dev_csr = dev_csr;
drivers/edac/xgene_edac.c:	ctx->name = "xgene_soc_err";
drivers/edac/xgene_edac.c:	ctx->edac_idx = edac_idx;
drivers/edac/xgene_edac.c:	ctx->edac = edac;
drivers/edac/xgene_edac.c:	ctx->edac_dev = edac_dev;
drivers/edac/xgene_edac.c:	ctx->ddev = *edac->dev;
drivers/edac/xgene_edac.c:	ctx->version = version;
drivers/edac/xgene_edac.c:	edac_dev->dev = &ctx->ddev;
drivers/edac/xgene_edac.c:	edac_dev->ctl_name = ctx->name;
drivers/edac/xgene_edac.c:	edac_dev->dev_name = ctx->name;
drivers/edac/xgene_edac.c:	list_add(&ctx->next, &edac->socs);
drivers/edac/xgene_edac.c:		list_for_each_entry(mcu, &ctx->mcus, next)
drivers/edac/xgene_edac.c:	list_for_each_entry(pmd, &ctx->pmds, next) {
drivers/edac/xgene_edac.c:	list_for_each_entry(node, &ctx->l3s, next)
drivers/edac/xgene_edac.c:	list_for_each_entry(node, &ctx->socs, next)
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->wmem = kmalloc(LZO1X_MEM_COMPRESS, GFP_KERNEL);
drivers/base/regmap/regcache-lzo.c:	if (!lzo_ctx->wmem)
drivers/base/regmap/regcache-lzo.c:	ret = lzo1x_1_compress(lzo_ctx->src, lzo_ctx->src_len,
drivers/base/regmap/regcache-lzo.c:			       lzo_ctx->dst, &compress_size, lzo_ctx->wmem);
drivers/base/regmap/regcache-lzo.c:	if (ret != LZO_E_OK || compress_size > lzo_ctx->dst_len)
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->dst_len = compress_size;
drivers/base/regmap/regcache-lzo.c:	dst_len = lzo_ctx->dst_len;
drivers/base/regmap/regcache-lzo.c:	ret = lzo1x_decompress_safe(lzo_ctx->src, lzo_ctx->src_len,
drivers/base/regmap/regcache-lzo.c:				    lzo_ctx->dst, &dst_len);
drivers/base/regmap/regcache-lzo.c:	if (ret != LZO_E_OK || dst_len != lzo_ctx->dst_len)
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->dst_len = lzo1x_worst_compress(PAGE_SIZE);
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->dst = kmalloc(lzo_ctx->dst_len, GFP_KERNEL);
drivers/base/regmap/regcache-lzo.c:	if (!lzo_ctx->dst) {
drivers/base/regmap/regcache-lzo.c:		lzo_ctx->dst_len = 0;
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->dst_len = lzo_ctx->decompressed_size;
drivers/base/regmap/regcache-lzo.c:	lzo_ctx->dst = kmalloc(lzo_ctx->dst_len, GFP_KERNEL);
drivers/base/regmap/regcache-lzo.c:	if (!lzo_ctx->dst) {
drivers/base/regmap/regcache-lzo.c:		lzo_ctx->dst_len = 0;
drivers/base/regmap/regcache-rbtree.c:	rbnode = rbtree_ctx->cached_rbnode;
drivers/base/regmap/regcache-rbtree.c:	node = rbtree_ctx->root.rb_node;
drivers/base/regmap/regcache-rbtree.c:			rbtree_ctx->cached_rbnode = rbnode;
drivers/base/regmap/regcache-rbtree.c:	for (node = rb_first(&rbtree_ctx->root); node != NULL;
drivers/base/regmap/regcache-rbtree.c:	rbtree_ctx->root = RB_ROOT;
drivers/base/regmap/regcache-rbtree.c:	rbtree_ctx->cached_rbnode = NULL;
drivers/base/regmap/regcache-rbtree.c:	next = rb_first(&rbtree_ctx->root);
drivers/base/regmap/regcache-rbtree.c:		rb_erase(&rbtree_node->node, &rbtree_ctx->root);
drivers/base/regmap/regcache-rbtree.c:		node = rbtree_ctx->root.rb_node;
drivers/base/regmap/regcache-rbtree.c:			rbtree_ctx->cached_rbnode = rbnode;
drivers/base/regmap/regcache-rbtree.c:		regcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);
drivers/base/regmap/regcache-rbtree.c:		rbtree_ctx->cached_rbnode = rbnode;
drivers/base/regmap/regcache-rbtree.c:	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
drivers/base/regmap/regcache-rbtree.c:	for (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {
drivers/base/regmap/regmap-mmio.c:	writeb(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	writew(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	iowrite16be(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	writel(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	iowrite32be(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	writeq(val, ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	if (!IS_ERR(ctx->clk)) {
drivers/base/regmap/regmap-mmio.c:		ret = clk_enable(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	ctx->reg_write(ctx, reg, val);
drivers/base/regmap/regmap-mmio.c:	if (!IS_ERR(ctx->clk))
drivers/base/regmap/regmap-mmio.c:		clk_disable(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	return readb(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	return readw(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	return ioread16be(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	return readl(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	return ioread32be(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	return readq(ctx->regs + reg);
drivers/base/regmap/regmap-mmio.c:	if (!IS_ERR(ctx->clk)) {
drivers/base/regmap/regmap-mmio.c:		ret = clk_enable(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	*val = ctx->reg_read(ctx, reg);
drivers/base/regmap/regmap-mmio.c:	if (!IS_ERR(ctx->clk))
drivers/base/regmap/regmap-mmio.c:		clk_disable(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	if (!IS_ERR(ctx->clk)) {
drivers/base/regmap/regmap-mmio.c:		clk_unprepare(ctx->clk);
drivers/base/regmap/regmap-mmio.c:		clk_put(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	ctx->regs = regs;
drivers/base/regmap/regmap-mmio.c:	ctx->val_bytes = config->val_bits / 8;
drivers/base/regmap/regmap-mmio.c:	ctx->clk = ERR_PTR(-ENODEV);
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read8;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write8;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read16le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write16le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read32le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write32le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read64le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write64le;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read8;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write8;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read16be;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write16be;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_read = regmap_mmio_read32be;
drivers/base/regmap/regmap-mmio.c:			ctx->reg_write = regmap_mmio_write32be;
drivers/base/regmap/regmap-mmio.c:	ctx->clk = clk_get(dev, clk_id);
drivers/base/regmap/regmap-mmio.c:	if (IS_ERR(ctx->clk)) {
drivers/base/regmap/regmap-mmio.c:		ret = PTR_ERR(ctx->clk);
drivers/base/regmap/regmap-mmio.c:	ret = clk_prepare(ctx->clk);
drivers/base/regmap/regmap-mmio.c:		clk_put(ctx->clk);
drivers/usb/misc/usbtest.c:	spin_lock(&ctx->lock);
drivers/usb/misc/usbtest.c:	ctx->count--;
drivers/usb/misc/usbtest.c:	ctx->pending--;
drivers/usb/misc/usbtest.c:		if ((subcase->number - ctx->last) != 1) {
drivers/usb/misc/usbtest.c:			ERROR(ctx->dev,
drivers/usb/misc/usbtest.c:				subcase->number, ctx->last);
drivers/usb/misc/usbtest.c:			ctx->last = subcase->number;
drivers/usb/misc/usbtest.c:	ctx->last = subcase->number;
drivers/usb/misc/usbtest.c:			ERROR(ctx->dev, "subtest %d error, status %d\n",
drivers/usb/misc/usbtest.c:		if (ctx->status == 0) {
drivers/usb/misc/usbtest.c:			ctx->status = status;
drivers/usb/misc/usbtest.c:			ERROR(ctx->dev, "control queue %02x.%02x, err %d, "
drivers/usb/misc/usbtest.c:					status, ctx->count, subcase->number,
drivers/usb/misc/usbtest.c:			for (i = 1; i < ctx->param->sglen; i++) {
drivers/usb/misc/usbtest.c:				struct urb *u = ctx->urb[
drivers/usb/misc/usbtest.c:							% ctx->param->sglen];
drivers/usb/misc/usbtest.c:				spin_unlock(&ctx->lock);
drivers/usb/misc/usbtest.c:				spin_lock(&ctx->lock);
drivers/usb/misc/usbtest.c:					ERROR(ctx->dev, "urb unlink --> %d\n",
drivers/usb/misc/usbtest.c:			status = ctx->status;
drivers/usb/misc/usbtest.c:	if ((status == 0) && (ctx->pending < ctx->count)) {
drivers/usb/misc/usbtest.c:			ERROR(ctx->dev,
drivers/usb/misc/usbtest.c:			ctx->pending++;
drivers/usb/misc/usbtest.c:	if (ctx->pending == 0)
drivers/usb/misc/usbtest.c:		complete(&ctx->complete);
drivers/usb/misc/usbtest.c:	spin_unlock(&ctx->lock);
drivers/usb/misc/usbtest.c:	if (ctx->status)
drivers/usb/misc/usbtest.c:	if (urb == ctx->urbs[ctx->num - 4] || urb == ctx->urbs[ctx->num - 2]) {
drivers/usb/misc/usbtest.c:		ctx->status = status;
drivers/usb/misc/usbtest.c:	if (atomic_dec_and_test(&ctx->pending))
drivers/usb/misc/usbtest.c:		complete(&ctx->complete);
drivers/usb/misc/usbtest.c:	spin_lock(&ctx->lock);
drivers/usb/misc/usbtest.c:	ctx->count--;
drivers/usb/misc/usbtest.c:	ctx->packet_count += urb->number_of_packets;
drivers/usb/misc/usbtest.c:		ctx->errors += urb->error_count;
drivers/usb/misc/usbtest.c:		ctx->errors += (ctx->is_iso ? urb->number_of_packets : 1);
drivers/usb/misc/usbtest.c:		ctx->errors++;
drivers/usb/misc/usbtest.c:	else if (check_guard_bytes(ctx->dev, urb) != 0)
drivers/usb/misc/usbtest.c:		ctx->errors++;
drivers/usb/misc/usbtest.c:	if (urb->status == 0 && ctx->count > (ctx->pending - 1)
drivers/usb/misc/usbtest.c:			&& !ctx->submit_error) {
drivers/usb/misc/usbtest.c:			dev_err(&ctx->dev->intf->dev,
drivers/usb/misc/usbtest.c:			ctx->submit_error = 1;
drivers/usb/misc/usbtest.c:	ctx->pending--;
drivers/usb/misc/usbtest.c:	if (ctx->pending == 0) {
drivers/usb/misc/usbtest.c:		if (ctx->errors)
drivers/usb/misc/usbtest.c:			dev_err(&ctx->dev->intf->dev,
drivers/usb/misc/usbtest.c:				ctx->errors, ctx->packet_count);
drivers/usb/misc/usbtest.c:		complete(&ctx->done);
drivers/usb/misc/usbtest.c:	spin_unlock(&ctx->lock);
drivers/usb/core/message.c:	ctx->status = urb->status;
drivers/usb/core/message.c:	complete(&ctx->done);
drivers/usb/host/xhci.h:	(le32_to_cpu(ctrl_ctx->add_flags) & (1 << (i + 1)))
drivers/usb/host/xhci.h:	(le32_to_cpu(ctrl_ctx->drop_flags) & (1 << (i + 1)))
drivers/usb/host/xhci-dbg.c:	switch (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state))) {
drivers/usb/host/xhci-dbg.c:	dma_addr_t dma = ctx->dma +
drivers/usb/host/xhci-dbg.c:		((unsigned long)slot_ctx - (unsigned long)ctx->bytes);
drivers/usb/host/xhci-dbg.c:			&slot_ctx->dev_info,
drivers/usb/host/xhci-dbg.c:			(unsigned long long)dma, slot_ctx->dev_info);
drivers/usb/host/xhci-dbg.c:			&slot_ctx->dev_info2,
drivers/usb/host/xhci-dbg.c:			(unsigned long long)dma, slot_ctx->dev_info2);
drivers/usb/host/xhci-dbg.c:			&slot_ctx->tt_info,
drivers/usb/host/xhci-dbg.c:			(unsigned long long)dma, slot_ctx->tt_info);
drivers/usb/host/xhci-dbg.c:			&slot_ctx->dev_state,
drivers/usb/host/xhci-dbg.c:			(unsigned long long)dma, slot_ctx->dev_state);
drivers/usb/host/xhci-dbg.c:				&slot_ctx->reserved[i], (unsigned long long)dma,
drivers/usb/host/xhci-dbg.c:				slot_ctx->reserved[i], i);
drivers/usb/host/xhci-dbg.c:		dma_addr_t dma = ctx->dma +
drivers/usb/host/xhci-dbg.c:			((unsigned long)ep_ctx - (unsigned long)ctx->bytes);
drivers/usb/host/xhci-dbg.c:				&ep_ctx->ep_info,
drivers/usb/host/xhci-dbg.c:				(unsigned long long)dma, ep_ctx->ep_info);
drivers/usb/host/xhci-dbg.c:				&ep_ctx->ep_info2,
drivers/usb/host/xhci-dbg.c:				(unsigned long long)dma, ep_ctx->ep_info2);
drivers/usb/host/xhci-dbg.c:				&ep_ctx->deq,
drivers/usb/host/xhci-dbg.c:				(unsigned long long)dma, ep_ctx->deq);
drivers/usb/host/xhci-dbg.c:				&ep_ctx->tx_info,
drivers/usb/host/xhci-dbg.c:				(unsigned long long)dma, ep_ctx->tx_info);
drivers/usb/host/xhci-dbg.c:					&ep_ctx->reserved[j],
drivers/usb/host/xhci-dbg.c:					ep_ctx->reserved[j], j);
drivers/usb/host/xhci-dbg.c:	dma_addr_t dma = ctx->dma;
drivers/usb/host/xhci-dbg.c:	if (ctx->type == XHCI_CTX_TYPE_INPUT) {
drivers/usb/host/xhci-dbg.c:			 &ctrl_ctx->drop_flags, (unsigned long long)dma,
drivers/usb/host/xhci-dbg.c:			 ctrl_ctx->drop_flags);
drivers/usb/host/xhci-dbg.c:			 &ctrl_ctx->add_flags, (unsigned long long)dma,
drivers/usb/host/xhci-dbg.c:			 ctrl_ctx->add_flags);
drivers/usb/host/xhci-dbg.c:				 &ctrl_ctx->rsvd2[i], (unsigned long long)dma,
drivers/usb/host/xhci-dbg.c:				 ctrl_ctx->rsvd2[i], i);
drivers/usb/host/xhci-mtk-sch.c:	ep_type = CTX_TO_EP_TYPE(le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci-mtk-sch.c:	ep_interval = CTX_TO_EP_INTERVAL(le32_to_cpu(ep_ctx->ep_info));
drivers/usb/host/xhci-mtk-sch.c:	max_packet_size = MAX_PACKET_DECODED(le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci-mtk-sch.c:	max_burst = CTX_TO_MAX_BURST(le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci-mtk-sch.c:	mult = CTX_TO_EP_MULT(le32_to_cpu(ep_ctx->ep_info));
drivers/usb/host/xhci-mtk-sch.c:	if (!need_bw_sch(ep, udev->speed, slot_ctx->tt_info & TT_SLOT)) {
drivers/usb/host/xhci-mtk-sch.c:			ep_ctx->reserved[0] |= cpu_to_le32(EP_BPKTS(1));
drivers/usb/host/xhci-mtk-sch.c:	ep_ctx->reserved[0] |= cpu_to_le32(EP_BPKTS(sch_ep->pkts)
drivers/usb/host/xhci-mtk-sch.c:	ep_ctx->reserved[1] |= cpu_to_le32(EP_BOFFSET(sch_ep->offset)
drivers/usb/host/xhci-mtk-sch.c:	if (!need_bw_sch(ep, udev->speed, slot_ctx->tt_info & TT_SLOT))
drivers/usb/host/xhci-mem.c:	ctx->type = type;
drivers/usb/host/xhci-mem.c:	ctx->size = HCC_64BYTE_CONTEXT(xhci->hcc_params) ? 2048 : 1024;
drivers/usb/host/xhci-mem.c:		ctx->size += CTX_SIZE(xhci->hcc_params);
drivers/usb/host/xhci-mem.c:	ctx->bytes = dma_pool_zalloc(xhci->device_pool, flags, &ctx->dma);
drivers/usb/host/xhci-mem.c:	if (!ctx->bytes) {
drivers/usb/host/xhci-mem.c:	dma_pool_free(xhci->device_pool, ctx->bytes, ctx->dma);
drivers/usb/host/xhci-mem.c:	if (ctx->type != XHCI_CTX_TYPE_INPUT)
drivers/usb/host/xhci-mem.c:	return (struct xhci_input_control_ctx *)ctx->bytes;
drivers/usb/host/xhci-mem.c:	if (ctx->type == XHCI_CTX_TYPE_DEVICE)
drivers/usb/host/xhci-mem.c:		return (struct xhci_slot_ctx *)ctx->bytes;
drivers/usb/host/xhci-mem.c:		(ctx->bytes + CTX_SIZE(xhci->hcc_params));
drivers/usb/host/xhci-mem.c:	if (ctx->type == XHCI_CTX_TYPE_INPUT)
drivers/usb/host/xhci-mem.c:		(ctx->bytes + (ep_index * CTX_SIZE(xhci->hcc_params)));
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info &= cpu_to_le32(~EP_MAXPSTREAMS_MASK);
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info |= cpu_to_le32(EP_MAXPSTREAMS(max_primary_streams)
drivers/usb/host/xhci-mem.c:	ep_ctx->deq  = cpu_to_le64(stream_info->ctx_array_dma);
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info &= cpu_to_le32(~(EP_MAXPSTREAMS_MASK | EP_HAS_LSA));
drivers/usb/host/xhci-mem.c:	ep_ctx->deq  = cpu_to_le64(addr | ep->ring->cycle_state);
drivers/usb/host/xhci-mem.c:			(unsigned long long)dev->out_ctx->dma);
drivers/usb/host/xhci-mem.c:			(unsigned long long)dev->in_ctx->dma);
drivers/usb/host/xhci-mem.c:	xhci->dcbaa->dev_context_ptrs[slot_id] = cpu_to_le64(dev->out_ctx->dma);
drivers/usb/host/xhci-mem.c:	ep0_ctx->deq = cpu_to_le64(xhci_trb_virt_to_dma(ep_ring->enq_seg,
drivers/usb/host/xhci-mem.c:	slot_ctx->dev_info |= cpu_to_le32(LAST_CTX(1) | udev->route);
drivers/usb/host/xhci-mem.c:		slot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_SSP);
drivers/usb/host/xhci-mem.c:		slot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_SS);
drivers/usb/host/xhci-mem.c:		slot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_HS);
drivers/usb/host/xhci-mem.c:		slot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_FS);
drivers/usb/host/xhci-mem.c:		slot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_LS);
drivers/usb/host/xhci-mem.c:	slot_ctx->dev_info2 |= cpu_to_le32(ROOT_HUB_PORT(port_num));
drivers/usb/host/xhci-mem.c:		slot_ctx->tt_info = cpu_to_le32(udev->tt->hub->slot_id |
drivers/usb/host/xhci-mem.c:			slot_ctx->dev_info |= cpu_to_le32(DEV_MTT);
drivers/usb/host/xhci-mem.c:	ep0_ctx->ep_info2 = cpu_to_le32(EP_TYPE(CTRL_EP));
drivers/usb/host/xhci-mem.c:	ep0_ctx->ep_info2 |= cpu_to_le32(MAX_BURST(0) | ERROR_COUNT(3) |
drivers/usb/host/xhci-mem.c:	ep0_ctx->deq = cpu_to_le64(dev->eps[0].ring->first_seg->dma |
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info = cpu_to_le32(EP_MAX_ESIT_PAYLOAD_HI(max_esit_payload) |
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info2 = cpu_to_le32(EP_TYPE(endpoint_type) |
drivers/usb/host/xhci-mem.c:	ep_ctx->deq = cpu_to_le64(ep_ring->first_seg->dma |
drivers/usb/host/xhci-mem.c:	ep_ctx->tx_info = cpu_to_le32(EP_MAX_ESIT_PAYLOAD_LO(max_esit_payload) |
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info = 0;
drivers/usb/host/xhci-mem.c:	ep_ctx->ep_info2 = 0;
drivers/usb/host/xhci-mem.c:	ep_ctx->deq = 0;
drivers/usb/host/xhci-mem.c:	ep_ctx->tx_info = 0;
drivers/usb/host/xhci-mem.c:			ep_type = CTX_TO_EP_TYPE(le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci-mem.c:					le32_to_cpu(ep_ctx->ep_info));
drivers/usb/host/xhci-mem.c:					le32_to_cpu(ep_ctx->ep_info)) + 1;
drivers/usb/host/xhci-mem.c:					le32_to_cpu(ep_ctx->ep_info2)) + 1;
drivers/usb/host/xhci-mem.c:					le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci-mem.c:					le32_to_cpu(ep_ctx->tx_info));
drivers/usb/host/xhci-mem.c:	in_ep_ctx->ep_info = out_ep_ctx->ep_info;
drivers/usb/host/xhci-mem.c:	in_ep_ctx->ep_info2 = out_ep_ctx->ep_info2;
drivers/usb/host/xhci-mem.c:	in_ep_ctx->deq = out_ep_ctx->deq;
drivers/usb/host/xhci-mem.c:	in_ep_ctx->tx_info = out_ep_ctx->tx_info;
drivers/usb/host/xhci-mem.c:	in_slot_ctx->dev_info = out_slot_ctx->dev_info;
drivers/usb/host/xhci-mem.c:	in_slot_ctx->dev_info2 = out_slot_ctx->dev_info2;
drivers/usb/host/xhci-mem.c:	in_slot_ctx->tt_info = out_slot_ctx->tt_info;
drivers/usb/host/xhci-mem.c:	in_slot_ctx->dev_state = out_slot_ctx->dev_state;
drivers/usb/host/xhci-ring.c:		hw_dequeue = le64_to_cpu(ctx->stream_ring);
drivers/usb/host/xhci-ring.c:		hw_dequeue = le64_to_cpu(ep_ctx->deq);
drivers/usb/host/xhci-ring.c:			ep_state = le32_to_cpu(ep_ctx->ep_info);
drivers/usb/host/xhci-ring.c:			slot_state = le32_to_cpu(slot_ctx->dev_state);
drivers/usb/host/xhci-ring.c:			deq = le64_to_cpu(ctx->stream_ring) & SCTX_DEQ_MASK;
drivers/usb/host/xhci-ring.c:			deq = le64_to_cpu(ep_ctx->deq) & ~EP_CTX_CYCLE_MASK;
drivers/usb/host/xhci-ring.c:				xhci->devs[slot_id]->in_ctx->dma, slot_id,
drivers/usb/host/xhci-ring.c:	add_flags = le32_to_cpu(ctrl_ctx->add_flags);
drivers/usb/host/xhci-ring.c:	drop_flags = le32_to_cpu(ctrl_ctx->drop_flags);
drivers/usb/host/xhci-ring.c:		if ((ep_ctx->ep_info & cpu_to_le32(EP_STATE_MASK)) ==
drivers/usb/host/xhci-ring.c:	    (le32_to_cpu(ep_ctx->ep_info) & EP_STATE_MASK) ==
drivers/usb/host/xhci-ring.c:			   le32_to_cpu(ep_ctx->ep_info) & EP_STATE_MASK,
drivers/usb/host/xhci-ring.c:	xhci_interval = EP_INTERVAL_TO_UFRAMES(le32_to_cpu(ep_ctx->ep_info));
drivers/usb/host/xhci-ring.c:	ret = prepare_ring(xhci, ep_ring, le32_to_cpu(ep_ctx->ep_info) & EP_STATE_MASK,
drivers/usb/host/xhci-ring.c:		if ((le32_to_cpu(ep_ctx->ep_info) & EP_STATE_MASK) ==
drivers/usb/host/xhci-trace.h:			((ctx->type == XHCI_CTX_TYPE_INPUT) + ep_num + 1))
drivers/usb/host/xhci-trace.h:		__entry->ctx_type = ctx->type;
drivers/usb/host/xhci-trace.h:		__entry->ctx_dma = ctx->dma;
drivers/usb/host/xhci-trace.h:		__entry->ctx_va = ctx->bytes;
drivers/usb/host/xhci-trace.h:		memcpy(__get_dynamic_array(ctx_data), ctx->bytes,
drivers/usb/host/xhci-trace.h:			((ctx->type == XHCI_CTX_TYPE_INPUT) + ep_num + 1));
drivers/usb/host/xhci.c:	hw_max_packet_size = MAX_PACKET_DECODED(le32_to_cpu(ep_ctx->ep_info2));
drivers/usb/host/xhci.c:		ep_ctx->ep_info2 &= cpu_to_le32(~MAX_PACKET_MASK);
drivers/usb/host/xhci.c:		ep_ctx->ep_info2 |= cpu_to_le32(MAX_PACKET(max_packet_size));
drivers/usb/host/xhci.c:		ctrl_ctx->add_flags = cpu_to_le32(EP0_FLAG);
drivers/usb/host/xhci.c:		ctrl_ctx->drop_flags = 0;
drivers/usb/host/xhci.c:		ctrl_ctx->add_flags = cpu_to_le32(SLOT_FLAG);
drivers/usb/host/xhci.c:	if (((ep_ctx->ep_info & cpu_to_le32(EP_STATE_MASK)) ==
drivers/usb/host/xhci.c:	    le32_to_cpu(ctrl_ctx->drop_flags) &
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags |= cpu_to_le32(drop_flag);
drivers/usb/host/xhci.c:	new_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags);
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags &= cpu_to_le32(~drop_flag);
drivers/usb/host/xhci.c:	new_add_flags = le32_to_cpu(ctrl_ctx->add_flags);
drivers/usb/host/xhci.c:			!(le32_to_cpu(ctrl_ctx->drop_flags) & added_ctxs)) {
drivers/usb/host/xhci.c:	if (le32_to_cpu(ctrl_ctx->add_flags) & added_ctxs) {
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags |= cpu_to_le32(added_ctxs);
drivers/usb/host/xhci.c:	new_add_flags = le32_to_cpu(ctrl_ctx->add_flags);
drivers/usb/host/xhci.c:	new_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags);
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags = 0;
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags = 0;
drivers/usb/host/xhci.c:	slot_ctx->dev_info &= cpu_to_le32(~LAST_CTX_MASK);
drivers/usb/host/xhci.c:	slot_ctx->dev_info |= cpu_to_le32(LAST_CTX(1));
drivers/usb/host/xhci.c:		ep_ctx->ep_info = 0;
drivers/usb/host/xhci.c:		ep_ctx->ep_info2 = 0;
drivers/usb/host/xhci.c:		ep_ctx->deq = 0;
drivers/usb/host/xhci.c:		ep_ctx->tx_info = 0;
drivers/usb/host/xhci.c:	valid_add_flags = le32_to_cpu(ctrl_ctx->add_flags) >> 2;
drivers/usb/host/xhci.c:	valid_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags) >> 2;
drivers/usb/host/xhci.c:	valid_add_flags = le32_to_cpu(ctrl_ctx->add_flags) >> 2;
drivers/usb/host/xhci.c:	valid_drop_flags = le32_to_cpu(ctrl_ctx->drop_flags) >> 2;
drivers/usb/host/xhci.c:				command->in_ctx->dma,
drivers/usb/host/xhci.c:				command->in_ctx->dma,
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags &= cpu_to_le32(~EP0_FLAG);
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags &= cpu_to_le32(~(SLOT_FLAG | EP0_FLAG));
drivers/usb/host/xhci.c:	if (ctrl_ctx->add_flags == cpu_to_le32(SLOT_FLAG) &&
drivers/usb/host/xhci.c:	    ctrl_ctx->drop_flags == 0) {
drivers/usb/host/xhci.c:		if ((virt_dev->eps[i-1].ring && !(ctrl_ctx->drop_flags & le32))
drivers/usb/host/xhci.c:		    || (ctrl_ctx->add_flags & le32) || i == 1) {
drivers/usb/host/xhci.c:			slot_ctx->dev_info &= cpu_to_le32(~LAST_CTX_MASK);
drivers/usb/host/xhci.c:			slot_ctx->dev_info |= cpu_to_le32(LAST_CTX(i));
drivers/usb/host/xhci.c:		     LAST_CTX_TO_EP_NUM(le32_to_cpu(slot_ctx->dev_info)));
drivers/usb/host/xhci.c:		     LAST_CTX_TO_EP_NUM(le32_to_cpu(slot_ctx->dev_info)));
drivers/usb/host/xhci.c:		if ((le32_to_cpu(ctrl_ctx->drop_flags) & (1 << (i + 1))) &&
drivers/usb/host/xhci.c:		    !(le32_to_cpu(ctrl_ctx->add_flags) & (1 << (i + 1)))) {
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags = cpu_to_le32(add_flags);
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags = cpu_to_le32(drop_flags);
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);
drivers/usb/host/xhci.c:	ep_ctx->deq = cpu_to_le64(addr | deq_state->new_cycle_state);
drivers/usb/host/xhci.c:	if (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state)) ==
drivers/usb/host/xhci.c:		if (GET_SLOT_STATE(le32_to_cpu(slot_ctx->dev_state)) ==
drivers/usb/host/xhci.c:	if (!slot_ctx->dev_info)
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags = cpu_to_le32(SLOT_FLAG | EP0_FLAG);
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags = 0;
drivers/usb/host/xhci.c:				le32_to_cpu(slot_ctx->dev_info) >> 27);
drivers/usb/host/xhci.c:	ret = xhci_queue_address_device(xhci, command, virt_dev->in_ctx->dma,
drivers/usb/host/xhci.c:			(unsigned long long)virt_dev->out_ctx->dma);
drivers/usb/host/xhci.c:				le32_to_cpu(slot_ctx->dev_info) >> 27);
drivers/usb/host/xhci.c:				le32_to_cpu(slot_ctx->dev_info) >> 27);
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags = 0;
drivers/usb/host/xhci.c:	ctrl_ctx->drop_flags = 0;
drivers/usb/host/xhci.c:		       le32_to_cpu(slot_ctx->dev_state) & DEV_ADDR_MASK);
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);
drivers/usb/host/xhci.c:	slot_ctx->dev_info2 &= cpu_to_le32(~((u32) MAX_EXIT));
drivers/usb/host/xhci.c:	slot_ctx->dev_info2 |= cpu_to_le32(max_exit_latency);
drivers/usb/host/xhci.c:	slot_ctx->dev_state = 0;
drivers/usb/host/xhci.c:	ctrl_ctx->add_flags |= cpu_to_le32(SLOT_FLAG);
drivers/usb/host/xhci.c:	slot_ctx->dev_info |= cpu_to_le32(DEV_HUB);
drivers/usb/host/xhci.c:		slot_ctx->dev_info |= cpu_to_le32(DEV_MTT);
drivers/usb/host/xhci.c:		slot_ctx->dev_info &= cpu_to_le32(~DEV_MTT);
drivers/usb/host/xhci.c:		slot_ctx->dev_info2 |= cpu_to_le32(XHCI_MAX_PORTS(hdev->maxchild));
drivers/usb/host/xhci.c:			slot_ctx->tt_info |=
drivers/usb/host/xhci.c:	slot_ctx->dev_state = 0;
drivers/scsi/aacraid/commsup.c:		if (fibctx->count > 20) {
drivers/scsi/aacraid/commsup.c:			u32 time_last = fibctx->jiffies;
drivers/scsi/aacraid/commsup.c:			list_add_tail(&fib->fiblink, &fibctx->fib_list);
drivers/scsi/aacraid/commsup.c:			fibctx->count++;
drivers/scsi/aacraid/commsup.c:			up(&fibctx->wait_sem);
drivers/scsi/aacraid/commsup.c:					if (fibctx->count > 20)
drivers/scsi/aacraid/commsup.c:						time_last = fibctx->jiffies;
drivers/scsi/aacraid/commsup.c:						list_add_tail(&newfib->fiblink, &fibctx->fib_list);
drivers/scsi/aacraid/commsup.c:						fibctx->count++;
drivers/scsi/aacraid/commsup.c:						up(&fibctx->wait_sem);
drivers/scsi/aacraid/commctrl.c:		fibctx->type = FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT;
drivers/scsi/aacraid/commctrl.c:		fibctx->size = sizeof(struct aac_fib_context);
drivers/scsi/aacraid/commctrl.c:		fibctx->unique = (u32)((ulong)fibctx & 0xFFFFFFFF);
drivers/scsi/aacraid/commctrl.c:		sema_init(&fibctx->wait_sem, 0);
drivers/scsi/aacraid/commctrl.c:		fibctx->wait = 0;
drivers/scsi/aacraid/commctrl.c:		fibctx->count = 0;
drivers/scsi/aacraid/commctrl.c:		INIT_LIST_HEAD(&fibctx->fib_list);
drivers/scsi/aacraid/commctrl.c:		fibctx->jiffies = jiffies/HZ;
drivers/scsi/aacraid/commctrl.c:			if (context->unique == fibctx->unique) {
drivers/scsi/aacraid/commctrl.c:				fibctx->unique++;
drivers/scsi/aacraid/commctrl.c:		list_add_tail(&fibctx->next, &dev->fib_list);
drivers/scsi/aacraid/commctrl.c:		if (copy_to_user(arg, &fibctx->unique,
drivers/scsi/aacraid/commctrl.c:						sizeof(fibctx->unique))) {
drivers/scsi/aacraid/commctrl.c:		if (fibctx->unique == f.fibctx) { /* We found a winner */
drivers/scsi/aacraid/commctrl.c:	if((fibctx->type != FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT) ||
drivers/scsi/aacraid/commctrl.c:		 (fibctx->size != sizeof(struct aac_fib_context))) {
drivers/scsi/aacraid/commctrl.c:	if (!list_empty(&fibctx->fib_list)) {
drivers/scsi/aacraid/commctrl.c:		entry = fibctx->fib_list.next;
drivers/scsi/aacraid/commctrl.c:		fibctx->count--;
drivers/scsi/aacraid/commctrl.c:			if(down_interruptible(&fibctx->wait_sem) < 0) {
drivers/scsi/aacraid/commctrl.c:	fibctx->jiffies = jiffies/HZ;
drivers/scsi/aacraid/commctrl.c:	while (!list_empty(&fibctx->fib_list)) {
drivers/scsi/aacraid/commctrl.c:		entry = fibctx->fib_list.next;
drivers/scsi/aacraid/commctrl.c:		fibctx->count--;
drivers/scsi/aacraid/commctrl.c:	list_del(&fibctx->next);
drivers/scsi/aacraid/commctrl.c:	fibctx->type = 0;
drivers/scsi/aacraid/commctrl.c:		if (fibctx->unique == (u32)(uintptr_t)arg) /* We found a winner */
drivers/scsi/aacraid/commctrl.c:	if((fibctx->type != FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT) ||
drivers/scsi/aacraid/commctrl.c:		 (fibctx->size != sizeof(struct aac_fib_context)))
drivers/scsi/aacraid/src.c:	dev = ctx->dev;
drivers/scsi/aacraid/src.c:	vector_no = ctx->vector_no;
drivers/scsi/qla2xxx/qla_target.c:		dma_pool_free(ha->dl_dma_pool, cmd->ctx, cmd->ctx->crc_ctx_dma);
drivers/scsi/qla2xxx/qla_target.c:	ctx->app_tag = 0;
drivers/scsi/qla2xxx/qla_target.c:	ctx->app_tag_mask[0] = 0x0;
drivers/scsi/qla2xxx/qla_target.c:	ctx->app_tag_mask[1] = 0x0;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag = cpu_to_le32(lba);
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[0] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[1] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[2] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[3] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag = cpu_to_le32(lba);
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[0] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[1] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[2] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[3] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag = cpu_to_le32(lba);
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[0] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[1] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[2] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[3] = 0xff;
drivers/scsi/qla2xxx/qla_target.c:		ctx->ref_tag_mask[0] = ctx->ref_tag_mask[1] =
drivers/scsi/qla2xxx/qla_target.c:			ctx->ref_tag_mask[2] = ctx->ref_tag_mask[3] = 0x00;
drivers/scsi/qla2xxx/qla_inline.h:	    &ctx->dsd_list, list) {
drivers/scsi/qla2xxx/qla_inline.h:	INIT_LIST_HEAD(&ctx->dsd_list);
drivers/scsi/qla2xxx/qla_iocb.c:		list_add_tail(&dsd_ptr->list, &ctx->dsd_list);
drivers/scsi/qla2xxx/qla_iocb.c:		ctx->dsd_use_cnt++;
drivers/scsi/qla2xxx/qla_iocb.c:				    &(tc->ctx->dsd_list));
drivers/scsi/qla2xxx/qla_iocb.c:				    &(tc->ctx->dsd_list));
drivers/scsi/qla2xxx/qla_iocb.c:				    &(tc->ctx->dsd_list));
drivers/scsi/qla2xxx/qla_iocb.c:		ctx->fcp_cmnd = dma_pool_alloc(ha->fcp_cmnd_dma_pool,
drivers/scsi/qla2xxx/qla_iocb.c:			GFP_ATOMIC, &ctx->fcp_cmnd_dma);
drivers/scsi/qla2xxx/qla_iocb.c:		if (!ctx->fcp_cmnd) {
drivers/scsi/qla2xxx/qla_iocb.c:		INIT_LIST_HEAD(&ctx->dsd_list);
drivers/scsi/qla2xxx/qla_iocb.c:		ctx->dsd_use_cnt = 0;
drivers/scsi/qla2xxx/qla_iocb.c:			ctx->fcp_cmnd_len = 12 + cmd->cmd_len + 4;
drivers/scsi/qla2xxx/qla_iocb.c:			ctx->fcp_cmnd_len = 12 + 16 + 4;
drivers/scsi/qla2xxx/qla_iocb.c:		memset(ctx->fcp_cmnd, 0, sizeof(struct fcp_cmnd));
drivers/scsi/qla2xxx/qla_iocb.c:		int_to_scsilun(cmd->device->lun, &ctx->fcp_cmnd->lun);
drivers/scsi/qla2xxx/qla_iocb.c:		ctx->fcp_cmnd->additional_cdb_len = additional_cdb_len;
drivers/scsi/qla2xxx/qla_iocb.c:			ctx->fcp_cmnd->additional_cdb_len |= 1;
drivers/scsi/qla2xxx/qla_iocb.c:			ctx->fcp_cmnd->additional_cdb_len |= 2;
drivers/scsi/qla2xxx/qla_iocb.c:			ctx->fcp_cmnd->task_attribute |=
drivers/scsi/qla2xxx/qla_iocb.c:		memcpy(ctx->fcp_cmnd->cdb, cmd->cmnd, cmd->cmd_len);
drivers/scsi/qla2xxx/qla_iocb.c:		fcp_dl = (uint32_t *)(ctx->fcp_cmnd->cdb + 16 +
drivers/scsi/qla2xxx/qla_iocb.c:		cmd_pkt->fcp_cmnd_dseg_len = cpu_to_le16(ctx->fcp_cmnd_len);
drivers/scsi/qla2xxx/qla_iocb.c:		    cpu_to_le32(LSD(ctx->fcp_cmnd_dma));
drivers/scsi/qla2xxx/qla_iocb.c:		    cpu_to_le32(MSD(ctx->fcp_cmnd_dma));
drivers/scsi/qla2xxx/qla_iocb.c:	dma_pool_free(ha->fcp_cmnd_dma_pool, ctx->fcp_cmnd, ctx->fcp_cmnd_dma);
drivers/scsi/be2iscsi/be_main.h:#define BE_GET_ASYNC_CRI_FROM_CID(cid) (pasync_ctx->cid_to_async_cri_map[cid])
drivers/scsi/be2iscsi/be_main.c:				&pasync_ctx->async_header.free_list);
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_header.free_entries++;
drivers/scsi/be2iscsi/be_main.c:				&pasync_ctx->async_data.free_list);
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_data.free_entries++;
drivers/scsi/be2iscsi/be_main.c:		pasync_handle = pasync_ctx->async_entry[ci].header;
drivers/scsi/be2iscsi/be_main.c:		pasync_handle = pasync_ctx->async_entry[ci].data;
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_entry[ci].header = NULL;
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_entry[ci].data = NULL;
drivers/scsi/be2iscsi/be_main.c:	plist  = &pasync_ctx->async_entry[cri].wq.list;
drivers/scsi/be2iscsi/be_main.c:	INIT_LIST_HEAD(&pasync_ctx->async_entry[cri].wq.list);
drivers/scsi/be2iscsi/be_main.c:	pasync_ctx->async_entry[cri].wq.hdr_len = 0;
drivers/scsi/be2iscsi/be_main.c:	pasync_ctx->async_entry[cri].wq.bytes_received = 0;
drivers/scsi/be2iscsi/be_main.c:	pasync_ctx->async_entry[cri].wq.bytes_needed = 0;
drivers/scsi/be2iscsi/be_main.c:	plist = &pasync_ctx->async_entry[cri].wq.list;
drivers/scsi/be2iscsi/be_main.c:			    pasync_ctx->async_entry[cri].wq.hdr_len,
drivers/scsi/be2iscsi/be_main.c:			    pasync_ctx->async_entry[cri].wq.bytes_needed,
drivers/scsi/be2iscsi/be_main.c:			    pasync_ctx->async_entry[cri].wq.bytes_received);
drivers/scsi/be2iscsi/be_main.c:	wq = &pasync_ctx->async_entry[cri].wq;
drivers/scsi/be2iscsi/be_main.c:	num_entries = pasync_ctx->num_entries;
drivers/scsi/be2iscsi/be_main.c:		cons = pasync_ctx->async_header.free_entries;
drivers/scsi/be2iscsi/be_main.c:		hfree_list = &pasync_ctx->async_header.free_list;
drivers/scsi/be2iscsi/be_main.c:		cons = pasync_ctx->async_data.free_entries;
drivers/scsi/be2iscsi/be_main.c:		hfree_list = &pasync_ctx->async_data.free_list;
drivers/scsi/be2iscsi/be_main.c:			slot = &pasync_ctx->async_entry[index].header;
drivers/scsi/be2iscsi/be_main.c:			slot = &pasync_ctx->async_entry[index].data;
drivers/scsi/be2iscsi/be_main.c:			pasync_sge = pasync_ctx->async_header.ring_base;
drivers/scsi/be2iscsi/be_main.c:			pasync_sge = pasync_ctx->async_data.ring_base;
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_header.free_entries -= prod;
drivers/scsi/be2iscsi/be_main.c:		pasync_ctx->async_data.free_entries -= prod;
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_entry =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->num_entries = BEISCSI_GET_CID_COUNT(phba,
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_header.buffer_size = p->defpdu_hdr_sz;
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_header.va_base =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_header.pa_base.u.a64.address =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_header.ring_base =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_header.handle_base =
drivers/scsi/be2iscsi/be_main.c:			INIT_LIST_HEAD(&pasync_ctx->async_header.free_list);
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_data.ring_base =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_data.handle_base =
drivers/scsi/be2iscsi/be_main.c:			INIT_LIST_HEAD(&pasync_ctx->async_data.free_list);
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_header.handle_base;
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_data.handle_base;
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_data.buffer_size = p->defpdu_data_sz;
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_data.va_base =
drivers/scsi/be2iscsi/be_main.c:			pasync_ctx->async_data.pa_base.u.a64.address =
drivers/scsi/be2iscsi/be_main.c:						 (pasync_ctx->
drivers/scsi/be2iscsi/be_main.c:					pasync_ctx->async_header.pa_base.u.a64.
drivers/scsi/be2iscsi/be_main.c:					      &pasync_ctx->async_header.
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_header.free_entries++;
drivers/scsi/be2iscsi/be_main.c:				INIT_LIST_HEAD(&pasync_ctx->async_entry[index].
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_entry[index].header = NULL;
drivers/scsi/be2iscsi/be_main.c:					pasync_ctx->async_data.va_base =
drivers/scsi/be2iscsi/be_main.c:					pasync_ctx->async_data.pa_base.u.
drivers/scsi/be2iscsi/be_main.c:					(pasync_ctx->async_data.va_base) +
drivers/scsi/be2iscsi/be_main.c:					pasync_ctx->async_data.pa_base.u.a64.
drivers/scsi/be2iscsi/be_main.c:					      &pasync_ctx->async_data.
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_data.free_entries++;
drivers/scsi/be2iscsi/be_main.c:				pasync_ctx->async_entry[index].data = NULL;
drivers/scsi/be2iscsi/be_main.c:					pasync_ctx->cid_to_async_cri_map[
drivers/scsi/aic7xxx/aic79xx_osm.h:	return (scb->io_ctx->sc_data_direction);
drivers/scsi/aic7xxx/aic79xx_osm.h:	if ((scb->io_ctx->result & (CAM_DEV_QFRZN << 16)) == 0) {
drivers/scsi/aic7xxx/aic79xx_osm.h:                scb->io_ctx->result |= CAM_DEV_QFRZN << 16;
drivers/scsi/aic7xxx/aic79xx_core.c:			 && scb->io_ctx->ccb_h.func_code== XPT_RESET_DEV
drivers/scsi/aic7xxx/aic79xx_core.c:		group = XPT_FC_GROUP(scb->io_ctx->ccb_h.func_code);
drivers/scsi/aic7xxx/aic79xx_core.c:			      && ((tag == scb->io_ctx->csio.tag_id)
drivers/scsi/aic7xxx/aic79xx_core.c:			ccbh = &scb->io_ctx->ccb_h;
drivers/scsi/aic7xxx/aic79xx_osm.c:		} else if (amount_xferred < scb->io_ctx->underflow) {
drivers/scsi/aic7xxx/aic79xx_osm.c:			for (i = 0; i < scb->io_ctx->cmd_len; i++)
drivers/scsi/aic7xxx/aic79xx_osm.c:				printk(" 0x%x", scb->io_ctx->cmnd[i]);
drivers/scsi/aic7xxx/aic7xxx_core.c:				 && scb->io_ctx->ccb_h.func_code== XPT_RESET_DEV
drivers/scsi/aic7xxx/aic7xxx_core.c:		group = XPT_FC_GROUP(scb->io_ctx->ccb_h.func_code);
drivers/scsi/aic7xxx/aic7xxx_core.c:			      && ((tag == scb->io_ctx->csio.tag_id)
drivers/scsi/aic7xxx/aic7xxx_core.c:			ccbh = &scb->io_ctx->ccb_h;
drivers/scsi/aic7xxx/aic7xxx_osm.h:	return (scb->io_ctx->sc_data_direction);
drivers/scsi/aic7xxx/aic7xxx_osm.h:	if ((scb->io_ctx->result & (CAM_DEV_QFRZN << 16)) == 0) {
drivers/scsi/aic7xxx/aic7xxx_osm.h:                scb->io_ctx->result |= CAM_DEV_QFRZN << 16;
drivers/scsi/aic7xxx/aic7xxx_osm.c:		} else if (amount_xferred < scb->io_ctx->underflow) {
drivers/scsi/aic7xxx/aic7xxx_osm.c:			for (i = 0; i < scb->io_ctx->cmd_len; i++)
drivers/scsi/aic7xxx/aic7xxx_osm.c:				printk(" 0x%x", scb->io_ctx->cmnd[i]);
drivers/scsi/vmw_pvscsi.c:		if (ctx->cmd == cmd)
drivers/scsi/vmw_pvscsi.c:	ctx->cmd = cmd;
drivers/scsi/vmw_pvscsi.c:	list_del(&ctx->list);
drivers/scsi/vmw_pvscsi.c:	ctx->cmd = NULL;
drivers/scsi/vmw_pvscsi.c:	ctx->abort_cmp = NULL;
drivers/scsi/vmw_pvscsi.c:	list_add(&ctx->list, &adapter->cmd_pool);
drivers/scsi/vmw_pvscsi.c:	cmd.target = ctx->cmd->device->id;
drivers/scsi/vmw_pvscsi.c:	sge = &ctx->sgl->sge[0];
drivers/scsi/vmw_pvscsi.c:			ctx->sglPA = pci_map_single(adapter->dev, ctx->sgl,
drivers/scsi/vmw_pvscsi.c:			if (pci_dma_mapping_error(adapter->dev, ctx->sglPA)) {
drivers/scsi/vmw_pvscsi.c:				ctx->sglPA = 0;
drivers/scsi/vmw_pvscsi.c:			e->dataAddr = ctx->sglPA;
drivers/scsi/vmw_pvscsi.c:		ctx->dataPA = pci_map_single(adapter->dev, sg, bufflen,
drivers/scsi/vmw_pvscsi.c:		if (pci_dma_mapping_error(adapter->dev, ctx->dataPA)) {
drivers/scsi/vmw_pvscsi.c:		e->dataAddr = ctx->dataPA;
drivers/scsi/vmw_pvscsi.c:	cmd = ctx->cmd;
drivers/scsi/vmw_pvscsi.c:			if (ctx->sglPA) {
drivers/scsi/vmw_pvscsi.c:				pci_unmap_single(adapter->dev, ctx->sglPA,
drivers/scsi/vmw_pvscsi.c:				ctx->sglPA = 0;
drivers/scsi/vmw_pvscsi.c:			pci_unmap_single(adapter->dev, ctx->dataPA, bufflen,
drivers/scsi/vmw_pvscsi.c:		pci_unmap_single(adapter->dev, ctx->sensePA,
drivers/scsi/vmw_pvscsi.c:	cmd = ctx->cmd;
drivers/scsi/vmw_pvscsi.c:	abort_cmp = ctx->abort_cmp;
drivers/scsi/vmw_pvscsi.c:		ctx->sensePA = pci_map_single(adapter->dev, cmd->sense_buffer,
drivers/scsi/vmw_pvscsi.c:		if (pci_dma_mapping_error(adapter->dev, ctx->sensePA)) {
drivers/scsi/vmw_pvscsi.c:			ctx->sensePA = 0;
drivers/scsi/vmw_pvscsi.c:		e->senseAddr = ctx->sensePA;
drivers/scsi/vmw_pvscsi.c:			pci_unmap_single(adapter->dev, ctx->sensePA,
drivers/scsi/vmw_pvscsi.c:			ctx->sensePA = 0;
drivers/scsi/vmw_pvscsi.c:	ctx->abort_cmp = &abort_cmp;
drivers/scsi/vmw_pvscsi.c:		ctx->abort_cmp = NULL;
drivers/scsi/vmw_pvscsi.c:		struct scsi_cmnd *cmd = ctx->cmd;
drivers/scsi/vmw_pvscsi.c:		free_pages((unsigned long)ctx->sgl, get_order(SGL_SIZE));
drivers/scsi/vmw_pvscsi.c:		ctx->sgl = (void *)__get_free_pages(GFP_KERNEL,
drivers/scsi/vmw_pvscsi.c:		ctx->sglPA = 0;
drivers/scsi/vmw_pvscsi.c:		BUG_ON(!IS_ALIGNED(((unsigned long)ctx->sgl), PAGE_SIZE));
drivers/scsi/vmw_pvscsi.c:		if (!ctx->sgl) {
drivers/scsi/vmw_pvscsi.c:				free_pages((unsigned long)ctx->sgl,
drivers/scsi/vmw_pvscsi.c:				ctx->sgl = NULL;
drivers/scsi/vmw_pvscsi.c:		list_add(&ctx->list, &adapter->cmd_pool);
drivers/pinctrl/intel/pinctrl-cherryview.c:		ctx->padctrl0 = readl(reg) & ~CHV_PADCTRL0_GPIORXSTATE;
drivers/pinctrl/intel/pinctrl-cherryview.c:		ctx->padctrl1 = readl(reg);
drivers/pinctrl/intel/pinctrl-cherryview.c:		if (ctx->padctrl0 != val) {
drivers/pinctrl/intel/pinctrl-cherryview.c:			chv_writel(ctx->padctrl0, reg);
drivers/pinctrl/intel/pinctrl-cherryview.c:		if (ctx->padctrl1 != val) {
drivers/pinctrl/intel/pinctrl-cherryview.c:			chv_writel(ctx->padctrl1, reg);
drivers/mailbox/mailbox-xgene-slimpro.c:		ctx->mc[i].irq = platform_get_irq(pdev, i);
drivers/mailbox/mailbox-xgene-slimpro.c:		if (ctx->mc[i].irq < 0) {
drivers/mailbox/mailbox-xgene-slimpro.c:		ctx->mc[i].dev = &pdev->dev;
drivers/mailbox/mailbox-xgene-slimpro.c:		ctx->mc[i].reg = mb_base + i * MBOX_REG_SET_OFFSET;
drivers/mailbox/mailbox-xgene-slimpro.c:		ctx->mc[i].chan = &ctx->chans[i];
drivers/mailbox/mailbox-xgene-slimpro.c:		ctx->chans[i].con_priv = &ctx->mc[i];
drivers/mailbox/mailbox-xgene-slimpro.c:	ctx->mb_ctrl.dev = &pdev->dev;
drivers/mailbox/mailbox-xgene-slimpro.c:	ctx->mb_ctrl.chans = ctx->chans;
drivers/mailbox/mailbox-xgene-slimpro.c:	ctx->mb_ctrl.txdone_irq = true;
drivers/mailbox/mailbox-xgene-slimpro.c:	ctx->mb_ctrl.ops = &slimpro_mbox_ops;
drivers/mailbox/mailbox-xgene-slimpro.c:	ctx->mb_ctrl.num_chans = i;
drivers/mailbox/mailbox-xgene-slimpro.c:	rc = mbox_controller_register(&ctx->mb_ctrl);
drivers/hwmon/pwm-fan.c:	pwm_get_args(ctx->pwm, &pargs);
drivers/hwmon/pwm-fan.c:	mutex_lock(&ctx->lock);
drivers/hwmon/pwm-fan.c:	if (ctx->pwm_value == pwm)
drivers/hwmon/pwm-fan.c:	ret = pwm_config(ctx->pwm, duty, pargs.period);
drivers/hwmon/pwm-fan.c:		pwm_disable(ctx->pwm);
drivers/hwmon/pwm-fan.c:	if (ctx->pwm_value == 0) {
drivers/hwmon/pwm-fan.c:		ret = pwm_enable(ctx->pwm);
drivers/hwmon/pwm-fan.c:	ctx->pwm_value = pwm;
drivers/hwmon/pwm-fan.c:	mutex_unlock(&ctx->lock);
drivers/hwmon/pwm-fan.c:	for (i = 0; i < ctx->pwm_fan_max_state; ++i)
drivers/hwmon/pwm-fan.c:		if (pwm < ctx->pwm_fan_cooling_levels[i + 1])
drivers/hwmon/pwm-fan.c:	ctx->pwm_fan_state = i;
drivers/hwmon/pwm-fan.c:	return sprintf(buf, "%u\n", ctx->pwm_value);
drivers/hwmon/pwm-fan.c:	*state = ctx->pwm_fan_max_state;
drivers/hwmon/pwm-fan.c:	*state = ctx->pwm_fan_state;
drivers/hwmon/pwm-fan.c:	if (!ctx || (state > ctx->pwm_fan_max_state))
drivers/hwmon/pwm-fan.c:	if (state == ctx->pwm_fan_state)
drivers/hwmon/pwm-fan.c:	ret = __set_pwm(ctx, ctx->pwm_fan_cooling_levels[state]);
drivers/hwmon/pwm-fan.c:	ctx->pwm_fan_state = state;
drivers/hwmon/pwm-fan.c:	ctx->pwm_fan_cooling_levels = devm_kzalloc(dev, num * sizeof(u32),
drivers/hwmon/pwm-fan.c:	if (!ctx->pwm_fan_cooling_levels)
drivers/hwmon/pwm-fan.c:					 ctx->pwm_fan_cooling_levels, num);
drivers/hwmon/pwm-fan.c:		if (ctx->pwm_fan_cooling_levels[i] > MAX_PWM) {
drivers/hwmon/pwm-fan.c:				ctx->pwm_fan_cooling_levels[i], MAX_PWM);
drivers/hwmon/pwm-fan.c:	ctx->pwm_fan_max_state = num - 1;
drivers/hwmon/pwm-fan.c:	mutex_init(&ctx->lock);
drivers/hwmon/pwm-fan.c:	ctx->pwm = devm_of_pwm_get(&pdev->dev, pdev->dev.of_node, NULL);
drivers/hwmon/pwm-fan.c:	if (IS_ERR(ctx->pwm)) {
drivers/hwmon/pwm-fan.c:		return PTR_ERR(ctx->pwm);
drivers/hwmon/pwm-fan.c:	pwm_apply_args(ctx->pwm);
drivers/hwmon/pwm-fan.c:	pwm_get_args(ctx->pwm, &pargs);
drivers/hwmon/pwm-fan.c:	ctx->pwm_value = MAX_PWM;
drivers/hwmon/pwm-fan.c:	ret = pwm_config(ctx->pwm, duty_cycle, pargs.period);
drivers/hwmon/pwm-fan.c:	ret = pwm_enable(ctx->pwm);
drivers/hwmon/pwm-fan.c:		pwm_disable(ctx->pwm);
drivers/hwmon/pwm-fan.c:	ctx->pwm_fan_state = ctx->pwm_fan_max_state;
drivers/hwmon/pwm-fan.c:			pwm_disable(ctx->pwm);
drivers/hwmon/pwm-fan.c:		ctx->cdev = cdev;
drivers/hwmon/pwm-fan.c:	thermal_cooling_device_unregister(ctx->cdev);
drivers/hwmon/pwm-fan.c:	if (ctx->pwm_value)
drivers/hwmon/pwm-fan.c:		pwm_disable(ctx->pwm);
drivers/hwmon/pwm-fan.c:	if (ctx->pwm_value)
drivers/hwmon/pwm-fan.c:		pwm_disable(ctx->pwm);
drivers/hwmon/pwm-fan.c:	if (ctx->pwm_value == 0)
drivers/hwmon/pwm-fan.c:	pwm_get_args(ctx->pwm, &pargs);
drivers/hwmon/pwm-fan.c:	duty = DIV_ROUND_UP(ctx->pwm_value * (pargs.period - 1), MAX_PWM);
drivers/hwmon/pwm-fan.c:	ret = pwm_config(ctx->pwm, duty, pargs.period);
drivers/hwmon/pwm-fan.c:	return pwm_enable(ctx->pwm);
drivers/hwmon/xgene-hwmon.c:	struct acpi_pcct_shared_memory *generic_comm_base = ctx->pcc_comm_addr;
drivers/hwmon/xgene-hwmon.c:	mutex_lock(&ctx->rd_mutex);
drivers/hwmon/xgene-hwmon.c:	init_completion(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	ctx->resp_pending = true;
drivers/hwmon/xgene-hwmon.c:		   cpu_to_le32(PCC_SIGNATURE_MASK | ctx->mbox_idx));
drivers/hwmon/xgene-hwmon.c:	rc = mbox_send_message(ctx->mbox_chan, msg);
drivers/hwmon/xgene-hwmon.c:		dev_err(ctx->dev, "Mailbox send error %d\n", rc);
drivers/hwmon/xgene-hwmon.c:	if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/hwmon/xgene-hwmon.c:					 usecs_to_jiffies(ctx->usecs_lat))) {
drivers/hwmon/xgene-hwmon.c:		dev_err(ctx->dev, "Mailbox operation timed out\n");
drivers/hwmon/xgene-hwmon.c:	if (MSG_TYPE(ctx->sync_msg.msg) == MSG_TYPE_ERR) {
drivers/hwmon/xgene-hwmon.c:	msg[0] = ctx->sync_msg.msg;
drivers/hwmon/xgene-hwmon.c:	msg[1] = ctx->sync_msg.param1;
drivers/hwmon/xgene-hwmon.c:	msg[2] = ctx->sync_msg.param2;
drivers/hwmon/xgene-hwmon.c:	mbox_chan_txdone(ctx->mbox_chan, 0);
drivers/hwmon/xgene-hwmon.c:	ctx->resp_pending = false;
drivers/hwmon/xgene-hwmon.c:	mutex_unlock(&ctx->rd_mutex);
drivers/hwmon/xgene-hwmon.c:	mutex_lock(&ctx->rd_mutex);
drivers/hwmon/xgene-hwmon.c:	init_completion(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	ctx->resp_pending = true;
drivers/hwmon/xgene-hwmon.c:	rc = mbox_send_message(ctx->mbox_chan, msg);
drivers/hwmon/xgene-hwmon.c:		dev_err(ctx->dev, "Mailbox send error %d\n", rc);
drivers/hwmon/xgene-hwmon.c:	if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/hwmon/xgene-hwmon.c:		dev_err(ctx->dev, "Mailbox operation timed out\n");
drivers/hwmon/xgene-hwmon.c:	if (MSG_TYPE(ctx->sync_msg.msg) == MSG_TYPE_ERR) {
drivers/hwmon/xgene-hwmon.c:	msg[0] = ctx->sync_msg.msg;
drivers/hwmon/xgene-hwmon.c:	msg[1] = ctx->sync_msg.param1;
drivers/hwmon/xgene-hwmon.c:	msg[2] = ctx->sync_msg.param2;
drivers/hwmon/xgene-hwmon.c:	ctx->resp_pending = false;
drivers/hwmon/xgene-hwmon.c:	mutex_unlock(&ctx->rd_mutex);
drivers/hwmon/xgene-hwmon.c:	return snprintf(buf, PAGE_SIZE, "%d\n", ctx->temp_critical_alarm);
drivers/hwmon/xgene-hwmon.c:	ctx->temp_critical_alarm = !!amsg->param2;
drivers/hwmon/xgene-hwmon.c:	sysfs_notify(&ctx->dev->kobj, NULL, "temp1_critical_alarm");
drivers/hwmon/xgene-hwmon.c:	while (kfifo_out_spinlocked(&ctx->async_msg_fifo, &amsg,
drivers/hwmon/xgene-hwmon.c:				    &ctx->kfifo_lock)) {
drivers/hwmon/xgene-hwmon.c:	if (IS_ERR_OR_NULL(ctx->hwmon_dev) && !ctx->resp_pending) {
drivers/hwmon/xgene-hwmon.c:		kfifo_in_spinlocked(&ctx->async_msg_fifo, msg,
drivers/hwmon/xgene-hwmon.c:				    &ctx->kfifo_lock);
drivers/hwmon/xgene-hwmon.c:	if (ctx->resp_pending &&
drivers/hwmon/xgene-hwmon.c:		ctx->sync_msg.msg = ((u32 *)msg)[0];
drivers/hwmon/xgene-hwmon.c:		ctx->sync_msg.param1 = ((u32 *)msg)[1];
drivers/hwmon/xgene-hwmon.c:		ctx->sync_msg.param2 = ((u32 *)msg)[2];
drivers/hwmon/xgene-hwmon.c:		complete(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	kfifo_in_spinlocked(&ctx->async_msg_fifo, msg,
drivers/hwmon/xgene-hwmon.c:			    sizeof(struct slimpro_resp_msg), &ctx->kfifo_lock);
drivers/hwmon/xgene-hwmon.c:	schedule_work(&ctx->workq);
drivers/hwmon/xgene-hwmon.c:	struct acpi_pcct_shared_memory *generic_comm_base = ctx->pcc_comm_addr;
drivers/hwmon/xgene-hwmon.c:	if (ctx->resp_pending &&
drivers/hwmon/xgene-hwmon.c:			ctx->sync_msg.msg = ((u32 *)msg)[0];
drivers/hwmon/xgene-hwmon.c:			ctx->sync_msg.param1 = ((u32 *)msg)[1];
drivers/hwmon/xgene-hwmon.c:			ctx->sync_msg.param2 = ((u32 *)msg)[2];
drivers/hwmon/xgene-hwmon.c:			complete(&ctx->rd_complete);
drivers/hwmon/xgene-hwmon.c:	kfifo_in_spinlocked(&ctx->async_msg_fifo, &amsg,
drivers/hwmon/xgene-hwmon.c:			    sizeof(struct slimpro_resp_msg), &ctx->kfifo_lock);
drivers/hwmon/xgene-hwmon.c:	schedule_work(&ctx->workq);
drivers/hwmon/xgene-hwmon.c:	ctx->dev = &pdev->dev;
drivers/hwmon/xgene-hwmon.c:	cl = &ctx->mbox_client;
drivers/hwmon/xgene-hwmon.c:	spin_lock_init(&ctx->kfifo_lock);
drivers/hwmon/xgene-hwmon.c:	mutex_init(&ctx->rd_mutex);
drivers/hwmon/xgene-hwmon.c:	rc = kfifo_alloc(&ctx->async_msg_fifo,
drivers/hwmon/xgene-hwmon.c:	INIT_WORK(&ctx->workq, xgene_hwmon_evt_work);
drivers/hwmon/xgene-hwmon.c:		ctx->mbox_chan = mbox_request_channel(cl, 0);
drivers/hwmon/xgene-hwmon.c:		if (IS_ERR(ctx->mbox_chan)) {
drivers/hwmon/xgene-hwmon.c:					     &ctx->mbox_idx)) {
drivers/hwmon/xgene-hwmon.c:		ctx->mbox_chan = pcc_mbox_request_channel(cl, ctx->mbox_idx);
drivers/hwmon/xgene-hwmon.c:		if (IS_ERR(ctx->mbox_chan)) {
drivers/hwmon/xgene-hwmon.c:		cppc_ss = ctx->mbox_chan->con_priv;
drivers/hwmon/xgene-hwmon.c:		if (!ctx->mbox_chan->mbox->txdone_irq) {
drivers/hwmon/xgene-hwmon.c:		ctx->comm_base_addr = cppc_ss->base_address;
drivers/hwmon/xgene-hwmon.c:		if (ctx->comm_base_addr) {
drivers/hwmon/xgene-hwmon.c:			ctx->pcc_comm_addr = memremap(ctx->comm_base_addr,
drivers/hwmon/xgene-hwmon.c:		if (!ctx->pcc_comm_addr) {
drivers/hwmon/xgene-hwmon.c:		ctx->usecs_lat = PCC_NUM_RETRIES * cppc_ss->latency;
drivers/hwmon/xgene-hwmon.c:	ctx->hwmon_dev = hwmon_device_register_with_groups(ctx->dev,
drivers/hwmon/xgene-hwmon.c:	if (IS_ERR(ctx->hwmon_dev)) {
drivers/hwmon/xgene-hwmon.c:		rc = PTR_ERR(ctx->hwmon_dev);
drivers/hwmon/xgene-hwmon.c:	schedule_work(&ctx->workq);
drivers/hwmon/xgene-hwmon.c:		mbox_free_channel(ctx->mbox_chan);
drivers/hwmon/xgene-hwmon.c:		pcc_mbox_free_channel(ctx->mbox_chan);
drivers/hwmon/xgene-hwmon.c:	kfifo_free(&ctx->async_msg_fifo);
drivers/hwmon/xgene-hwmon.c:	hwmon_device_unregister(ctx->hwmon_dev);
drivers/hwmon/xgene-hwmon.c:	kfifo_free(&ctx->async_msg_fifo);
drivers/hwmon/xgene-hwmon.c:		mbox_free_channel(ctx->mbox_chan);
drivers/hwmon/xgene-hwmon.c:		pcc_mbox_free_channel(ctx->mbox_chan);
drivers/spi/spi-omap2-mcspi.c:	ctx->modulctrl = l;
drivers/spi/spi-omap2-mcspi.c:	mcspi_write_reg(spi_cntrl, OMAP2_MCSPI_MODULCTRL, ctx->modulctrl);
drivers/spi/spi-omap2-mcspi.c:	mcspi_write_reg(spi_cntrl, OMAP2_MCSPI_WAKEUPENABLE, ctx->wakeupenable);
drivers/spi/spi-omap2-mcspi.c:	list_for_each_entry(cs, &ctx->cs, node)
drivers/spi/spi-omap2-mcspi.c:		list_add_tail(&cs->node, &ctx->cs);
drivers/spi/spi-omap2-mcspi.c:	list_for_each_entry(cs, &ctx->cs, node) {
drivers/spi/spi-omap2-mcspi.c:	ctx->wakeupenable = OMAP2_MCSPI_WAKEUPENABLE_WKEN;
drivers/spi/spi-omap2-mcspi.c:	list_for_each_entry(cs, &ctx->cs, node) {
drivers/auxdisplay/img-ascii-lcd.c:	val = *((u64 *)&ctx->curr[0]);
drivers/auxdisplay/img-ascii-lcd.c:	__raw_writeq(val, ctx->base);
drivers/auxdisplay/img-ascii-lcd.c:	val = *((u32 *)&ctx->curr[0]);
drivers/auxdisplay/img-ascii-lcd.c:	__raw_writel(val, ctx->base);
drivers/auxdisplay/img-ascii-lcd.c:	val = *((u32 *)&ctx->curr[4]);
drivers/auxdisplay/img-ascii-lcd.c:	__raw_writel(val, ctx->base + 4);
drivers/auxdisplay/img-ascii-lcd.c:	for (i = 0; i < ctx->cfg->num_chars; i++) {
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_write(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				   ctx->offset + (i * 8), ctx->curr[i]);
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_read(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				  ctx->offset + SEAD3_REG_CPLD_STATUS,
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_read(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				  ctx->offset + SEAD3_REG_LCD_CTRL,
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_read(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				  ctx->offset + SEAD3_REG_CPLD_DATA,
drivers/auxdisplay/img-ascii-lcd.c:	for (i = 0; i < ctx->cfg->num_chars; i++) {
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_write(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				   ctx->offset + SEAD3_REG_LCD_CTRL,
drivers/auxdisplay/img-ascii-lcd.c:		err = regmap_write(ctx->regmap,
drivers/auxdisplay/img-ascii-lcd.c:				   ctx->offset + SEAD3_REG_LCD_DATA,
drivers/auxdisplay/img-ascii-lcd.c:				   ctx->curr[i]);
drivers/auxdisplay/img-ascii-lcd.c:	unsigned int i, ch = ctx->scroll_pos;
drivers/auxdisplay/img-ascii-lcd.c:	unsigned int num_chars = ctx->cfg->num_chars;
drivers/auxdisplay/img-ascii-lcd.c:		for (; i < num_chars && ch < ctx->message_len; i++, ch++)
drivers/auxdisplay/img-ascii-lcd.c:			ctx->curr[i] = ctx->message[ch];
drivers/auxdisplay/img-ascii-lcd.c:	ctx->cfg->update(ctx);
drivers/auxdisplay/img-ascii-lcd.c:	ctx->scroll_pos++;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->scroll_pos %= ctx->message_len;
drivers/auxdisplay/img-ascii-lcd.c:	if (ctx->message_len > ctx->cfg->num_chars)
drivers/auxdisplay/img-ascii-lcd.c:		mod_timer(&ctx->timer, jiffies + ctx->scroll_rate);
drivers/auxdisplay/img-ascii-lcd.c:	del_timer_sync(&ctx->timer);
drivers/auxdisplay/img-ascii-lcd.c:	new_msg = devm_kmalloc(&ctx->pdev->dev, count + 1, GFP_KERNEL);
drivers/auxdisplay/img-ascii-lcd.c:	if (ctx->message)
drivers/auxdisplay/img-ascii-lcd.c:		devm_kfree(&ctx->pdev->dev, ctx->message);
drivers/auxdisplay/img-ascii-lcd.c:	ctx->message = new_msg;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->message_len = count;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->scroll_pos = 0;
drivers/auxdisplay/img-ascii-lcd.c:	return sprintf(buf, "%s\n", ctx->message);
drivers/auxdisplay/img-ascii-lcd.c:		ctx->regmap = syscon_node_to_regmap(pdev->dev.parent->of_node);
drivers/auxdisplay/img-ascii-lcd.c:		if (IS_ERR(ctx->regmap))
drivers/auxdisplay/img-ascii-lcd.c:			return PTR_ERR(ctx->regmap);
drivers/auxdisplay/img-ascii-lcd.c:					 &ctx->offset))
drivers/auxdisplay/img-ascii-lcd.c:		ctx->base = devm_ioremap_resource(&pdev->dev, res);
drivers/auxdisplay/img-ascii-lcd.c:		if (IS_ERR(ctx->base))
drivers/auxdisplay/img-ascii-lcd.c:			return PTR_ERR(ctx->base);
drivers/auxdisplay/img-ascii-lcd.c:	ctx->pdev = pdev;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->cfg = cfg;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->message = NULL;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->scroll_pos = 0;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->scroll_rate = HZ / 2;
drivers/auxdisplay/img-ascii-lcd.c:	init_timer(&ctx->timer);
drivers/auxdisplay/img-ascii-lcd.c:	ctx->timer.function = img_ascii_lcd_scroll;
drivers/auxdisplay/img-ascii-lcd.c:	ctx->timer.data = (unsigned long)ctx;
drivers/auxdisplay/img-ascii-lcd.c:	del_timer_sync(&ctx->timer);
drivers/auxdisplay/img-ascii-lcd.c:	del_timer_sync(&ctx->timer);
drivers/soc/qcom/glink_spi_xprt.c:	if (pctx->size < pctx->size_remaining) {
drivers/soc/qcom/glink_spi_xprt.c:		pctx->size_remaining = pctx->size;
drivers/soc/qcom/glink_spi_xprt.c:	if (!pctx->size_remaining)
drivers/soc/qcom/glink_spi_xprt.c:		if (pctx->size_remaining == pctx->size)
drivers/soc/qcom/glink_spi_xprt.c:		if (pctx->size_remaining == pctx->size)
drivers/soc/qcom/glink_spi_xprt.c:	cmd.riid = pctx->riid;
drivers/soc/qcom/glink_spi_xprt.c:	data_start = get_tx_vaddr(pctx, pctx->size - pctx->size_remaining,
drivers/soc/qcom/glink_spi_xprt.c:	if (likely(pctx->cookie))
drivers/soc/qcom/glink_spi_xprt.c:		dst = pctx->cookie + (pctx->size - pctx->size_remaining);
drivers/soc/qcom/glink_spi_xprt.c:	pctx->size_remaining -= tx_size;
drivers/soc/qcom/glink_spi_xprt.c:	cmd.size_left = pctx->size_remaining;
drivers/soc/qcom/glink_spi_xprt.c:		tracer_pkt_log_event((void *)(pctx->data), GLINK_XPRT_TX);
drivers/soc/qcom/glink_spi_xprt.c:	if (pctx->size < pctx->size_remaining) {
drivers/soc/qcom/glink_spi_xprt.c:		pctx->size_remaining = pctx->size;
drivers/soc/qcom/glink_spi_xprt.c:	if (!pctx->size_remaining)
drivers/soc/qcom/glink_spi_xprt.c:	cmd.riid = pctx->riid;
drivers/soc/qcom/glink_spi_xprt.c:	data_start = get_tx_vaddr(pctx, pctx->size - pctx->size_remaining,
drivers/soc/qcom/glink_spi_xprt.c:	pctx->size_remaining -= tx_size;
drivers/soc/qcom/glink_spi_xprt.c:	cmd.size_left = pctx->size_remaining;
drivers/soc/qcom/glink_spi_xprt.c:	if (pctx->size_remaining <= SHORT_PKT_SIZE)
drivers/soc/qcom/glink.c:	rwref_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		if (!strcmp(subsystem, xprt_ctx->edge) &&
drivers/soc/qcom/glink.c:			spin_lock_irqsave(&xprt_ctx->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:			for (i = 0; i < xprt_ctx->num_priority; i++)
drivers/soc/qcom/glink.c:						&xprt_ctx->prio_bin[i].tx_ready,
drivers/soc/qcom/glink.c:						&ch_ctx->tx_ready_list_node);
drivers/soc/qcom/glink.c:			spin_unlock_irqrestore(&xprt_ctx->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:			xprt_ctx->ops->ssr(xprt_ctx->ops);
drivers/soc/qcom/glink.c:		ctx->local_open_state = GLINK_CHANNEL_CLOSED;
drivers/soc/qcom/glink.c:	if (ctx->notify_state) {
drivers/soc/qcom/glink.c:		ctx->notify_state(ctx, ctx->user_priv,
drivers/soc/qcom/glink.c:		ctx->remote_opened = false;
drivers/soc/qcom/glink.c:	ctx->rcid = 0;
drivers/soc/qcom/glink.c:	ctx->int_req_ack = false;
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_ack_complete);
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_complete);
drivers/soc/qcom/glink.c:	if (ctx->local_open_state != GLINK_CHANNEL_CLOSED &&
drivers/soc/qcom/glink.c:		ctx->local_open_state != GLINK_CHANNEL_CLOSING) {
drivers/soc/qcom/glink.c:		if (ctx->notify_state)
drivers/soc/qcom/glink.c:			ctx->notify_state(ctx, ctx->user_priv,
drivers/soc/qcom/glink.c:	if (ctx->local_open_state == GLINK_CHANNEL_CLOSED)
drivers/soc/qcom/glink.c:	if (xprt_ctx->num_priority == GLINK_QOS_DEF_NUM_PRIORITY)
drivers/soc/qcom/glink.c:	new_rate_kBps = xprt_ctx->curr_qos_rate_kBps + req_rate_kBps;
drivers/soc/qcom/glink.c:	if (new_rate_kBps > xprt_ctx->threshold_rate_kBps) {
drivers/soc/qcom/glink.c:			xprt_ctx->curr_qos_rate_kBps, req_rate_kBps,
drivers/soc/qcom/glink.c:			xprt_ctx->threshold_rate_kBps);
drivers/soc/qcom/glink.c:	old_priority = ctx->curr_priority;
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->tx_ready_list_node)) {
drivers/soc/qcom/glink.c:		ctx->transport_ptr->prio_bin[old_priority].active_ch_cnt--;
drivers/soc/qcom/glink.c:		list_move(&ctx->tx_ready_list_node,
drivers/soc/qcom/glink.c:			  &ctx->transport_ptr->prio_bin[new_priority].tx_ready);
drivers/soc/qcom/glink.c:		ctx->transport_ptr->prio_bin[new_priority].active_ch_cnt++;
drivers/soc/qcom/glink.c:	ctx->curr_priority = new_priority;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	if (ctx->req_rate_kBps) {
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:	ret = glink_qos_check_feasibility(ctx->transport_ptr, req_rate_kBps);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:	spin_lock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	i = ctx->transport_ptr->num_priority - 1;
drivers/soc/qcom/glink.c:	       ctx->transport_ptr->prio_bin[i-1].max_rate_kBps >= req_rate_kBps)
drivers/soc/qcom/glink.c:	ctx->initial_priority = i;
drivers/soc/qcom/glink.c:	ctx->req_rate_kBps = req_rate_kBps;
drivers/soc/qcom/glink.c:		ctx->transport_ptr->curr_qos_rate_kBps += req_rate_kBps;
drivers/soc/qcom/glink.c:		ctx->token_count = ctx->transport_ptr->token_count;
drivers/soc/qcom/glink.c:		ctx->txd_len = 0;
drivers/soc/qcom/glink.c:		ctx->token_start_time = arch_counter_get_cntvct();
drivers/soc/qcom/glink.c:	spin_unlock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	spin_lock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	if (ctx->initial_priority > 0) {
drivers/soc/qcom/glink.c:		ctx->initial_priority = 0;
drivers/soc/qcom/glink.c:		ctx->transport_ptr->curr_qos_rate_kBps -= ctx->req_rate_kBps;
drivers/soc/qcom/glink.c:		ctx->txd_len = 0;
drivers/soc/qcom/glink.c:		ctx->req_rate_kBps = 0;
drivers/soc/qcom/glink.c:	spin_unlock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	if (unlikely(!ctx || !ctx->transport_ptr))
drivers/soc/qcom/glink.c:	prio = ctx->curr_priority;
drivers/soc/qcom/glink.c:	ctx->transport_ptr->prio_bin[prio].active_ch_cnt++;
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->prio_bin[prio].active_ch_cnt == 1 &&
drivers/soc/qcom/glink.c:	    ctx->transport_ptr->active_high_prio < prio) {
drivers/soc/qcom/glink.c:		ctx->transport_ptr->active_high_prio = prio;
drivers/soc/qcom/glink.c:		return ctx->transport_ptr->ops->power_vote(
drivers/soc/qcom/glink.c:				ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:				glink_prio_to_power_state(ctx->transport_ptr,
drivers/soc/qcom/glink.c:	if (unlikely(!ctx || !ctx->transport_ptr))
drivers/soc/qcom/glink.c:	prio = ctx->curr_priority;
drivers/soc/qcom/glink.c:	ctx->transport_ptr->prio_bin[prio].active_ch_cnt--;
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->prio_bin[prio].active_ch_cnt ||
drivers/soc/qcom/glink.c:	    ctx->transport_ptr->active_high_prio > prio)
drivers/soc/qcom/glink.c:		if (!ctx->transport_ptr->prio_bin[prio].active_ch_cnt)
drivers/soc/qcom/glink.c:		ctx->transport_ptr->active_high_prio = prio;
drivers/soc/qcom/glink.c:		return ctx->transport_ptr->ops->power_vote(
drivers/soc/qcom/glink.c:				ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:				glink_prio_to_power_state(ctx->transport_ptr,
drivers/soc/qcom/glink.c:	return ctx->transport_ptr->ops->power_unvote(ctx->transport_ptr->ops);
drivers/soc/qcom/glink.c:	ctx->tx_intent_cnt++;
drivers/soc/qcom/glink.c:	ctx->tx_cnt++;
drivers/soc/qcom/glink.c:	if (ctx->tx_intent_cnt)
drivers/soc/qcom/glink.c:		ctx->tx_intent_cnt--;
drivers/soc/qcom/glink.c:	WARN_ON(ctx->tx_cnt == 0);
drivers/soc/qcom/glink.c:	ctx->tx_cnt = 0;
drivers/soc/qcom/glink.c:	struct glink_core_edge_ctx *edge_ctx = xprt_ctx->edge_ctx;
drivers/soc/qcom/glink.c:	rwref_get(&edge_ctx->edge_ref_lock_lhd1);
drivers/soc/qcom/glink.c:	mutex_lock(&edge_ctx->edge_migration_lock_lhd2);
drivers/soc/qcom/glink.c:	struct glink_core_edge_ctx *edge_ctx = xprt_ctx->edge_ctx;
drivers/soc/qcom/glink.c:	mutex_unlock(&edge_ctx->edge_migration_lock_lhd2);
drivers/soc/qcom/glink.c:	rwref_put(&edge_ctx->edge_ref_lock_lhd1);
drivers/soc/qcom/glink.c:	list_del(&ctx->list_node);
drivers/soc/qcom/glink.c:		if (!strcmp(edge_ctx->name, xprt_ctx->edge)) {
drivers/soc/qcom/glink.c:			rwref_get(&edge_ctx->edge_ref_lock_lhd1);
drivers/soc/qcom/glink.c:	strlcpy(edge_ctx->name, xprt_ctx->edge, GLINK_NAME_SIZE);
drivers/soc/qcom/glink.c:	rwref_lock_init(&edge_ctx->edge_ref_lock_lhd1, glink_edge_ctx_release);
drivers/soc/qcom/glink.c:	mutex_init(&edge_ctx->edge_migration_lock_lhd2);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&edge_ctx->list_node);
drivers/soc/qcom/glink.c:	list_add_tail(&edge_ctx->list_node, &edge_list);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(entry, &xprt_ctx->channels, port_list_node)
drivers/soc/qcom/glink.c:			spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(entry, &xprt_ctx->channels, port_list_node)
drivers/soc/qcom/glink.c:			spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(intent, &ctx->rmt_rx_intent_list, list) {
drivers/soc/qcom/glink.c:				&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->capabilities & GCAP_INTENTLESS) {
drivers/soc/qcom/glink.c:		*riid_ptr = ++ctx->dummy_riid;
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->rmt_rx_intent_lst_lock_lhc2,
drivers/soc/qcom/glink.c:	list_for_each_entry_safe(intent, intent_tmp, &ctx->rmt_rx_intent_list,
drivers/soc/qcom/glink.c:			&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	gfp_flag = (ctx->transport_ptr->capabilities & GCAP_AUTO_QUEUE_RX_INT) ?
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	list_add_tail(&intent->list, &ctx->rmt_rx_intent_list);
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_complete);
drivers/soc/qcom/glink.c:	if (ctx->notify_remote_rx_intent)
drivers/soc/qcom/glink.c:		ctx->notify_remote_rx_intent(ctx, ctx->user_priv, size);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:		if (ctx->max_used_liid >= ctx->transport_ptr->max_iid) {
drivers/soc/qcom/glink.c:				__func__, ctx->transport_ptr->max_iid);
drivers/soc/qcom/glink.c:		intent->id = ++ctx->max_used_liid;
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->allocate_rx_intent(
drivers/soc/qcom/glink.c:					ctx->transport_ptr->ops, size, intent);
drivers/soc/qcom/glink.c:		spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_free_list);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_add_tail(&intent->list, &ctx->local_rx_intent_list);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->max_iid < liid) {
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry_safe(intent, tmp_intent, &ctx->local_rx_intent_list,
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_free_list);
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->local_rx_intent_list)) {
drivers/soc/qcom/glink.c:		intent = list_first_entry(&ctx->local_rx_intent_list,
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:		intent->id = ++ctx->max_used_liid;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_add_tail(&intent->list, &ctx->local_rx_intent_list);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->max_iid < liid) {
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->capabilities & GCAP_INTENTLESS)
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(intent, &ctx->local_rx_intent_list, list) {
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry_safe(intent, tmp_intent, &ctx->local_rx_intent_list,
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_ntfy_list);
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(ptr_intent, &ctx->local_rx_intent_ntfy_list,
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_ntfy_list, list) {
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_list);
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_free_list);
drivers/soc/qcom/glink.c:					&ctx->local_rx_intent_lst_lock_lhc1,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->local_rx_intent_free_list)) {
drivers/soc/qcom/glink.c:		ptr_intent = list_first_entry(&ctx->local_rx_intent_free_list,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry_safe(tx_info, tx_info_temp, &ctx->tx_active,
drivers/soc/qcom/glink.c:		ctx->notify_tx_abort(ctx, ctx->user_priv,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:				 &ctx->tx_pending_remote_done, list_done) {
drivers/soc/qcom/glink.c:		ctx->notify_tx_abort(ctx, ctx->user_priv, tx_info->pkt_priv);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_list, list) {
drivers/soc/qcom/glink.c:		ctx->notify_rx_abort(ctx, ctx->user_priv,
drivers/soc/qcom/glink.c:		ctx->transport_ptr->ops->deallocate_rx_intent(
drivers/soc/qcom/glink.c:					ctx->transport_ptr->ops, ptr_intent);
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->local_rx_intent_ntfy_list))
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_free_list, list) {
drivers/soc/qcom/glink.c:	ctx->max_used_liid = 0;
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:			&ctx->rmt_rx_intent_list, list) {
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->rmt_rx_intent_lst_lock_lhc2, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(tx_pkt, &ctx->tx_pending_remote_done, list_done) {
drivers/soc/qcom/glink.c:				&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:			&ctx->tx_pending_remote_done, list_done) {
drivers/soc/qcom/glink.c:				&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_pending_rmt_done_lock_lhc4, flags);
drivers/soc/qcom/glink.c:			__func__, ctx->transport_ptr->name,
drivers/soc/qcom/glink.c:			ctx->transport_ptr->edge, ctx->lcid);
drivers/soc/qcom/glink.c:	free_lcid->lcid = ctx->lcid;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:			&ctx->transport_ptr->free_lcid_list);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->transport_ptr->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	ctx->transport_ptr = NULL;
drivers/soc/qcom/glink.c:	ctx->local_open_state = GLINK_CHANNEL_CLOSED;
drivers/soc/qcom/glink.c:	strlcpy(ctx->name, name, GLINK_NAME_SIZE);
drivers/soc/qcom/glink.c:	rwref_lock_init(&ctx->ch_state_lhb2, glink_ch_ctx_release);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->tx_ready_list_node);
drivers/soc/qcom/glink.c:	init_completion(&ctx->int_req_ack_complete);
drivers/soc/qcom/glink.c:	init_completion(&ctx->int_req_complete);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->local_rx_intent_list);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->local_rx_intent_ntfy_list);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->local_rx_intent_free_list);
drivers/soc/qcom/glink.c:	spin_lock_init(&ctx->local_rx_intent_lst_lock_lhc1);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->rmt_rx_intent_list);
drivers/soc/qcom/glink.c:	spin_lock_init(&ctx->rmt_rx_intent_lst_lock_lhc2);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->tx_active);
drivers/soc/qcom/glink.c:	spin_lock_init(&ctx->tx_pending_rmt_done_lock_lhc4);
drivers/soc/qcom/glink.c:	INIT_LIST_HEAD(&ctx->tx_pending_remote_done);
drivers/soc/qcom/glink.c:	spin_lock_init(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	rwref_write_get(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	if (xprt_ctx->local_state != GLINK_XPRT_OPENED) {
drivers/soc/qcom/glink.c:		rwref_write_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry_safe(entry, temp, &xprt_ctx->channels,
drivers/soc/qcom/glink.c:			spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:			rwref_write_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:		if (list_empty(&xprt_ctx->free_lcid_list)) {
drivers/soc/qcom/glink.c:			if (xprt_ctx->next_lcid > xprt_ctx->max_cid) {
drivers/soc/qcom/glink.c:					__func__, xprt_ctx->max_cid);
drivers/soc/qcom/glink.c:						&xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:				rwref_write_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:			ctx->lcid = xprt_ctx->next_lcid++;
drivers/soc/qcom/glink.c:			flcid = list_first_entry(&xprt_ctx->free_lcid_list,
drivers/soc/qcom/glink.c:			ctx->lcid = flcid->lcid;
drivers/soc/qcom/glink.c:		ctx->transport_ptr = xprt_ctx;
drivers/soc/qcom/glink.c:		rwref_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:			ctx->local_open_state = GLINK_CHANNEL_OPENING;
drivers/soc/qcom/glink.c:		list_add_tail(&ctx->port_list_node, &xprt_ctx->channels);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	rwref_write_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	mutex_lock(&xprt_ctx->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	mutex_unlock(&xprt_ctx->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	ctx->rcid = rcid;
drivers/soc/qcom/glink.c:	rwref_write_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->local_open_state = lstate;
drivers/soc/qcom/glink.c:	rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_write_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->remote_opened = rstate;
drivers/soc/qcom/glink.c:	rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->remote_opened && ctx->local_open_state == GLINK_CHANNEL_OPENED)
drivers/soc/qcom/glink.c:	if (!ctx->remote_opened &&
drivers/soc/qcom/glink.c:			ctx->local_open_state == GLINK_CHANNEL_CLOSED)
drivers/soc/qcom/glink.c:	pctx->size_remaining = 0;
drivers/soc/qcom/glink.c:	ctx->user_priv = cfg->priv;
drivers/soc/qcom/glink.c:	ctx->rx_intent_req_timeout_jiffies =
drivers/soc/qcom/glink.c:	ctx->notify_rx = cfg->notify_rx;
drivers/soc/qcom/glink.c:	ctx->notify_tx_done = cfg->notify_tx_done;
drivers/soc/qcom/glink.c:	ctx->notify_state = cfg->notify_state;
drivers/soc/qcom/glink.c:	ctx->notify_rx_intent_req = cfg->notify_rx_intent_req;
drivers/soc/qcom/glink.c:	ctx->notify_rxv = cfg->notify_rxv;
drivers/soc/qcom/glink.c:	ctx->notify_rx_sigs = cfg->notify_rx_sigs;
drivers/soc/qcom/glink.c:	ctx->notify_rx_abort = cfg->notify_rx_abort;
drivers/soc/qcom/glink.c:	ctx->notify_tx_abort = cfg->notify_tx_abort;
drivers/soc/qcom/glink.c:	ctx->notify_rx_tracer_pkt = cfg->notify_rx_tracer_pkt;
drivers/soc/qcom/glink.c:	ctx->notify_remote_rx_intent = cfg->notify_remote_rx_intent;
drivers/soc/qcom/glink.c:	if (!ctx->notify_rx_intent_req)
drivers/soc/qcom/glink.c:		ctx->notify_rx_intent_req = glink_dummy_notify_rx_intent_req;
drivers/soc/qcom/glink.c:	if (!ctx->notify_rx_sigs)
drivers/soc/qcom/glink.c:		ctx->notify_rx_sigs = glink_dummy_notify_rx_sigs;
drivers/soc/qcom/glink.c:	if (!ctx->notify_rx_abort)
drivers/soc/qcom/glink.c:		ctx->notify_rx_abort = glink_dummy_notify_rx_abort;
drivers/soc/qcom/glink.c:	if (!ctx->notify_tx_abort)
drivers/soc/qcom/glink.c:		ctx->notify_tx_abort = glink_dummy_notify_tx_abort;
drivers/soc/qcom/glink.c:	if (!ctx->rx_intent_req_timeout_jiffies)
drivers/soc/qcom/glink.c:		ctx->rx_intent_req_timeout_jiffies = MAX_SCHEDULE_TIMEOUT;
drivers/soc/qcom/glink.c:	ctx->local_xprt_req = best_id;
drivers/soc/qcom/glink.c:	ctx->no_migrate = cfg->transport &&
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->tx_cmd_ch_open(ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:		ctx->lcid, cfg->name, best_id);
drivers/soc/qcom/glink.c:		ctx->local_open_state = GLINK_CHANNEL_CLOSED;
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	return ctx->lcid;
drivers/soc/qcom/glink.c:	return ctx->name;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->port_list_node))
drivers/soc/qcom/glink.c:		list_del_init(&ctx->port_list_node);
drivers/soc/qcom/glink.c:	if (list_empty(&ctx->transport_ptr->channels) &&
drivers/soc/qcom/glink.c:			list_empty(&ctx->transport_ptr->notified))
drivers/soc/qcom/glink.c:			&ctx->transport_ptr->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	mutex_lock(&ctx->transport_ptr->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	glink_debugfs_remove_channel(ctx, ctx->transport_ptr);
drivers/soc/qcom/glink.c:	mutex_unlock(&ctx->transport_ptr->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->local_open_state == GLINK_CHANNEL_CLOSED) {
drivers/soc/qcom/glink.c:	if (ctx->local_open_state == GLINK_CHANNEL_CLOSING) {
drivers/soc/qcom/glink.c:	rwref_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:relock: xprt_ctx = ctx->transport_ptr;
drivers/soc/qcom/glink.c:	rwref_read_get(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	rwref_write_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (xprt_ctx != ctx->transport_ptr) {
drivers/soc/qcom/glink.c:		rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_read_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:		__func__, ctx->local_open_state);
drivers/soc/qcom/glink.c:	ctx->local_open_state = GLINK_CHANNEL_CLOSING;
drivers/soc/qcom/glink.c:	ctx->pending_delete = true;
drivers/soc/qcom/glink.c:	ctx->int_req_ack = false;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&xprt_ctx->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	if (!list_empty(&ctx->tx_ready_list_node))
drivers/soc/qcom/glink.c:		list_del_init(&ctx->tx_ready_list_node);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&xprt_ctx->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	if (xprt_ctx->local_state != GLINK_XPRT_DOWN) {
drivers/soc/qcom/glink.c:		ret = xprt_ctx->ops->tx_cmd_ch_close(xprt_ctx->ops, ctx->lcid);
drivers/soc/qcom/glink.c:		rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	} else if (!strcmp(xprt_ctx->name, "dummy")) {
drivers/soc/qcom/glink.c:		rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:			rwref_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:			if (is_empty && !xprt_ctx->dummy_in_use)
drivers/soc/qcom/glink.c:				rwref_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:			ctx->local_open_state, ctx->remote_opened);
drivers/soc/qcom/glink.c:		rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_ack_complete);
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_complete);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_read_put(&xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	rwref_read_get_atomic(&ctx->ch_state_lhb2, is_atomic);
drivers/soc/qcom/glink.c:		if (!(ctx->transport_ptr->capabilities & GCAP_TRACER_PKT)) {
drivers/soc/qcom/glink.c:		if (is_atomic && !(ctx->transport_ptr->capabilities &
drivers/soc/qcom/glink.c:		reinit_completion(&ctx->int_req_ack_complete);
drivers/soc/qcom/glink.c:		ret = ctx->transport_ptr->ops->tx_cmd_rx_intent_req(
drivers/soc/qcom/glink.c:				ctx->transport_ptr->ops, ctx->lcid, size);
drivers/soc/qcom/glink.c:			rwref_read_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:			if (ctx->transport_ptr->local_state == GLINK_XPRT_DOWN
drivers/soc/qcom/glink.c:					&ctx->int_req_ack_complete,
drivers/soc/qcom/glink.c:					ctx->rx_intent_req_timeout_jiffies)) {
drivers/soc/qcom/glink.c:			if (!ctx->int_req_ack) {
drivers/soc/qcom/glink.c:					&ctx->int_req_complete,
drivers/soc/qcom/glink.c:					ctx->rx_intent_req_timeout_jiffies)) {
drivers/soc/qcom/glink.c:			reinit_completion(&ctx->int_req_complete);
drivers/soc/qcom/glink.c:			rwref_read_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		spin_lock_irqsave(&ctx->transport_ptr->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:		glink_pm_qos_vote(ctx->transport_ptr);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3,
drivers/soc/qcom/glink.c:	tx_info->rcid = ctx->rcid;
drivers/soc/qcom/glink.c:	    (ctx->transport_ptr->capabilities & GCAP_INTENTLESS))
drivers/soc/qcom/glink.c:		ret = xprt_single_threaded_tx(ctx->transport_ptr,
drivers/soc/qcom/glink.c:		xprt_schedule_tx(ctx->transport_ptr, ctx, tx_info);
drivers/soc/qcom/glink.c:	rwref_read_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_read_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->transport_ptr->capabilities & GCAP_INTENTLESS) {
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->tx_cmd_local_rx_intent(
drivers/soc/qcom/glink.c:		ctx->transport_ptr->ops, ctx->lcid, size, intent_ptr->id);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	list_for_each_entry(intent, &ctx->local_rx_intent_list, list) {
drivers/soc/qcom/glink.c:				&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->local_rx_intent_lst_lock_lhc1, flags);
drivers/soc/qcom/glink.c:		ret = ctx->transport_ptr->ops->reuse_rx_intent(
drivers/soc/qcom/glink.c:					ctx->transport_ptr->ops, liid_ptr);
drivers/soc/qcom/glink.c:			ctx->transport_ptr->ops->deallocate_rx_intent(
drivers/soc/qcom/glink.c:					ctx->transport_ptr->ops, liid_ptr);
drivers/soc/qcom/glink.c:		ctx->transport_ptr->ops->deallocate_rx_intent(
drivers/soc/qcom/glink.c:					ctx->transport_ptr->ops, liid_ptr);
drivers/soc/qcom/glink.c:	ctx->transport_ptr->ops->tx_cmd_local_rx_done(ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:			ctx->lcid, id, reuse);
drivers/soc/qcom/glink.c:	ctx->lsigs = sigs;
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->tx_cmd_set_sigs(ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:			ctx->lcid, ctx->lsigs);
drivers/soc/qcom/glink.c:	*sigs = ctx->lsigs;
drivers/soc/qcom/glink.c:	*sigs = ctx->rsigs;
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	spin_lock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	spin_unlock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->transport_ptr->tx_ready_lock_lhb3, flags);
drivers/soc/qcom/glink.c:	return ctx->transport_ptr->ops->get_power_vote_ramp_time(
drivers/soc/qcom/glink.c:			ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:			glink_prio_to_power_state(ctx->transport_ptr,
drivers/soc/qcom/glink.c:						ctx->initial_priority));
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->rx_rt_vote(ctx->transport_ptr->ops);
drivers/soc/qcom/glink.c:	ctx->rt_vote_on++;
drivers/soc/qcom/glink.c:	ret = ctx->transport_ptr->ops->rx_rt_unvote(ctx->transport_ptr->ops);
drivers/soc/qcom/glink.c:	ctx->rt_vote_off++;
drivers/soc/qcom/glink.c:	if (!ctx->transport_ptr ||
drivers/soc/qcom/glink.c:	    !(ctx->transport_ptr->capabilities & GCAP_INTENTLESS))
drivers/soc/qcom/glink.c:	return ctx->transport_ptr->ops->poll(ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:					     ctx->lcid);
drivers/soc/qcom/glink.c:	if (!ctx->transport_ptr ||
drivers/soc/qcom/glink.c:	    !(ctx->transport_ptr->capabilities & GCAP_INTENTLESS))
drivers/soc/qcom/glink.c:	return ctx->transport_ptr->ops->mask_rx_irq(ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:						    ctx->lcid, mask, pstruct);
drivers/soc/qcom/glink.c:	if (!ctx->transport_ptr) {
drivers/soc/qcom/glink.c:	return ctx->transport_ptr->ops->wait_link_down(ctx->transport_ptr->ops);
drivers/soc/qcom/glink.c:				xprt_ctx->name,
drivers/soc/qcom/glink.c:				xprt_ctx->edge);
drivers/soc/qcom/glink.c:	xprt_rm_dbgfs.curr_name = xprt_ctx->name;
drivers/soc/qcom/glink.c:	rwref_put(&xprt_ctx->edge_ctx->edge_ref_lock_lhd1);
drivers/soc/qcom/glink.c:	kthread_stop(xprt_ctx->tx_task);
drivers/soc/qcom/glink.c:	xprt_ctx->tx_task = NULL;
drivers/soc/qcom/glink.c:				xprt_ctx->name,
drivers/soc/qcom/glink.c:				xprt_ctx->edge);
drivers/soc/qcom/glink.c:	kfree(xprt_ctx->ops);
drivers/soc/qcom/glink.c:	xprt_ctx->ops = NULL;
drivers/soc/qcom/glink.c:	strlcpy(xprt_ptr->edge, orig_xprt_ctx->edge, GLINK_NAME_SIZE);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	if (!list_empty(&xprt_ctx->channels)) {
drivers/soc/qcom/glink.c:		ctx = list_first_entry(&xprt_ctx->channels,
drivers/soc/qcom/glink.c:		rwref_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&xprt_ctx->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&dummy_xprt_ctx->xprt_ctx_lock_lhb1, d_flags);
drivers/soc/qcom/glink.c:	rwref_get(&dummy_xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:	list_move_tail(&ctx->port_list_node, &dummy_xprt_ctx->channels);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&dummy_xprt_ctx->xprt_ctx_lock_lhb1, d_flags);
drivers/soc/qcom/glink.c:	rwref_read_get(&dummy_xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:		spin_lock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:		if (!list_empty(&ctx->tx_active))
drivers/soc/qcom/glink.c:		spin_unlock(&ctx->tx_lists_lock_lhc3);
drivers/soc/qcom/glink.c:		rwref_write_get_atomic(&ctx->ch_state_lhb2, true);
drivers/soc/qcom/glink.c:		if (ctx->local_open_state == GLINK_CHANNEL_OPENED ||
drivers/soc/qcom/glink.c:			ctx->local_open_state == GLINK_CHANNEL_OPENING) {
drivers/soc/qcom/glink.c:			ctx->transport_ptr = dummy_xprt_ctx;
drivers/soc/qcom/glink.c:			if (ctx->local_open_state == GLINK_CHANNEL_CLOSING)
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_write_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&dummy_xprt_ctx->xprt_ctx_lock_lhb1, d_flags);
drivers/soc/qcom/glink.c:	dummy_xprt_ctx->dummy_in_use = false;
drivers/soc/qcom/glink.c:	while (!list_empty(&dummy_xprt_ctx->channels)) {
drivers/soc/qcom/glink.c:		ctx = list_first_entry(&dummy_xprt_ctx->channels,
drivers/soc/qcom/glink.c:		list_move_tail(&ctx->port_list_node,
drivers/soc/qcom/glink.c:					&dummy_xprt_ctx->notified);
drivers/soc/qcom/glink.c:		rwref_get(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&dummy_xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:		spin_lock_irqsave(&dummy_xprt_ctx->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&dummy_xprt_ctx->xprt_ctx_lock_lhb1, d_flags);
drivers/soc/qcom/glink.c:	rwref_read_put(&dummy_xprt_ctx->xprt_state_lhb0);
drivers/soc/qcom/glink.c:		if (!strcmp(r_ctx->transport_ptr->edge, xprt->edge)) {
drivers/soc/qcom/glink.c:				if (!strcmp(ctx->name, r_ctx->name) &&
drivers/soc/qcom/glink.c:							ctx->local_xprt_req &&
drivers/soc/qcom/glink.c:							ctx->local_xprt_resp) {
drivers/soc/qcom/glink.c:					rwref_get(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		if (!strcmp(l_ctx->transport_ptr->edge, xprt->edge)) {
drivers/soc/qcom/glink.c:				if (!strcmp(ctx->name, l_ctx->name) &&
drivers/soc/qcom/glink.c:							ctx->remote_xprt_req &&
drivers/soc/qcom/glink.c:							ctx->remote_xprt_resp) {
drivers/soc/qcom/glink.c:					rwref_get(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_get(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_get(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (l_ctx->local_xprt_req == r_ctx->remote_xprt_req &&
drivers/soc/qcom/glink.c:			l_ctx->local_xprt_req == l_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:	if (l_ctx->no_migrate)
drivers/soc/qcom/glink.c:	if (l_ctx->local_xprt_req > r_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:		l_ctx->local_xprt_req = r_ctx->transport_ptr->id;
drivers/soc/qcom/glink.c:		(l_ctx->transport_ptr->id == l_ctx->local_xprt_req))
drivers/soc/qcom/glink.c:	new_xprt = max(l_ctx->local_xprt_req, r_ctx->remote_xprt_req);
drivers/soc/qcom/glink.c:	if (new_xprt == l_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:		rwref_put(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_put(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_get(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_get(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_put(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		(l_ctx->transport_ptr->id == l_ctx->local_xprt_req)) {
drivers/soc/qcom/glink.c:		rwref_put(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_put(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (l_ctx->local_xprt_req == r_ctx->remote_xprt_req &&
drivers/soc/qcom/glink.c:			l_ctx->local_xprt_req == l_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:	if (l_ctx->no_migrate)
drivers/soc/qcom/glink.c:	if (l_ctx->local_xprt_req > r_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:		l_ctx->local_xprt_req = r_ctx->transport_ptr->id;
drivers/soc/qcom/glink.c:	new_xprt = max(l_ctx->local_xprt_req, r_ctx->remote_xprt_req);
drivers/soc/qcom/glink.c:	if (new_xprt == l_ctx->transport_ptr->id)
drivers/soc/qcom/glink.c:		if (!strcmp(l_ctx->transport_ptr->edge, xprt->edge))
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&l_ctx->transport_ptr->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	list_del_init(&l_ctx->port_list_node);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&l_ctx->transport_ptr->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	mutex_lock(&l_ctx->transport_ptr->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	glink_debugfs_remove_channel(l_ctx, l_ctx->transport_ptr);
drivers/soc/qcom/glink.c:	mutex_unlock(&l_ctx->transport_ptr->xprt_dbgfs_lock_lhb4);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&l_ctx->transport_ptr->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:					&l_ctx->transport_ptr->channels);
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&l_ctx->transport_ptr->xprt_ctx_lock_lhb1,
drivers/soc/qcom/glink.c:	l_ctx->transport_ptr->ops->tx_cmd_ch_close(l_ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:								l_ctx->lcid);
drivers/soc/qcom/glink.c:	l_ctx->transport_ptr = xprt;
drivers/soc/qcom/glink.c:	l_ctx->local_xprt_req = 0;
drivers/soc/qcom/glink.c:	l_ctx->local_xprt_resp = 0;
drivers/soc/qcom/glink.c:	if (new_xprt != r_ctx->transport_ptr->id || l_ctx == r_ctx) {
drivers/soc/qcom/glink.c:		if (new_xprt != r_ctx->transport_ptr->id) {
drivers/soc/qcom/glink.c:			r_ctx->local_xprt_req = 0;
drivers/soc/qcom/glink.c:			r_ctx->local_xprt_resp = 0;
drivers/soc/qcom/glink.c:			r_ctx->remote_xprt_req = 0;
drivers/soc/qcom/glink.c:			r_ctx->remote_xprt_resp = 0;
drivers/soc/qcom/glink.c:		l_ctx->remote_xprt_req = 0;
drivers/soc/qcom/glink.c:		l_ctx->remote_xprt_resp = 0;
drivers/soc/qcom/glink.c:		l_ctx->remote_opened = false;
drivers/soc/qcom/glink.c:			l_ctx->lcid = xprt->next_lcid++;
drivers/soc/qcom/glink.c:			l_ctx->lcid = flcid->lcid;
drivers/soc/qcom/glink.c:		list_add_tail(&l_ctx->port_list_node, &xprt->channels);
drivers/soc/qcom/glink.c:		l_ctx->lcid = r_ctx->lcid;
drivers/soc/qcom/glink.c:		l_ctx->rcid = r_ctx->rcid;
drivers/soc/qcom/glink.c:		l_ctx->remote_opened = r_ctx->remote_opened;
drivers/soc/qcom/glink.c:		l_ctx->remote_xprt_req = r_ctx->remote_xprt_req;
drivers/soc/qcom/glink.c:		l_ctx->remote_xprt_resp = r_ctx->remote_xprt_resp;
drivers/soc/qcom/glink.c:		list_add_tail(&l_ctx->port_list_node, &xprt->channels);
drivers/soc/qcom/glink.c:		if (!strcmp(l_ctx->transport_ptr->edge, xprt->edge))
drivers/soc/qcom/glink.c:	l_ctx->local_open_state = GLINK_CHANNEL_OPENING;
drivers/soc/qcom/glink.c:	l_ctx->local_xprt_req = best_xprt;
drivers/soc/qcom/glink.c:	l_ctx->transport_ptr->ops->tx_cmd_ch_open(l_ctx->transport_ptr->ops,
drivers/soc/qcom/glink.c:					l_ctx->lcid, l_ctx->name, best_xprt);
drivers/soc/qcom/glink.c:	rwref_put(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&r_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		r_ctx->remote_xprt_resp = r_ctx->transport_ptr->id;
drivers/soc/qcom/glink.c:	} else if (r_ctx->remote_xprt_req == r_ctx->transport_ptr->id) {
drivers/soc/qcom/glink.c:		r_ctx->remote_xprt_resp = r_ctx->remote_xprt_req;
drivers/soc/qcom/glink.c:		if (!l_ctx->local_xprt_req)
drivers/soc/qcom/glink.c:			r_ctx->remote_xprt_resp = r_ctx->remote_xprt_req;
drivers/soc/qcom/glink.c:		else if (l_ctx->no_migrate)
drivers/soc/qcom/glink.c:			r_ctx->remote_xprt_resp = l_ctx->local_xprt_req;
drivers/soc/qcom/glink.c:			r_ctx->remote_xprt_resp = max(l_ctx->local_xprt_req,
drivers/soc/qcom/glink.c:							r_ctx->remote_xprt_req);
drivers/soc/qcom/glink.c:		rwref_put(&l_ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	return r_ctx->remote_xprt_resp;
drivers/soc/qcom/glink.c:	if (ctx->remote_opened) {
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->remote_opened = true;
drivers/soc/qcom/glink.c:	ctx->transport_ptr = if_ptr->glink_core_priv;
drivers/soc/qcom/glink.c:	ctx->remote_xprt_req = req_xprt;
drivers/soc/qcom/glink.c:		ctx->notify_state(ctx, ctx->user_priv, GLINK_CONNECTED);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->local_open_state != GLINK_CHANNEL_OPENING) {
drivers/soc/qcom/glink.c:				__func__, ctx->local_open_state, current->pid);
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->local_xprt_resp = xprt_resp;
drivers/soc/qcom/glink.c:		ctx->local_open_state = GLINK_CHANNEL_OPENED;
drivers/soc/qcom/glink.c:			ctx->notify_state(ctx, ctx->user_priv, GLINK_CONNECTED);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (!ctx->remote_opened) {
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->transport_ptr->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	ctx->pending_delete = true;
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->transport_ptr->xprt_ctx_lock_lhb1, flags);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->local_open_state != GLINK_CHANNEL_CLOSING) {
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (!ctx->notify_rx_intent_req) {
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	cb_ret = ctx->notify_rx_intent_req(ctx, ctx->user_priv, size);
drivers/soc/qcom/glink.c:	if_ptr->tx_cmd_remote_rx_intent_req_ack(if_ptr, ctx->lcid, cb_ret);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->int_req_ack = granted;
drivers/soc/qcom/glink.c:	complete_all(&ctx->int_req_ack_complete);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:		if (ctx->notify_rx_tracer_pkt)
drivers/soc/qcom/glink.c:			ctx->notify_rx_tracer_pkt(ctx, ctx->user_priv,
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (!intent_ptr->data && !ctx->notify_rxv) {
drivers/soc/qcom/glink.c:			rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->notify_rx && (intent_ptr->data || intent_ptr->bounce_buf)) {
drivers/soc/qcom/glink.c:		ctx->notify_rx(ctx, ctx->user_priv, intent_ptr->pkt_priv,
drivers/soc/qcom/glink.c:	} else if (ctx->notify_rxv) {
drivers/soc/qcom/glink.c:		ctx->notify_rxv(ctx, ctx->user_priv, intent_ptr->pkt_priv,
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	ctx->notify_tx_done(ctx, ctx->user_priv, tx_pkt->pkt_priv,
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	if (ctx->initial_priority == 0)
drivers/soc/qcom/glink.c:	if (ctx->token_count)
drivers/soc/qcom/glink.c:	token_consume_time = (token_end_time - ctx->token_start_time) *
drivers/soc/qcom/glink.c:	obs_rate_kBps = glink_qos_calc_rate_kBps(ctx->txd_len,
drivers/soc/qcom/glink.c:	if (obs_rate_kBps > ctx->req_rate_kBps) {
drivers/soc/qcom/glink.c:			__func__, obs_rate_kBps, ctx->req_rate_kBps);
drivers/soc/qcom/glink.c:		glink_qos_update_ch_prio(ctx, ctx->initial_priority);
drivers/soc/qcom/glink.c:	ctx->token_count = xprt_ctx->token_count;
drivers/soc/qcom/glink.c:	ctx->txd_len = 0;
drivers/soc/qcom/glink.c:	ctx->token_start_time = arch_counter_get_cntvct();
drivers/soc/qcom/glink.c:	spin_lock_irqsave(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:	while (txd_len < xprt_ctx->mtu &&
drivers/soc/qcom/glink.c:		!list_empty(&ctx->tx_active)) {
drivers/soc/qcom/glink.c:		tx_info = list_first_entry(&ctx->tx_active,
drivers/soc/qcom/glink.c:		spin_lock(&ctx->tx_pending_rmt_done_lock_lhc4);
drivers/soc/qcom/glink.c:				 &ctx->tx_pending_remote_done);
drivers/soc/qcom/glink.c:		spin_unlock(&ctx->tx_pending_rmt_done_lock_lhc4);
drivers/soc/qcom/glink.c:		spin_unlock_irqrestore(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:			ret = xprt_ctx->ops->tx_cmd_tracer_pkt(xprt_ctx->ops,
drivers/soc/qcom/glink.c:						ctx->lcid, tx_info);
drivers/soc/qcom/glink.c:				 (xprt_ctx->mtu - txd_len) ?
drivers/soc/qcom/glink.c:				 (xprt_ctx->mtu - txd_len);
drivers/soc/qcom/glink.c:			ret = xprt_ctx->ops->tx(xprt_ctx->ops,
drivers/soc/qcom/glink.c:						ctx->lcid, tx_info);
drivers/soc/qcom/glink.c:		spin_lock_irqsave(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:		if (!list_empty(&ctx->tx_active)) {
drivers/soc/qcom/glink.c:			temp_tx_info = list_first_entry(&ctx->tx_active,
drivers/soc/qcom/glink.c:	ctx->txd_len += txd_len;
drivers/soc/qcom/glink.c:		if (num_pkts >= ctx->token_count)
drivers/soc/qcom/glink.c:			ctx->token_count = 0;
drivers/soc/qcom/glink.c:			ctx->token_count -= num_pkts;
drivers/soc/qcom/glink.c:			ctx->token_count--;
drivers/soc/qcom/glink.c:	spin_unlock_irqrestore(&ctx->tx_lists_lock_lhc3, flags);
drivers/soc/qcom/glink.c:		rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	old_sigs = ctx->rsigs;
drivers/soc/qcom/glink.c:	ctx->rsigs = sigs;
drivers/soc/qcom/glink.c:	if (ctx->notify_rx_sigs) {
drivers/soc/qcom/glink.c:		ctx->notify_rx_sigs(ctx, ctx->user_priv, old_sigs, ctx->rsigs);
drivers/soc/qcom/glink.c:				__func__, old_sigs, ctx->rsigs);
drivers/soc/qcom/glink.c:	rwref_put(&ctx->ch_state_lhb2);
drivers/soc/qcom/glink.c:	return xprt_ctx->name;
drivers/soc/qcom/glink.c:	return xprt_ctx->edge;
drivers/soc/qcom/glink.c:	return glink_get_xprt_state_string(xprt_ctx->local_state);
drivers/soc/qcom/glink.c:	ver = &xprt_ctx->versions[xprt_ctx->local_version_idx];
drivers/soc/qcom/glink.c:	return ch_ctx->name;
drivers/soc/qcom/glink.c:	return ch_ctx->transport_ptr->edge;
drivers/soc/qcom/glink.c:	return ch_ctx->lcid;
drivers/soc/qcom/glink.c:	return ch_ctx->rcid;
drivers/soc/qcom/glink.c:	return glink_get_ch_state_string(ch_ctx->local_open_state);
drivers/soc/qcom/glink.c:	return ch_ctx->remote_opened;
drivers/soc/qcom/glink.c:	return ch_ctx->transport_ptr->name;
drivers/soc/qcom/glink.c:	list_for_each_entry(intent, &ch_ctx->local_rx_intent_list, list)
drivers/soc/qcom/glink.c:	list_for_each_entry(intent, &ch_ctx->rmt_rx_intent_list, list)
drivers/soc/qcom/glink.c:	ch_ctx_i->li_lst_lock = &ch_ctx->local_rx_intent_lst_lock_lhc1;
drivers/soc/qcom/glink.c:	ch_ctx_i->li_avail_list = &ch_ctx->local_rx_intent_list;
drivers/soc/qcom/glink.c:	ch_ctx_i->li_used_list = &ch_ctx->local_rx_intent_ntfy_list;
drivers/soc/qcom/glink.c:	ch_ctx_i->ri_lst_lock = &ch_ctx->rmt_rx_intent_lst_lock_lhc2;
drivers/soc/qcom/glink.c:	ch_ctx_i->ri_list = &ch_ctx->rmt_rx_intent_list;
drivers/soc/qcom/glink_xprt_if.h:	if (pctx->vprovider) {
drivers/soc/qcom/glink_xprt_if.h:		return pctx->vprovider((void *)pctx->iovec, offset, tx_size);
drivers/soc/qcom/glink_xprt_if.h:	} else if (pctx->pprovider) {
drivers/soc/qcom/glink_xprt_if.h:		pdata = pctx->pprovider((void *)pctx->iovec, offset, tx_size);
drivers/soc/qcom/smp2p_loopback.c:		(void)msm_smp2p_out_write(ctx->out, test_request);
drivers/soc/qcom/smp2p_loopback.c:			(void)msm_smp2p_in_read(ctx->proc_id,
drivers/soc/qcom/smp2p_loopback.c:			(void)msm_smp2p_out_write(ctx->out, test_request);
drivers/soc/qcom/smp2p_loopback.c:		(void)msm_smp2p_out_write(ctx->out, test_request);
drivers/soc/qcom/smp2p_loopback.c:	if (!ctx->in_is_active || !ctx->out_is_active)
drivers/soc/qcom/smp2p_loopback.c:	if (ctx->rmt_cmd.previous_value == ctx->rmt_cmd.current_value)
drivers/soc/qcom/smp2p_loopback.c:	lpb_cmd_type =  SMP2P_GET_RMT_CMD_TYPE(ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:	lpb_cmd = SMP2P_GET_RMT_CMD(ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:	lpb_data = SMP2P_GET_RMT_DATA(ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:		SMP2P_SET_RMT_CMD_TYPE(ctx->rmt_cmd.current_value, 0);
drivers/soc/qcom/smp2p_loopback.c:		SMP2P_SET_RMT_DATA(ctx->rmt_cmd.current_value,
drivers/soc/qcom/smp2p_loopback.c:		(void)msm_smp2p_out_write(ctx->out,
drivers/soc/qcom/smp2p_loopback.c:					ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:		ctx->rmt_cmd.current_value = 0;
drivers/soc/qcom/smp2p_loopback.c:		(void)msm_smp2p_out_write(ctx->out,
drivers/soc/qcom/smp2p_loopback.c:					ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:		SMP2P_SET_RMT_CMD_TYPE(ctx->rmt_cmd.current_value, 0);
drivers/soc/qcom/smp2p_loopback.c:			SMP2P_SET_RMT_DATA(ctx->rmt_cmd.current_value,
drivers/soc/qcom/smp2p_loopback.c:			(void)msm_smp2p_out_write(ctx->out,
drivers/soc/qcom/smp2p_loopback.c:					ctx->rmt_cmd.current_value);
drivers/soc/qcom/smp2p_loopback.c:	if (data && ctx->in_is_active) {
drivers/soc/qcom/smp2p_loopback.c:		ctx->rmt_cmd = *(struct msm_smp2p_update_notif *)data;
drivers/soc/qcom/smp2p_loopback.c:		schedule_work(&ctx->rmt_lpb_work);
drivers/soc/qcom/smp2p_loopback.c:				ctx->proc_id);
drivers/soc/qcom/smp2p_loopback.c:	ctx->in_nb.notifier_call = smp2p_rmt_in_edge_notify;
drivers/soc/qcom/smp2p_loopback.c:	ctx->out_nb.notifier_call = smp2p_rmt_out_edge_notify;
drivers/soc/qcom/smp2p_loopback.c:	ctx->proc_id = pid;
drivers/soc/qcom/smp2p_loopback.c:	ctx->in_is_active = true;
drivers/soc/qcom/smp2p_loopback.c:	ctx->out_is_active = true;
drivers/soc/qcom/smp2p_loopback.c:	tmp = msm_smp2p_out_open(pid, entry, &ctx->out_nb,
drivers/soc/qcom/smp2p_loopback.c:						&ctx->out);
drivers/soc/qcom/smp2p_loopback.c:	tmp = msm_smp2p_in_register(ctx->proc_id,
drivers/soc/qcom/smp2p_loopback.c:				&ctx->in_nb);
drivers/soc/qcom/smp2p_loopback.c:	flush_work(&ctx->rmt_lpb_work);
drivers/soc/qcom/glink_private.h:		GLINK_XPRT_IPC_LOG_STR(ctx->transport_ptr, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->name, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->edge, \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:		GLINK_XPRT_IPC_LOG_STR(ctx->transport_ptr, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->name, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->edge, \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:		GLINK_XPRT_IPC_LOG_STR(ctx->transport_ptr, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->name, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->edge, \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:		GLINK_XPRT_IPC_LOG_STR(ctx->transport_ptr, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->name, \
drivers/soc/qcom/glink_private.h:				ctx->transport_ptr->edge, \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:				ctx->name, \
drivers/soc/qcom/glink_private.h:				ctx->lcid, \
drivers/soc/qcom/glink_private.h:				ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:		ctx->transport_ptr->name, \
drivers/soc/qcom/glink_private.h:		ctx->transport_ptr->edge, \
drivers/soc/qcom/glink_private.h:		ctx->name, \
drivers/soc/qcom/glink_private.h:		ctx->lcid, \
drivers/soc/qcom/glink_private.h:		ctx->rcid, args);  \
drivers/soc/qcom/glink_private.h:		ctx->name, \
drivers/soc/qcom/glink_private.h:		ctx->lcid, \
drivers/soc/qcom/glink_private.h:		ctx->rcid, args);  \
drivers/soc/qcom/glink_smem_native_xprt.c:	if (pctx->size < pctx->size_remaining) {
drivers/soc/qcom/glink_smem_native_xprt.c:		pctx->size_remaining = pctx->size;
drivers/soc/qcom/glink_smem_native_xprt.c:	if (!pctx->size_remaining)
drivers/soc/qcom/glink_smem_native_xprt.c:	    (pctx->size_remaining != pctx->size || cmd_id == TRACER_PKT_CMD)) {
drivers/soc/qcom/glink_smem_native_xprt.c:		if (pctx->size_remaining == pctx->size)
drivers/soc/qcom/glink_smem_native_xprt.c:		if (pctx->size_remaining == pctx->size)
drivers/soc/qcom/glink_smem_native_xprt.c:	cmd.riid = pctx->riid;
drivers/soc/qcom/glink_smem_native_xprt.c:	data_start = get_tx_vaddr(pctx, pctx->size - pctx->size_remaining,
drivers/soc/qcom/glink_smem_native_xprt.c:	if (einfo->intentless && size < sizeof(cmd) + pctx->size) {
drivers/soc/qcom/glink_smem_native_xprt.c:	pctx->size_remaining -= size;
drivers/soc/qcom/glink_smem_native_xprt.c:	cmd.size_left = pctx->size_remaining;
drivers/soc/qcom/glink_smem_native_xprt.c:		tracer_pkt_log_event((void *)(pctx->data), GLINK_XPRT_TX);
drivers/soc/qcom/glink_smem_native_xprt.c:		cmd.lcid = pctx->rcid;
drivers/ata/ahci_xgene.c:	dev_dbg(ctx->dev, "Release memory from shutdown\n");
drivers/ata/ahci_xgene.c:	writel(0x0, ctx->csr_diag + CFG_MEM_RAM_SHUTDOWN);
drivers/ata/ahci_xgene.c:	readl(ctx->csr_diag + CFG_MEM_RAM_SHUTDOWN); /* Force a barrier */
drivers/ata/ahci_xgene.c:	if (readl(ctx->csr_diag + BLOCK_MEM_RDY) != 0xFFFFFFFF) {
drivers/ata/ahci_xgene.c:		dev_err(ctx->dev, "failed to release memory from shutdown\n");
drivers/ata/ahci_xgene.c:	if (ctx->class[ap->port_no] == ATA_DEV_PMP) {
drivers/ata/ahci_xgene.c:	if (unlikely((ctx->last_cmd[ap->port_no] == ATA_CMD_ID_ATA) ||
drivers/ata/ahci_xgene.c:	    (ctx->last_cmd[ap->port_no] == ATA_CMD_PACKET) ||
drivers/ata/ahci_xgene.c:	    (ctx->last_cmd[ap->port_no] == ATA_CMD_SMART)))
drivers/ata/ahci_xgene.c:	ctx->last_cmd[ap->port_no] = qc->tf.command;
drivers/ata/ahci_xgene.c:	void __iomem *diagcsr = ctx->csr_diag;
drivers/ata/ahci_xgene.c:	void __iomem *mmio = ctx->hpriv->mmio;
drivers/ata/ahci_xgene.c:	dev_dbg(ctx->dev, "port configure mmio 0x%p channel %d\n",
drivers/ata/ahci_xgene.c:				dev_warn(ctx->dev, "link has error\n");
drivers/ata/ahci_xgene.c:	ctx->class[ap->port_no] = *class;
drivers/ata/ahci_xgene.c:	writel(0, ctx->csr_core + INTSTATUSMASK);
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_core + INTSTATUSMASK); /* Force a barrier */
drivers/ata/ahci_xgene.c:	dev_dbg(ctx->dev, "top level interrupt mask 0x%X value 0x%08X\n",
drivers/ata/ahci_xgene.c:	writel(0x0, ctx->csr_core + ERRINTSTATUSMASK);
drivers/ata/ahci_xgene.c:	readl(ctx->csr_core + ERRINTSTATUSMASK); /* Force a barrier */
drivers/ata/ahci_xgene.c:	writel(0x0, ctx->csr_axi + INT_SLV_TMOMASK);
drivers/ata/ahci_xgene.c:	readl(ctx->csr_axi + INT_SLV_TMOMASK);
drivers/ata/ahci_xgene.c:	writel(0xffffffff, ctx->csr_core + SLVRDERRATTRIBUTES);
drivers/ata/ahci_xgene.c:	writel(0xffffffff, ctx->csr_core + SLVWRERRATTRIBUTES);
drivers/ata/ahci_xgene.c:	writel(0xffffffff, ctx->csr_core + MSTRDERRATTRIBUTES);
drivers/ata/ahci_xgene.c:	writel(0xffffffff, ctx->csr_core + MSTWRERRATTRIBUTES);
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_core + BUSCTLREG);
drivers/ata/ahci_xgene.c:	writel(val, ctx->csr_core + BUSCTLREG);
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_core + IOFMSTRWAUX);
drivers/ata/ahci_xgene.c:	writel(val, ctx->csr_core + IOFMSTRWAUX);
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_core + IOFMSTRWAUX);
drivers/ata/ahci_xgene.c:	dev_dbg(ctx->dev, "coherency 0x%X value 0x%08X\n",
drivers/ata/ahci_xgene.c:	if (!ctx->csr_mux)
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_mux + SATA_ENET_CONFIG_REG);
drivers/ata/ahci_xgene.c:	writel(val, ctx->csr_mux + SATA_ENET_CONFIG_REG);
drivers/ata/ahci_xgene.c:	val = readl(ctx->csr_mux + SATA_ENET_CONFIG_REG);
drivers/ata/ahci_xgene.c:	ctx->hpriv = hpriv;
drivers/ata/ahci_xgene.c:	ctx->dev = dev;
drivers/ata/ahci_xgene.c:	ctx->csr_core = devm_ioremap_resource(dev, res);
drivers/ata/ahci_xgene.c:	if (IS_ERR(ctx->csr_core))
drivers/ata/ahci_xgene.c:		return PTR_ERR(ctx->csr_core);
drivers/ata/ahci_xgene.c:	ctx->csr_diag = devm_ioremap_resource(dev, res);
drivers/ata/ahci_xgene.c:	if (IS_ERR(ctx->csr_diag))
drivers/ata/ahci_xgene.c:		return PTR_ERR(ctx->csr_diag);
drivers/ata/ahci_xgene.c:	ctx->csr_axi = devm_ioremap_resource(dev, res);
drivers/ata/ahci_xgene.c:	if (IS_ERR(ctx->csr_axi))
drivers/ata/ahci_xgene.c:		return PTR_ERR(ctx->csr_axi);
drivers/ata/ahci_xgene.c:		ctx->csr_mux = csr;
drivers/ata/ahci_xgene.c:	dev_dbg(dev, "VAddr 0x%p Mmio VAddr 0x%p\n", ctx->csr_core,
drivers/nfc/st95hf/core.c:		dev_err(&spictx->spidev->dev, "sleep for semaphore interrupted by signal\n");
drivers/nfc/st95hf/core.c:		dev_err(&spictx->spidev->dev,
drivers/staging/media/omap4iss/iss_csi2.c:	ctx->ping_addr = addr;
drivers/staging/media/omap4iss/iss_csi2.c:	ctx->pong_addr = addr;
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_PING_ADDR(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		      ctx->ping_addr);
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_PONG_ADDR(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		      ctx->pong_addr);
drivers/staging/media/omap4iss/iss_csi2.c:	ctx->enabled = enable;
drivers/staging/media/omap4iss/iss_csi2.c:	ctx->frame = 0;
drivers/staging/media/omap4iss/iss_csi2.c:	if (ctx->eof_enabled)
drivers/staging/media/omap4iss/iss_csi2.c:	if (ctx->eol_enabled)
drivers/staging/media/omap4iss/iss_csi2.c:	if (ctx->checksum_enabled)
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_CTRL1(ctx->ctxnum), reg);
drivers/staging/media/omap4iss/iss_csi2.c:	reg = ctx->virtual_id << CSI2_CTX_CTRL2_VIRTUAL_ID_SHIFT;
drivers/staging/media/omap4iss/iss_csi2.c:	reg |= ctx->format_id << CSI2_CTX_CTRL2_FORMAT_SHIFT;
drivers/staging/media/omap4iss/iss_csi2.c:	if (ctx->dpcm_decompress && ctx->dpcm_predictor)
drivers/staging/media/omap4iss/iss_csi2.c:	if (is_usr_def_mapping(ctx->format_id))
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_CTRL2(ctx->ctxnum), reg);
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_CTRL3(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		      ctx->alpha << CSI2_CTX_CTRL3_ALPHA_SHIFT);
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_update(csi2->iss, csi2->regs1, CSI2_CTX_DAT_OFST(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		       CSI2_CTX_DAT_OFST_MASK, ctx->data_offset);
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_PING_ADDR(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		      ctx->ping_addr);
drivers/staging/media/omap4iss/iss_csi2.c:	iss_reg_write(csi2->iss, csi2->regs1, CSI2_CTX_PONG_ADDR(ctx->ctxnum),
drivers/staging/media/omap4iss/iss_csi2.c:		      ctx->pong_addr);
drivers/staging/media/omap4iss/iss_csi2.c:	unsigned int n = ctx->ctxnum;
drivers/staging/media/omap4iss/iss_csi2.c:				     CSI2_CTX_CTRL2(ctx->ctxnum))
drivers/staging/media/omap4iss/iss_csi2.c:			delta = frame - ctx->frame;
drivers/staging/media/omap4iss/iss_csi2.c:			if (frame < ctx->frame)
drivers/staging/media/omap4iss/iss_csi2.c:			ctx->frame = frame;
drivers/staging/media/omap4iss/iss_csi2.c:			ctx->format_id = csi2_ctx_map_format(csi2);
drivers/staging/unisys/visorbus/visorchipset.c:	phdr = (struct spar_controlvm_parameters_header *)(ctx->data);
drivers/staging/unisys/visorbus/visorchipset.c:	phdr = (struct spar_controlvm_parameters_header *)(ctx->data);
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->curr = ctx->data + phdr->initiator_offset;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->bytes_remaining = phdr->initiator_length;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->curr = ctx->data + phdr->target_offset;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->bytes_remaining = phdr->target_length;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->curr = ctx->data + phdr->connection_offset;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->bytes_remaining = phdr->connection_length;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->curr = ctx->data + phdr->name_offset;
drivers/staging/unisys/visorbus/visorchipset.c:		ctx->bytes_remaining = phdr->name_length;
drivers/staging/unisys/visorbus/visorchipset.c:	controlvm_payload_bytes_buffered -= ctx->param_bytes;
drivers/staging/unisys/visorbus/visorchipset.c:	pscan = ctx->curr;
drivers/staging/unisys/visorbus/visorchipset.c:	nscan = ctx->bytes_remaining;
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->allocbytes = allocbytes;
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->param_bytes = bytes;
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->curr = NULL;
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->bytes_remaining = 0;
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->byte_stream = false;
drivers/staging/unisys/visorbus/visorchipset.c:		memcpy(ctx->data, p, bytes);
drivers/staging/unisys/visorbus/visorchipset.c:		memcpy(ctx->data, mapping, bytes);
drivers/staging/unisys/visorbus/visorchipset.c:	ctx->byte_stream = true;
drivers/staging/unisys/visorbus/visorchipset.c:	controlvm_payload_bytes_buffered += ctx->param_bytes;
drivers/staging/lustre/lustre/llite/dir.c:			ctx->pos = lhash;
drivers/staging/lustre/lustre/llite/dir.c:			 * so the parameter 'name' for 'ctx->actor()'
drivers/staging/lustre/lustre/llite/dir.c:	ctx->pos = pos;
drivers/staging/lustre/lustre/llite/dir.c:	ctx->pos = pos;
drivers/staging/lustre/lustre/llite/dir.c:	pos = ctx->pos;
drivers/staging/lustre/lustre/llite/dir.c:	ctx->pos = pos;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	phdr->ph_sp = ctx->cc_sec->ps_part;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		atomic_inc(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		atomic_set(&ctx->cc_refcount, 1); /* for cache */
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		ctx->cc_sec = &plsec->pls_base;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		ctx->cc_ops = &plain_ctx_ops;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		ctx->cc_expire = 0;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		ctx->cc_flags = PTLRPC_CTX_CACHED | PTLRPC_CTX_UPTODATE;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		ctx->cc_vcred.vc_uid = 0;
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		spin_lock_init(&ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		INIT_LIST_HEAD(&ctx->cc_req_list);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		INIT_LIST_HEAD(&ctx->cc_gc_chain);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		atomic_inc(&ctx->cc_refcount); /* for caller */
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:		atomic_inc(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	LASSERT(atomic_read(&ctx->cc_refcount) == 0);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	LASSERT(ctx->cc_sec == sec);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	atomic_inc(&req->rq_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	atomic_inc(&req->rq_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	LASSERT(atomic_read(&rs->rs_svc_ctx->sc_refcount) > 1);
drivers/staging/lustre/lustre/ptlrpc/sec_plain.c:	atomic_dec(&rs->rs_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_gc.c:		list_del_init(&ctx->cc_gc_chain);
drivers/staging/lustre/lustre/ptlrpc/sec_gc.c:		LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec_gc.c:		LASSERT(atomic_read(&ctx->cc_refcount) == 1);
drivers/staging/lustre/lustre/ptlrpc/sec_gc.c:		       ctx, ctx->cc_vcred.vc_uid, sec2target_str(ctx->cc_sec));
drivers/staging/lustre/lustre/ptlrpc/sec.c:	atomic_inc(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	struct ptlrpc_sec *sec = ctx->cc_sec;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT_ATOMIC_POS(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (!atomic_dec_and_test(&ctx->cc_refcount))
drivers/staging/lustre/lustre/ptlrpc/sec.c:		spin_lock(&req->rq_cli_ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		spin_unlock(&req->rq_cli_ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	       oldctx, oldctx->cc_vcred.vc_uid, sec2target_str(oldctx->cc_sec),
drivers/staging/lustre/lustre/ptlrpc/sec.c:	       newctx, newctx->cc_vcred.vc_uid, sec2target_str(newctx->cc_sec),
drivers/staging/lustre/lustre/ptlrpc/sec.c:	       oldctx->cc_sec, oldctx->cc_sec->ps_policy->sp_name,
drivers/staging/lustre/lustre/ptlrpc/sec.c:	       newctx->cc_sec, newctx->cc_sec->ps_policy->sp_name);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		     test_bit(PTLRPC_CTX_DEAD_BIT, &oldctx->cc_flags))) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:		       newctx, newctx->cc_flags);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		req->rq_cli_ctx->cc_ops->force_die(req->rq_cli_ctx, 0);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	spin_lock(&ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	spin_unlock(&ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (unlikely(test_bit(PTLRPC_CTX_NEW_BIT, &ctx->cc_flags))) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:		LASSERT(ctx->cc_ops->refresh);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		ctx->cc_ops->refresh(ctx);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(test_bit(PTLRPC_CTX_NEW_BIT, &ctx->cc_flags) == 0);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_ops->validate);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (ctx->cc_ops->validate(ctx) == 0) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (unlikely(test_bit(PTLRPC_CTX_ERROR_BIT, &ctx->cc_flags))) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (test_bit(PTLRPC_CTX_UPTODATE_BIT, &ctx->cc_flags) &&
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (unlikely(test_bit(PTLRPC_CTX_DEAD_BIT, &ctx->cc_flags))) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:	spin_lock(&ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		list_add(&req->rq_ctx_chain, &ctx->cc_req_list);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	spin_unlock(&ctx->cc_lock);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(req->rq_cli_ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	sec = req->rq_cli_ctx->cc_sec;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	    ctx->cc_ops->validate(ctx) == 0) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		LASSERT(ctx->cc_ops->sign);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->sign(ctx, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		LASSERT(ctx->cc_ops->seal);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->seal(ctx, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		LASSERT(ctx->cc_ops->verify);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->verify(ctx, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		LASSERT(ctx->cc_ops->unseal);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->unseal(ctx, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:		policy = sptlrpc_policy_get(svc_ctx->sc_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec->ps_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT_ATOMIC_POS(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = ctx->cc_sec->ps_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	rc = policy->sp_cops->alloc_reqbuf(ctx->cc_sec, req, msgsize);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec->ps_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT_ATOMIC_POS(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = ctx->cc_sec->ps_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy->sp_cops->free_reqbuf(ctx->cc_sec, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	cops = ctx->cc_sec->ps_policy->sp_cops;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	return cops->enlarge_reqbuf(ctx->cc_sec, req, segment, newsize);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec->ps_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = ctx->cc_sec->ps_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	return policy->sp_cops->alloc_repbuf(ctx->cc_sec, req, msgsize);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(ctx->cc_sec->ps_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT_ATOMIC_POS(&ctx->cc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = ctx->cc_sec->ps_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy->sp_cops->free_repbuf(ctx->cc_sec, req);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	struct ptlrpc_sec_policy *policy = ctx->sc_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(req->rq_svc_ctx->sc_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = req->rq_svc_ctx->sc_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(req->rq_svc_ctx->sc_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = req->rq_svc_ctx->sc_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT(rs->rs_svc_ctx->sc_policy);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	policy = rs->rs_svc_ctx->sc_policy;
drivers/staging/lustre/lustre/ptlrpc/sec.c:		atomic_inc(&ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	LASSERT_ATOMIC_POS(&ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (atomic_dec_and_test(&ctx->sc_refcount)) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:		if (ctx->sc_policy->sp_sops->free_ctx)
drivers/staging/lustre/lustre/ptlrpc/sec.c:			ctx->sc_policy->sp_sops->free_ctx(ctx);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (ctx->cc_ops->wrap_bulk)
drivers/staging/lustre/lustre/ptlrpc/sec.c:		return ctx->cc_ops->wrap_bulk(ctx, req, desc);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (ctx->cc_ops->unwrap_bulk) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->unwrap_bulk(ctx, req, desc);
drivers/staging/lustre/lustre/ptlrpc/sec.c:	if (ctx->cc_ops->unwrap_bulk) {
drivers/staging/lustre/lustre/ptlrpc/sec.c:		rc = ctx->cc_ops->unwrap_bulk(ctx, req, desc);
drivers/staging/lustre/lustre/ptlrpc/sec_null.c:	atomic_inc(&req->rq_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_null.c:	atomic_inc(&req->rq_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/ptlrpc/sec_null.c:	LASSERT_ATOMIC_GT(&rs->rs_svc_ctx->sc_refcount, 1);
drivers/staging/lustre/lustre/ptlrpc/sec_null.c:	atomic_dec(&rs->rs_svc_ctx->sc_refcount);
drivers/staging/lustre/lustre/include/lustre_sec.h:	return (ctx->cc_flags & PTLRPC_CTX_STATUS_MASK);
drivers/staging/lustre/lustre/include/lustre_sec.h:	return ((ctx->cc_flags & PTLRPC_CTX_UPTODATE) != 0);
drivers/staging/lustre/lustre/include/lustre_sec.h:	return ((ctx->cc_flags & PTLRPC_CTX_ERROR) != 0);
drivers/staging/lustre/lustre/include/lustre_sec.h:	return ((ctx->cc_flags & (PTLRPC_CTX_DEAD | PTLRPC_CTX_ERROR)) != 0);
drivers/staging/lustre/lustre/include/lustre_sec.h:	return ((ctx->cc_flags & PTLRPC_CTX_ETERNAL) != 0);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	if (ctx->lc_value && ctx->lc_value[index]) {
drivers/staging/lustre/lustre/obdclass/lu_object.c:		key->lct_fini(ctx, key, ctx->lc_value[index]);
drivers/staging/lustre/lustre/obdclass/lu_object.c:		if ((ctx->lc_tags & LCT_NOREF) == 0) {
drivers/staging/lustre/lustre/obdclass/lu_object.c:		ctx->lc_value[index] = NULL;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	LINVRNT(ctx->lc_state == LCS_ENTERED);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	return ctx->lc_value[key->lct_index];
drivers/staging/lustre/lustre/obdclass/lu_object.c:	if (!ctx->lc_value)
drivers/staging/lustre/lustre/obdclass/lu_object.c:	kfree(ctx->lc_value);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_value = NULL;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	LINVRNT(ctx->lc_value);
drivers/staging/lustre/lustre/obdclass/lu_object.c:		if (!ctx->lc_value[i] && key &&
drivers/staging/lustre/lustre/obdclass/lu_object.c:		    (key->lct_tags & ctx->lc_tags) &&
drivers/staging/lustre/lustre/obdclass/lu_object.c:			if (!(ctx->lc_tags & LCT_NOREF))
drivers/staging/lustre/lustre/obdclass/lu_object.c:			 * element of ctx->lc_value[] array is set to non-NULL
drivers/staging/lustre/lustre/obdclass/lu_object.c:			ctx->lc_value[i] = value;
drivers/staging/lustre/lustre/obdclass/lu_object.c:				ctx->lc_tags |= LCT_HAS_EXIT;
drivers/staging/lustre/lustre/obdclass/lu_object.c:		ctx->lc_version = key_set_version;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_value = kcalloc(ARRAY_SIZE(lu_keys), sizeof(ctx->lc_value[0]),
drivers/staging/lustre/lustre/obdclass/lu_object.c:	if (likely(ctx->lc_value))
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_state = LCS_INITIALIZED;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_tags = tags;
drivers/staging/lustre/lustre/obdclass/lu_object.c:		list_add(&ctx->lc_remember, &lu_context_remembered);
drivers/staging/lustre/lustre/obdclass/lu_object.c:		INIT_LIST_HEAD(&ctx->lc_remember);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	LINVRNT(ctx->lc_state == LCS_INITIALIZED || ctx->lc_state == LCS_LEFT);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_state = LCS_FINALIZED;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	if ((ctx->lc_tags & LCT_REMEMBER) == 0) {
drivers/staging/lustre/lustre/obdclass/lu_object.c:		LASSERT(list_empty(&ctx->lc_remember));
drivers/staging/lustre/lustre/obdclass/lu_object.c:		list_del_init(&ctx->lc_remember);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	LINVRNT(ctx->lc_state == LCS_INITIALIZED || ctx->lc_state == LCS_LEFT);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_state = LCS_ENTERED;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	LINVRNT(ctx->lc_state == LCS_ENTERED);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	ctx->lc_state = LCS_LEFT;
drivers/staging/lustre/lustre/obdclass/lu_object.c:	if (ctx->lc_tags & LCT_HAS_EXIT && ctx->lc_value) {
drivers/staging/lustre/lustre/obdclass/lu_object.c:			if (ctx->lc_value[i]) {
drivers/staging/lustre/lustre/obdclass/lu_object.c:						      key, ctx->lc_value[i]);
drivers/staging/lustre/lustre/obdclass/lu_object.c:	return likely(ctx->lc_version == key_set_version) ? 0 : keys_fill(ctx);
drivers/staging/rtl8712/rtl871x_security.c:	state = parc4ctx->state;
drivers/staging/rtl8712/rtl871x_security.c:	parc4ctx->x = 0;
drivers/staging/rtl8712/rtl871x_security.c:	parc4ctx->y = 0;
drivers/staging/rtl8712/rtl871x_security.c:	state = parc4ctx->state;
drivers/staging/rtl8712/rtl871x_security.c:	x = (parc4ctx->x + 1) & 0xff;
drivers/staging/rtl8712/rtl871x_security.c:	y = (sx + parc4ctx->y) & 0xff;
drivers/staging/rtl8712/rtl871x_security.c:	parc4ctx->x = x;
drivers/staging/rtl8712/rtl871x_security.c:	parc4ctx->y = y;
drivers/staging/skein/threefish_api.c:	key_ctx->tweak[0] = tweak[0];
drivers/staging/skein/threefish_api.c:	key_ctx->tweak[1] = tweak[1];
drivers/staging/skein/threefish_api.c:	key_ctx->tweak[2] = tweak[0] ^ tweak[1];
drivers/staging/skein/threefish_api.c:		key_ctx->key[i] = key_data[i];
drivers/staging/skein/threefish_api.c:	key_ctx->key[i] = parity;
drivers/staging/skein/threefish_api.c:	key_ctx->state_size = state_size;
drivers/staging/skein/threefish_api.c:	skein_get64_lsb_first(plain, in, key_ctx->state_size / 64);
drivers/staging/skein/threefish_api.c:	skein_put64_lsb_first(out, cipher, key_ctx->state_size / 8);
drivers/staging/skein/threefish_api.c:	switch (key_ctx->state_size) {
drivers/staging/skein/threefish_api.c:	skein_get64_lsb_first(cipher, in, key_ctx->state_size / 64);
drivers/staging/skein/threefish_api.c:	skein_put64_lsb_first(out, plain, key_ctx->state_size / 8);
drivers/staging/skein/threefish_api.c:	switch (key_ctx->state_size) {
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4], k5 = key_ctx->key[5],
drivers/staging/skein/threefish_block.c:	    k6 = key_ctx->key[6], k7 = key_ctx->key[7],
drivers/staging/skein/threefish_block.c:	    k8 = key_ctx->key[8];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4], k5 = key_ctx->key[5],
drivers/staging/skein/threefish_block.c:	    k6 = key_ctx->key[6], k7 = key_ctx->key[7],
drivers/staging/skein/threefish_block.c:	    k8 = key_ctx->key[8];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4], k5 = key_ctx->key[5],
drivers/staging/skein/threefish_block.c:	    k6 = key_ctx->key[6], k7 = key_ctx->key[7],
drivers/staging/skein/threefish_block.c:	    k8 = key_ctx->key[8], k9 = key_ctx->key[9],
drivers/staging/skein/threefish_block.c:	    k10 = key_ctx->key[10], k11 = key_ctx->key[11],
drivers/staging/skein/threefish_block.c:	    k12 = key_ctx->key[12], k13 = key_ctx->key[13],
drivers/staging/skein/threefish_block.c:	    k14 = key_ctx->key[14], k15 = key_ctx->key[15],
drivers/staging/skein/threefish_block.c:	    k16 = key_ctx->key[16];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/threefish_block.c:	u64 k0 = key_ctx->key[0], k1 = key_ctx->key[1],
drivers/staging/skein/threefish_block.c:	    k2 = key_ctx->key[2], k3 = key_ctx->key[3],
drivers/staging/skein/threefish_block.c:	    k4 = key_ctx->key[4], k5 = key_ctx->key[5],
drivers/staging/skein/threefish_block.c:	    k6 = key_ctx->key[6], k7 = key_ctx->key[7],
drivers/staging/skein/threefish_block.c:	    k8 = key_ctx->key[8], k9 = key_ctx->key[9],
drivers/staging/skein/threefish_block.c:	    k10 = key_ctx->key[10], k11 = key_ctx->key[11],
drivers/staging/skein/threefish_block.c:	    k12 = key_ctx->key[12], k13 = key_ctx->key[13],
drivers/staging/skein/threefish_block.c:	    k14 = key_ctx->key[14], k15 = key_ctx->key[15],
drivers/staging/skein/threefish_block.c:	    k16 = key_ctx->key[16];
drivers/staging/skein/threefish_block.c:	u64 t0 = key_ctx->tweak[0], t1 = key_ctx->tweak[1],
drivers/staging/skein/threefish_block.c:	    t2 = key_ctx->tweak[2];
drivers/staging/skein/skein_api.c:	ctx->skein_size = size;
drivers/staging/skein/skein_api.c:	x = ctx->m.s256.x;
drivers/staging/skein/skein_api.c:	x_len = ctx->skein_size / 8;
drivers/staging/skein/skein_api.c:	switch (ctx->skein_size) {
drivers/staging/skein/skein_api.c:		ret = skein_256_init_ext(&ctx->m.s256, hash_bit_len,
drivers/staging/skein/skein_api.c:		ret = skein_512_init_ext(&ctx->m.s512, hash_bit_len,
drivers/staging/skein/skein_api.c:		ret = skein_1024_init_ext(&ctx->m.s1024, hash_bit_len,
drivers/staging/skein/skein_api.c:		memcpy(ctx->x_save, x, x_len);
drivers/staging/skein/skein_api.c:	x = ctx->m.s256.x;
drivers/staging/skein/skein_api.c:	x_len = ctx->skein_size / 8;
drivers/staging/skein/skein_api.c:	switch (ctx->skein_size) {
drivers/staging/skein/skein_api.c:		ret = skein_256_init_ext(&ctx->m.s256, hash_bit_len,
drivers/staging/skein/skein_api.c:		ret = skein_512_init_ext(&ctx->m.s512, hash_bit_len,
drivers/staging/skein/skein_api.c:		ret = skein_1024_init_ext(&ctx->m.s1024, hash_bit_len,
drivers/staging/skein/skein_api.c:		memcpy(ctx->x_save, x, x_len);
drivers/staging/skein/skein_api.c:	x = ctx->m.s256.x;
drivers/staging/skein/skein_api.c:	x_len = ctx->skein_size / 8;
drivers/staging/skein/skein_api.c:	memcpy(x, ctx->x_save, x_len);
drivers/staging/skein/skein_api.c:	skein_start_new_type(&ctx->m, MSG);
drivers/staging/skein/skein_api.c:	switch (ctx->skein_size) {
drivers/staging/skein/skein_api.c:		ret = skein_256_update(&ctx->m.s256, (const u8 *)msg,
drivers/staging/skein/skein_api.c:		ret = skein_512_update(&ctx->m.s512, (const u8 *)msg,
drivers/staging/skein/skein_api.c:		ret = skein_1024_update(&ctx->m.s1024, (const u8 *)msg,
drivers/staging/skein/skein_api.c:	skein_assert_ret((ctx->m.h.T[1] & SKEIN_T1_FLAG_BIT_PAD) == 0 ||
drivers/staging/skein/skein_api.c:	up = (u8 *)ctx->m.s256.x + ctx->skein_size / 8;
drivers/staging/skein/skein_api.c:	skein_set_bit_pad_flag(ctx->m.h);
drivers/staging/skein/skein_api.c:	length = ctx->m.h.b_cnt;
drivers/staging/skein/skein_api.c:	switch (ctx->skein_size) {
drivers/staging/skein/skein_api.c:		ret = skein_256_final(&ctx->m.s256, (u8 *)hash);
drivers/staging/skein/skein_api.c:		ret = skein_512_final(&ctx->m.s512, (u8 *)hash);
drivers/staging/skein/skein_api.c:		ret = skein_1024_final(&ctx->m.s1024, (u8 *)hash);
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;         /* output hash bit count */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_256_IV_256, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_256_IV_224, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_256_IV_160, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_256_IV_128, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:	/* The chaining vars ctx->x are now initialized for hash_bit_len. */
drivers/staging/skein/skein_base.c:	/* compute the initial chaining values ctx->x[], based on key */
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		skein_assert(sizeof(cfg.b) >= sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		ctx->h.hash_bit_len = 8 * sizeof(ctx->x);
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		/* copy over into ctx->x[] */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, cfg.b, sizeof(cfg.b));
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;
drivers/staging/skein/skein_base.c:	/* The chaining vars ctx->x are now initialized */
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_256_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	if (msg_byte_cnt + ctx->h.b_cnt > SKEIN_256_BLOCK_BYTES) {
drivers/staging/skein/skein_base.c:		if (ctx->h.b_cnt) {
drivers/staging/skein/skein_base.c:			n = SKEIN_256_BLOCK_BYTES - ctx->h.b_cnt;
drivers/staging/skein/skein_base.c:				memcpy(&ctx->b[ctx->h.b_cnt], msg, n);
drivers/staging/skein/skein_base.c:				ctx->h.b_cnt += n;
drivers/staging/skein/skein_base.c:			skein_assert(ctx->h.b_cnt == SKEIN_256_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:			skein_256_process_block(ctx, ctx->b, 1,
drivers/staging/skein/skein_base.c:			ctx->h.b_cnt = 0;
drivers/staging/skein/skein_base.c:		skein_assert(ctx->h.b_cnt == 0);
drivers/staging/skein/skein_base.c:		skein_assert(msg_byte_cnt + ctx->h.b_cnt <=
drivers/staging/skein/skein_base.c:		memcpy(&ctx->b[ctx->h.b_cnt], msg, msg_byte_cnt);
drivers/staging/skein/skein_base.c:		ctx->h.b_cnt += msg_byte_cnt;
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_256_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_256_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_256_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_256_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_256_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;         /* output hash bit count */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_512_IV_512, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_512_IV_384, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_512_IV_256, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_512_IV_224, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:	 * The chaining vars ctx->x are now initialized for the given
drivers/staging/skein/skein_base.c:	/* compute the initial chaining values ctx->x[], based on key */
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		skein_assert(sizeof(cfg.b) >= sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		ctx->h.hash_bit_len = 8 * sizeof(ctx->x);
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		/* copy over into ctx->x[] */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, cfg.b, sizeof(cfg.b));
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;          /* output hash bit count */
drivers/staging/skein/skein_base.c:	/* The chaining vars ctx->x are now initialized */
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_512_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	if (msg_byte_cnt + ctx->h.b_cnt > SKEIN_512_BLOCK_BYTES) {
drivers/staging/skein/skein_base.c:		if (ctx->h.b_cnt) {
drivers/staging/skein/skein_base.c:			n = SKEIN_512_BLOCK_BYTES - ctx->h.b_cnt;
drivers/staging/skein/skein_base.c:				memcpy(&ctx->b[ctx->h.b_cnt], msg, n);
drivers/staging/skein/skein_base.c:				ctx->h.b_cnt += n;
drivers/staging/skein/skein_base.c:			skein_assert(ctx->h.b_cnt == SKEIN_512_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:			skein_512_process_block(ctx, ctx->b, 1,
drivers/staging/skein/skein_base.c:			ctx->h.b_cnt = 0;
drivers/staging/skein/skein_base.c:		skein_assert(ctx->h.b_cnt == 0);
drivers/staging/skein/skein_base.c:		skein_assert(msg_byte_cnt + ctx->h.b_cnt <=
drivers/staging/skein/skein_base.c:		memcpy(&ctx->b[ctx->h.b_cnt], msg, msg_byte_cnt);
drivers/staging/skein/skein_base.c:		ctx->h.b_cnt += msg_byte_cnt;
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_512_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_512_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_512_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_512_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_512_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;         /* output hash bit count */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_1024_IV_512, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_1024_IV_384, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, SKEIN_1024_IV_1024, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:	/* The chaining vars ctx->x are now initialized for the hash_bit_len. */
drivers/staging/skein/skein_base.c:	/* compute the initial chaining values ctx->x[], based on key */
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		skein_assert(sizeof(cfg.b) >= sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		ctx->h.hash_bit_len = 8 * sizeof(ctx->x);
drivers/staging/skein/skein_base.c:		memset(ctx->x, 0, sizeof(ctx->x));
drivers/staging/skein/skein_base.c:		/* copy over into ctx->x[] */
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, cfg.b, sizeof(cfg.b));
drivers/staging/skein/skein_base.c:	ctx->h.hash_bit_len = hash_bit_len;
drivers/staging/skein/skein_base.c:	/* The chaining vars ctx->x are now initialized */
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_1024_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	if (msg_byte_cnt + ctx->h.b_cnt > SKEIN_1024_BLOCK_BYTES) {
drivers/staging/skein/skein_base.c:		if (ctx->h.b_cnt) {
drivers/staging/skein/skein_base.c:			n = SKEIN_1024_BLOCK_BYTES - ctx->h.b_cnt;
drivers/staging/skein/skein_base.c:				memcpy(&ctx->b[ctx->h.b_cnt], msg, n);
drivers/staging/skein/skein_base.c:				ctx->h.b_cnt += n;
drivers/staging/skein/skein_base.c:			skein_assert(ctx->h.b_cnt == SKEIN_1024_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:			skein_1024_process_block(ctx, ctx->b, 1,
drivers/staging/skein/skein_base.c:			ctx->h.b_cnt = 0;
drivers/staging/skein/skein_base.c:		skein_assert(ctx->h.b_cnt == 0);
drivers/staging/skein/skein_base.c:		skein_assert(msg_byte_cnt + ctx->h.b_cnt <=
drivers/staging/skein/skein_base.c:		memcpy(&ctx->b[ctx->h.b_cnt], msg, msg_byte_cnt);
drivers/staging/skein/skein_base.c:		ctx->h.b_cnt += msg_byte_cnt;
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_1024_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_1024_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_1024_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_1024_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_1024_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_256_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_256_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_256_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_256_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_put64_lsb_first(hash_val, ctx->x, SKEIN_256_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_512_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_512_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_512_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_512_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_put64_lsb_first(hash_val, ctx->x, SKEIN_512_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_1024_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	ctx->h.tweak[1] |= SKEIN_T1_FLAG_FINAL;
drivers/staging/skein/skein_base.c:	if (ctx->h.b_cnt < SKEIN_1024_BLOCK_BYTES)
drivers/staging/skein/skein_base.c:		memset(&ctx->b[ctx->h.b_cnt], 0,
drivers/staging/skein/skein_base.c:		       SKEIN_1024_BLOCK_BYTES - ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_1024_process_block(ctx, ctx->b, 1, ctx->h.b_cnt);
drivers/staging/skein/skein_base.c:	skein_put64_lsb_first(hash_val, ctx->x, SKEIN_1024_BLOCK_BYTES);
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_256_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_256_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_512_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_512_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_base.c:	skein_assert_ret(ctx->h.b_cnt <= SKEIN_1024_BLOCK_BYTES, SKEIN_FAIL);
drivers/staging/skein/skein_base.c:	byte_cnt = (ctx->h.hash_bit_len + 7) >> 3;
drivers/staging/skein/skein_base.c:	memset(ctx->b, 0, sizeof(ctx->b));
drivers/staging/skein/skein_base.c:	memcpy(x, ctx->x, sizeof(x));
drivers/staging/skein/skein_base.c:		((u64 *)ctx->b)[0] = skein_swap64((u64)i);
drivers/staging/skein/skein_base.c:		skein_1024_process_block(ctx, ctx->b, 1, sizeof(u64));
drivers/staging/skein/skein_base.c:				      ctx->x, n);
drivers/staging/skein/skein_base.c:		memcpy(ctx->x, x, sizeof(x));
drivers/staging/skein/skein_block.c:	ctx->h.tweak[0] = ts[0];    \
drivers/staging/skein/skein_block.c:	ctx->h.tweak[1] = ts[1];    \
drivers/staging/skein/skein_block.c:	ts[0] = ctx->h.tweak[0];
drivers/staging/skein/skein_block.c:	ts[1] = ctx->h.tweak[1];
drivers/staging/skein/skein_block.c:		ks[0] = ctx->x[0];
drivers/staging/skein/skein_block.c:		ks[1] = ctx->x[1];
drivers/staging/skein/skein_block.c:		ks[2] = ctx->x[2];
drivers/staging/skein/skein_block.c:		ks[3] = ctx->x[3];
drivers/staging/skein/skein_block.c:		ctx->x[0] = X0 ^ w[0];
drivers/staging/skein/skein_block.c:		ctx->x[1] = X1 ^ w[1];
drivers/staging/skein/skein_block.c:		ctx->x[2] = X2 ^ w[2];
drivers/staging/skein/skein_block.c:		ctx->x[3] = X3 ^ w[3];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[0] = ts[0];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[1] = ts[1];
drivers/staging/skein/skein_block.c:	ts[0] = ctx->h.tweak[0];
drivers/staging/skein/skein_block.c:	ts[1] = ctx->h.tweak[1];
drivers/staging/skein/skein_block.c:		ks[0] = ctx->x[0];
drivers/staging/skein/skein_block.c:		ks[1] = ctx->x[1];
drivers/staging/skein/skein_block.c:		ks[2] = ctx->x[2];
drivers/staging/skein/skein_block.c:		ks[3] = ctx->x[3];
drivers/staging/skein/skein_block.c:		ks[4] = ctx->x[4];
drivers/staging/skein/skein_block.c:		ks[5] = ctx->x[5];
drivers/staging/skein/skein_block.c:		ks[6] = ctx->x[6];
drivers/staging/skein/skein_block.c:		ks[7] = ctx->x[7];
drivers/staging/skein/skein_block.c:		ctx->x[0] = X0 ^ w[0];
drivers/staging/skein/skein_block.c:		ctx->x[1] = X1 ^ w[1];
drivers/staging/skein/skein_block.c:		ctx->x[2] = X2 ^ w[2];
drivers/staging/skein/skein_block.c:		ctx->x[3] = X3 ^ w[3];
drivers/staging/skein/skein_block.c:		ctx->x[4] = X4 ^ w[4];
drivers/staging/skein/skein_block.c:		ctx->x[5] = X5 ^ w[5];
drivers/staging/skein/skein_block.c:		ctx->x[6] = X6 ^ w[6];
drivers/staging/skein/skein_block.c:		ctx->x[7] = X7 ^ w[7];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[0] = ts[0];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[1] = ts[1];
drivers/staging/skein/skein_block.c:	ts[0] = ctx->h.tweak[0];
drivers/staging/skein/skein_block.c:	ts[1] = ctx->h.tweak[1];
drivers/staging/skein/skein_block.c:		ks[0]  = ctx->x[0];
drivers/staging/skein/skein_block.c:		ks[1]  = ctx->x[1];
drivers/staging/skein/skein_block.c:		ks[2]  = ctx->x[2];
drivers/staging/skein/skein_block.c:		ks[3]  = ctx->x[3];
drivers/staging/skein/skein_block.c:		ks[4]  = ctx->x[4];
drivers/staging/skein/skein_block.c:		ks[5]  = ctx->x[5];
drivers/staging/skein/skein_block.c:		ks[6]  = ctx->x[6];
drivers/staging/skein/skein_block.c:		ks[7]  = ctx->x[7];
drivers/staging/skein/skein_block.c:		ks[8]  = ctx->x[8];
drivers/staging/skein/skein_block.c:		ks[9]  = ctx->x[9];
drivers/staging/skein/skein_block.c:		ks[10] = ctx->x[10];
drivers/staging/skein/skein_block.c:		ks[11] = ctx->x[11];
drivers/staging/skein/skein_block.c:		ks[12] = ctx->x[12];
drivers/staging/skein/skein_block.c:		ks[13] = ctx->x[13];
drivers/staging/skein/skein_block.c:		ks[14] = ctx->x[14];
drivers/staging/skein/skein_block.c:		ks[15] = ctx->x[15];
drivers/staging/skein/skein_block.c:		ctx->x[0] = X00 ^ w[0];
drivers/staging/skein/skein_block.c:		ctx->x[1] = X01 ^ w[1];
drivers/staging/skein/skein_block.c:		ctx->x[2] = X02 ^ w[2];
drivers/staging/skein/skein_block.c:		ctx->x[3] = X03 ^ w[3];
drivers/staging/skein/skein_block.c:		ctx->x[4] = X04 ^ w[4];
drivers/staging/skein/skein_block.c:		ctx->x[5] = X05 ^ w[5];
drivers/staging/skein/skein_block.c:		ctx->x[6] = X06 ^ w[6];
drivers/staging/skein/skein_block.c:		ctx->x[7] = X07 ^ w[7];
drivers/staging/skein/skein_block.c:		ctx->x[8] = X08 ^ w[8];
drivers/staging/skein/skein_block.c:		ctx->x[9] = X09 ^ w[9];
drivers/staging/skein/skein_block.c:		ctx->x[10] = X10 ^ w[10];
drivers/staging/skein/skein_block.c:		ctx->x[11] = X11 ^ w[11];
drivers/staging/skein/skein_block.c:		ctx->x[12] = X12 ^ w[12];
drivers/staging/skein/skein_block.c:		ctx->x[13] = X13 ^ w[13];
drivers/staging/skein/skein_block.c:		ctx->x[14] = X14 ^ w[14];
drivers/staging/skein/skein_block.c:		ctx->x[15] = X15 ^ w[15];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[0] = ts[0];
drivers/staging/skein/skein_block.c:	ctx->h.tweak[1] = ts[1];
drivers/staging/rtl8188eu/core/rtw_xmit.c:	sctx->timeout_ms = timeout_ms;
drivers/staging/rtl8188eu/core/rtw_xmit.c:	sctx->submit_time = jiffies;
drivers/staging/rtl8188eu/core/rtw_xmit.c:	init_completion(&sctx->done);
drivers/staging/rtl8188eu/core/rtw_xmit.c:	sctx->status = RTW_SCTX_SUBMITTED;
drivers/staging/rtl8188eu/core/rtw_xmit.c:	expire = sctx->timeout_ms ? msecs_to_jiffies(sctx->timeout_ms) : MAX_SCHEDULE_TIMEOUT;
drivers/staging/rtl8188eu/core/rtw_xmit.c:	if (!wait_for_completion_timeout(&sctx->done, expire)) {
drivers/staging/rtl8188eu/core/rtw_xmit.c:		status = sctx->status;
drivers/staging/rtl8188eu/core/rtw_security.c:	state = parc4ctx->state;
drivers/staging/rtl8188eu/core/rtw_security.c:	parc4ctx->x = 0;
drivers/staging/rtl8188eu/core/rtw_security.c:	parc4ctx->y = 0;
drivers/staging/rtl8188eu/core/rtw_security.c:	state = parc4ctx->state;
drivers/staging/rtl8188eu/core/rtw_security.c:	x = (parc4ctx->x + 1) & 0xff;
drivers/staging/rtl8188eu/core/rtw_security.c:	y = (sx + parc4ctx->y) & 0xff;
drivers/staging/rtl8188eu/core/rtw_security.c:	parc4ctx->x = x;
drivers/staging/rtl8188eu/core/rtw_security.c:	parc4ctx->y = y;
drivers/mtd/ubi/block.c:	struct ubiblock *dev = hctx->queue->queuedata;
drivers/mtd/nand/au1550nd.c:		this->IO_ADDR_W = ctx->base + MEM_STNAND_CMD;
drivers/mtd/nand/au1550nd.c:		this->IO_ADDR_W = ctx->base + MEM_STNAND_DATA;
drivers/mtd/nand/au1550nd.c:		this->IO_ADDR_W = ctx->base + MEM_STNAND_ADDR;
drivers/mtd/nand/au1550nd.c:		this->IO_ADDR_W = ctx->base + MEM_STNAND_DATA;
drivers/mtd/nand/au1550nd.c:		alchemy_wrsmem((1 << (4 + ctx->cs)), AU1000_MEM_STNDCTL);
drivers/mtd/nand/au1550nd.c:		ctx->write_byte(mtd, readcmd);
drivers/mtd/nand/au1550nd.c:	ctx->write_byte(mtd, command);
drivers/mtd/nand/au1550nd.c:			ctx->write_byte(mtd, column);
drivers/mtd/nand/au1550nd.c:			ctx->write_byte(mtd, (u8)(page_addr & 0xff));
drivers/mtd/nand/au1550nd.c:			ctx->write_byte(mtd, (u8)(page_addr >> 8));
drivers/mtd/nand/au1550nd.c:				ctx->write_byte(mtd,
drivers/mtd/nand/au1550nd.c:	ctx->base = ioremap_nocache(r->start, 0x1000);
drivers/mtd/nand/au1550nd.c:	if (!ctx->base) {
drivers/mtd/nand/au1550nd.c:	this = &ctx->chip;
drivers/mtd/nand/au1550nd.c:	ctx->cs = cs;
drivers/mtd/nand/au1550nd.c:	ctx->write_byte = (pd->devwidth) ? au_write_byte16 : au_write_byte;
drivers/mtd/nand/au1550nd.c:	iounmap(ctx->base);
drivers/mtd/nand/au1550nd.c:	nand_release(nand_to_mtd(&ctx->chip));
drivers/mtd/nand/au1550nd.c:	iounmap(ctx->base);
drivers/ssb/main.c:	ctx->bus = bus;
drivers/ssb/main.c:	SSB_WARN_ON(bus->nr_devices > ARRAY_SIZE(ctx->device_frozen));
drivers/ssb/main.c:		ctx->device_frozen[i] = 1;
drivers/ssb/main.c:	struct ssb_bus *bus = ctx->bus;
drivers/ssb/main.c:		if (!ctx->device_frozen[i])
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->buf = kmalloc(dma_size, GFP_KERNEL);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (!ioctx->buf)
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->dma = ib_dma_map_single(sdev->device, ioctx->buf, dma_size, dir);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (ib_dma_mapping_error(sdev->device, ioctx->dma))
drivers/infiniband/ulp/srpt/ib_srpt.c:	kfree(ioctx->buf);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ib_dma_unmap_single(sdev->device, ioctx->dma, dma_size, dir);
drivers/infiniband/ulp/srpt/ib_srpt.c:	kfree(ioctx->buf);
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_irqsave(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	state = ioctx->state;
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_unlock_irqrestore(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_irqsave(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	previous = ioctx->state;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = new;
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_unlock_irqrestore(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_irqsave(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	previous = ioctx->state;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = new;
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_unlock_irqrestore(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	list.addr = ioctx->ioctx.dma;
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->ioctx.cqe.done = srpt_recv_done;
drivers/infiniband/ulp/srpt/ib_srpt.c:	wr.wr_cqe = &ioctx->ioctx.cqe;
drivers/infiniband/ulp/srpt/ib_srpt.c:	enum dma_data_direction dir = target_reverse_dma_direction(&ioctx->cmd);
drivers/infiniband/ulp/srpt/ib_srpt.c:	struct srpt_rdma_ch *ch = ioctx->ch;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->rw_ctxs = &ioctx->s_rw_ctx;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->rw_ctxs = kmalloc_array(nbufs, sizeof(*ioctx->rw_ctxs),
drivers/infiniband/ulp/srpt/ib_srpt.c:		if (!ioctx->rw_ctxs)
drivers/infiniband/ulp/srpt/ib_srpt.c:	for (i = ioctx->n_rw_ctx; i < nbufs; i++, db++) {
drivers/infiniband/ulp/srpt/ib_srpt.c:		struct srpt_rw_ctx *ctx = &ioctx->rw_ctxs[i];
drivers/infiniband/ulp/srpt/ib_srpt.c:		ret = target_alloc_sgl(&ctx->sg, &ctx->nents, size, false,
drivers/infiniband/ulp/srpt/ib_srpt.c:		ret = rdma_rw_ctx_init(&ctx->rw, ch->qp, ch->sport->port,
drivers/infiniband/ulp/srpt/ib_srpt.c:				ctx->sg, ctx->nents, 0, remote_addr, rkey, dir);
drivers/infiniband/ulp/srpt/ib_srpt.c:			target_free_sgl(ctx->sg, ctx->nents);
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->n_rdma += ret;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->n_rw_ctx++;
drivers/infiniband/ulp/srpt/ib_srpt.c:			sg_chain(prev, prev_nents + 1, ctx->sg);
drivers/infiniband/ulp/srpt/ib_srpt.c:			*sg = ctx->sg;
drivers/infiniband/ulp/srpt/ib_srpt.c:		prev = ctx->sg;
drivers/infiniband/ulp/srpt/ib_srpt.c:		prev_nents = ctx->nents;
drivers/infiniband/ulp/srpt/ib_srpt.c:		*sg_cnt += ctx->nents;
drivers/infiniband/ulp/srpt/ib_srpt.c:		struct srpt_rw_ctx *ctx = &ioctx->rw_ctxs[i];
drivers/infiniband/ulp/srpt/ib_srpt.c:		rdma_rw_ctx_destroy(&ctx->rw, ch->qp, ch->sport->port,
drivers/infiniband/ulp/srpt/ib_srpt.c:				ctx->sg, ctx->nents, dir);
drivers/infiniband/ulp/srpt/ib_srpt.c:		target_free_sgl(ctx->sg, ctx->nents);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (ioctx->rw_ctxs != &ioctx->s_rw_ctx)
drivers/infiniband/ulp/srpt/ib_srpt.c:		kfree(ioctx->rw_ctxs);
drivers/infiniband/ulp/srpt/ib_srpt.c:	enum dma_data_direction dir = target_reverse_dma_direction(&ioctx->cmd);
drivers/infiniband/ulp/srpt/ib_srpt.c:	for (i = 0; i < ioctx->n_rw_ctx; i++) {
drivers/infiniband/ulp/srpt/ib_srpt.c:		struct srpt_rw_ctx *ctx = &ioctx->rw_ctxs[i];
drivers/infiniband/ulp/srpt/ib_srpt.c:		rdma_rw_ctx_destroy(&ctx->rw, ch->qp, ch->sport->port,
drivers/infiniband/ulp/srpt/ib_srpt.c:				ctx->sg, ctx->nents, dir);
drivers/infiniband/ulp/srpt/ib_srpt.c:		target_free_sgl(ctx->sg, ctx->nents);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (ioctx->rw_ctxs != &ioctx->s_rw_ctx)
drivers/infiniband/ulp/srpt/ib_srpt.c:		kfree(ioctx->rw_ctxs);
drivers/infiniband/ulp/srpt/ib_srpt.c: * This function initializes ioctx->nrbuf and ioctx->r_bufs.
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->cmd.data_direction = *dir;
drivers/infiniband/ulp/srpt/ib_srpt.c:		list_del(&ioctx->free_list);
drivers/infiniband/ulp/srpt/ib_srpt.c:	BUG_ON(ioctx->ch != ch);
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_init(&ioctx->spinlock);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->state = SRPT_STATE_NEW;
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->n_rdma = 0;
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->n_rw_ctx = 0;
drivers/infiniband/ulp/srpt/ib_srpt.c:	init_completion(&ioctx->tx_done);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->queue_status_only = false;
drivers/infiniband/ulp/srpt/ib_srpt.c:	memset(&ioctx->cmd, 0, sizeof(ioctx->cmd));
drivers/infiniband/ulp/srpt/ib_srpt.c:	memset(&ioctx->sense_data, 0, sizeof(ioctx->sense_data));
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_irqsave(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	state = ioctx->state;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = SRPT_STATE_DATA_IN;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = SRPT_STATE_DONE;
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_unlock_irqrestore(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:		 ioctx->cmd.tag);
drivers/infiniband/ulp/srpt/ib_srpt.c:		pr_debug("tag %#llx: RDMA read error\n", ioctx->cmd.tag);
drivers/infiniband/ulp/srpt/ib_srpt.c:		transport_generic_request_failure(&ioctx->cmd,
drivers/infiniband/ulp/srpt/ib_srpt.c:		transport_generic_free_cmd(&ioctx->cmd, 0);
drivers/infiniband/ulp/srpt/ib_srpt.c:		transport_generic_free_cmd(&ioctx->cmd, 0);
drivers/infiniband/ulp/srpt/ib_srpt.c:	WARN_ON(ioctx->n_rdma <= 0);
drivers/infiniband/ulp/srpt/ib_srpt.c:	atomic_add(ioctx->n_rdma, &ch->sq_wr_avail);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->n_rdma = 0;
drivers/infiniband/ulp/srpt/ib_srpt.c:		target_execute_cmd(&ioctx->cmd);
drivers/infiniband/ulp/srpt/ib_srpt.c: *   be built in the buffer ioctx->buf points at and hence this function will
drivers/infiniband/ulp/srpt/ib_srpt.c:	srp_rsp = ioctx->ioctx.buf;
drivers/infiniband/ulp/srpt/ib_srpt.c:	sense_data = ioctx->sense_data;
drivers/infiniband/ulp/srpt/ib_srpt.c:	sense_data_len = ioctx->cmd.scsi_sense_length;
drivers/infiniband/ulp/srpt/ib_srpt.c:	WARN_ON(sense_data_len > sizeof(ioctx->sense_data));
drivers/infiniband/ulp/srpt/ib_srpt.c:	srp_rsp = ioctx->ioctx.buf;
drivers/infiniband/ulp/srpt/ib_srpt.c:	return target_put_sess_cmd(&ioctx->cmd);
drivers/infiniband/ulp/srpt/ib_srpt.c:	srp_cmd = recv_ioctx->ioctx.buf;
drivers/infiniband/ulp/srpt/ib_srpt.c:	cmd = &send_ioctx->cmd;
drivers/infiniband/ulp/srpt/ib_srpt.c:			       &send_ioctx->sense_data[0],
drivers/infiniband/ulp/srpt/ib_srpt.c:	send_ioctx->state = SRPT_STATE_DONE;
drivers/infiniband/ulp/srpt/ib_srpt.c:	srp_tsk = recv_ioctx->ioctx.buf;
drivers/infiniband/ulp/srpt/ib_srpt.c:	cmd = &send_ioctx->cmd;
drivers/infiniband/ulp/srpt/ib_srpt.c:	send_ioctx->cmd.tag = srp_tsk->tag;
drivers/infiniband/ulp/srpt/ib_srpt.c:	rc = target_submit_tmr(&send_ioctx->cmd, sess, NULL,
drivers/infiniband/ulp/srpt/ib_srpt.c:		send_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;
drivers/infiniband/ulp/srpt/ib_srpt.c:				   recv_ioctx->ioctx.dma, srp_max_req_size,
drivers/infiniband/ulp/srpt/ib_srpt.c:	srp_cmd = recv_ioctx->ioctx.buf;
drivers/infiniband/ulp/srpt/ib_srpt.c:	list_add_tail(&recv_ioctx->wait_list, &ch->cmd_wait_list);
drivers/infiniband/ulp/srpt/ib_srpt.c:		list_del(&recv_ioctx->wait_list);
drivers/infiniband/ulp/srpt/ib_srpt.c:	atomic_add(1 + ioctx->n_rdma, &ch->sq_wr_avail);
drivers/infiniband/ulp/srpt/ib_srpt.c:		transport_generic_free_cmd(&ioctx->cmd, 0);
drivers/infiniband/ulp/srpt/ib_srpt.c:		       " wr_id = %u.\n", ioctx->ioctx.index);
drivers/infiniband/ulp/srpt/ib_srpt.c:	struct srpt_rdma_ch *ch = ioctx->ch;
drivers/infiniband/ulp/srpt/ib_srpt.c:	struct ib_cqe *cqe = &ioctx->rdma_cqe;
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (atomic_sub_return(ioctx->n_rdma, &ch->sq_wr_avail) < 0) {
drivers/infiniband/ulp/srpt/ib_srpt.c:				__func__, ioctx->n_rdma);
drivers/infiniband/ulp/srpt/ib_srpt.c:	for (i = ioctx->n_rw_ctx - 1; i >= 0; i--) {
drivers/infiniband/ulp/srpt/ib_srpt.c:		struct srpt_rw_ctx *ctx = &ioctx->rw_ctxs[i];
drivers/infiniband/ulp/srpt/ib_srpt.c:		first_wr = rdma_rw_ctx_wrs(&ctx->rw, ch->qp, ch->sport->port,
drivers/infiniband/ulp/srpt/ib_srpt.c:			 __func__, ret, ioctx->n_rdma,
drivers/infiniband/ulp/srpt/ib_srpt.c:	atomic_add(ioctx->n_rdma, &ch->sq_wr_avail);
drivers/infiniband/ulp/srpt/ib_srpt.c:	struct srpt_rdma_ch *ch = ioctx->ch;
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_lock_irqsave(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	state = ioctx->state;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = SRPT_STATE_CMD_RSP_SENT;
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->state = SRPT_STATE_MGMT_RSP_SENT;
drivers/infiniband/ulp/srpt/ib_srpt.c:			ch, ioctx->ioctx.index, ioctx->state);
drivers/infiniband/ulp/srpt/ib_srpt.c:	spin_unlock_irqrestore(&ioctx->spinlock, flags);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (unlikely(transport_check_aborted_status(&ioctx->cmd, false)
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (ioctx->cmd.data_direction == DMA_FROM_DEVICE &&
drivers/infiniband/ulp/srpt/ib_srpt.c:	    ioctx->cmd.data_length &&
drivers/infiniband/ulp/srpt/ib_srpt.c:	    !ioctx->queue_status_only) {
drivers/infiniband/ulp/srpt/ib_srpt.c:		for (i = ioctx->n_rw_ctx - 1; i >= 0; i--) {
drivers/infiniband/ulp/srpt/ib_srpt.c:			struct srpt_rw_ctx *ctx = &ioctx->rw_ctxs[i];
drivers/infiniband/ulp/srpt/ib_srpt.c:			first_wr = rdma_rw_ctx_wrs(&ctx->rw, ch->qp,
drivers/infiniband/ulp/srpt/ib_srpt.c:		resp_len = srpt_build_cmd_rsp(ch, ioctx, ioctx->cmd.tag,
drivers/infiniband/ulp/srpt/ib_srpt.c:						 ioctx->cmd.tag);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (unlikely(atomic_sub_return(1 + ioctx->n_rdma,
drivers/infiniband/ulp/srpt/ib_srpt.c:				__func__, ioctx->n_rdma);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ib_dma_sync_single_for_device(sdev->device, ioctx->ioctx.dma, resp_len,
drivers/infiniband/ulp/srpt/ib_srpt.c:	sge.addr = ioctx->ioctx.dma;
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->ioctx.cqe.done = srpt_send_done;
drivers/infiniband/ulp/srpt/ib_srpt.c:	send_wr.wr_cqe = &ioctx->ioctx.cqe;
drivers/infiniband/ulp/srpt/ib_srpt.c:			__func__, ioctx->cmd.tag, ret);
drivers/infiniband/ulp/srpt/ib_srpt.c:	atomic_add(1 + ioctx->n_rdma, &ch->sq_wr_avail);
drivers/infiniband/ulp/srpt/ib_srpt.c:	target_put_sess_cmd(&ioctx->cmd);
drivers/infiniband/ulp/srpt/ib_srpt.c:	BUG_ON(ioctx->sense_data != cmd->sense_buffer);
drivers/infiniband/ulp/srpt/ib_srpt.c:	ioctx->queue_status_only = true;
drivers/infiniband/ulp/srpt/ib_srpt.c:	struct srpt_rdma_ch *ch = ioctx->ch;
drivers/infiniband/ulp/srpt/ib_srpt.c:	WARN_ON(ioctx->state != SRPT_STATE_DONE);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (ioctx->n_rw_ctx) {
drivers/infiniband/ulp/srpt/ib_srpt.c:		ioctx->n_rw_ctx = 0;
drivers/infiniband/ulp/srpt/ib_srpt.c:	list_add(&ioctx->free_list, &ch->free_list);
drivers/infiniband/ulp/ipoib/ipoib_main.c:	priv = cb_ctx->priv;
drivers/infiniband/ulp/ipoib/ipoib_main.c:	complete(&cb_ctx->done);
drivers/infiniband/ulp/iser/iser_initiator.c:	else if (likely(rkey == desc->pi_ctx->sig_mr->rkey))
drivers/infiniband/ulp/iser/iser_initiator.c:		desc->pi_ctx->sig_mr_valid = 0;
drivers/infiniband/ulp/iser/iser_memory.c:	struct ib_mr *mr = pi_ctx->sig_mr;
drivers/infiniband/ulp/iser/iser_memory.c:	if (pi_ctx->sig_mr_valid)
drivers/infiniband/ulp/iser/iser_memory.c:	pi_ctx->sig_mr_valid = 1;
drivers/infiniband/ulp/iser/iser_memory.c:	return device->reg_ops->reg_mem(task, mem, &desc->pi_ctx->rsc, reg);
drivers/infiniband/ulp/iser/iser_memory.c:		desc->pi_ctx->sig_protected = 1;
drivers/infiniband/ulp/iser/iser_verbs.c:	ret = iser_alloc_reg_res(device, pd, &pi_ctx->rsc, size);
drivers/infiniband/ulp/iser/iser_verbs.c:	pi_ctx->sig_mr = ib_alloc_mr(pd, IB_MR_TYPE_SIGNATURE, 2);
drivers/infiniband/ulp/iser/iser_verbs.c:	if (IS_ERR(pi_ctx->sig_mr)) {
drivers/infiniband/ulp/iser/iser_verbs.c:		ret = PTR_ERR(pi_ctx->sig_mr);
drivers/infiniband/ulp/iser/iser_verbs.c:	pi_ctx->sig_mr_valid = 0;
drivers/infiniband/ulp/iser/iser_verbs.c:	desc->pi_ctx->sig_protected = 0;
drivers/infiniband/ulp/iser/iser_verbs.c:	iser_free_reg_res(&pi_ctx->rsc);
drivers/infiniband/ulp/iser/iser_verbs.c:	iser_free_reg_res(&pi_ctx->rsc);
drivers/infiniband/ulp/iser/iser_verbs.c:	ib_dereg_mr(pi_ctx->sig_mr);
drivers/infiniband/ulp/iser/iser_verbs.c:	if (desc && desc->pi_ctx->sig_protected) {
drivers/infiniband/ulp/iser/iser_verbs.c:		desc->pi_ctx->sig_protected = 0;
drivers/infiniband/ulp/iser/iser_verbs.c:		ret = ib_check_mr_status(desc->pi_ctx->sig_mr,
drivers/infiniband/core/ucm.c:	else if (ctx->file != file)
drivers/infiniband/core/ucm.c:		atomic_inc(&ctx->ref);
drivers/infiniband/core/ucm.c:	if (atomic_dec_and_test(&ctx->ref))
drivers/infiniband/core/ucm.c:		complete(&ctx->comp);
drivers/infiniband/core/ucm.c:	mutex_lock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:	list_del(&ctx->file_list);
drivers/infiniband/core/ucm.c:	while (!list_empty(&ctx->events)) {
drivers/infiniband/core/ucm.c:		uevent = list_entry(ctx->events.next,
drivers/infiniband/core/ucm.c:		mutex_unlock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:		mutex_lock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:	mutex_unlock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:	atomic_set(&ctx->ref, 1);
drivers/infiniband/core/ucm.c:	init_completion(&ctx->comp);
drivers/infiniband/core/ucm.c:	ctx->file = file;
drivers/infiniband/core/ucm.c:	INIT_LIST_HEAD(&ctx->events);
drivers/infiniband/core/ucm.c:	ctx->id = idr_alloc(&ctx_id_table, ctx, 0, 0, GFP_KERNEL);
drivers/infiniband/core/ucm.c:	if (ctx->id < 0)
drivers/infiniband/core/ucm.c:	list_add_tail(&ctx->file_list, &file->ctxs);
drivers/infiniband/core/ucm.c:	uevent->resp.uid = ctx->uid;
drivers/infiniband/core/ucm.c:	uevent->resp.id = ctx->id;
drivers/infiniband/core/ucm.c:	mutex_lock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:	list_add_tail(&uevent->file_list, &ctx->file->events);
drivers/infiniband/core/ucm.c:	list_add_tail(&uevent->ctx_list, &ctx->events);
drivers/infiniband/core/ucm.c:	wake_up_interruptible(&ctx->file->poll_wait);
drivers/infiniband/core/ucm.c:	mutex_unlock(&ctx->file->file_mutex);
drivers/infiniband/core/ucm.c:		ctx->cm_id = uevent->cm_id;
drivers/infiniband/core/ucm.c:		ctx->cm_id->context = ctx;
drivers/infiniband/core/ucm.c:		uevent->resp.id = ctx->id;
drivers/infiniband/core/ucm.c:	uevent->ctx->events_reported++;
drivers/infiniband/core/ucm.c:	ctx->uid = cmd.uid;
drivers/infiniband/core/ucm.c:	ctx->cm_id = ib_create_cm_id(file->device->ib_dev,
drivers/infiniband/core/ucm.c:	if (IS_ERR(ctx->cm_id)) {
drivers/infiniband/core/ucm.c:		result = PTR_ERR(ctx->cm_id);
drivers/infiniband/core/ucm.c:	resp.id = ctx->id;
drivers/infiniband/core/ucm.c:	ib_destroy_cm_id(ctx->cm_id);
drivers/infiniband/core/ucm.c:	idr_remove(&ctx_id_table, ctx->id);
drivers/infiniband/core/ucm.c:	else if (ctx->file != file)
drivers/infiniband/core/ucm.c:		idr_remove(&ctx_id_table, ctx->id);
drivers/infiniband/core/ucm.c:	wait_for_completion(&ctx->comp);
drivers/infiniband/core/ucm.c:	ib_destroy_cm_id(ctx->cm_id);
drivers/infiniband/core/ucm.c:	resp.events_reported = ctx->events_reported;
drivers/infiniband/core/ucm.c:	resp.service_id   = ctx->cm_id->service_id;
drivers/infiniband/core/ucm.c:	resp.service_mask = ctx->cm_id->service_mask;
drivers/infiniband/core/ucm.c:	resp.local_id     = ctx->cm_id->local_id;
drivers/infiniband/core/ucm.c:	resp.remote_id    = ctx->cm_id->remote_id;
drivers/infiniband/core/ucm.c:	result = ib_cm_init_qp_attr(ctx->cm_id, &qp_attr, &resp.qp_attr_mask);
drivers/infiniband/core/ucm.c:	result = ib_cm_listen(ctx->cm_id, cmd.service_id, cmd.service_mask);
drivers/infiniband/core/ucm.c:	result = ib_cm_notify(ctx->cm_id, (enum ib_event_type) cmd.event);
drivers/infiniband/core/ucm.c:		result = ib_send_cm_req(ctx->cm_id, &param);
drivers/infiniband/core/ucm.c:		ctx->uid = cmd.uid;
drivers/infiniband/core/ucm.c:		result = ib_send_cm_rep(ctx->cm_id, &param);
drivers/infiniband/core/ucm.c:		result = func(ctx->cm_id, private_data, cmd.len);
drivers/infiniband/core/ucm.c:		result = func(ctx->cm_id, cmd.status, info, cmd.info_len,
drivers/infiniband/core/ucm.c:		result = ib_send_cm_mra(ctx->cm_id, cmd.timeout, data, cmd.len);
drivers/infiniband/core/ucm.c:		result = ib_send_cm_lap(ctx->cm_id, path, data, cmd.len);
drivers/infiniband/core/ucm.c:		result = ib_send_cm_sidr_req(ctx->cm_id, &param);
drivers/infiniband/core/ucm.c:		result = ib_send_cm_sidr_rep(ctx->cm_id, &param);
drivers/infiniband/core/ucm.c:		idr_remove(&ctx_id_table, ctx->id);
drivers/infiniband/core/ucm.c:		ib_destroy_cm_id(ctx->cm_id);
drivers/infiniband/core/rw.c:	ctx->nr_ops = (sg_cnt + pages_per_mr - 1) / pages_per_mr;
drivers/infiniband/core/rw.c:	ctx->reg = kcalloc(ctx->nr_ops, sizeof(*ctx->reg), GFP_KERNEL);
drivers/infiniband/core/rw.c:	if (!ctx->reg) {
drivers/infiniband/core/rw.c:	for (i = 0; i < ctx->nr_ops; i++) {
drivers/infiniband/core/rw.c:		struct rdma_rw_reg_ctx *reg = &ctx->reg[i];
drivers/infiniband/core/rw.c:	ctx->type = RDMA_RW_MR;
drivers/infiniband/core/rw.c:		ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->reg[i].mr);
drivers/infiniband/core/rw.c:	kfree(ctx->reg);
drivers/infiniband/core/rw.c:	ctx->nr_ops = DIV_ROUND_UP(sg_cnt, max_sge);
drivers/infiniband/core/rw.c:	ctx->map.sges = sge = kcalloc(sg_cnt, sizeof(*sge), GFP_KERNEL);
drivers/infiniband/core/rw.c:	if (!ctx->map.sges)
drivers/infiniband/core/rw.c:	ctx->map.wrs = kcalloc(ctx->nr_ops, sizeof(*ctx->map.wrs), GFP_KERNEL);
drivers/infiniband/core/rw.c:	if (!ctx->map.wrs)
drivers/infiniband/core/rw.c:	for (i = 0; i < ctx->nr_ops; i++) {
drivers/infiniband/core/rw.c:		struct ib_rdma_wr *rdma_wr = &ctx->map.wrs[i];
drivers/infiniband/core/rw.c:		rdma_wr->wr.next = i + 1 < ctx->nr_ops ?
drivers/infiniband/core/rw.c:			&ctx->map.wrs[i + 1].wr : NULL;
drivers/infiniband/core/rw.c:	ctx->type = RDMA_RW_MULTI_WR;
drivers/infiniband/core/rw.c:	return ctx->nr_ops;
drivers/infiniband/core/rw.c:	kfree(ctx->map.sges);
drivers/infiniband/core/rw.c:	struct ib_rdma_wr *rdma_wr = &ctx->single.wr;
drivers/infiniband/core/rw.c:	ctx->nr_ops = 1;
drivers/infiniband/core/rw.c:	ctx->single.sge.lkey = qp->pd->local_dma_lkey;
drivers/infiniband/core/rw.c:	ctx->single.sge.addr = ib_sg_dma_address(dev, sg) + offset;
drivers/infiniband/core/rw.c:	ctx->single.sge.length = ib_sg_dma_len(dev, sg) - offset;
drivers/infiniband/core/rw.c:	rdma_wr->wr.sg_list = &ctx->single.sge;
drivers/infiniband/core/rw.c:	ctx->type = RDMA_RW_SINGLE_WR;
drivers/infiniband/core/rw.c:	ctx->type = RDMA_RW_SIG_MR;
drivers/infiniband/core/rw.c:	ctx->nr_ops = 1;
drivers/infiniband/core/rw.c:	ctx->sig = kcalloc(1, sizeof(*ctx->sig), GFP_KERNEL);
drivers/infiniband/core/rw.c:	if (!ctx->sig) {
drivers/infiniband/core/rw.c:	ret = rdma_rw_init_one_mr(qp, port_num, &ctx->sig->data, sg, sg_cnt, 0);
drivers/infiniband/core/rw.c:	prev_wr = &ctx->sig->data.reg_wr.wr;
drivers/infiniband/core/rw.c:		ret = rdma_rw_init_one_mr(qp, port_num, &ctx->sig->prot,
drivers/infiniband/core/rw.c:		if (ctx->sig->prot.inv_wr.next)
drivers/infiniband/core/rw.c:			prev_wr->next = &ctx->sig->prot.inv_wr;
drivers/infiniband/core/rw.c:			prev_wr->next = &ctx->sig->prot.reg_wr.wr;
drivers/infiniband/core/rw.c:		prev_wr = &ctx->sig->prot.reg_wr.wr;
drivers/infiniband/core/rw.c:		ctx->sig->prot.mr = NULL;
drivers/infiniband/core/rw.c:	ctx->sig->sig_mr = ib_mr_pool_get(qp, &qp->sig_mrs);
drivers/infiniband/core/rw.c:	if (!ctx->sig->sig_mr) {
drivers/infiniband/core/rw.c:	if (ctx->sig->sig_mr->need_inval) {
drivers/infiniband/core/rw.c:		memset(&ctx->sig->sig_inv_wr, 0, sizeof(ctx->sig->sig_inv_wr));
drivers/infiniband/core/rw.c:		ctx->sig->sig_inv_wr.opcode = IB_WR_LOCAL_INV;
drivers/infiniband/core/rw.c:		ctx->sig->sig_inv_wr.ex.invalidate_rkey = ctx->sig->sig_mr->rkey;
drivers/infiniband/core/rw.c:		prev_wr->next = &ctx->sig->sig_inv_wr;
drivers/infiniband/core/rw.c:		prev_wr = &ctx->sig->sig_inv_wr;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.wr.opcode = IB_WR_REG_SIG_MR;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.wr.wr_cqe = NULL;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.wr.sg_list = &ctx->sig->data.sge;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.wr.num_sge = 1;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.access_flags = IB_ACCESS_LOCAL_WRITE;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.sig_attrs = sig_attrs;
drivers/infiniband/core/rw.c:	ctx->sig->sig_wr.sig_mr = ctx->sig->sig_mr;
drivers/infiniband/core/rw.c:		ctx->sig->sig_wr.prot = &ctx->sig->prot.sge;
drivers/infiniband/core/rw.c:	prev_wr->next = &ctx->sig->sig_wr.wr;
drivers/infiniband/core/rw.c:	prev_wr = &ctx->sig->sig_wr.wr;
drivers/infiniband/core/rw.c:	ctx->sig->sig_sge.addr = 0;
drivers/infiniband/core/rw.c:	ctx->sig->sig_sge.length = ctx->sig->data.sge.length;
drivers/infiniband/core/rw.c:		ctx->sig->sig_sge.length += ctx->sig->prot.sge.length;
drivers/infiniband/core/rw.c:	rdma_wr = &ctx->sig->data.wr;
drivers/infiniband/core/rw.c:	rdma_wr->wr.sg_list = &ctx->sig->sig_sge;
drivers/infiniband/core/rw.c:		ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->sig->prot.mr);
drivers/infiniband/core/rw.c:	ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->sig->data.mr);
drivers/infiniband/core/rw.c:	kfree(ctx->sig);
drivers/infiniband/core/rw.c:	switch (ctx->type) {
drivers/infiniband/core/rw.c:		rdma_rw_update_lkey(&ctx->sig->data, true);
drivers/infiniband/core/rw.c:		if (ctx->sig->prot.mr)
drivers/infiniband/core/rw.c:			rdma_rw_update_lkey(&ctx->sig->prot, true);
drivers/infiniband/core/rw.c:		ctx->sig->sig_mr->need_inval = true;
drivers/infiniband/core/rw.c:		ib_update_fast_reg_key(ctx->sig->sig_mr,
drivers/infiniband/core/rw.c:			ib_inc_rkey(ctx->sig->sig_mr->lkey));
drivers/infiniband/core/rw.c:		ctx->sig->sig_sge.lkey = ctx->sig->sig_mr->lkey;
drivers/infiniband/core/rw.c:		if (ctx->sig->data.inv_wr.next)
drivers/infiniband/core/rw.c:			first_wr = &ctx->sig->data.inv_wr;
drivers/infiniband/core/rw.c:			first_wr = &ctx->sig->data.reg_wr.wr;
drivers/infiniband/core/rw.c:		last_wr = &ctx->sig->data.wr.wr;
drivers/infiniband/core/rw.c:		for (i = 0; i < ctx->nr_ops; i++) {
drivers/infiniband/core/rw.c:			rdma_rw_update_lkey(&ctx->reg[i],
drivers/infiniband/core/rw.c:				ctx->reg[i].wr.wr.opcode !=
drivers/infiniband/core/rw.c:		if (ctx->reg[0].inv_wr.next)
drivers/infiniband/core/rw.c:			first_wr = &ctx->reg[0].inv_wr;
drivers/infiniband/core/rw.c:			first_wr = &ctx->reg[0].reg_wr.wr;
drivers/infiniband/core/rw.c:		last_wr = &ctx->reg[ctx->nr_ops - 1].wr.wr;
drivers/infiniband/core/rw.c:		first_wr = &ctx->map.wrs[0].wr;
drivers/infiniband/core/rw.c:		last_wr = &ctx->map.wrs[ctx->nr_ops - 1].wr;
drivers/infiniband/core/rw.c:		first_wr = &ctx->single.wr.wr;
drivers/infiniband/core/rw.c:		last_wr = &ctx->single.wr.wr;
drivers/infiniband/core/rw.c:	switch (ctx->type) {
drivers/infiniband/core/rw.c:		for (i = 0; i < ctx->nr_ops; i++)
drivers/infiniband/core/rw.c:			ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->reg[i].mr);
drivers/infiniband/core/rw.c:		kfree(ctx->reg);
drivers/infiniband/core/rw.c:		kfree(ctx->map.wrs);
drivers/infiniband/core/rw.c:		kfree(ctx->map.sges);
drivers/infiniband/core/rw.c:	if (WARN_ON_ONCE(ctx->type != RDMA_RW_SIG_MR))
drivers/infiniband/core/rw.c:	ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->sig->data.mr);
drivers/infiniband/core/rw.c:	if (ctx->sig->prot.mr) {
drivers/infiniband/core/rw.c:		ib_mr_pool_put(qp, &qp->rdma_mrs, ctx->sig->prot.mr);
drivers/infiniband/core/rw.c:	ib_mr_pool_put(qp, &qp->sig_mrs, ctx->sig->sig_mr);
drivers/infiniband/core/rw.c:	kfree(ctx->sig);
drivers/infiniband/core/ucma.c:	else if (ctx->file != file)
drivers/infiniband/core/ucma.c:		if (ctx->closing)
drivers/infiniband/core/ucma.c:			atomic_inc(&ctx->ref);
drivers/infiniband/core/ucma.c:	if (atomic_dec_and_test(&ctx->ref))
drivers/infiniband/core/ucma.c:		complete(&ctx->comp);
drivers/infiniband/core/ucma.c:	wait_for_completion(&ctx->comp);
drivers/infiniband/core/ucma.c:	rdma_destroy_id(ctx->cm_id);
drivers/infiniband/core/ucma.c:	INIT_WORK(&ctx->close_work, ucma_close_id);
drivers/infiniband/core/ucma.c:	atomic_set(&ctx->ref, 1);
drivers/infiniband/core/ucma.c:	init_completion(&ctx->comp);
drivers/infiniband/core/ucma.c:	INIT_LIST_HEAD(&ctx->mc_list);
drivers/infiniband/core/ucma.c:	ctx->file = file;
drivers/infiniband/core/ucma.c:	ctx->id = idr_alloc(&ctx_idr, ctx, 0, 0, GFP_KERNEL);
drivers/infiniband/core/ucma.c:	if (ctx->id < 0)
drivers/infiniband/core/ucma.c:	list_add_tail(&ctx->list, &file->ctx_list);
drivers/infiniband/core/ucma.c:	list_add_tail(&mc->list, &ctx->mc_list);
drivers/infiniband/core/ucma.c:		uevent->resp.uid = ctx->uid;
drivers/infiniband/core/ucma.c:		uevent->resp.id = ctx->id;
drivers/infiniband/core/ucma.c:	if (ctx->destroying)
drivers/infiniband/core/ucma.c:	if (ctx->cm_id == cm_id) {
drivers/infiniband/core/ucma.c:		ctx->closing = 1;
drivers/infiniband/core/ucma.c:		queue_work(ctx->file->close_wq, &ctx->close_work);
drivers/infiniband/core/ucma.c:	list_for_each_entry(con_req_eve, &ctx->file->event_list, list) {
drivers/infiniband/core/ucma.c:			queue_work(ctx->file->close_wq, &con_req_eve->close_work);
drivers/infiniband/core/ucma.c:	mutex_lock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:		if (!ctx->backlog) {
drivers/infiniband/core/ucma.c:		ctx->backlog--;
drivers/infiniband/core/ucma.c:	} else if (!ctx->uid || ctx->cm_id != cm_id) {
drivers/infiniband/core/ucma.c:	list_add_tail(&uevent->list, &ctx->file->event_list);
drivers/infiniband/core/ucma.c:	wake_up_interruptible(&ctx->file->poll_wait);
drivers/infiniband/core/ucma.c:	mutex_unlock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:		uevent->ctx->backlog++;
drivers/infiniband/core/ucma.c:		ctx->cm_id = uevent->cm_id;
drivers/infiniband/core/ucma.c:		ctx->cm_id->context = ctx;
drivers/infiniband/core/ucma.c:		uevent->resp.id = ctx->id;
drivers/infiniband/core/ucma.c:	uevent->ctx->events_reported++;
drivers/infiniband/core/ucma.c:	ctx->uid = cmd.uid;
drivers/infiniband/core/ucma.c:	ctx->cm_id = rdma_create_id(current->nsproxy->net_ns,
drivers/infiniband/core/ucma.c:	if (IS_ERR(ctx->cm_id)) {
drivers/infiniband/core/ucma.c:		ret = PTR_ERR(ctx->cm_id);
drivers/infiniband/core/ucma.c:	resp.id = ctx->id;
drivers/infiniband/core/ucma.c:	rdma_destroy_id(ctx->cm_id);
drivers/infiniband/core/ucma.c:	idr_remove(&ctx_idr, ctx->id);
drivers/infiniband/core/ucma.c:	list_for_each_entry_safe(mc, tmp, &ctx->mc_list, list) {
drivers/infiniband/core/ucma.c:	list_for_each_entry_safe(uevent, tmp, &mc->ctx->file->event_list, list) {
drivers/infiniband/core/ucma.c:	mutex_lock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:	list_for_each_entry_safe(uevent, tmp, &ctx->file->event_list, list) {
drivers/infiniband/core/ucma.c:	list_del(&ctx->list);
drivers/infiniband/core/ucma.c:	mutex_unlock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:	events_reported = ctx->events_reported;
drivers/infiniband/core/ucma.c:		idr_remove(&ctx_idr, ctx->id);
drivers/infiniband/core/ucma.c:	mutex_lock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:	ctx->destroying = 1;
drivers/infiniband/core/ucma.c:	mutex_unlock(&ctx->file->mut);
drivers/infiniband/core/ucma.c:	flush_workqueue(ctx->file->close_wq);
drivers/infiniband/core/ucma.c:	if (!ctx->closing) {
drivers/infiniband/core/ucma.c:		wait_for_completion(&ctx->comp);
drivers/infiniband/core/ucma.c:		rdma_destroy_id(ctx->cm_id);
drivers/infiniband/core/ucma.c:	ret = rdma_bind_addr(ctx->cm_id, (struct sockaddr *) &cmd.addr);
drivers/infiniband/core/ucma.c:	ret = rdma_bind_addr(ctx->cm_id, addr);
drivers/infiniband/core/ucma.c:	ret = rdma_resolve_addr(ctx->cm_id, (struct sockaddr *) &cmd.src_addr,
drivers/infiniband/core/ucma.c:	ret = rdma_resolve_addr(ctx->cm_id, src, dst, cmd.timeout_ms);
drivers/infiniband/core/ucma.c:	ret = rdma_resolve_route(ctx->cm_id, cmd.timeout_ms);
drivers/infiniband/core/ucma.c:	addr = (struct sockaddr *) &ctx->cm_id->route.addr.src_addr;
drivers/infiniband/core/ucma.c:	addr = (struct sockaddr *) &ctx->cm_id->route.addr.dst_addr;
drivers/infiniband/core/ucma.c:	if (!ctx->cm_id->device)
drivers/infiniband/core/ucma.c:	resp.node_guid = (__force __u64) ctx->cm_id->device->node_guid;
drivers/infiniband/core/ucma.c:	resp.port_num = ctx->cm_id->port_num;
drivers/infiniband/core/ucma.c:	if (rdma_cap_ib_sa(ctx->cm_id->device, ctx->cm_id->port_num))
drivers/infiniband/core/ucma.c:		ucma_copy_ib_route(&resp, &ctx->cm_id->route);
drivers/infiniband/core/ucma.c:	else if (rdma_protocol_roce(ctx->cm_id->device, ctx->cm_id->port_num))
drivers/infiniband/core/ucma.c:		ucma_copy_iboe_route(&resp, &ctx->cm_id->route);
drivers/infiniband/core/ucma.c:	else if (rdma_protocol_iwarp(ctx->cm_id->device, ctx->cm_id->port_num))
drivers/infiniband/core/ucma.c:		ucma_copy_iw_route(&resp, &ctx->cm_id->route);
drivers/infiniband/core/ucma.c:	addr = (struct sockaddr *) &ctx->cm_id->route.addr.src_addr;
drivers/infiniband/core/ucma.c:	addr = (struct sockaddr *) &ctx->cm_id->route.addr.dst_addr;
drivers/infiniband/core/ucma.c:	ucma_query_device_addr(ctx->cm_id, &resp);
drivers/infiniband/core/ucma.c:	resp->num_paths = ctx->cm_id->route.num_paths;
drivers/infiniband/core/ucma.c:		ib_sa_pack_path(&ctx->cm_id->route.path_rec[i],
drivers/infiniband/core/ucma.c:	ucma_query_device_addr(ctx->cm_id, &resp);
drivers/infiniband/core/ucma.c:	if (ctx->cm_id->route.addr.src_addr.ss_family == AF_IB) {
drivers/infiniband/core/ucma.c:		memcpy(addr, &ctx->cm_id->route.addr.src_addr, resp.src_size);
drivers/infiniband/core/ucma.c:		rdma_addr_get_sgid(&ctx->cm_id->route.addr.dev_addr,
drivers/infiniband/core/ucma.c:		addr->sib_sid = rdma_get_service_id(ctx->cm_id, (struct sockaddr *)
drivers/infiniband/core/ucma.c:						    &ctx->cm_id->route.addr.src_addr);
drivers/infiniband/core/ucma.c:	if (ctx->cm_id->route.addr.dst_addr.ss_family == AF_IB) {
drivers/infiniband/core/ucma.c:		memcpy(addr, &ctx->cm_id->route.addr.dst_addr, resp.dst_size);
drivers/infiniband/core/ucma.c:		rdma_addr_get_dgid(&ctx->cm_id->route.addr.dev_addr,
drivers/infiniband/core/ucma.c:		addr->sib_sid = rdma_get_service_id(ctx->cm_id, (struct sockaddr *)
drivers/infiniband/core/ucma.c:						    &ctx->cm_id->route.addr.dst_addr);
drivers/infiniband/core/ucma.c:	ucma_copy_conn_param(ctx->cm_id, &conn_param, &cmd.conn_param);
drivers/infiniband/core/ucma.c:	ret = rdma_connect(ctx->cm_id, &conn_param);
drivers/infiniband/core/ucma.c:	ctx->backlog = cmd.backlog > 0 && cmd.backlog < max_backlog ?
drivers/infiniband/core/ucma.c:	ret = rdma_listen(ctx->cm_id, ctx->backlog);
drivers/infiniband/core/ucma.c:		ucma_copy_conn_param(ctx->cm_id, &conn_param, &cmd.conn_param);
drivers/infiniband/core/ucma.c:		ret = rdma_accept(ctx->cm_id, &conn_param);
drivers/infiniband/core/ucma.c:			ctx->uid = cmd.uid;
drivers/infiniband/core/ucma.c:		ret = rdma_accept(ctx->cm_id, NULL);
drivers/infiniband/core/ucma.c:	ret = rdma_reject(ctx->cm_id, cmd.private_data, cmd.private_data_len);
drivers/infiniband/core/ucma.c:	ret = rdma_disconnect(ctx->cm_id);
drivers/infiniband/core/ucma.c:	ret = rdma_init_qp_attr(ctx->cm_id, &qp_attr, &resp.qp_attr_mask);
drivers/infiniband/core/ucma.c:		rdma_set_service_type(ctx->cm_id, *((u8 *) optval));
drivers/infiniband/core/ucma.c:		ret = rdma_set_reuseaddr(ctx->cm_id, *((int *) optval) ? 1 : 0);
drivers/infiniband/core/ucma.c:		ret = rdma_set_afonly(ctx->cm_id, *((int *) optval) ? 1 : 0);
drivers/infiniband/core/ucma.c:	ret = rdma_set_ib_paths(ctx->cm_id, &sa_path, 1);
drivers/infiniband/core/ucma.c:	return ucma_event_handler(ctx->cm_id, &event);
drivers/infiniband/core/ucma.c:	ret = rdma_notify(ctx->cm_id, (enum ib_event_type) cmd.event);
drivers/infiniband/core/ucma.c:	ret = rdma_join_multicast(ctx->cm_id, (struct sockaddr *)&mc->addr,
drivers/infiniband/core/ucma.c:	rdma_leave_multicast(ctx->cm_id, (struct sockaddr *) &mc->addr);
drivers/infiniband/core/ucma.c:	else if (mc->ctx->file != file)
drivers/infiniband/core/ucma.c:	else if (!atomic_inc_not_zero(&mc->ctx->ref))
drivers/infiniband/core/ucma.c:	rdma_leave_multicast(mc->ctx->cm_id, (struct sockaddr *) &mc->addr);
drivers/infiniband/core/ucma.c:	mutex_lock(&mc->ctx->file->mut);
drivers/infiniband/core/ucma.c:	mutex_unlock(&mc->ctx->file->mut);
drivers/infiniband/core/ucma.c:	list_for_each_entry_safe(uevent, tmp, &ctx->file->event_list, list)
drivers/infiniband/core/ucma.c:	cur_file = ctx->file;
drivers/infiniband/core/ucma.c:		resp.events_reported = ctx->events_reported;
drivers/infiniband/core/ucma.c:	list_move_tail(&ctx->list, &new_file->ctx_list);
drivers/infiniband/core/ucma.c:	ctx->file = new_file;
drivers/infiniband/core/ucma.c:	resp.events_reported = ctx->events_reported;
drivers/infiniband/core/ucma.c:		ctx->destroying = 1;
drivers/infiniband/core/ucma.c:		idr_remove(&ctx_idr, ctx->id);
drivers/infiniband/core/ucma.c:		if (!ctx->closing) {
drivers/infiniband/core/ucma.c:			rdma_destroy_id(ctx->cm_id);
drivers/infiniband/core/verbs.c:	if (ctx->gid_type != gid_attr->gid_type)
drivers/infiniband/core/verbs.c:	if ((!!(ctx->vlan_id != 0xffff) == !is_vlan_dev(gid_attr->ndev)) ||
drivers/infiniband/core/verbs.c:	     vlan_dev_vlan_id(gid_attr->ndev) != ctx->vlan_id))
drivers/infiniband/core/cma.c:			 cb_ctx->device->name, cb_ctx->port_num, status);
drivers/infiniband/core/cma.c:	memcpy(cb_ctx->class_port_info, rec, sizeof(struct ib_class_port_info));
drivers/infiniband/core/cma.c:	complete(&cb_ctx->done);
drivers/infiniband/core/cma.c:	cb_ctx->device = device;
drivers/infiniband/core/cma.c:	cb_ctx->class_port_info = class_port_info;
drivers/infiniband/core/cma.c:	cb_ctx->port_num = port_num;
drivers/infiniband/core/cma.c:	init_completion(&cb_ctx->done);
drivers/infiniband/core/cma.c:					     cb_ctx, &cb_ctx->sa_query);
drivers/infiniband/core/cma.c:	wait_for_completion(&cb_ctx->done);
drivers/infiniband/hw/qedr/verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/qedr/verbs.c:	list_add(&mm->entry, &uctx->mm_head);
drivers/infiniband/hw/qedr/verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/qedr/verbs.c:	DP_DEBUG(uctx->dev, QEDR_MSG_MISC,
drivers/infiniband/hw/qedr/verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/qedr/verbs.c:	list_for_each_entry(mm, &uctx->mm_head, entry) {
drivers/infiniband/hw/qedr/verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/qedr/verbs.c:	DP_DEBUG(uctx->dev, QEDR_MSG_MISC,
drivers/infiniband/hw/qedr/verbs.c:	ctx->dpi = oparams.dpi;
drivers/infiniband/hw/qedr/verbs.c:	ctx->dpi_addr = oparams.dpi_addr;
drivers/infiniband/hw/qedr/verbs.c:	ctx->dpi_phys_addr = oparams.dpi_phys_addr;
drivers/infiniband/hw/qedr/verbs.c:	ctx->dpi_size = oparams.dpi_size;
drivers/infiniband/hw/qedr/verbs.c:	INIT_LIST_HEAD(&ctx->mm_head);
drivers/infiniband/hw/qedr/verbs.c:	mutex_init(&ctx->mm_list_lock);
drivers/infiniband/hw/qedr/verbs.c:	uresp.db_pa = ctx->dpi_phys_addr;
drivers/infiniband/hw/qedr/verbs.c:	uresp.db_size = ctx->dpi_size;
drivers/infiniband/hw/qedr/verbs.c:	ctx->dev = dev;
drivers/infiniband/hw/qedr/verbs.c:	rc = qedr_add_mmap(ctx, ctx->dpi_phys_addr, ctx->dpi_size);
drivers/infiniband/hw/qedr/verbs.c:		 &ctx->ibucontext);
drivers/infiniband/hw/qedr/verbs.c:	return &ctx->ibucontext;
drivers/infiniband/hw/qedr/verbs.c:	DP_DEBUG(uctx->dev, QEDR_MSG_INIT, "Deallocating user context %p\n",
drivers/infiniband/hw/qedr/verbs.c:	uctx->dev->ops->rdma_remove_user(uctx->dev->rdma_ctx, uctx->dpi);
drivers/infiniband/hw/qedr/verbs.c:	list_for_each_entry_safe(mm, tmp, &uctx->mm_head, entry) {
drivers/infiniband/hw/qedr/verbs.c:		DP_DEBUG(uctx->dev, QEDR_MSG_MISC,
drivers/infiniband/hw/qedr/verbs.c:		pd->uctx->pd = pd;
drivers/infiniband/hw/qedr/verbs.c:	params->dpi = (ctx) ? ctx->dpi : dev->dpi;
drivers/infiniband/hw/qedr/verbs.c:	params->dpi = pd->uctx ? pd->uctx->dpi : dev->dpi;
drivers/infiniband/hw/mthca/mthca_cq.c:		cq_context->logsize_usrpage |= cpu_to_be32(ctx->uar.index);
drivers/infiniband/hw/mthca/mthca_srq.c:		srq_attr->srq_limit = be16_to_cpu(arbel_ctx->limit_watermark);
drivers/infiniband/hw/mthca/mthca_srq.c:		srq_attr->srq_limit = be16_to_cpu(tavor_ctx->limit_watermark);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	if (!list_empty(&uctx->qpids)) {
drivers/infiniband/hw/cxgb3/cxio_hal.c:		entry = list_entry(uctx->qpids.next, struct cxio_qpid_list,
drivers/infiniband/hw/cxgb3/cxio_hal.c:			list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	list_for_each_safe(pos, nxt, &uctx->qpids) {
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	INIT_LIST_HEAD(&uctx->qpids);
drivers/infiniband/hw/cxgb3/cxio_hal.c:	mutex_init(&uctx->lock);
drivers/infiniband/hw/mlx4/mad.c:	return cpu_to_be64(atomic_inc_return(&ctx->tid)) |
drivers/infiniband/hw/mlx4/mad.c:	if (!tun_ctx || tun_ctx->state != DEMUX_PV_STATE_ACTIVE)
drivers/infiniband/hw/mlx4/mad.c:		tun_qp = &tun_ctx->qp[0];
drivers/infiniband/hw/mlx4/mad.c:		tun_qp = &tun_ctx->qp[1];
drivers/infiniband/hw/mlx4/mad.c:	ah = ib_create_ah(tun_ctx->pd, &attr);
drivers/infiniband/hw/mlx4/mad.c:	list.lkey = tun_ctx->pd->local_dma_lkey;
drivers/infiniband/hw/mlx4/mad.c:	struct mlx4_ib_dev *dev = to_mdev(ctx->ib_dev);
drivers/infiniband/hw/mlx4/mad.c:	if (!dev->sriov.is_going_down && ctx->state == DEMUX_PV_STATE_ACTIVE)
drivers/infiniband/hw/mlx4/mad.c:		queue_work(ctx->wq, &ctx->work);
drivers/infiniband/hw/mlx4/mad.c:	sg_list.lkey = ctx->pd->local_dma_lkey;
drivers/infiniband/hw/mlx4/mad.c:	ib_dma_sync_single_for_device(ctx->ib_dev, tun_qp->ring[index].map,
drivers/infiniband/hw/mlx4/mad.c:	if (!sqp_ctx || sqp_ctx->state != DEMUX_PV_STATE_ACTIVE)
drivers/infiniband/hw/mlx4/mad.c:		sqp = &sqp_ctx->qp[0];
drivers/infiniband/hw/mlx4/mad.c:		sqp = &sqp_ctx->qp[1];
drivers/infiniband/hw/mlx4/mad.c:	ah = ib_create_ah(sqp_ctx->pd, attr);
drivers/infiniband/hw/mlx4/mad.c:	list.lkey = sqp_ctx->pd->local_dma_lkey;
drivers/infiniband/hw/mlx4/mad.c:	struct mlx4_ib_dev *dev = to_mdev(ctx->ib_dev);
drivers/infiniband/hw/mlx4/mad.c:	struct mlx4_ib_demux_pv_qp *tun_qp = &ctx->qp[MLX4_TUN_WRID_QPN(wc->wr_id)];
drivers/infiniband/hw/mlx4/mad.c:	    (wc->src_qp & 0x1) != ctx->port - 1 ||
drivers/infiniband/hw/mlx4/mad.c:		mlx4_ib_warn(ctx->ib_dev, "can't multiplex bad sqp:%d\n", wc->src_qp);
drivers/infiniband/hw/mlx4/mad.c:	if (slave != ctx->slave) {
drivers/infiniband/hw/mlx4/mad.c:		mlx4_ib_warn(ctx->ib_dev, "can't multiplex bad sqp:%d: "
drivers/infiniband/hw/mlx4/mad.c:	ib_dma_sync_single_for_cpu(ctx->ib_dev, tun_qp->ring[wr_ix].map,
drivers/infiniband/hw/mlx4/mad.c:			mlx4_ib_warn(ctx->ib_dev, "egress mad has non-null tid msb:%d "
drivers/infiniband/hw/mlx4/mad.c:		    !mlx4_vf_smi_enabled(dev->dev, slave, ctx->port))
drivers/infiniband/hw/mlx4/mad.c:		if (mlx4_ib_multiplex_sa_handler(ctx->ib_dev, ctx->port, slave,
drivers/infiniband/hw/mlx4/mad.c:		if (mlx4_ib_multiplex_cm_handler(ctx->ib_dev, ctx->port, slave,
drivers/infiniband/hw/mlx4/mad.c:			mlx4_ib_warn(ctx->ib_dev, "dropping unsupported egress mad from class:%d "
drivers/infiniband/hw/mlx4/mad.c:	ah.ibah.device = ctx->ib_dev;
drivers/infiniband/hw/mlx4/mad.c:		fill_in_real_sgid_index(dev, slave, ctx->port, &ah_attr);
drivers/infiniband/hw/mlx4/mad.c:	mlx4_get_slave_default_vlan(dev->dev, ctx->port, slave,
drivers/infiniband/hw/mlx4/mad.c:	mlx4_ib_send_to_wire(dev, slave, ctx->port,
drivers/infiniband/hw/mlx4/mad.c:	tun_qp = &ctx->qp[qp_type];
drivers/infiniband/hw/mlx4/mad.c:		tun_qp->ring[i].map = ib_dma_map_single(ctx->ib_dev,
drivers/infiniband/hw/mlx4/mad.c:		if (ib_dma_mapping_error(ctx->ib_dev, tun_qp->ring[i].map)) {
drivers/infiniband/hw/mlx4/mad.c:			ib_dma_map_single(ctx->ib_dev,
drivers/infiniband/hw/mlx4/mad.c:		if (ib_dma_mapping_error(ctx->ib_dev,
drivers/infiniband/hw/mlx4/mad.c:		ib_dma_unmap_single(ctx->ib_dev, tun_qp->tx_ring[i].buf.map,
drivers/infiniband/hw/mlx4/mad.c:		ib_dma_unmap_single(ctx->ib_dev, tun_qp->ring[i].map,
drivers/infiniband/hw/mlx4/mad.c:	tun_qp = &ctx->qp[qp_type];
drivers/infiniband/hw/mlx4/mad.c:		ib_dma_unmap_single(ctx->ib_dev, tun_qp->ring[i].map,
drivers/infiniband/hw/mlx4/mad.c:		ib_dma_unmap_single(ctx->ib_dev, tun_qp->tx_ring[i].buf.map,
drivers/infiniband/hw/mlx4/mad.c:	ib_req_notify_cq(ctx->cq, IB_CQ_NEXT_COMP);
drivers/infiniband/hw/mlx4/mad.c:	while (ib_poll_cq(ctx->cq, 1, &wc) == 1) {
drivers/infiniband/hw/mlx4/mad.c:		tun_qp = &ctx->qp[MLX4_TUN_WRID_QPN(wc.wr_id)];
drivers/infiniband/hw/mlx4/mad.c:				 ctx->slave, wc.status, wc.wr_id);
drivers/infiniband/hw/mlx4/mad.c:	tun_qp = &ctx->qp[qp_type];
drivers/infiniband/hw/mlx4/mad.c:	qp_init_attr.init_attr.send_cq = ctx->cq;
drivers/infiniband/hw/mlx4/mad.c:	qp_init_attr.init_attr.recv_cq = ctx->cq;
drivers/infiniband/hw/mlx4/mad.c:		qp_init_attr.port = ctx->port;
drivers/infiniband/hw/mlx4/mad.c:		qp_init_attr.slave = ctx->slave;
drivers/infiniband/hw/mlx4/mad.c:	qp_init_attr.init_attr.port_num = ctx->port;
drivers/infiniband/hw/mlx4/mad.c:	tun_qp->qp = ib_create_qp(ctx->pd, &qp_init_attr.init_attr);
drivers/infiniband/hw/mlx4/mad.c:		ret = find_slave_port_pkey_ix(to_mdev(ctx->ib_dev), ctx->slave,
drivers/infiniband/hw/mlx4/mad.c:					      ctx->port, IB_DEFAULT_PKEY_FULL,
drivers/infiniband/hw/mlx4/mad.c:			to_mdev(ctx->ib_dev)->pkeys.virt2phys_pkey[ctx->slave][ctx->port - 1][0];
drivers/infiniband/hw/mlx4/mad.c:	attr.port_num = ctx->port;
drivers/infiniband/hw/mlx4/mad.c:	ib_req_notify_cq(ctx->cq, IB_CQ_NEXT_COMP);
drivers/infiniband/hw/mlx4/mad.c:	while (mlx4_ib_poll_cq(ctx->cq, 1, &wc) == 1) {
drivers/infiniband/hw/mlx4/mad.c:		sqp = &ctx->qp[MLX4_TUN_WRID_QPN(wc.wr_id)];
drivers/infiniband/hw/mlx4/mad.c:				mlx4_ib_demux_mad(ctx->ib_dev, ctx->port, &wc, grh, mad);
drivers/infiniband/hw/mlx4/mad.c:				 ctx->slave, wc.status, wc.wr_id);
drivers/infiniband/hw/mlx4/mad.c:	ctx->ib_dev = &dev->ib_dev;
drivers/infiniband/hw/mlx4/mad.c:	ctx->port = port;
drivers/infiniband/hw/mlx4/mad.c:	ctx->slave = slave;
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->state != DEMUX_PV_STATE_DOWN)
drivers/infiniband/hw/mlx4/mad.c:	ctx->state = DEMUX_PV_STATE_STARTING;
drivers/infiniband/hw/mlx4/mad.c:	if (rdma_port_get_link_layer(ibdev, ctx->port) ==
drivers/infiniband/hw/mlx4/mad.c:		ctx->has_smi = 1;
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->has_smi) {
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->has_smi)
drivers/infiniband/hw/mlx4/mad.c:	ctx->cq = ib_create_cq(ctx->ib_dev, mlx4_ib_tunnel_comp_handler,
drivers/infiniband/hw/mlx4/mad.c:	if (IS_ERR(ctx->cq)) {
drivers/infiniband/hw/mlx4/mad.c:		ret = PTR_ERR(ctx->cq);
drivers/infiniband/hw/mlx4/mad.c:	ctx->pd = ib_alloc_pd(ctx->ib_dev, 0);
drivers/infiniband/hw/mlx4/mad.c:	if (IS_ERR(ctx->pd)) {
drivers/infiniband/hw/mlx4/mad.c:		ret = PTR_ERR(ctx->pd);
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->has_smi) {
drivers/infiniband/hw/mlx4/mad.c:		INIT_WORK(&ctx->work, mlx4_ib_tunnel_comp_worker);
drivers/infiniband/hw/mlx4/mad.c:		INIT_WORK(&ctx->work, mlx4_ib_sqp_comp_worker);
drivers/infiniband/hw/mlx4/mad.c:	ctx->wq = to_mdev(ibdev)->sriov.demux[port - 1].wq;
drivers/infiniband/hw/mlx4/mad.c:	ret = ib_req_notify_cq(ctx->cq, IB_CQ_NEXT_COMP);
drivers/infiniband/hw/mlx4/mad.c:	ctx->state = DEMUX_PV_STATE_ACTIVE;
drivers/infiniband/hw/mlx4/mad.c:	ctx->wq = NULL;
drivers/infiniband/hw/mlx4/mad.c:	ib_destroy_qp(ctx->qp[1].qp);
drivers/infiniband/hw/mlx4/mad.c:	ctx->qp[1].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->has_smi)
drivers/infiniband/hw/mlx4/mad.c:		ib_destroy_qp(ctx->qp[0].qp);
drivers/infiniband/hw/mlx4/mad.c:	ctx->qp[0].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:	ib_dealloc_pd(ctx->pd);
drivers/infiniband/hw/mlx4/mad.c:	ctx->pd = NULL;
drivers/infiniband/hw/mlx4/mad.c:	ib_destroy_cq(ctx->cq);
drivers/infiniband/hw/mlx4/mad.c:	ctx->cq = NULL;
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->has_smi)
drivers/infiniband/hw/mlx4/mad.c:	ctx->state = DEMUX_PV_STATE_DOWN;
drivers/infiniband/hw/mlx4/mad.c:	if (ctx->state > DEMUX_PV_STATE_DOWN) {
drivers/infiniband/hw/mlx4/mad.c:		ctx->state = DEMUX_PV_STATE_DOWNING;
drivers/infiniband/hw/mlx4/mad.c:			flush_workqueue(ctx->wq);
drivers/infiniband/hw/mlx4/mad.c:		if (ctx->has_smi) {
drivers/infiniband/hw/mlx4/mad.c:			ib_destroy_qp(ctx->qp[0].qp);
drivers/infiniband/hw/mlx4/mad.c:			ctx->qp[0].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_destroy_qp(ctx->qp[1].qp);
drivers/infiniband/hw/mlx4/mad.c:		ctx->qp[1].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_dealloc_pd(ctx->pd);
drivers/infiniband/hw/mlx4/mad.c:		ctx->pd = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_destroy_cq(ctx->cq);
drivers/infiniband/hw/mlx4/mad.c:		ctx->cq = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ctx->state = DEMUX_PV_STATE_DOWN;
drivers/infiniband/hw/mlx4/mad.c:	ctx->tun = kcalloc(dev->dev->caps.sqp_demux,
drivers/infiniband/hw/mlx4/mad.c:	if (!ctx->tun)
drivers/infiniband/hw/mlx4/mad.c:	ctx->dev = dev;
drivers/infiniband/hw/mlx4/mad.c:	ctx->port = port;
drivers/infiniband/hw/mlx4/mad.c:	ctx->ib_dev = &dev->ib_dev;
drivers/infiniband/hw/mlx4/mad.c:		ret = alloc_pv_object(dev, i, port, &ctx->tun[i]);
drivers/infiniband/hw/mlx4/mad.c:	ctx->wq = alloc_ordered_workqueue(name, WQ_MEM_RECLAIM);
drivers/infiniband/hw/mlx4/mad.c:	if (!ctx->wq) {
drivers/infiniband/hw/mlx4/mad.c:	ctx->ud_wq = alloc_ordered_workqueue(name, WQ_MEM_RECLAIM);
drivers/infiniband/hw/mlx4/mad.c:	if (!ctx->ud_wq) {
drivers/infiniband/hw/mlx4/mad.c:	destroy_workqueue(ctx->wq);
drivers/infiniband/hw/mlx4/mad.c:	ctx->wq = NULL;
drivers/infiniband/hw/mlx4/mad.c:	kfree(ctx->tun);
drivers/infiniband/hw/mlx4/mad.c:	ctx->tun = NULL;
drivers/infiniband/hw/mlx4/mad.c:	if (sqp_ctx->state > DEMUX_PV_STATE_DOWN) {
drivers/infiniband/hw/mlx4/mad.c:		sqp_ctx->state = DEMUX_PV_STATE_DOWNING;
drivers/infiniband/hw/mlx4/mad.c:		flush_workqueue(sqp_ctx->wq);
drivers/infiniband/hw/mlx4/mad.c:		if (sqp_ctx->has_smi) {
drivers/infiniband/hw/mlx4/mad.c:			ib_destroy_qp(sqp_ctx->qp[0].qp);
drivers/infiniband/hw/mlx4/mad.c:			sqp_ctx->qp[0].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_destroy_qp(sqp_ctx->qp[1].qp);
drivers/infiniband/hw/mlx4/mad.c:		sqp_ctx->qp[1].qp = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_dealloc_pd(sqp_ctx->pd);
drivers/infiniband/hw/mlx4/mad.c:		sqp_ctx->pd = NULL;
drivers/infiniband/hw/mlx4/mad.c:		ib_destroy_cq(sqp_ctx->cq);
drivers/infiniband/hw/mlx4/mad.c:		sqp_ctx->cq = NULL;
drivers/infiniband/hw/mlx4/mad.c:		sqp_ctx->state = DEMUX_PV_STATE_DOWN;
drivers/infiniband/hw/mlx4/mad.c:		struct mlx4_ib_dev *dev = to_mdev(ctx->ib_dev);
drivers/infiniband/hw/mlx4/mad.c:			if (!ctx->tun[i])
drivers/infiniband/hw/mlx4/mad.c:			if (ctx->tun[i]->state > DEMUX_PV_STATE_DOWN)
drivers/infiniband/hw/mlx4/mad.c:				ctx->tun[i]->state = DEMUX_PV_STATE_DOWNING;
drivers/infiniband/hw/mlx4/mad.c:		flush_workqueue(ctx->wq);
drivers/infiniband/hw/mlx4/mad.c:			destroy_pv_resources(dev, i, ctx->port, ctx->tun[i], 0);
drivers/infiniband/hw/mlx4/mad.c:			free_pv_object(dev, i, ctx->port);
drivers/infiniband/hw/mlx4/mad.c:		kfree(ctx->tun);
drivers/infiniband/hw/mlx4/mad.c:		destroy_workqueue(ctx->ud_wq);
drivers/infiniband/hw/mlx4/mad.c:		destroy_workqueue(ctx->wq);
drivers/infiniband/hw/mlx4/alias_GUID.c:	dev = cb_ctx->dev;
drivers/infiniband/hw/mlx4/alias_GUID.c:	port_index = cb_ctx->port - 1;
drivers/infiniband/hw/mlx4/alias_GUID.c:		all_rec_per_port[cb_ctx->block_num];
drivers/infiniband/hw/mlx4/alias_GUID.c:			 cb_ctx->port, status);
drivers/infiniband/hw/mlx4/alias_GUID.c:	if (guid_rec->block_num != cb_ctx->block_num) {
drivers/infiniband/hw/mlx4/alias_GUID.c:		       cb_ctx->block_num, guid_rec->block_num);
drivers/infiniband/hw/mlx4/alias_GUID.c:		 be16_to_cpu(guid_rec->lid), cb_ctx->port,
drivers/infiniband/hw/mlx4/alias_GUID.c:		if (!(cb_ctx->guid_indexes &
drivers/infiniband/hw/mlx4/alias_GUID.c:		if (cb_ctx->method == MLX4_GUID_INFO_RECORD_DELETE) {
drivers/infiniband/hw/mlx4/alias_GUID.c:							    cb_ctx->port);
drivers/infiniband/hw/mlx4/alias_GUID.c:	applied_guid_indexes =  cb_ctx->guid_indexes & ~declined_guid_indexes;
drivers/infiniband/hw/mlx4/alias_GUID.c:					     cb_ctx->port,
drivers/infiniband/hw/mlx4/alias_GUID.c:	if (cb_ctx->sa_query) {
drivers/infiniband/hw/mlx4/alias_GUID.c:		list_del(&cb_ctx->list);
drivers/infiniband/hw/mlx4/alias_GUID.c:		complete(&cb_ctx->done);
drivers/infiniband/hw/mlx4/alias_GUID.c:			sa_query = cb_ctx->sa_query;
drivers/infiniband/hw/mlx4/alias_GUID.c:			cb_ctx->sa_query = NULL;
drivers/infiniband/hw/mlx4/alias_GUID.c:			list_del(&cb_ctx->list);
drivers/infiniband/hw/mlx4/alias_GUID.c:			ib_sa_cancel_query(cb_ctx->query_id, sa_query);
drivers/infiniband/hw/mlx4/alias_GUID.c:			wait_for_completion(&cb_ctx->done);
drivers/infiniband/hw/mlx4/mcg.c:	struct rb_node *node = ctx->mcg_table.rb_node;
drivers/infiniband/hw/mlx4/mcg.c:	struct rb_node **link = &ctx->mcg_table.rb_node;
drivers/infiniband/hw/mlx4/mcg.c:	rb_insert_color(&group->node, &ctx->mcg_table);
drivers/infiniband/hw/mlx4/mcg.c:	struct mlx4_ib_dev *dev = ctx->dev;
drivers/infiniband/hw/mlx4/mcg.c:	if (!dev->sm_ah[ctx->port - 1]) {
drivers/infiniband/hw/mlx4/mcg.c:	mlx4_ib_query_ah(dev->sm_ah[ctx->port - 1], &ah_attr);
drivers/infiniband/hw/mlx4/mcg.c:				    ctx->port, IB_QPT_GSI, 0, 1, IB_QP1_QKEY,
drivers/infiniband/hw/mlx4/mcg.c:	struct mlx4_ib_dev *dev = ctx->dev;
drivers/infiniband/hw/mlx4/mcg.c:	struct ib_mad_agent *agent = dev->send_agent[ctx->port - 1][1];
drivers/infiniband/hw/mlx4/mcg.c:	ib_query_ah(dev->sm_ah[ctx->port - 1], &ah_attr);
drivers/infiniband/hw/mlx4/mcg.c:	if (ib_find_cached_pkey(&dev->ib_dev, ctx->port, IB_DEFAULT_PKEY_FULL, &wc.pkey_index))
drivers/infiniband/hw/mlx4/mcg.c:	wc.port_num = ctx->port;
drivers/infiniband/hw/mlx4/mcg.c:	return mlx4_ib_send_to_slave(dev, slave, ctx->port, IB_QPT_GSI, &wc, NULL, mad);
drivers/infiniband/hw/mlx4/mcg.c:	mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:				mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:			del_sysfs_port_mcg_attr(ctx->dev, ctx->port, &group->dentry.attr);
drivers/infiniband/hw/mlx4/mcg.c:			rb_erase(&group->node, &ctx->mcg_table);
drivers/infiniband/hw/mlx4/mcg.c:		mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	list_for_each_entry_safe(group, n, &ctx->mcg_mgid0_list, mgid0_list) {
drivers/infiniband/hw/mlx4/mcg.c:					mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:				add_sysfs_port_mcg_attr(ctx->dev, ctx->port, &group->dentry.attr);
drivers/infiniband/hw/mlx4/mcg.c:				mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:				mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		list_add(&group->mgid0_list, &ctx->mcg_mgid0_list);
drivers/infiniband/hw/mlx4/mcg.c:	add_sysfs_port_mcg_attr(ctx->dev, ctx->port, &group->dentry.attr);
drivers/infiniband/hw/mlx4/mcg.c:		mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		if (!queue_work(ctx->mcg_wq, &group->work))
drivers/infiniband/hw/mlx4/mcg.c:	if (ctx->flushing)
drivers/infiniband/hw/mlx4/mcg.c:		mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	atomic_set(&ctx->tid, 0);
drivers/infiniband/hw/mlx4/mcg.c:	sprintf(name, "mlx4_ib_mcg%d", ctx->port);
drivers/infiniband/hw/mlx4/mcg.c:	ctx->mcg_wq = alloc_ordered_workqueue(name, WQ_MEM_RECLAIM);
drivers/infiniband/hw/mlx4/mcg.c:	if (!ctx->mcg_wq)
drivers/infiniband/hw/mlx4/mcg.c:	mutex_init(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	ctx->mcg_table = RB_ROOT;
drivers/infiniband/hw/mlx4/mcg.c:	INIT_LIST_HEAD(&ctx->mcg_mgid0_list);
drivers/infiniband/hw/mlx4/mcg.c:	ctx->flushing = 0;
drivers/infiniband/hw/mlx4/mcg.c:		mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:		for (p = rb_first(&ctx->mcg_table); p; p = rb_next(p))
drivers/infiniband/hw/mlx4/mcg.c:		mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	flush_workqueue(ctx->mcg_wq);
drivers/infiniband/hw/mlx4/mcg.c:		destroy_workqueue(ctx->mcg_wq);
drivers/infiniband/hw/mlx4/mcg.c:	mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	while ((p = rb_first(&ctx->mcg_table)) != NULL) {
drivers/infiniband/hw/mlx4/mcg.c:	mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	cw->ctx->flushing = 0;
drivers/infiniband/hw/mlx4/mcg.c:	if (ctx->flushing)
drivers/infiniband/hw/mlx4/mcg.c:	ctx->flushing = 1;
drivers/infiniband/hw/mlx4/mcg.c:		ctx->flushing = 0;
drivers/infiniband/hw/mlx4/mcg.c:		ctx->flushing = 0;
drivers/infiniband/hw/mlx4/mcg.c:	mutex_lock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/mcg.c:	for (p = rb_first(&ctx->mcg_table); p; p = rb_next(p)) {
drivers/infiniband/hw/mlx4/mcg.c:	mutex_unlock(&ctx->mcg_table_lock);
drivers/infiniband/hw/mlx4/main.c:				port_gid_table->gids[free].ctx->real_index = free;
drivers/infiniband/hw/mlx4/main.c:				port_gid_table->gids[free].ctx->refcount = 1;
drivers/infiniband/hw/mlx4/main.c:		ctx->refcount++;
drivers/infiniband/hw/mlx4/main.c:		ctx->refcount--;
drivers/infiniband/hw/mlx4/main.c:		if (!ctx->refcount) {
drivers/infiniband/hw/mlx4/main.c:			unsigned int real_index = ctx->real_index;
drivers/infiniband/hw/mlx4/main.c:		real_index = ctx->real_index;
drivers/infiniband/hw/ocrdma/ocrdma_ah.c:	if ((pd->uctx) && (pd->uctx->ah_tbl.va)) {
drivers/infiniband/hw/ocrdma/ocrdma_ah.c:		ahid_addr = pd->uctx->ah_tbl.va + attr->dlid;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	list_add_tail(&mm->entry, &uctx->mm_head);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	list_for_each_entry_safe(mm, tmp, &uctx->mm_head, entry) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	list_for_each_entry(mm, &uctx->mm_head, entry) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	return (uctx->cntxt_pd == pd ? true : false);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uctx->cntxt_pd = _ocrdma_alloc_pd(dev, uctx, udata);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	if (IS_ERR(uctx->cntxt_pd)) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:		status = PTR_ERR(uctx->cntxt_pd);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:		uctx->cntxt_pd = NULL;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uctx->cntxt_pd->uctx = uctx;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uctx->cntxt_pd->ibpd.device = &dev->ibdev;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	struct ocrdma_pd *pd = uctx->cntxt_pd;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	if (uctx->pd_in_use) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uctx->cntxt_pd = NULL;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	if (!uctx->pd_in_use) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:		uctx->pd_in_use = true;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:		pd = uctx->cntxt_pd;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_lock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uctx->pd_in_use = false;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_unlock(&uctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	INIT_LIST_HEAD(&ctx->mm_head);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	mutex_init(&ctx->mm_list_lock);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	ctx->ah_tbl.va = dma_alloc_coherent(&pdev->dev, map_len,
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:					    &ctx->ah_tbl.pa, GFP_KERNEL);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	if (!ctx->ah_tbl.va) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	memset(ctx->ah_tbl.va, 0, map_len);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	ctx->ah_tbl.len = map_len;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	resp.ah_tbl_len = ctx->ah_tbl.len;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	resp.ah_tbl_page = virt_to_phys(ctx->ah_tbl.va);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	return &ctx->ibucontext;
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	ocrdma_del_mmap(ctx, ctx->ah_tbl.pa, ctx->ah_tbl.len);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	dma_free_coherent(&pdev->dev, ctx->ah_tbl.len, ctx->ah_tbl.va,
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:			  ctx->ah_tbl.pa);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	struct ocrdma_dev *dev = get_ocrdma_dev(ibctx->device);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	ocrdma_del_mmap(uctx, uctx->ah_tbl.pa, uctx->ah_tbl.len);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	dma_free_coherent(&pdev->dev, uctx->ah_tbl.len, uctx->ah_tbl.va,
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:			  uctx->ah_tbl.pa);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	list_for_each_entry_safe(mm, tmp, &uctx->mm_head, entry) {
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:	uresp.db_page_addr =  ocrdma_get_db_addr(dev, uctx->cntxt_pd->id);
drivers/infiniband/hw/ocrdma/ocrdma_verbs.c:		pd_id = uctx->cntxt_pd->id;
drivers/infiniband/hw/cxgb4/resource.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	if (!list_empty(&uctx->cqids)) {
drivers/infiniband/hw/cxgb4/resource.c:		entry = list_entry(uctx->cqids.next, struct c4iw_qid_list,
drivers/infiniband/hw/cxgb4/resource.c:			list_add_tail(&entry->entry, &uctx->cqids);
drivers/infiniband/hw/cxgb4/resource.c:		list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb4/resource.c:			list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	list_add_tail(&entry->entry, &uctx->cqids);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	if (!list_empty(&uctx->qpids)) {
drivers/infiniband/hw/cxgb4/resource.c:		entry = list_entry(uctx->qpids.next, struct c4iw_qid_list,
drivers/infiniband/hw/cxgb4/resource.c:			list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb4/resource.c:		list_add_tail(&entry->entry, &uctx->cqids);
drivers/infiniband/hw/cxgb4/resource.c:			list_add_tail(&entry->entry, &uctx->cqids);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb4/resource.c:	list_add_tail(&entry->entry, &uctx->qpids);
drivers/infiniband/hw/cxgb4/resource.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb4/device.c:	mutex_lock(&uctx->lock);
drivers/infiniband/hw/cxgb4/device.c:	list_for_each_safe(pos, nxt, &uctx->qpids) {
drivers/infiniband/hw/cxgb4/device.c:	list_for_each_safe(pos, nxt, &uctx->qpids) {
drivers/infiniband/hw/cxgb4/device.c:	mutex_unlock(&uctx->lock);
drivers/infiniband/hw/cxgb4/device.c:	INIT_LIST_HEAD(&uctx->qpids);
drivers/infiniband/hw/cxgb4/device.c:	INIT_LIST_HEAD(&uctx->cqids);
drivers/infiniband/hw/cxgb4/device.c:	mutex_init(&uctx->lock);
drivers/infiniband/hw/cxgb4/device.c:	c4iw_rdev_close(&ctx->dev->rdev);
drivers/infiniband/hw/cxgb4/device.c:	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->cqidr));
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->cqidr);
drivers/infiniband/hw/cxgb4/device.c:	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->qpidr));
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->qpidr);
drivers/infiniband/hw/cxgb4/device.c:	WARN_ON_ONCE(!idr_is_empty(&ctx->dev->mmidr));
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->mmidr);
drivers/infiniband/hw/cxgb4/device.c:	wait_event(ctx->dev->wait, idr_is_empty(&ctx->dev->hwtid_idr));
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->hwtid_idr);
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->stid_idr);
drivers/infiniband/hw/cxgb4/device.c:	idr_destroy(&ctx->dev->atid_idr);
drivers/infiniband/hw/cxgb4/device.c:	if (ctx->dev->rdev.bar2_kva)
drivers/infiniband/hw/cxgb4/device.c:		iounmap(ctx->dev->rdev.bar2_kva);
drivers/infiniband/hw/cxgb4/device.c:	if (ctx->dev->rdev.oc_mw_kva)
drivers/infiniband/hw/cxgb4/device.c:		iounmap(ctx->dev->rdev.oc_mw_kva);
drivers/infiniband/hw/cxgb4/device.c:	ib_dealloc_device(&ctx->dev->ibdev);
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev = NULL;
drivers/infiniband/hw/cxgb4/device.c:	PDBG("%s c4iw_dev %p\n", __func__,  ctx->dev);
drivers/infiniband/hw/cxgb4/device.c:	c4iw_unregister_device(ctx->dev);
drivers/infiniband/hw/cxgb4/device.c:	ctx->lldi = *infop;
drivers/infiniband/hw/cxgb4/device.c:	     __func__, pci_name(ctx->lldi.pdev),
drivers/infiniband/hw/cxgb4/device.c:	     ctx->lldi.nchan, ctx->lldi.nrxq,
drivers/infiniband/hw/cxgb4/device.c:	     ctx->lldi.ntxq, ctx->lldi.nports);
drivers/infiniband/hw/cxgb4/device.c:	list_add_tail(&ctx->entry, &uld_ctx_list);
drivers/infiniband/hw/cxgb4/device.c:	for (i = 0; i < ctx->lldi.nrxq; i++)
drivers/infiniband/hw/cxgb4/device.c:		PDBG("rxqid[%u] %u\n", i, ctx->lldi.rxq_ids[i]);
drivers/infiniband/hw/cxgb4/device.c:	struct c4iw_dev *dev = ctx->dev;
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev), gl->va,
drivers/infiniband/hw/cxgb4/device.c:		printk(KERN_INFO MOD "%s: Up\n", pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:		if (!ctx->dev) {
drivers/infiniband/hw/cxgb4/device.c:			ctx->dev = c4iw_alloc(&ctx->lldi);
drivers/infiniband/hw/cxgb4/device.c:			if (IS_ERR(ctx->dev)) {
drivers/infiniband/hw/cxgb4/device.c:				       pci_name(ctx->lldi.pdev),
drivers/infiniband/hw/cxgb4/device.c:				       PTR_ERR(ctx->dev));
drivers/infiniband/hw/cxgb4/device.c:				ctx->dev = NULL;
drivers/infiniband/hw/cxgb4/device.c:			ret = c4iw_register_device(ctx->dev);
drivers/infiniband/hw/cxgb4/device.c:				       pci_name(ctx->lldi.pdev), ret);
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:		if (ctx->dev)
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:		if (ctx->dev) {
drivers/infiniband/hw/cxgb4/device.c:			ctx->dev->rdev.flags |= T4_FATAL_ERROR;
drivers/infiniband/hw/cxgb4/device.c:			event.device = &ctx->dev->ibdev;
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:		if (ctx->dev)
drivers/infiniband/hw/cxgb4/device.c:	spin_lock_irqsave(&ctx->dev->lock, flags);
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev->rdev.stats.db_state_transitions++;
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev->db_state = STOPPED;
drivers/infiniband/hw/cxgb4/device.c:	if (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED)
drivers/infiniband/hw/cxgb4/device.c:		idr_for_each(&ctx->dev->qpidr, disable_qp_db, NULL);
drivers/infiniband/hw/cxgb4/device.c:		ctx->dev->rdev.status_page->db_off = 1;
drivers/infiniband/hw/cxgb4/device.c:	spin_unlock_irqrestore(&ctx->dev->lock, flags);
drivers/infiniband/hw/cxgb4/device.c:		qp = list_first_entry(&ctx->dev->db_fc_list, struct c4iw_qp,
drivers/infiniband/hw/cxgb4/device.c:		if (list_empty(&ctx->dev->db_fc_list))
drivers/infiniband/hw/cxgb4/device.c:	spin_lock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:	if (ctx->dev->db_state != STOPPED)
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev->db_state = FLOW_CONTROL;
drivers/infiniband/hw/cxgb4/device.c:		if (list_empty(&ctx->dev->db_fc_list)) {
drivers/infiniband/hw/cxgb4/device.c:			WARN_ON(ctx->dev->db_state != FLOW_CONTROL);
drivers/infiniband/hw/cxgb4/device.c:			ctx->dev->db_state = NORMAL;
drivers/infiniband/hw/cxgb4/device.c:			ctx->dev->rdev.stats.db_state_transitions++;
drivers/infiniband/hw/cxgb4/device.c:			if (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED) {
drivers/infiniband/hw/cxgb4/device.c:				idr_for_each(&ctx->dev->qpidr, enable_qp_db,
drivers/infiniband/hw/cxgb4/device.c:				ctx->dev->rdev.status_page->db_off = 0;
drivers/infiniband/hw/cxgb4/device.c:			if (cxgb4_dbfifo_count(ctx->dev->rdev.lldi.ports[0], 1)
drivers/infiniband/hw/cxgb4/device.c:			    < (ctx->dev->rdev.lldi.dbfifo_int_thresh <<
drivers/infiniband/hw/cxgb4/device.c:			if (!list_empty(&ctx->dev->db_fc_list)) {
drivers/infiniband/hw/cxgb4/device.c:				spin_unlock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:				spin_lock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:				if (ctx->dev->db_state != FLOW_CONTROL)
drivers/infiniband/hw/cxgb4/device.c:	if (ctx->dev->db_state != NORMAL)
drivers/infiniband/hw/cxgb4/device.c:		ctx->dev->rdev.stats.db_fc_interruptions++;
drivers/infiniband/hw/cxgb4/device.c:	spin_unlock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:			       pci_name(ctx->lldi.pdev), qp->wq.sq.qid);
drivers/infiniband/hw/cxgb4/device.c:			       pci_name(ctx->lldi.pdev), qp->wq.rq.qid);
drivers/infiniband/hw/cxgb4/device.c:	ret = cxgb4_flush_eq_cache(ctx->dev->rdev.lldi.ports[0]);
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:	spin_lock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:	WARN_ON(ctx->dev->db_state != STOPPED);
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev->db_state = RECOVERY;
drivers/infiniband/hw/cxgb4/device.c:	idr_for_each(&ctx->dev->qpidr, count_qps, &count);
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev));
drivers/infiniband/hw/cxgb4/device.c:		spin_unlock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:	idr_for_each(&ctx->dev->qpidr, add_and_ref_qp, &qp_list);
drivers/infiniband/hw/cxgb4/device.c:	spin_unlock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:	spin_lock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:	WARN_ON(ctx->dev->db_state != RECOVERY);
drivers/infiniband/hw/cxgb4/device.c:	ctx->dev->db_state = STOPPED;
drivers/infiniband/hw/cxgb4/device.c:	spin_unlock_irq(&ctx->dev->lock);
drivers/infiniband/hw/cxgb4/device.c:		ctx->dev->rdev.stats.db_full++;
drivers/infiniband/hw/cxgb4/device.c:		mutex_lock(&ctx->dev->rdev.stats.lock);
drivers/infiniband/hw/cxgb4/device.c:		ctx->dev->rdev.stats.db_empty++;
drivers/infiniband/hw/cxgb4/device.c:		mutex_unlock(&ctx->dev->rdev.stats.lock);
drivers/infiniband/hw/cxgb4/device.c:		mutex_lock(&ctx->dev->rdev.stats.lock);
drivers/infiniband/hw/cxgb4/device.c:		ctx->dev->rdev.stats.db_drop++;
drivers/infiniband/hw/cxgb4/device.c:		mutex_unlock(&ctx->dev->rdev.stats.lock);
drivers/infiniband/hw/cxgb4/device.c:		       pci_name(ctx->lldi.pdev), control);
drivers/infiniband/hw/cxgb4/device.c:		if (ctx->dev)
drivers/infiniband/hw/mlx5/main.c:	struct list_head *vma_head = &ctx->vma_private_list;
drivers/infiniband/hw/usnic/usnic_ib_verbs.c:	list_for_each_entry(qp_grp, &uctx->qp_grp_list, link) {
drivers/infiniband/hw/usnic/usnic_ib_main.c:		list_for_each_entry(qp_grp, &ctx->qp_grp_list, link) {
drivers/perf/xgene_pmu.c:	pmu->inf = &ctx->inf;
drivers/perf/xgene_pmu.c:	ctx->pmu_dev = pmu;
drivers/perf/xgene_pmu.c:	rc = xgene_init_perf(pmu, ctx->name);
drivers/perf/xgene_pmu.c:		dev_err(dev, "%s PMU: Failed to init perf driver\n", ctx->name);
drivers/perf/xgene_pmu.c:	dev_info(dev, "%s PMU registered\n", ctx->name);
drivers/perf/xgene_pmu.c:			_xgene_pmu_isr(irq, ctx->pmu_dev);
drivers/perf/xgene_pmu.c:			_xgene_pmu_isr(irq, ctx->pmu_dev);
drivers/perf/xgene_pmu.c:			_xgene_pmu_isr(irq, ctx->pmu_dev);
drivers/perf/xgene_pmu.c:			_xgene_pmu_isr(irq, ctx->pmu_dev);
drivers/perf/xgene_pmu.c:	ctx->name = xgene_pmu_dev_name(dev, type, enable_bit);
drivers/perf/xgene_pmu.c:	if (!ctx->name) {
drivers/perf/xgene_pmu.c:	inf = &ctx->inf;
drivers/perf/xgene_pmu.c:	switch (ctx->inf.type) {
drivers/perf/xgene_pmu.c:		list_add(&ctx->next, &xgene_pmu->l3cpmus);
drivers/perf/xgene_pmu.c:		list_add(&ctx->next, &xgene_pmu->iobpmus);
drivers/perf/xgene_pmu.c:		list_add(&ctx->next, &xgene_pmu->mcbpmus);
drivers/perf/xgene_pmu.c:		list_add(&ctx->next, &xgene_pmu->mcpmus);
drivers/perf/xgene_pmu.c:	ctx->name = xgene_pmu_dev_name(dev, type, enable_bit);
drivers/perf/xgene_pmu.c:	if (!ctx->name) {
drivers/perf/xgene_pmu.c:	inf = &ctx->inf;
drivers/perf/xgene_pmu.c:		switch (ctx->inf.type) {
drivers/perf/xgene_pmu.c:			list_add(&ctx->next, &xgene_pmu->l3cpmus);
drivers/perf/xgene_pmu.c:			list_add(&ctx->next, &xgene_pmu->iobpmus);
drivers/perf/xgene_pmu.c:			list_add(&ctx->next, &xgene_pmu->mcbpmus);
drivers/perf/xgene_pmu.c:			list_add(&ctx->next, &xgene_pmu->mcpmus);
drivers/perf/xgene_pmu.c:		pmu_dev = ctx->pmu_dev;
drivers/ntb/test/ntb_perf.c:	atomic_dec(&pctx->dma_sync);
drivers/ntb/test/ntb_perf.c:	struct perf_ctx *perf = pctx->perf;
drivers/ntb/test/ntb_perf.c:	struct dma_chan *chan = pctx->dma_chan;
drivers/ntb/test/ntb_perf.c:		pctx->dma_prep_err++;
drivers/ntb/test/ntb_perf.c:	atomic_inc(&pctx->dma_sync);
drivers/ntb/test/ntb_perf.c:		while (atomic_read(&pctx->dma_sync) != 0) {
drivers/ntb/test/ntb_perf.c:	pctx->copied = copied;
drivers/ntb/test/ntb_perf.c:	pctx->diff_us = diff_us;
drivers/ntb/test/ntb_perf.c:	struct perf_ctx *perf = pctx->perf;
drivers/ntb/test/ntb_perf.c:	if (use_dma && !pctx->dma_chan) {
drivers/ntb/test/ntb_perf.c:		pctx->dma_chan = dma_chan;
drivers/ntb/test/ntb_perf.c:		pctx->srcs[i] = kmalloc_node(MAX_TEST_SIZE, GFP_KERNEL, node);
drivers/ntb/test/ntb_perf.c:		if (!pctx->srcs[i]) {
drivers/ntb/test/ntb_perf.c:	src = pctx->srcs[pctx->src_idx];
drivers/ntb/test/ntb_perf.c:	pctx->src_idx = (pctx->src_idx + 1) & (MAX_SRCS - 1);
drivers/ntb/test/ntb_perf.c:		kfree(pctx->srcs[i]);
drivers/ntb/test/ntb_perf.c:		pctx->srcs[i] = NULL;
drivers/ntb/test/ntb_perf.c:	wake_up(pctx->wq);
drivers/ntb/test/ntb_perf.c:		kfree(pctx->srcs[i]);
drivers/ntb/test/ntb_perf.c:		pctx->srcs[i] = NULL;
drivers/ntb/test/ntb_perf.c:		pctx->dma_chan = NULL;
drivers/ntb/test/ntb_perf.c:		if (pctx->status == -ENODATA)
drivers/ntb/test/ntb_perf.c:		if (pctx->status) {
drivers/ntb/test/ntb_perf.c:					    pctx->status);
drivers/ntb/test/ntb_perf.c:		rate = div64_u64(pctx->copied, pctx->diff_us);
drivers/ntb/test/ntb_perf.c:			i, pctx->copied, pctx->diff_us, rate);
drivers/ntb/test/ntb_perf.c:		if (pctx->thread) {
drivers/ntb/test/ntb_perf.c:			pctx->status = kthread_stop(pctx->thread);
drivers/ntb/test/ntb_perf.c:			pctx->thread = NULL;
drivers/ntb/test/ntb_perf.c:		atomic_set(&pctx->dma_sync, 0);
drivers/ntb/test/ntb_perf.c:		pctx->perf = perf;
drivers/ntb/test/ntb_perf.c:		pctx->wq = &wq;
drivers/ntb/test/ntb_perf.c:		pctx->thread =
drivers/ntb/test/ntb_perf.c:		if (IS_ERR(pctx->thread)) {
drivers/ntb/test/ntb_perf.c:			pctx->thread = NULL;
drivers/ntb/test/ntb_perf.c:			wake_up_process(pctx->thread);
drivers/ntb/test/ntb_perf.c:			if (pctx->dma_chan)
drivers/ntb/test/ntb_perf.c:				dma_release_channel(pctx->dma_chan);
drivers/gpio/gpio-dwapb.c:		ctx->dir = dwapb_read(gpio, offset);
drivers/gpio/gpio-dwapb.c:		ctx->data = dwapb_read(gpio, offset);
drivers/gpio/gpio-dwapb.c:		ctx->ext = dwapb_read(gpio, offset);
drivers/gpio/gpio-dwapb.c:			ctx->int_mask	= dwapb_read(gpio, GPIO_INTMASK);
drivers/gpio/gpio-dwapb.c:			ctx->int_en	= dwapb_read(gpio, GPIO_INTEN);
drivers/gpio/gpio-dwapb.c:			ctx->int_pol	= dwapb_read(gpio, GPIO_INT_POLARITY);
drivers/gpio/gpio-dwapb.c:			ctx->int_type	= dwapb_read(gpio, GPIO_INTTYPE_LEVEL);
drivers/gpio/gpio-dwapb.c:			ctx->int_deb	= dwapb_read(gpio, GPIO_PORTA_DEBOUNCE);
drivers/gpio/gpio-dwapb.c:		dwapb_write(gpio, offset, ctx->data);
drivers/gpio/gpio-dwapb.c:		dwapb_write(gpio, offset, ctx->dir);
drivers/gpio/gpio-dwapb.c:		dwapb_write(gpio, offset, ctx->ext);
drivers/gpio/gpio-dwapb.c:			dwapb_write(gpio, GPIO_INTTYPE_LEVEL, ctx->int_type);
drivers/gpio/gpio-dwapb.c:			dwapb_write(gpio, GPIO_INT_POLARITY, ctx->int_pol);
drivers/gpio/gpio-dwapb.c:			dwapb_write(gpio, GPIO_PORTA_DEBOUNCE, ctx->int_deb);
drivers/gpio/gpio-dwapb.c:			dwapb_write(gpio, GPIO_INTEN, ctx->int_en);
drivers/gpio/gpio-dwapb.c:			dwapb_write(gpio, GPIO_INTMASK, ctx->int_mask);
drivers/platform/msm/mhi_dev/mhi.c:	if (list_empty(&mhi_ctx->event_ring_list) &&
drivers/platform/msm/mhi_dev/mhi.c:			list_empty(&mhi_ctx->process_ring_list))
drivers/platform/msm/mhi_dev/mhi.c:	ep_pcie_config_db_routing(mhi_ctx->phandle, chdb_cfg, erdb_cfg);
drivers/platform/msm/mhi_dev/mhi.c:	rc = ep_pcie_get_msi_config(mhi_ctx->phandle, &cfg);
drivers/platform/msm/mhi_dev/mhi.c:	ipa_init_params.mmio_addr = ((uint32_t) mhi_ctx->mmio_base_pa_addr);
drivers/platform/msm/mhi_dev/mhi.c:				ring->ring_ctx->generic.rbase;
drivers/platform/msm/mhi_dev/mhi.c:			evnt_ring) + (uint32_t) &ring->ring_ctx->ev.rp -
drivers/platform/msm/mhi_dev/mhi.c:	msi = cfg.data + mhi_ctx->mhi_ep_msi_num;
drivers/platform/msm/mhi_dev/mhi.c:			mhi_ctx->mhi_ep_msi_num, msi_addr.host_pa, msi);
drivers/platform/msm/mhi_dev/mhi.c:	compl_event.evt_tr_comp.ptr = ch->ring->ring_ctx->generic.rbase +
drivers/platform/msm/mhi_dev/mhi.c:	mutex_lock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_unlock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_lock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:			mutex_unlock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:			mutex_unlock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:			mutex_unlock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_unlock(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->ch_ctx_cache)
drivers/platform/msm/mhi_dev/mhi.c:					mhi_ctx->ev_ctx_cache->rbase,
drivers/platform/msm/mhi_dev/mhi.c:	mutex_lock(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_unlock(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:	pdev = mhi_ctx->pdev;
drivers/platform/msm/mhi_dev/mhi.c:	ch = &mhi_ctx->ch[chan_id];
drivers/platform/msm/mhi_dev/mhi.c:		ch->ring = &mhi_ctx->ring[chan_id + mhi_ctx->ch_ring_start];
drivers/platform/msm/mhi_dev/mhi.c:	mutex_lock(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:	if (atomic_read(&mhi_ctx->is_suspended)) {
drivers/platform/msm/mhi_dev/mhi.c:			mutex_unlock(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:	atomic_inc(&mhi_ctx->write_active);
drivers/platform/msm/mhi_dev/mhi.c:	while (atomic_read(&mhi_ctx->is_suspended) &&
drivers/platform/msm/mhi_dev/mhi.c:	atomic_dec(&mhi_ctx->write_active);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_unlock(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:				&mhi_ctx->ifc_id);
drivers/platform/msm/mhi_dev/mhi.c:				&mhi_ctx->mhi_ep_msi_num);
drivers/platform/msm/mhi_dev/mhi.c:				&mhi_ctx->mhi_version);
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->phandle = ep_pcie_get_phandle(mhi_ctx->ifc_id);
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->phandle) {
drivers/platform/msm/mhi_dev/mhi.c:	if (ep_pcie_get_linkstatus(mhi_ctx->phandle) != EP_PCIE_LINK_ENABLED) {
drivers/platform/msm/mhi_dev/mhi.c:	INIT_WORK(&mhi_ctx->chdb_ctrl_work, mhi_dev_scheduler);
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->pending_ring_wq = alloc_workqueue("mhi_pending_wq",
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->pending_ring_wq) {
drivers/platform/msm/mhi_dev/mhi.c:	INIT_WORK(&mhi_ctx->pending_work, mhi_dev_process_ring_pending);
drivers/platform/msm/mhi_dev/mhi.c:	INIT_WORK(&mhi_ctx->ring_init_cb_work, mhi_dev_enable);
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->ring_init_wq = alloc_workqueue("mhi_ring_init_cb_wq",
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->ring_init_wq) {
drivers/platform/msm/mhi_dev/mhi.c:	INIT_LIST_HEAD(&mhi_ctx->event_ring_list);
drivers/platform/msm/mhi_dev/mhi.c:	INIT_LIST_HEAD(&mhi_ctx->process_ring_list);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_init(&mhi_ctx->mhi_lock);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_init(&mhi_ctx->mhi_event_lock);
drivers/platform/msm/mhi_dev/mhi.c:	mutex_init(&mhi_ctx->mhi_write_test);
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->dma_cache = dma_alloc_coherent(&pdev->dev,
drivers/platform/msm/mhi_dev/mhi.c:			&mhi_ctx->cache_dma_handle, GFP_KERNEL);
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->dma_cache)
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->read_handle = dma_alloc_coherent(&pdev->dev,
drivers/platform/msm/mhi_dev/mhi.c:			&mhi_ctx->read_dma_handle,
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->read_handle)
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->write_handle = dma_alloc_coherent(&pdev->dev,
drivers/platform/msm/mhi_dev/mhi.c:			&mhi_ctx->write_dma_handle,
drivers/platform/msm/mhi_dev/mhi.c:	if (!mhi_ctx->write_handle)
drivers/platform/msm/mhi_dev/mhi.c:	rc = mhi_dev_mmio_write(mhi_ctx, MHIVER, mhi_ctx->mhi_version);
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->event_reg.events = EP_PCIE_EVENT_PM_D3_HOT |
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->event_reg.user = mhi_ctx;
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->event_reg.mode = EP_PCIE_TRIGGER_CALLBACK;
drivers/platform/msm/mhi_dev/mhi.c:	mhi_ctx->event_reg.callback = mhi_dev_sm_pcie_handler;
drivers/platform/msm/mhi_dev/mhi.c:	rc = ep_pcie_register_event(mhi_ctx->phandle, &mhi_ctx->event_reg);
drivers/platform/msm/mhi_dev/mhi_sm.c:	struct mhi_dev *dev = mhi_sm_ctx->mhi_dev;
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->mhi_state = state;
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = (mhi_sm_ctx->d_state == MHI_SM_EP_PCIE_D0_STATE &&
drivers/platform/msm/mhi_dev/mhi_sm.c:	old_state = mhi_sm_ctx->mhi_state;
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = mhi_dev_config_outbound_iatu(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_get_msi_config(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = mhi_pcie_config_db_routing(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:	res = mhi_dev_send_state_change_event(mhi_sm_ctx->mhi_dev,
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = mhi_dev_send_ee_event(mhi_sm_ctx->mhi_dev, 2);
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = mhi_dev_resume(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:	old_state = mhi_sm_ctx->mhi_state;
drivers/platform/msm/mhi_dev/mhi_sm.c:	res = mhi_dev_suspend(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:	res = mhi_dev_send_state_change_event(mhi_sm_ctx->mhi_dev,
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->mhi_state == MHI_DEV_M3_STATE) {
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_wakeup_host(mhi_sm_ctx->mhi_dev->phandle);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_mstate_str(mhi_sm_ctx->mhi_state),
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_dstate_str(mhi_sm_ctx->d_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->mhi_state == MHI_DEV_SYSERR_STATE) {
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->syserr_occurred = true;
drivers/platform/msm/mhi_dev/mhi_sm.c:	link_status = ep_pcie_get_linkstatus(mhi_sm_ctx->mhi_dev->phandle);
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_enable_endpoint(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_dev_restore_mmio(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_enable_endpoint(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:	res = mhi_dev_send_state_change_event(mhi_sm_ctx->mhi_dev,
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_lock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_mstate_str(mhi_sm_ctx->mhi_state),
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_dstate_str(mhi_sm_ctx->d_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->syserr_occurred) {
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (!mhi_sm_is_legal_event_on_state(mhi_sm_ctx->mhi_state,
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_mstate_str(mhi_sm_ctx->mhi_state),
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_dstate_str(mhi_sm_ctx->d_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_unlock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_dec(&mhi_sm_ctx->pending_device_events);
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_lock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	old_dstate = mhi_sm_ctx->d_state;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_mstate_str(mhi_sm_ctx->mhi_state),
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->syserr_occurred &&
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (!mhi_sm_is_legal_pcie_event_on_state(mhi_sm_ctx->mhi_state,
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_mstate_str(mhi_sm_ctx->mhi_state),
drivers/platform/msm/mhi_dev/mhi_sm.c:		if (mhi_sm_ctx->d_state == MHI_SM_EP_PCIE_LINK_DISABLE)
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D0_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D3_HOT_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:		ep_pcie_disable_endpoint(mhi_sm_ctx->mhi_dev->phandle);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D3_COLD_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_enable_endpoint(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_dev_restore_mmio(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:		res = ep_pcie_enable_endpoint(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D0_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D0_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_unlock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_dec(&mhi_sm_ctx->pending_pcie_events);
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->mhi_sm_wq = create_singlethread_workqueue("mhi_sm_wq");
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (!mhi_sm_ctx->mhi_sm_wq) {
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_init(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->mhi_dev = mhi_dev;
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->mhi_state = MHI_DEV_RESET_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_sm_ctx->syserr_occurred = false;
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_set(&mhi_sm_ctx->pending_device_events, 0);
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_set(&mhi_sm_ctx->pending_pcie_events, 0);
drivers/platform/msm/mhi_dev/mhi_sm.c:	link_state = ep_pcie_get_linkstatus(mhi_sm_ctx->mhi_dev->phandle);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D0_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_LINK_DISABLE;
drivers/platform/msm/mhi_dev/mhi_sm.c:	*state = mhi_sm_ctx->mhi_state;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_dstate_str(mhi_sm_ctx->d_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_lock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->mhi_state != MHI_DEV_RESET_STATE) {
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_mstate_str(mhi_sm_ctx->mhi_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:	if (mhi_sm_ctx->d_state != MHI_SM_EP_PCIE_D0_STATE) {
drivers/platform/msm/mhi_dev/mhi_sm.c:		if (ep_pcie_get_linkstatus(mhi_sm_ctx->mhi_dev->phandle) ==
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->d_state = MHI_SM_EP_PCIE_D0_STATE;
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_dev_mmio_masked_read(mhi_sm_ctx->mhi_dev,
drivers/platform/msm/mhi_dev/mhi_sm.c:	mhi_dev_mmio_masked_read(mhi_sm_ctx->mhi_dev, MHISTATUS,
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_unlock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.m0_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.m3_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.hw_acc_wakeup_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.mhi_core_wakeup_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_inc(&mhi_sm_ctx->pending_device_events);
drivers/platform/msm/mhi_dev/mhi_sm.c:	queue_work(mhi_sm_ctx->mhi_sm_wq, &state_change_event->work);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.linkup_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.d3_cold_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.d3_hot_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_dev_backup_mmio(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.rst_deast_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.d0_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->stats.linkdown_event_cnt++;
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_sm_ctx->syserr_occurred = true;
drivers/platform/msm/mhi_dev/mhi_sm.c:		ep_pcie_mask_irq_event(mhi_sm_ctx->mhi_dev->phandle,
drivers/platform/msm/mhi_dev/mhi_sm.c:		mhi_dev_notify_a7_event(mhi_sm_ctx->mhi_dev);
drivers/platform/msm/mhi_dev/mhi_sm.c:	queue_work(mhi_sm_ctx->mhi_sm_wq, &dstate_change_evt->work);
drivers/platform/msm/mhi_dev/mhi_sm.c:	atomic_inc(&mhi_sm_ctx->pending_pcie_events);
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_lock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:	mutex_unlock(&mhi_sm_ctx->mhi_state_lock);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_dstate_str(mhi_sm_ctx->d_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_mstate_str(mhi_sm_ctx->mhi_state));
drivers/platform/msm/mhi_dev/mhi_sm.c:			atomic_read(&mhi_sm_ctx->pending_device_events));
drivers/platform/msm/mhi_dev/mhi_sm.c:			atomic_read(&mhi_sm_ctx->pending_pcie_events));
drivers/platform/msm/mhi_dev/mhi_sm.c:			"M0 events: %d\n", mhi_sm_ctx->stats.m0_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			"M3 events: %d\n", mhi_sm_ctx->stats.m3_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.hw_acc_wakeup_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.mhi_core_wakeup_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.linkup_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.rst_deast_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.d0_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.d3_hot_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.d3_cold_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:			mhi_sm_ctx->stats.linkdown_event_cnt);
drivers/platform/msm/mhi_dev/mhi_sm.c:		if (atomic_read(&mhi_sm_ctx->pending_device_events) ||
drivers/platform/msm/mhi_dev/mhi_sm.c:			atomic_read(&mhi_sm_ctx->pending_pcie_events))
drivers/platform/msm/mhi_dev/mhi_sm.c:		memset(&mhi_sm_ctx->stats, 0, sizeof(struct mhi_sm_stats));
drivers/platform/msm/mhi_dev/mhi_ring.c:	rbase = ring->ring_ctx->generic.rbase;
drivers/platform/msm/mhi_dev/mhi_ring.c:	return ring->ring_ctx->generic.rlen/
drivers/platform/msm/mhi_dev/mhi_ring.c:	if (ring->id >= mhi_ctx->ev_ring_start &&
drivers/platform/msm/mhi_dev/mhi_ring.c:		ring->id < (mhi_ctx->ev_ring_start +
drivers/platform/msm/mhi_dev/mhi_ring.c:				mhi_ctx->cfg.event_rings)) {
drivers/platform/msm/mhi_dev/mhi_ring.c:	ring->ring_ctx->generic.rp = (ring->rd_offset *
drivers/platform/msm/mhi_dev/mhi_ring.c:				ring->ring_ctx->generic.rbase;
drivers/platform/msm/mhi_dev/mhi_ring.c:					ring->ring_ctx->generic.rp);
drivers/platform/msm/mhi_dev/mhi_ring.c:					ring->ring_ctx->generic.rp);
drivers/platform/msm/mhi_dev/mhi_ring.c:					ring->ring_ctx->generic.wp);
drivers/platform/msm/mhi_dev/mhi_ring.c:	offset = (uint32_t)(ring->ring_ctx->generic.rbase -
drivers/platform/msm/mhi_dev/mhi_ring.c:			(uint32_t)ring->ring_ctx->generic.rbase,
drivers/platform/msm/mhi_dev/mhi_ring.c:			(uint32_t)ring->ring_ctx->generic.rp,
drivers/platform/msm/mhi_dev/mhi_ring.c:			(uint32_t)ring->ring_ctx->generic.wp);
drivers/platform/msm/usb_bam.c:	for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:			pipe = ctx->usb_bam_sps.sps_pipes[i];
drivers/platform/msm/usb_bam.c:	timer_ctrl.timeout_msec = ctx->inactivity_timer_ms;
drivers/platform/msm/usb_bam.c:	struct device *dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:				ctx->usb_bam_data->usb_bam_fifo_baseaddr;
drivers/platform/msm/usb_bam.c:				ctx->usb_bam_data->usb_bam_fifo_baseaddr;
drivers/platform/msm/usb_bam.c:					&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_sps.sps_connections[idx];
drivers/platform/msm/usb_bam.c:	struct device *dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	struct usb_bam_sps_type usb_bam_sps = ctx->usb_bam_sps;
drivers/platform/msm/usb_bam.c:					&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	struct usb_bam_sps_type usb_bam_sps = ctx->usb_bam_sps;
drivers/platform/msm/usb_bam.c:					&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	struct sps_pipe *pipe = ctx->usb_bam_sps.sps_pipes[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_sps.sps_connections[idx];
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_sps.sps_pipes[idx] = NULL;
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (ctx->pipes_enabled_per_bam == 0)
drivers/platform/msm/usb_bam.c:			ctx->pipes_enabled_per_bam -= 1;
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	struct usb_bam_sps_type usb_bam_sps = ctx->usb_bam_sps;
drivers/platform/msm/usb_bam.c:	pipe = ctx->usb_bam_sps.sps_pipes[idx];
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:		sps_get_bam_debug_info(ctx->h_bam, 93,
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (ctx->pipes_enabled_per_bam == 0)
drivers/platform/msm/usb_bam.c:			ctx->pipes_enabled_per_bam -= 1;
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:					&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	struct device *bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	if (idx < 0 || idx > ctx->max_connections) {
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if ((ctx->usb_bam_data->reset_on_connect == true) &&
drivers/platform/msm/usb_bam.c:			    (ctx->pipes_enabled_per_bam == 0)) {
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		sps_device_reset(ctx->h_bam);
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	ctx->pipes_enabled_per_bam += 1;
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		&ctx->usb_bam_sps.sps_connections[idx];
drivers/platform/msm/usb_bam.c:	u32 idx = ARRAY_INDEX_FROM_ADDR(ctx->usb_bam_connections, pipe_connect);
drivers/platform/msm/usb_bam.c:	struct sps_pipe *pipe = ctx->usb_bam_sps.sps_pipes[idx];
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:			  idx, get_pm_runtime_counter(&ctx->usb_bam_pdev->dev));
drivers/platform/msm/usb_bam.c:		pm_runtime_get(&ctx->usb_bam_pdev->dev);
drivers/platform/msm/usb_bam.c:			ctx->pipes_enabled_per_bam);
drivers/platform/msm/usb_bam.c:	return info[cur_bam].pipes_suspended == ctx->pipes_enabled_per_bam;
drivers/platform/msm/usb_bam.c:	struct device *bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:		cons_pipe = ctx->usb_bam_sps.sps_pipes[dst_idx];
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:			pm_runtime_put(&ctx->usb_bam_pdev->dev);
drivers/platform/msm/usb_bam.c:	if (info[cur_bam].pipes_suspended == ctx->pipes_enabled_per_bam &&
drivers/platform/msm/usb_bam.c:		for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:			pipe_iter = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (ctx->pipes_enabled_per_bam &&
drivers/platform/msm/usb_bam.c:		if (ctx->pipes_enabled_per_bam && !host_info[cur_bam].in_lpm)
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (!ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			queue_work(ctx->usb_bam_wq,
drivers/platform/msm/usb_bam.c:					 = &ctx->usb_bam_data->bam_type;
drivers/platform/msm/usb_bam.c:	prod_pipe_connect = &ctx->usb_bam_connections[src_idx];
drivers/platform/msm/usb_bam.c:	cons_pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:	prod_pipe = ctx->usb_bam_sps.sps_pipes[src_idx];
drivers/platform/msm/usb_bam.c:	cons_pipe = ctx->usb_bam_sps.sps_pipes[dst_idx];
drivers/platform/msm/usb_bam.c:	if (src_idx >= ctx->max_connections ||
drivers/platform/msm/usb_bam.c:				dst_idx >= ctx->max_connections) {
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[src_idx];
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:	if (info[cur_bam].pipes_to_suspend * 2 == ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:	bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:		pm_runtime_get(&ctx->usb_bam_pdev->dev);
drivers/platform/msm/usb_bam.c:	if (info[cur_bam].pipes_resumed == ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:	pm_runtime_put(&ctx->usb_bam_pdev->dev);
drivers/platform/msm/usb_bam.c:	if (src_idx >= ctx->max_connections ||
drivers/platform/msm/usb_bam.c:			dst_idx >= ctx->max_connections) {
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[src_idx];
drivers/platform/msm/usb_bam.c:	queue_work(ctx->usb_bam_wq, &info[cur_bam].resume_work);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	ctx->is_bam_inactivity = false;
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (ctx->inactivity_timer_ms)
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	    ctx->is_bam_inactivity && info[bam_type].in_lpm) {
drivers/platform/msm/usb_bam.c:			spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:			pipe_iter = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			  ctx->is_bam_inactivity, info[bam_type].cur_cons_state,
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			ctx->usb_bam_data->max_mbps_superspeed;
drivers/platform/msm/usb_bam.c:			ctx->usb_bam_data->max_mbps_highspeed;
drivers/platform/msm/usb_bam.c:	struct device *bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	if (idx >= ctx->max_connections) {
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (ctx->pipes_enabled_per_bam == 0) {
drivers/platform/msm/usb_bam.c:			spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (ctx->usb_bam_data->reset_on_connect &&
drivers/platform/msm/usb_bam.c:		!ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		sps_device_reset(ctx->h_bam);
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (!ctx->pipes_enabled_per_bam)
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (!ctx->pipes_enabled_per_bam && ctx->inactivity_timer_ms &&
drivers/platform/msm/usb_bam.c:	ctx->pipes_enabled_per_bam += 1;
drivers/platform/msm/usb_bam.c:	if (ctx->pipes_enabled_per_bam >= 2 &&
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			 &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	if (idx >= ctx->max_connections) {
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		if (ctx->inactivity_timer_ms)
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:			pipe_iter = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		queue_work(ctx->usb_bam_wq, &event_info->event_w);
drivers/platform/msm/usb_bam.c:			ctx->is_bam_inactivity) {
drivers/platform/msm/usb_bam.c:		ctx->is_bam_inactivity = false;
drivers/platform/msm/usb_bam.c:		queue_work(ctx->usb_bam_wq, &event_info->event_w);
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (idx < 0 || idx > ctx->max_connections) {
drivers/platform/msm/usb_bam.c:	pipe = ctx->usb_bam_sps.sps_pipes[idx];
drivers/platform/msm/usb_bam.c:	sps_connection = &ctx->usb_bam_sps.sps_connections[idx];
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:				&ctx->usb_bam_connections[dst_idx];
drivers/platform/msm/usb_bam.c:	struct device *bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (!ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:		ctx->pipes_enabled_per_bam -= 1;
drivers/platform/msm/usb_bam.c:	spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	if (ctx->usb_bam_data->reset_on_disconnect
drivers/platform/msm/usb_bam.c:				&& !ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:		sps_device_reset(ctx->h_bam);
drivers/platform/msm/usb_bam.c:	struct device *bam_dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	pipe_connect = &ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	if (!ctx->pipes_enabled_per_bam) {
drivers/platform/msm/usb_bam.c:			pm_runtime_put_sync(&ctx->usb_bam_pdev->dev);
drivers/platform/msm/usb_bam.c:		spin_lock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:		ctx->is_bam_inactivity = true;
drivers/platform/msm/usb_bam.c:		for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:			pipe_connect = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:				queue_work(ctx->usb_bam_wq,
drivers/platform/msm/usb_bam.c:		spin_unlock(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:	enum usb_ctrl bam_type = ctx->usb_bam_data->bam_type;
drivers/platform/msm/usb_bam.c:	props.phys_addr = ctx->io_res->start;
drivers/platform/msm/usb_bam.c:	props.virt_size = resource_size(ctx->io_res);
drivers/platform/msm/usb_bam.c:	props.irq = ctx->irq;
drivers/platform/msm/usb_bam.c:	props.summing_threshold = ctx->usb_bam_data->override_threshold;
drivers/platform/msm/usb_bam.c:	props.event_threshold = ctx->usb_bam_data->override_threshold;
drivers/platform/msm/usb_bam.c:	props.num_pipes = ctx->usb_bam_data->usb_bam_num_pipes;
drivers/platform/msm/usb_bam.c:	if (ctx->usb_bam_data->ignore_core_reset_ack && bam_type != DWC3_CTRL)
drivers/platform/msm/usb_bam.c:	if (ctx->usb_bam_data->disable_clk_gating)
drivers/platform/msm/usb_bam.c:	if (ctx->usb_bam_data->enable_hsusb_bam_on_boot
drivers/platform/msm/usb_bam.c:	dev = &ctx->usb_bam_pdev->dev;
drivers/platform/msm/usb_bam.c:	ret = sps_register_bam_device(&props, &ctx->h_bam);
drivers/platform/msm/usb_bam.c:	enum usb_ctrl bam_type = ctx->usb_bam_data->bam_type;
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_sps.sps_pipes = devm_kzalloc(&pdev->dev,
drivers/platform/msm/usb_bam.c:		ctx->max_connections * sizeof(struct sps_pipe *),
drivers/platform/msm/usb_bam.c:	if (!ctx->usb_bam_sps.sps_pipes) {
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_sps.sps_connections = devm_kzalloc(&pdev->dev,
drivers/platform/msm/usb_bam.c:		ctx->max_connections * sizeof(struct sps_connect),
drivers/platform/msm/usb_bam.c:	if (!ctx->usb_bam_sps.sps_connections) {
drivers/platform/msm/usb_bam.c:		if (ctx->h_bam)
drivers/platform/msm/usb_bam.c:	if (!ctx->pipes_enabled_per_bam || info[i].pipes_suspended)
drivers/platform/msm/usb_bam.c:	sps_get_bam_debug_info(ctx->h_bam, 93,
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_pdev = pdev;
drivers/platform/msm/usb_bam.c:	ctx->irq = irq;
drivers/platform/msm/usb_bam.c:	ctx->io_res = io_res;
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_data = usb_bam_data;
drivers/platform/msm/usb_bam.c:	for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:		ctx->usb_bam_connections[i].enabled = 0;
drivers/platform/msm/usb_bam.c:		INIT_WORK(&ctx->usb_bam_connections[i].event.event_w,
drivers/platform/msm/usb_bam.c:	ctx->usb_bam_wq = alloc_workqueue("usb_bam_wq",
drivers/platform/msm/usb_bam.c:	if (!ctx->usb_bam_wq) {
drivers/platform/msm/usb_bam.c:		destroy_workqueue(ctx->usb_bam_wq);
drivers/platform/msm/usb_bam.c:	spin_lock_init(&ctx->usb_bam_lock);
drivers/platform/msm/usb_bam.c:			&ctx->usb_bam_connections[idx];
drivers/platform/msm/usb_bam.c:	sps_connection = &ctx->usb_bam_sps.sps_connections[idx];
drivers/platform/msm/usb_bam.c:	for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:		if (ctx->usb_bam_connections[i].peer_bam == client &&
drivers/platform/msm/usb_bam.c:		    ctx->usb_bam_connections[i].dir == dir &&
drivers/platform/msm/usb_bam.c:		    ctx->usb_bam_connections[i].bam_mode == bam_mode &&
drivers/platform/msm/usb_bam.c:		    ctx->usb_bam_connections[i].pipe_num == num) {
drivers/platform/msm/usb_bam.c:	if (!ctx->usb_bam_pdev)
drivers/platform/msm/usb_bam.c:	usb_bam_data = ctx->usb_bam_data;
drivers/platform/msm/usb_bam.c:	sps_device_reset(ctx->h_bam);
drivers/platform/msm/usb_bam.c:	for (i = 0; i < ctx->max_connections; i++) {
drivers/platform/msm/usb_bam.c:		pipe_connect = &ctx->usb_bam_connections[i];
drivers/platform/msm/usb_bam.c:			pipe = ctx->usb_bam_sps.sps_pipes[i];
drivers/platform/msm/usb_bam.c:	usb_bam_ipa_delete_resources(ctx->usb_bam_data->bam_type);
drivers/platform/msm/usb_bam.c:	sps_deregister_bam_device(ctx->h_bam);
drivers/platform/msm/usb_bam.c:	destroy_workqueue(ctx->usb_bam_wq);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	file = write_work_ctx->file;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	write_work_ctx->file = file;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	INIT_WORK(&write_work_ctx->dbgfs_work,
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	queue_work(ipa_ut_ctx->wq, &write_work_ctx->dbgfs_work);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	file = write_work_ctx->file;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	write_work_ctx->file = file;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	INIT_WORK(&write_work_ctx->dbgfs_work,
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	queue_work(ipa_ut_ctx->wq, &write_work_ctx->dbgfs_work);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:			ipa_ut_ctx->test_dbgfs_suites);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (ipa_ut_ctx->enabled) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->test_dbgfs_suites = debugfs_create_dir("suites",
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		ipa_ut_ctx->test_dbgfs_root);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (!ipa_ut_ctx->test_dbgfs_suites ||
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		IS_ERR(ipa_ut_ctx->test_dbgfs_suites)) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->enabled = true;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	debugfs_remove_recursive(ipa_ut_ctx->test_dbgfs_suites);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (!ipa_ut_ctx->enabled) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	debugfs_remove_recursive(ipa_ut_ctx->test_dbgfs_suites);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->enabled = false;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	status = ipa_ut_ctx->enabled ?
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->ipa_dbgfs_root = ipa_debugfs_get_root();
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (!ipa_ut_ctx->ipa_dbgfs_root) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->wq = create_singlethread_workqueue("ipa_ut_dbgfs");
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (!ipa_ut_ctx->wq) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->test_dbgfs_root = debugfs_create_dir("test",
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		ipa_ut_ctx->ipa_dbgfs_root);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (!ipa_ut_ctx->test_dbgfs_root ||
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		IS_ERR(ipa_ut_ctx->test_dbgfs_root)) {
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		ipa_ut_ctx->test_dbgfs_root, 0, &ipa_ut_dbgfs_enable_fops);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	ipa_ut_ctx->inited = true;
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	debugfs_remove_recursive(ipa_ut_ctx->test_dbgfs_root);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_lock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	destroy_workqueue(ipa_ut_ctx->wq);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (ipa_ut_ctx->enabled)
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	if (ipa_ut_ctx->inited)
drivers/platform/msm/ipa/test/ipa_ut_framework.c:		debugfs_remove_recursive(ipa_ut_ctx->test_dbgfs_root);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_unlock(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_ut_framework.c:	mutex_init(&ipa_ut_ctx->lock);
drivers/platform/msm/ipa/test/ipa_test_dma.c:	src->base = dma_alloc_coherent(ipa3_ctx->pdev, src->size,
drivers/platform/msm/ipa/test/ipa_test_dma.c:	dest->base = dma_alloc_coherent(ipa3_ctx->pdev, dest->size,
drivers/platform/msm/ipa/test/ipa_test_dma.c:	dma_free_coherent(ipa3_ctx->pdev, dest->size, dest->base,
drivers/platform/msm/ipa/test/ipa_test_dma.c:	dma_free_coherent(ipa3_ctx->pdev, src->size, src->base,
drivers/platform/msm/ipa/test/ipa_test_dma.c:	dma_free_coherent(ipa3_ctx->pdev, src->size, src->base,
drivers/platform/msm/ipa/test/ipa_test_dma.c:	dma_free_coherent(ipa3_ctx->pdev, dest->size, dest->base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			if (*((u32 *)test_mhi_ctx->msi.base) ==		\
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			if (__both && (*((u32 *)test_mhi_ctx->msi.base) == \
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, test_mhi_ctx->mmio_buf.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->mmio_buf.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->mmio_buf.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, test_mhi_ctx->ev_ctx_array.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ctx_array.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, test_mhi_ctx->ch_ctx_array.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ch_ctx_array.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, test_mhi_ctx->msi.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->msi.base, test_mhi_ctx->msi.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	msi = &test_mhi_ctx->msi;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ch_ctx_array = &test_mhi_ctx->ch_ctx_array;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ev_ctx_array = &test_mhi_ctx->ev_ctx_array;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	mmio_buf = &test_mhi_ctx->mmio_buf;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	msi->base = dma_alloc_coherent(ipa3_ctx->pdev, msi->size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ch_ctx_array->base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ev_ctx_array->base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	mmio_buf->base = dma_alloc_coherent(ipa3_ctx->pdev, mmio_buf->size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, ev_ctx_array->size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, ch_ctx_array->size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, msi->size, msi->base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (test_mhi_ctx->out_buffer.base) {
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->out_buffer.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->out_buffer.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->out_buffer.base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (test_mhi_ctx->in_buffer.base) {
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->in_buffer.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->in_buffer.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->in_buffer.base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->in_buffer.size = IPA_MHI_TEST_MAX_DATA_BUF_SIZE;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->in_buffer.base = dma_alloc_coherent(
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ipa3_ctx->pdev, test_mhi_ctx->in_buffer.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer.phys_base, GFP_KERNEL);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (!test_mhi_ctx->in_buffer.base) {
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->in_buffer.base, 0,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->out_buffer.size = IPA_MHI_TEST_MAX_DATA_BUF_SIZE;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->out_buffer.base = dma_alloc_coherent(
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ipa3_ctx->pdev, test_mhi_ctx->out_buffer.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->out_buffer.phys_base, GFP_KERNEL);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (!test_mhi_ctx->out_buffer.base) {
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->out_buffer.base, 0,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->in_buffer.size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->in_buffer.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->in_buffer.base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->gsi_mmio = ioremap_nocache(gsi_ctx->per.phys_addr,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		gsi_ctx->per.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			gsi_ctx->per.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (ipa_setup_sys_pipe(&sys_in, &test_mhi_ctx->test_prod_hdl)) {
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	iounmap(test_mhi_ctx->gsi_mmio);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ipa_teardown_sys_pipe(test_mhi_ctx->test_prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	iounmap(test_mhi_ctx->gsi_mmio);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = test_mhi_ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	init_params.msi.addr_low = test_mhi_ctx->msi.phys_base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			&test_mhi_ctx->prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			&test_mhi_ctx->cons_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ctx->prod_hdl = 0;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ctx->cons_hdl = 0;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, ctx->xfer_ring_bufs[1].size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->xfer_ring_bufs[1].base, ctx->xfer_ring_bufs[1].phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ctx->xfer_ring_bufs[1].base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, ctx->xfer_ring_bufs[0].size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->xfer_ring_bufs[0].base, ctx->xfer_ring_bufs[0].phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ctx->xfer_ring_bufs[0].base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = test_mhi_ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->cons_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_disconnect_pipe(test_mhi_ctx->cons_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->cons_hdl = 0;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs[1].size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs[1].base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs[1].phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->xfer_ring_bufs[1].base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_disconnect_pipe(test_mhi_ctx->prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->prod_hdl = 0;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, test_mhi_ctx->xfer_ring_bufs[0].size,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs[0].base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs[0].phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	test_mhi_ctx->xfer_ring_bufs[0].base = NULL;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_connect_pipe(&prod_params, &test_mhi_ctx->prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_connect_pipe(&cons_params, &test_mhi_ctx->cons_hdl);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&(gsi_ctx->per.phys_addr), GSI_EE_n_EV_CH_k_DOORBELL_0_OFFS(
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			event_ring_index + ipa3_ctx->mhi_evid_limits[0], 0));
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->gsi_mmio +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			event_ring_index + ipa3_ctx->mhi_evid_limits[0], 0));
drivers/platform/msm/ipa/test/ipa_test_mhi.c:					, &(gsi_ctx->per.phys_addr)
drivers/platform/msm/ipa/test/ipa_test_mhi.c:					test_mhi_ctx->gsi_mmio +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = &test_mhi_ctx->mmio_buf;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->in_buffer.base, 0,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->out_buffer.base + i, (val + i) & 0xFF, 1);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->out_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			*((u32 *)test_mhi_ctx->msi.base));
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (memcmp(test_mhi_ctx->in_buffer.base, test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = test_mhi_ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = test_mhi_ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->in_buffer.base, 0, IPA_MHI_TEST_MAX_DATA_BUF_SIZE);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->out_buffer.base + i, i & 0xFF, 1);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->out_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (memcmp(test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa3_cfg_ep_aggr(test_mhi_ctx->cons_hdl, &ep_aggr);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->out_buffer.base + i, i & 0xFF, 1);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	ipahal_write_reg(IPA_AGGR_FORCE_CLOSE, (1 << test_mhi_ctx->cons_hdl));
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (memcmp(test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa3_cfg_ep_aggr(test_mhi_ctx->cons_hdl, &ep_aggr);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->in_buffer.base, 0, IPA_MHI_TEST_MAX_DATA_BUF_SIZE);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->out_buffer.base + i, i & 0xFF, 1);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	if (memcmp(test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->out_buffer.base + i, i & 0xFF, 1);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			&test_mhi_ctx->out_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			if (*((u32 *)test_mhi_ctx->msi.base) ==
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->in_buffer.base, 0,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		if (memcmp(test_mhi_ctx->in_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:			test_mhi_ctx->out_buffer.base,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_mmio = test_mhi_ctx->mmio_buf.base;
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	p_ch_ctx_array = test_mhi_ctx->ch_ctx_array.base +
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		(phys_addr - test_mhi_ctx->ch_ctx_array.phys_base);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa3_cfg_ep_aggr(test_mhi_ctx->cons_hdl, &ep_aggr);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	memset(test_mhi_ctx->msi.base, 0xFF, test_mhi_ctx->msi.size);
drivers/platform/msm/ipa/test/ipa_test_mhi.c:	rc = ipa_mhi_test_q_transfer_re(&test_mhi_ctx->mmio_buf,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->xfer_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		test_mhi_ctx->ev_ring_bufs,
drivers/platform/msm/ipa/test/ipa_test_mhi.c:		&test_mhi_ctx->in_buffer,
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:		vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	vote = atomic_read(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/test/ipa_pm_ut.c:	 idx = ipa3_ctx->ipa3_active_clients.bus_vote_idx;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		atomic_dec(&ctx->odu_pending);
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		if (atomic_read(&ctx->odu_pending) >= 64)
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		atomic_inc(&ctx->odu_pending);
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		&ctx->odu_prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		&ctx->odu_cons_hdl);
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:		ipa_teardown_sys_pipe(ctx->odu_prod_hdl);
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	ctx->rt4_usb = rt_lookup.hdl;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	ctx->rt6_usb = rt_lookup.hdl;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	ctx->rt4_odu_cons = rt_lookup.hdl;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	ctx->rt6_odu_cons = rt_lookup.hdl;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	flt_rule->rules[0].rule.rt_tbl_hdl = ctx->rt4_odu_cons;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	flt_rule->rules[0].rule.rt_tbl_hdl = ctx->rt6_odu_cons;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	flt_rule->rules[0].rule.rt_tbl_hdl = ctx->rt4_usb;
drivers/platform/msm/ipa/test/ipa_test_hw_stats.c:	flt_rule->rules[0].rule.rt_tbl_hdl = ctx->rt6_usb;
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:			IPA_IPC_LOGGING(ipa3_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v3/ipa_i.h:#define IPA_MEM_PART(x_) (ipa3_ctx->ctrl->mem_partition.x_)
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		if ((ep_suspend_data & bmsk) && (ipa3_ctx->ep[i].valid))
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		if (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_1) {
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		if (ipa3_ctx->apply_rg10_wa) {
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:			if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:				ipa3_ctx->uc_ctx.uc_failed = true;
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		if (ipa3_ctx->apply_rg10_wa && ipa3_ctx->uc_ctx.uc_failed)
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		queue_work(ipa3_ctx->power_mgmt_wq, &ipa3_interrupt_defer_work);
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		(ipa3_ctx->ipa_hw_type >= IPA_HW_v3_1)) {
drivers/platform/msm/ipa/ipa_v3/ipa_interrupts.c:		(ipa3_ctx->ipa_hw_type >= IPA_HW_v3_1)) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	#x "=0x%x\n", ipa3_uc_mhi_ctx->mhi_uc_stats_mmio->mhiCmnStats.x))
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	#x "=0x%x\n", ipa3_uc_mhi_ctx->mhi_uc_stats_mmio->mhiCnlStats[ch].x))
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (uc_sram_mmio->responseOp == ipa3_uc_mhi_ctx->expected_responseOp &&
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	    ipa3_uc_mhi_ctx->expected_responseParams) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	} else if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		ipa3_uc_mhi_ctx->wakeup_request_cb();
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->mhi_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	IPAERR("MHI stats ofst=0x%x\n", ipa3_uc_mhi_ctx->mhi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (ipa3_uc_mhi_ctx->mhi_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		ipa3_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:			ipa3_uc_mhi_ctx->mhi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->mhi_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		ioremap(ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		ipa3_uc_mhi_ctx->mhi_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (!ipa3_uc_mhi_ctx->mhi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->ready_cb = ready_cb;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->wakeup_request_cb = wakeup_request_cb;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	hdlrs.ipa_uc_loaded_hdlr = ipa3_uc_mhi_ctx->ready_cb;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:		dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (ipa_ep_idx < 0  || ipa_ep_idx >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	ipa3_uc_mhi_ctx->expected_responseParams = cmd.raw32b;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_mhi.c:	if (!ipa3_uc_mhi_ctx->mhi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	cmd.base = dma_alloc_coherent(ipa3_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_rx = &ipa3_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_tx = &ipa3_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	out->rx_uc_db_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	out->tx_uc_db_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	cmd.base = dma_alloc_coherent(ipa3_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_tx = &ipa3_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_rx = &ipa3_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_tx = &ipa3_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_rx = &ipa3_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_tx = &ipa3_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v3/ipa_wdi3_i.c:	ep_rx = &ipa3_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->ipa3_active_clients_logging.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	start_idx = (ipa3_ctx->ipa3_active_clients_logging.log_tail + 1) %
drivers/platform/msm/ipa/ipa_v3/ipa.c:	end_idx = ipa3_ctx->ipa3_active_clients_logging.log_head;
drivers/platform/msm/ipa/ipa_v3/ipa.c:				ipa3_ctx->ipa3_active_clients_logging
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->ipa3_active_clients_logging.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	hash_for_each(ipa3_ctx->ipa3_active_clients_logging.htable, i,
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->ipa3_active_clients_logging.log_rdy)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	head = ipa3_ctx->ipa3_active_clients_logging.log_head;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	tail = ipa3_ctx->ipa3_active_clients_logging.log_tail;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	memset(ipa3_ctx->ipa3_active_clients_logging.log_buffer[head], '_',
drivers/platform/msm/ipa/ipa_v3/ipa.c:	strlcpy(ipa3_ctx->ipa3_active_clients_logging.log_buffer[head], string,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_tail = tail;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_head = head;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->ipa3_active_clients_logging.lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_buffer[0] = kzalloc(
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa3_active_clients_logging.log_buffer == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ipa3_active_clients_logging.log_buffer[i] =
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa3_active_clients_logging.log_buffer[0] +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	hash_init(ipa3_ctx->ipa3_active_clients_logging.htable);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_rdy = 1;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->ipa3_active_clients_logging.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->ipa3_active_clients_logging.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_rdy = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kfree(ipa3_ctx->ipa3_active_clients_logging.log_buffer[0]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	return ipa3_ctx->pdev;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		mutex_lock(&ipa3_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		memcpy(&ipa3_ctx->ipa_cne_evt_req_cache[
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->num_ipa_cne_evt_req].wan_msg,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		memcpy(&ipa3_ctx->ipa_cne_evt_req_cache[
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->num_ipa_cne_evt_req].msg_meta,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->num_ipa_cne_evt_req++;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->num_ipa_cne_evt_req %= IPA_MAX_NUM_REQ_CACHE;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		mutex_unlock(&ipa3_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		wait_for_completion(&ipa3_ctx->init_completion_obj);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		memcpy(param, &ipa3_ctx->ipa_hw_type, pyld_sz);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rt_rule_entry->rule.hdr_hdl = ipa3_ctx->excp_hdr_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->dflt_v4_rt_rule_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->dflt_v6_rt_rule_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->excp_hdr_hdl = hdr_entry->hdr_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	route.route_def_hdr_table = !ipa3_ctx->hdr_tbl_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa.c:			if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	desc = kcalloc(ipa3_ctx->ep_flt_num, sizeof(struct ipa3_desc),
drivers/platform/msm/ipa/ipa_v3/ipa.c:	cmd_pyld = kcalloc(ipa3_ctx->ep_flt_num,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (pipe_idx = 0; pipe_idx < ipa3_ctx->ipa_num_pipes; pipe_idx++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (!ipa3_ctx->ep[pipe_idx].valid ||
drivers/platform/msm/ipa/ipa_v3/ipa.c:		    ipa3_ctx->ep[pipe_idx].skip_ep_cfg) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			if (num_cmds >= ipa3_ctx->ep_flt_num) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:				ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	desc = kcalloc(ipa3_ctx->ipa_num_pipes, sizeof(struct ipa3_desc),
drivers/platform/msm/ipa/ipa_v3/ipa.c:			(ipa3_ctx->ep[ep_idx].valid &&
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ep[ep_idx].skip_ep_cfg)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa_assert_on(num_descs >= ipa3_ctx->ipa_num_pipes);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->uc_ctx.uc_loaded) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	phys_addr = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->smem_restricted_bytes / 4);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa_sram_mmio = ioremap(phys_addr, ipa3_ctx->smem_sz);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	cmd.hdr_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	dma_cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->rt_idx_bitmap[IPA_IP_v4] |= (1 << i);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG("v4 rt bitmap 0x%lx\n", ipa3_ctx->rt_idx_bitmap[IPA_IP_v4]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v4_cmd.hash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v4_cmd.nhash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->rt_idx_bitmap[IPA_IP_v6] |= (1 << i);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG("v6 rt bitmap 0x%lx\n", ipa3_ctx->rt_idx_bitmap[IPA_IP_v6]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v6_cmd.hash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v6_cmd.nhash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rc = ipahal_flt_generate_empty_img(ipa3_ctx->ep_flt_num,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		IPA_MEM_PART(v4_flt_nhash_size), ipa3_ctx->ep_flt_bitmap,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v4_cmd.hash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v4_cmd.nhash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rc = ipahal_flt_generate_empty_img(ipa3_ctx->ep_flt_num,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		IPA_MEM_PART(v6_flt_nhash_size), ipa3_ctx->ep_flt_bitmap,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v6_cmd.hash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	v6_cmd.nhash_local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (pipe_idx = 0; pipe_idx < ipa3_ctx->ipa_num_pipes ; pipe_idx++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->gsi_ch20_wa) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_setup_sys_pipe(&sys_in, &ipa3_ctx->clnt_hdl_cmd)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_sram();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_hdr();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_rt4();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_rt6();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_flt4();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_init_flt6();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_setup_sys_pipe(&sys_in, &ipa3_ctx->clnt_hdl_data_in)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->ipa_config_is_mhi) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			&ipa3_ctx->clnt_hdl_data_out)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_teardown_sys_pipe(ipa3_ctx->clnt_hdl_data_in);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->dflt_v6_rt_rule_hdl)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		__ipa3_del_rt_rule(ipa3_ctx->dflt_v6_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->dflt_v4_rt_rule_hdl)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		__ipa3_del_rt_rule(ipa3_ctx->dflt_v4_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->excp_hdr_hdl)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		__ipa3_del_hdr(ipa3_ctx->excp_hdr_hdl, false);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_teardown_sys_pipe(ipa3_ctx->clnt_hdl_cmd);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->ipa_config_is_mhi)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_teardown_sys_pipe(ipa3_ctx->clnt_hdl_data_out);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_teardown_sys_pipe(ipa3_ctx->clnt_hdl_data_in);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	__ipa3_del_rt_rule(ipa3_ctx->dflt_v6_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	__ipa3_del_rt_rule(ipa3_ctx->dflt_v4_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	__ipa3_del_hdr(ipa3_ctx->excp_hdr_hdl, false);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_teardown_sys_pipe(ipa3_ctx->clnt_hdl_cmd);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG_LOW("curr_ipa_clk_rate=%d", ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_set_rate(ipa3_clk, ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->curr_ipa_clk_rate == ipa3_ctx->ctrl->ipa_clk_rate_svs2) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	} else if (ipa3_ctx->curr_ipa_clk_rate ==
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ctrl->ipa_clk_rate_svs) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	} else if (ipa3_ctx->curr_ipa_clk_rate ==
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ctrl->ipa_clk_rate_nominal) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	} else if (ipa3_ctx->curr_ipa_clk_rate ==
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->ipa_clk_rate_turbo) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		idx = ipa3_ctx->ctrl->msm_bus_data_ptr->num_usecases - 1;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG("curr %d idx %d\n", ipa3_ctx->curr_ipa_clk_rate, idx);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (msm_bus_scale_client_update_request(ipa3_ctx->ipa_bus_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa3_enable_clks();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa3_disable_clks();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (msm_bus_scale_client_update_request(ipa3_ctx->ipa_bus_hdl, 0))
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->ipa3_active_clients_logging.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	hash_for_each_possible(ipa3_ctx->ipa3_active_clients_logging.htable,
drivers/platform/msm/ipa/ipa_v3/ipa.c:				&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		hash_add(ipa3_ctx->ipa3_active_clients_logging.htable,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->ipa3_active_clients_logging.lock,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_inc_not_zero(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_inc_not_zero(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	atomic_inc(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_inc_not_zero(&ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!atomic_read(&ipa3_ctx->ipa3_active_clients.cnt)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_add_unless(&ipa3_ctx->ipa3_active_clients.cnt, -1, 1);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (atomic_read(&ipa3_ctx->ipa3_active_clients.cnt) == 1 &&
drivers/platform/msm/ipa/ipa_v3/ipa.c:	    ipa3_ctx->tag_process_before_gating) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->tag_process_before_gating = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		queue_work(ipa3_ctx->power_mgmt_wq, &ipa3_tag_work);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_sub_return(1, &ipa3_ctx->ipa3_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ret = atomic_add_unless(&ipa3_ctx->ipa3_active_clients.cnt, -1, 1);
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ipa3_active_clients.cnt));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	queue_work(ipa3_ctx->power_mgmt_wq,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->wakelock_ref_cnt.cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->wakelock_ref_cnt.cnt == 1)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		__pm_stay_awake(&ipa3_ctx->w_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->wakelock_ref_cnt.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_irqsave(&ipa3_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->wakelock_ref_cnt.cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->wakelock_ref_cnt.cnt);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->wakelock_ref_cnt.cnt == 0)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		__pm_relax(&ipa3_ctx->w_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_unlock_irqrestore(&ipa3_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->enable_clock_scaling)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (idx <= 0 || idx >= ipa3_ctx->ctrl->msm_bus_data_ptr->num_usecases) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_svs2;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_svs;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_nominal;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_turbo;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (clk_rate == ipa3_ctx->curr_ipa_clk_rate) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->curr_ipa_clk_rate = clk_rate;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients.bus_vote_idx = idx;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG_LOW("setting clock rate to %u\n", ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (atomic_read(&ipa3_ctx->ipa3_active_clients.cnt) > 0) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			clk_set_rate(ipa3_clk, ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (msm_bus_scale_client_update_request(ipa3_ctx->ipa_bus_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->enable_clock_scaling) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->clock_scaling_bw_threshold_turbo)
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->clock_scaling_bw_threshold_nominal)
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->clock_scaling_bw_threshold_svs)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_svs2;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_svs;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_nominal;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_turbo;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (clk_rate == ipa3_ctx->curr_ipa_clk_rate) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->curr_ipa_clk_rate = clk_rate;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	IPADBG_LOW("setting clock rate to %u\n", ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (atomic_read(&ipa3_ctx->ipa3_active_clients.cnt) > 0) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			clk_set_rate(ipa3_clk, ipa3_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (msm_bus_scale_client_update_request(ipa3_ctx->ipa_bus_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	queue_delayed_work(ipa3_ctx->transport_power_mgmt_wq,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++, bmsk = bmsk << 1) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if ((suspend_data & bmsk) && (ipa3_ctx->ep[i].valid)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			if (IPA_CLIENT_IS_APPS_CONS(ipa3_ctx->ep[i].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:				mutex_lock(&ipa3_ctx->transport_pm.
drivers/platform/msm/ipa/ipa_v3/ipa.c:					&ipa3_ctx->transport_pm.dec_clients)
drivers/platform/msm/ipa/ipa_v3/ipa.c:						ipa3_ctx->ep[i].client);
drivers/platform/msm/ipa/ipa_v3/ipa.c:					&ipa3_ctx->transport_pm.dec_clients,
drivers/platform/msm/ipa/ipa_v3/ipa.c:				mutex_unlock(&ipa3_ctx->transport_pm.
drivers/platform/msm/ipa/ipa_v3/ipa.c:					   ipa3_ctx->ep[i].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:					   ipa3_ctx->ep[i].client, &holb_cfg);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->transport_pm.transport_pm_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (atomic_read(&ipa3_ctx->transport_pm.dec_clients)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (atomic_read(&ipa3_ctx->transport_pm.eot_activity)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_set(&ipa3_ctx->transport_pm.dec_clients, 0);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	atomic_set(&ipa3_ctx->transport_pm.eot_activity, 0);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->transport_pm.transport_pm_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_destroy(&ipa3_ctx->flt_rule_ids[IPA_IP_v4]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_destroy(&ipa3_ctx->flt_rule_ids[IPA_IP_v6]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl = &ipa3_ctx->flt_tbl[i][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl = &ipa3_ctx->flt_tbl[i][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->smp2p_info.res_sent)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->smp2p_info.out_base_id == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.ipa_clk_on = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.ipa_clk_on = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	gpio_set_value(ipa3_ctx->smp2p_info.out_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.ipa_clk_on);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	gpio_set_value(ipa3_ctx->smp2p_info.out_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->smp2p_info.res_sent = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.ipa_clk_on ? "ON" : "OFF");
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->smp2p_info.res_sent == false)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->smp2p_info.ipa_clk_on)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	gpio_set_value(ipa3_ctx->smp2p_info.out_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	gpio_set_value(ipa3_ctx->smp2p_info.out_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->smp2p_info.res_sent = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->smp2p_info.ipa_clk_on = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	list_for_each_entry(info, &ipa3_ctx->ipa_ready_cb_list, link)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	complete_all(&ipa3_ctx->uc_loaded_completion_obj);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_initialization_complete)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ep_flt_bitmap, ipa3_ctx->ep_flt_num);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr = &(ipa3_ctx->flt_rule_ids[IPA_IP_v4]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr = &(ipa3_ctx->flt_rule_ids[IPA_IP_v6]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl = &ipa3_ctx->flt_tbl[i][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa.c:			!ipa3_ctx->ip4_flt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:			!ipa3_ctx->ip4_flt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl->rule_ids = &ipa3_ctx->flt_rule_ids[IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl = &ipa3_ctx->flt_tbl[i][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa.c:			!ipa3_ctx->ip6_flt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:			!ipa3_ctx->ip6_flt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		flt_tbl->rule_ids = &ipa3_ctx->flt_rule_ids[IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->apply_rg10_wa) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if ((ipa3_ctx->ipa_hw_type >= IPA_HW_v3_5
drivers/platform/msm/ipa/ipa_v3/ipa.c:		&& ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) &&
drivers/platform/msm/ipa/ipa_v3/ipa.c:		(!ipa3_ctx->ipa_config_is_mhi))
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_config_is_mhi) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		&ipa3_ctx->gsi_dev_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->use_ipa_teth_bridge) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->q6_proxy_clk_vote_valid = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->q6_proxy_clk_vote_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_initialization_complete = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	complete_all(&ipa3_ctx->init_completion_obj);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	gsi_deregister_device(ipa3_ctx->gsi_dev_hdl, false);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = request_firmware(&fw, IPA_FWS_PATH, ipa3_ctx->dev);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_is_msm_device() || (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_5))
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = ipa3_post_init(&ipa3_res, ipa3_ctx->dev);
drivers/platform/msm/ipa/ipa_v3/ipa.c:				ipa3_ctx->vlan_mode_iface[IPA_VLAN_IF_EMAC] =
drivers/platform/msm/ipa/ipa_v3/ipa.c:				ipa3_ctx->vlan_mode_iface[IPA_VLAN_IF_RNDIS] =
drivers/platform/msm/ipa/ipa_v3/ipa.c:				ipa3_ctx->vlan_mode_iface[IPA_VLAN_IF_ECM] =
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_config_is_mhi = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	queue_work(ipa3_ctx->transport_power_mgmt_wq,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->pkt_init_imm_opcode = cmd_pyld->opcode;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mem.size = cmd_pyld->len * ipa3_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->pkt_init_imm[i] = mem.phys_base + i * cmd_pyld->len;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->logbuf = ipc_log_context_create(IPA_IPC_LOG_PAGES, "ipa", 0);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->logbuf == NULL)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->pdev = ipa_dev;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->uc_pdev = ipa_dev;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->smmu_present = smmu_info.present;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->smmu_present) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->s1_bypass_arr[i] = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_AP] =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_wrapper_base = resource_p->ipa_mem_base;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_wrapper_size = resource_p->ipa_mem_size;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_hw_type = resource_p->ipa_hw_type;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_hw_mode = resource_p->ipa3_hw_mode;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->use_ipa_teth_bridge = resource_p->use_ipa_teth_bridge;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->modem_cfg_emb_pipe_flt = resource_p->modem_cfg_emb_pipe_flt;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_wdi2 = resource_p->ipa_wdi2;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->use_64_bit_dma_mask = resource_p->use_64_bit_dma_mask;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->wan_rx_ring_size = resource_p->wan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->lan_rx_ring_size = resource_p->lan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->skip_uc_pipe_reset = resource_p->skip_uc_pipe_reset;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->tethered_flow_control = resource_p->tethered_flow_control;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ee = resource_p->ee;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->apply_rg10_wa = resource_p->apply_rg10_wa;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->gsi_ch20_wa = resource_p->gsi_ch20_wa;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->use_ipa_pm = resource_p->use_ipa_pm;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa3_active_clients_logging.log_rdy = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->mhi_evid_limits[0] = resource_p->mhi_evid_limits[0];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->mhi_evid_limits[1] = resource_p->mhi_evid_limits[1];
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ipa_tz_unlock_reg_num =
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ipa_tz_unlock_reg = kcalloc(
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_tz_unlock_reg_num,
drivers/platform/msm/ipa/ipa_v3/ipa.c:			sizeof(*ipa3_ctx->ipa_tz_unlock_reg),
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (ipa3_ctx->ipa_tz_unlock_reg == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		for (i = 0; i < ipa3_ctx->ipa_tz_unlock_reg_num; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_tz_unlock_reg[i].reg_addr =
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_tz_unlock_reg[i].size =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = ipa3_tz_unlock_reg(ipa3_ctx->ipa_tz_unlock_reg,
drivers/platform/msm/ipa/ipa_v3/ipa.c:				    ipa3_ctx->ipa_tz_unlock_reg_num);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->aggregation_type = IPA_MBIM_16;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->aggregation_byte_limit = 1;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->aggregation_time_limit = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl = kzalloc(sizeof(*ipa3_ctx->ctrl), GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->ctrl) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = ipa3_controller_static_bind(ipa3_ctx->ctrl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ctrl->msm_bus_data_ptr = ipa3_bus_scale_table;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_bus_hdl =
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->msm_bus_data_ptr);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->ipa_bus_hdl) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	/* Enable ipa3_ctx->enable_clock_scaling */
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->enable_clock_scaling = 1;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->curr_ipa_clk_rate = ipa3_ctx->ctrl->ipa_clk_rate_turbo;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->mmio = ioremap(resource_p->ipa_mem_base +
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ctrl->ipa_reg_base_ofst,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipahal_init(ipa3_ctx->ipa_hw_type, ipa3_ctx->mmio,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->pdev)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ipa_num_pipes = ipa3_get_num_pipes();
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_num_pipes > IPA3_MAX_NUM_PIPES) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->ipa_num_pipes, IPA3_MAX_NUM_PIPES);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->ctrl->ipa_sram_read_settings();
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smem_sz, ipa3_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->hdr_tbl_lcl, ipa3_ctx->ip4_rt_tbl_hash_lcl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip4_rt_tbl_nhash_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip6_rt_tbl_hash_lcl, ipa3_ctx->ip6_rt_tbl_nhash_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip4_flt_tbl_hash_lcl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip4_flt_tbl_nhash_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip6_flt_tbl_hash_lcl,
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->ip6_flt_tbl_nhash_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->smem_reqd_sz > ipa3_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->smem_reqd_sz, ipa3_ctx->smem_sz);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	atomic_set(&ipa3_ctx->ipa3_active_clients.cnt, 1);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->power_mgmt_wq =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->power_mgmt_wq) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->transport_power_mgmt_wq =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->transport_power_mgmt_wq) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->transport_pm.transport_pm_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->flt_rule_cache = kmem_cache_create("IPA_FLT",
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->flt_rule_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->rt_rule_cache = kmem_cache_create("IPA_RT",
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->rt_rule_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->hdr_cache = kmem_cache_create("IPA_HDR",
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->hdr_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->hdr_offset_cache =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->hdr_offset_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->hdr_proc_ctx_cache = kmem_cache_create("IPA_HDR_PROC_CTX",
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->hdr_proc_ctx_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->hdr_proc_ctx_offset_cache =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->hdr_proc_ctx_offset_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->rt_tbl_cache = kmem_cache_create("IPA_RT_TBL",
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->rt_tbl_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->tx_pkt_wrapper_cache =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->tx_pkt_wrapper_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->rx_pkt_wrapper_cache =
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->rx_pkt_wrapper_cache) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->hdr_tbl.head_hdr_entry_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		INIT_LIST_HEAD(&ipa3_ctx->hdr_tbl.head_offset_list[i]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		INIT_LIST_HEAD(&ipa3_ctx->hdr_tbl.head_free_offset_list[i]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		INIT_LIST_HEAD(&ipa3_ctx->hdr_proc_ctx_tbl.head_offset_list[i]);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		INIT_LIST_HEAD(&ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->rt_tbl_set[IPA_IP_v4].head_rt_tbl_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_init(&ipa3_ctx->rt_tbl_set[IPA_IP_v4].rule_ids);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->rt_tbl_set[IPA_IP_v6].head_rt_tbl_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_init(&ipa3_ctx->rt_tbl_set[IPA_IP_v6].rule_ids);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rset = &ipa3_ctx->reap_rt_tbl_set[IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rset = &ipa3_ctx->reap_rt_tbl_set[IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->intf_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->msg_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->pull_msg_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	init_waitqueue_head(&ipa3_ctx->msg_waitq);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->q6_proxy_clk_vote_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_init(&ipa3_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->q6_proxy_clk_vote_cnt = 0;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_init(&ipa3_ctx->ipa_idr);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	memset(&ipa3_ctx->wc_memb, 0, sizeof(ipa3_ctx->wc_memb));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->class = class_create(THIS_MODULE, DRV_NAME);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = alloc_chrdev_region(&ipa3_ctx->dev_num, 0, 1, DRV_NAME);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->dev = device_create(ipa3_ctx->class, NULL, ipa3_ctx->dev_num,
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (IS_ERR(ipa3_ctx->dev)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	wakeup_source_init(&ipa3_ctx->w_lock, "IPA_WS");
drivers/platform/msm/ipa/ipa_v3/ipa.c:	spin_lock_init(&ipa3_ctx->wakelock_ref_cnt.spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_5)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	INIT_LIST_HEAD(&ipa3_ctx->ipa_ready_cb_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	init_completion(&ipa3_ctx->init_completion_obj);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	init_completion(&ipa3_ctx->uc_loaded_completion_obj);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_hw_type == IPA_HW_v3_0) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	cdev_init(&ipa3_ctx->cdev, &ipa3_drv_fops);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->cdev.ops = &ipa3_drv_fops;  /* from LDD3 */
drivers/platform/msm/ipa/ipa_v3/ipa.c:	result = cdev_add(&ipa3_ctx->cdev, ipa3_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v3/ipa.c:			MAJOR(ipa3_ctx->dev_num),
drivers/platform/msm/ipa/ipa_v3/ipa.c:			MINOR(ipa3_ctx->dev_num));
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (!ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa.c:	device_destroy(ipa3_ctx->class, ipa3_ctx->dev_num);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	unregister_chrdev_region(ipa3_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_destroy(&ipa3_ctx->ipa_idr);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rset = &ipa3_ctx->reap_rt_tbl_set[IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	rset = &ipa3_ctx->reap_rt_tbl_set[IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_destroy(&ipa3_ctx->rt_tbl_set[IPA_IP_v6].rule_ids);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	idr_destroy(&ipa3_ctx->rt_tbl_set[IPA_IP_v4].rule_ids);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->rx_pkt_wrapper_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->tx_pkt_wrapper_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->rt_tbl_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->hdr_proc_ctx_offset_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->hdr_proc_ctx_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->hdr_offset_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->hdr_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->rt_rule_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kmem_cache_destroy(ipa3_ctx->flt_rule_cache);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	destroy_workqueue(ipa3_ctx->transport_power_mgmt_wq);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	destroy_workqueue(ipa3_ctx->power_mgmt_wq);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	iounmap(ipa3_ctx->mmio);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	msm_bus_scale_unregister_client(ipa3_ctx->ipa_bus_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kfree(ipa3_ctx->ctrl);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	kfree(ipa3_ctx->ipa_tz_unlock_reg);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->logbuf)
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipc_log_context_destroy(ipa3_ctx->logbuf);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	return (ipa3_ctx) ? ipa3_ctx->use_ipa_pm : false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_WLAN] = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_WLAN] = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC] = true;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC] = false;
drivers/platform/msm/ipa/ipa_v3/ipa.c:	ipa3_ctx->uc_pdev = dev;
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.out_base_id = res;
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->smp2p_info.out_base_id);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		ipa3_ctx->smp2p_info.in_base_id = res;
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->smp2p_info.in_base_id);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		irq = gpio_to_irq(ipa3_ctx->smp2p_info.in_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:		res = enable_irq_wake(ipa3_ctx->smp2p_info.in_base_id +
drivers/platform/msm/ipa/ipa_v3/ipa.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		if (ipa3_ctx->ep[i].sys &&
drivers/platform/msm/ipa/ipa_v3/ipa.c:			atomic_read(&ipa3_ctx->ep[i].sys->curr_polling_state)) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		atomic_set(&ipa3_ctx->transport_pm.eot_activity, 0);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	if (ipa3_ctx->ipa_initialization_complete) {
drivers/platform/msm/ipa/ipa_v3/ipa.c:		mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	list_add_tail(&cb_info->link, &ipa3_ctx->ipa_ready_cb_list);
drivers/platform/msm/ipa/ipa_v3/ipa.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa.c:		is_smmu_enable = !(ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC] |
drivers/platform/msm/ipa/ipa_v3/ipa.c:			ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_WLAN]);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	((rmnet_ipa3_ctx && rmnet_ipa3_ctx->wwan_priv) ? \
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	  rmnet_ipa3_ctx->wwan_priv->net : NULL)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->qmap_hdr_hdl = hdr_entry->hdr_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	hdl_entry->hdl = rmnet_ipa3_ctx->qmap_hdr_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->qmap_hdr_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->qmap_hdr_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (index = 0; index < rmnet_ipa3_ctx->rmnet_index; index++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_del_qmap_hdr(rmnet_ipa3_ctx->mux_channel[index].hdr_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].hdr_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rt_rule_entry->rule.hdr_hdl = rmnet_ipa3_ctx->qmap_hdr_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->dflt_v4_wan_rt_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->dflt_v6_wan_rt_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rt_rule_entry->hdl = rmnet_ipa3_ctx->dflt_v4_wan_rt_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rt_rule_entry->hdl = rmnet_ipa3_ctx->dflt_v6_wan_rt_hdl;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	/* prevent multi-threads accessing rmnet_ipa3_ctx->num_q6_rules */
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->num_q6_rules =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->num_q6_rules);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->num_q6_rules = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->num_q6_rules; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->num_q6_rules);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].ip =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].action =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].rt_tbl_idx =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].mux_id =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].rule_id =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].is_rule_hashable =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.rule_eq_bitmap =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tos_eq_present =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tos_eq =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.protocol_eq =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		for (j = 0; j < ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.num_offset_meq_32 =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		for (j = 0; j < ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tc_eq_present =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tc_eq =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.fl_eq_present =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.fl_eq =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		for (j = 0; j < ipa3_qmi_ctx->q6_ul_filter_rule[i].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		for (j = 0; j < ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			memcpy(ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			memcpy(ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.metadata_meq32.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		    rmnet_ipa3_ctx->num_q6_rules) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				>= rmnet_ipa3_ctx->num_q6_rules) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				ipa3_qmi_ctx->q6_ul_filter_rule
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->num_q6_rules = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	memset(ipa3_qmi_ctx->q6_ul_filter_rule, 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		sizeof(ipa3_qmi_ctx->q6_ul_filter_rule));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->num_q6_rules; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		param->ip = ipa3_qmi_ctx->q6_ul_filter_rule[i].ip;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].action;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		= ipa3_qmi_ctx->q6_ul_filter_rule[i].rt_tbl_idx;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].is_rule_hashable;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].rule_id;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			&ipa3_qmi_ctx->q6_ul_filter_rule[i].eq_attrib,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule_hdl[i] =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	req->rule_id_len = rmnet_ipa3_ctx->num_q6_rules;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->num_q6_rules; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa3_qmi_ctx->q6_ul_filter_rule[i].rule_id;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->old_num_q6_rules = rmnet_ipa3_ctx->num_q6_rules;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->old_num_q6_rules);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->old_num_q6_rules; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		param->ip = ipa3_qmi_ctx->q6_ul_filter_rule[i].ip;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		flt_rule_entry.hdl = ipa3_qmi_ctx->q6_ul_filter_rule_hdl[i];
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->a7_ul_flt_set = false;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->old_num_q6_rules = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (mux_id == rmnet_ipa3_ctx->mux_channel[i].mux_id)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->rmnet_index; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (strcmp(rmnet_ipa3_ctx->mux_channel[i].vchannel_name,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (strcmp(rmnet_ipa3_ctx->mux_channel[i].vchannel_name,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].vchannel_name);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!rmnet_ipa3_ctx->mux_channel[index].mux_hdr_set) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->mux_channel[index].mux_id,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			&rmnet_ipa3_ctx->mux_channel[index].hdr_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].mux_hdr_set = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		 rmnet_ipa3_ctx->mux_channel[index].mux_id);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		 rmnet_ipa3_ctx->mux_channel[index].mux_id);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].mux_id << WWAN_METADATA_SHFT;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].mux_id << WWAN_METADATA_SHFT;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	pyld_sz = rmnet_ipa3_ctx->num_q6_rules *
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ext_properties.num_props = rmnet_ipa3_ctx->num_q6_rules;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->num_q6_rules; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				 &(ipa3_qmi_ctx->q6_ul_filter_rule[i]),
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[index].mux_id;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ret = ipa3_register_intf_ext(rmnet_ipa3_ctx->mux_channel[index].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->mux_channel[index].vchannel_name, ret);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->mux_channel[index].ul_flt_reg = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->rmnet_index; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (rmnet_ipa3_ctx->mux_channel[i].ul_flt_reg) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->mux_channel[i].vchannel_name);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:					rmnet_ipa3_ctx->mux_channel[i].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->mux_channel[i].vchannel_name,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[i].ul_flt_reg = false;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (rmnet_ipa3_ctx->egress_set) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (ipa3_qmi_ctx->modem_cfg_emb_pipe_flt == false) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			if (rmnet_ipa3_ctx->a7_ul_flt_set) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->a7_ul_flt_set = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (rmnet_ipa3_ctx->rmnet_index == 0) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	for (i = 0; i < rmnet_ipa3_ctx->rmnet_index; i++) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->mux_channel[i].vchannel_name,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->mux_channel[i].mux_id,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[i].vchannel_name);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->mux_channel[i].ul_flt_reg = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa_pm_activate(rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ret = ipa_pm_activate(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa_pm_deferred_deactivate(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa_pm_deferred_deactivate(rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!atomic_read(&rmnet_ipa3_ctx->is_ssr) &&
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa_pm_deferred_deactivate(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			ipa_pm_deferred_deactivate(rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			napi_complete(&(rmnet_ipa3_ctx->wwan_priv->napi));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_wan_ep_cfg = &rmnet_ipa3_ctx->ipa_to_apps_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (atomic_read(&rmnet_ipa3_ctx->is_ssr)) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ret = ipa3_setup_sys_pipe(&rmnet_ipa3_ctx->ipa_to_apps_ep_cfg,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	   &rmnet_ipa3_ctx->ipa3_to_apps_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_wan_ep_cfg = &rmnet_ipa3_ctx->apps_to_ipa_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (atomic_read(&rmnet_ipa3_ctx->is_ssr)) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa_wan_ep_cfg, &rmnet_ipa3_ctx->apps_to_ipa3_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (rmnet_ipa3_ctx->num_q6_rules != 0) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (ipa3_qmi_ctx->modem_cfg_emb_pipe_flt == false) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_lock(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->a7_ul_flt_set = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->egress_set = true;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_lock(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			if (rmnet_ipa3_ctx->rmnet_index
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->rmnet_index);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mux_channel = rmnet_ipa3_ctx->mux_channel;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_index = rmnet_ipa3_ctx->rmnet_index;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			if (rmnet_ipa3_ctx->num_q6_rules != 0) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:						rmnet_ipa3_ctx->rmnet_index);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:					mutex_unlock(&rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->rmnet_index++;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	queue_delayed_work(rmnet_ipa3_ctx->rm_q6_wq,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	queue_delayed_work(rmnet_ipa3_ctx->rm_q6_wq,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		return ipa_pm_activate_sync(rmnet_ipa3_ctx->q6_teth_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		return ipa_pm_deactivate_sync(rmnet_ipa3_ctx->q6_teth_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	result = ipa_pm_register(&pm_reg, &rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	result = ipa_pm_register(&pm_reg, &rmnet_ipa3_ctx->q6_teth_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_pm_deactivate_sync(rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_pm_deregister(rmnet_ipa3_ctx->q6_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ret = ipa_pm_set_perf_profile(rmnet_ipa3_ctx->q6_pm_hdl,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ret = ipa_pm_set_perf_profile(rmnet_ipa3_ctx->q6_teth_pm_hdl,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->rm_q6_wq = create_singlethread_workqueue("clnt_req");
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!rmnet_ipa3_ctx->rm_q6_wq)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	destroy_workqueue(rmnet_ipa3_ctx->rm_q6_wq);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (rmnet_ipa3_ctx->rm_q6_wq)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		destroy_workqueue(rmnet_ipa3_ctx->rm_q6_wq);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	result = ipa_pm_register(&pm_reg, &rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_pm_deactivate_sync(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ipa_pm_deregister(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	memset(&rmnet_ipa3_ctx->apps_to_ipa_ep_cfg, 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	memset(&rmnet_ipa3_ctx->ipa_to_apps_ep_cfg, 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->num_q6_rules = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->old_num_q6_rules = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->rmnet_index = 0;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->egress_set = false;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->a7_ul_flt_set = false;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		memset(&rmnet_ipa3_ctx->mux_channel[i], 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!atomic_read(&rmnet_ipa3_ctx->is_ssr)) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv = netdev_priv(dev);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	memset(rmnet_ipa3_ctx->wwan_priv, 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		sizeof(*(rmnet_ipa3_ctx->wwan_priv)));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	IPAWANDBG("wwan_ptr (private) = %p", rmnet_ipa3_ctx->wwan_priv);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv->net = dev;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv->outstanding_high = DEFAULT_OUTSTANDING_HIGH;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv->outstanding_low = DEFAULT_OUTSTANDING_LOW;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->wwan_priv->outstanding_pkts, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	spin_lock_init(&rmnet_ipa3_ctx->wwan_priv->lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		&rmnet_ipa3_ctx->wwan_priv->resource_granted_completion);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!atomic_read(&rmnet_ipa3_ctx->is_ssr)) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		netif_napi_add(dev, &(rmnet_ipa3_ctx->wwan_priv->napi),
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_initialized, 1);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!atomic_read(&rmnet_ipa3_ctx->is_ssr) && ipa3_ctx->ipa_hw_type !=
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_ssr, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		netif_napi_del(&(rmnet_ipa3_ctx->wwan_priv->napi));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (!atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (!atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv = NULL;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_ssr, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ret = ipa3_teardown_sys_pipe(rmnet_ipa3_ctx->ipa3_to_apps_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->ipa3_to_apps_hdl = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	ret = ipa3_teardown_sys_pipe(rmnet_ipa3_ctx->apps_to_ipa3_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->apps_to_ipa3_hdl = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		netif_napi_del(&(rmnet_ipa3_ctx->wwan_priv->napi));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->wwan_priv = NULL;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_qmi_ctx->modem_cfg_emb_pipe_flt == false)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_initialized, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		ipa_pm_deactivate_sync(rmnet_ipa3_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		atomic_set(&rmnet_ipa3_ctx->is_ssr, 1);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (atomic_read(&rmnet_ipa3_ctx->is_initialized))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (!atomic_read(&rmnet_ipa3_ctx->is_initialized) &&
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		       atomic_read(&rmnet_ipa3_ctx->is_ssr))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mux_id = rmnet_ipa3_ctx->mux_channel[index].mux_id;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	    "UPSTREAM=%s", rmnet_ipa3_ctx->mux_channel[index].vchannel_name);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	    "INTERFACE=%s", rmnet_ipa3_ctx->mux_channel[index].vchannel_name);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (rmnet_ipa3_ctx->tether_device[device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		memset(&rmnet_ipa3_ctx->tether_device[device_type], 0,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[device_type].ul_src_pipe = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->tether_device[device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			&rmnet_ipa3_ctx->tether_device[device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		if (rmnet_ipa3_ctx->tether_device[data->device_type]
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	&rmnet_ipa3_ctx->tether_device[data->device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->tether_device[data->device_type].ul_src_pipe =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!rmnet_ipa3_ctx->tether_device[data->device_type].hdr_len)
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[data->device_type].hdr_len =
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->tether_device[data->device_type].num_clients++;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[data->device_type].ul_src_pipe,
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[data->device_type].num_clients);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	&rmnet_ipa3_ctx->tether_device[data->device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_lock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			&rmnet_ipa3_ctx->tether_device[data->device_type].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[data->device_type].ul_src_pipe;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			(rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			(rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:				rmnet_ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_unlock(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_initialized, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	atomic_set(&rmnet_ipa3_ctx->is_ssr, 0);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_init(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_init(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_init(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->tether_device[i].ul_src_pipe = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:			rmnet_ipa3_ctx->tether_device[i].
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->ipa3_to_apps_hdl = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->apps_to_ipa3_hdl = -1;
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rmnet_ipa3_ctx->subsys_notify_handle = subsys_notif_register_notifier(
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	if (!IS_ERR(rmnet_ipa3_ctx->subsys_notify_handle))
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		return (int)PTR_ERR(rmnet_ipa3_ctx->subsys_notify_handle);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_destroy(&rmnet_ipa3_ctx->pipe_handle_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_destroy(&rmnet_ipa3_ctx->add_mux_channel_lock);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	mutex_destroy(&rmnet_ipa3_ctx->per_client_stats_guard);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:		rmnet_ipa3_ctx->subsys_notify_handle, &ipa3_ssr_notifier);
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	napi_schedule(&(rmnet_ipa3_ctx->wwan_priv->napi));
drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.c:	rcvd_pkts = ipa_rx_poll(rmnet_ipa3_ctx->ipa3_to_apps_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->apply_rg10_wa)					 \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		spin_lock_irqsave(&ipa3_ctx->uc_ctx.uc_spinlock, flags); \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		mutex_lock(&ipa3_ctx->uc_ctx.uc_lock);			 \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->apply_rg10_wa)					      \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		spin_unlock_irqrestore(&ipa3_ctx->uc_ctx.uc_spinlock, flags); \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		mutex_unlock(&ipa3_ctx->uc_ctx.uc_lock);		      \
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->uc_ctx.uc_event_top_ofst) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_event_top_ofst =
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_sram_mmio->eventParams;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (ipa3_ctx->uc_ctx.uc_event_top_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:				ipa3_ctx->uc_ctx.uc_event_top_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_event_top_mmio = ioremap(
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_event_top_ofst,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (!ipa3_ctx->uc_ctx.uc_event_top_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:					(ipa3_ctx->uc_ctx.uc_event_top_mmio);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventParams !=
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_event_top_ofst) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:				ipa3_ctx->uc_ctx.uc_sram_mmio->
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:				ipa3_ctx->uc_ctx.uc_event_top_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_event_top_ofst = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->uc_ctx.uc_inited) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->uc_ctx.uc_loaded) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	return ipa3_ctx->uc_ctx.uc_loaded;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	feature = EXTRACT_UC_FEATURE(ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			feature, ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			(ipa3_ctx->uc_ctx.uc_sram_mmio);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		evt.raw32b = ipa3_ctx->uc_ctx.uc_sram_mmio->eventParams;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_failed = true;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_error_type = evt.params.errorType;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_error_timestamp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	} else if (ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_sram_mmio->eventParams);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:				ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->cmdOp =
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.pending_cmd = ipa3_ctx->uc_ctx.uc_sram_mmio->cmdOp;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	feature = EXTRACT_UC_FEATURE(ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			feature, ipa3_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_sram_mmio,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			&ipa3_ctx->uc_ctx.uc_status);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			complete_all(&ipa3_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->uc_ctx.uc_loaded = true;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	} else if (ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		uc_rsp.raw32b = ipa3_ctx->uc_ctx.uc_sram_mmio->responseParams;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		    ipa3_ctx->uc_ctx.pending_cmd) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_status = uc_rsp.params.status;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			complete_all(&ipa3_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			       ipa3_ctx->uc_ctx.pending_cmd,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		       ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->apply_rg10_wa) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		init_completion(&ipa3_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->cmdParams = cmd_lo;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->cmdParams_hi = cmd_hi;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->cmdOp = opcode;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.pending_cmd = opcode;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio->responseParams = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_status = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:				uc_rsp.raw32b = ipa3_ctx->uc_ctx.uc_sram_mmio->
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:					ipa3_ctx->uc_ctx.pending_cmd) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:					ipa3_ctx->uc_ctx.uc_status =
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:					ipa_hw_error_str(ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (wait_for_completion_timeout(&ipa3_ctx->uc_ctx.uc_completion,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:					ipa_hw_error_str(ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->uc_ctx.uc_status != expected_status) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (ipa3_ctx->uc_ctx.uc_status ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		    ipa3_ctx->uc_ctx.uc_status ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->uc_ctx.uc_status ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		if (ipa3_ctx->uc_ctx.uc_status ==
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			if (ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:			ipa3_ctx->uc_ctx.uc_status, expected_status);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (ipa3_ctx->uc_ctx.uc_inited) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	mutex_init(&ipa3_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	spin_lock_init(&ipa3_ctx->uc_ctx.uc_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	phys_addr = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_sram_mmio = ioremap(phys_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->uc_ctx.uc_sram_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->apply_rg10_wa) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_inited = true;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	iounmap(ipa3_ctx->uc_ctx.uc_sram_mmio);
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	ipa3_ctx->uc_ctx.uc_loaded = true;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	if (!ipa3_ctx->apply_rg10_wa)
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	paddr = ipa3_ctx->ipa_wrapper_base + ipa3_ctx->ctrl->ipa_reg_base_ofst;
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa_uc.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:	} else if (req->source_pipe_index >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		memcpy(&(ipa3_qmi_ctx->ipa_install_fltr_rule_req_msg_cache[
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:			ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_msg]),
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_msg++;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_msg %= 10;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		memcpy(&(ipa3_qmi_ctx->ipa_install_fltr_rule_req_ex_msg_cache[
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:			ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_ex_msg]),
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_ex_msg++;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_install_fltr_rule_req_ex_msg %= 10;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		&(ipa3_qmi_ctx->ipa_configure_ul_firewall_rules_req_msg_cache[
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_configure_ul_firewall_rules_req_msg]),
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_configure_ul_firewall_rules_req_msg++;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_configure_ul_firewall_rules_req_msg %=
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:	} else if (req->source_pipe_index >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:	} else if (req->embedded_pipe_index >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		memcpy(&(ipa3_qmi_ctx->ipa_fltr_installed_notif_req_msg_cache[
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:			ipa3_qmi_ctx->num_ipa_fltr_installed_notif_req_msg]),
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_fltr_installed_notif_req_msg++;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:		ipa3_qmi_ctx->num_ipa_fltr_installed_notif_req_msg %= 10;
drivers/platform/msm/ipa/ipa_v3/ipa_qmi_service.c:	ipa3_qmi_ctx->modem_cfg_emb_pipe_flt =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_nat.c:	*entry_size = ipahal_nat_objs[ipahal_ctx->hw_type][nat_type].
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_nat.c:	*entry_zeroed = ipahal_nat_objs[ipahal_ctx->hw_type][nat_type].
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_nat.c:	result = ipahal_nat_objs[ipahal_ctx->hw_type][nat_type].
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	(BIT(ipahal_fltrt_objs[ipahal_ctx->hw_type].eq_bitfield[(__eq)]))
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	mem = &ipahal_ctx->empty_fltrt_tbl;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	mem->base = dma_alloc_coherent(ipahal_ctx->ipa_pdev, mem->size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	dma_free_coherent(ipahal_ctx->ipa_pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	if (ipahal_ctx && ipahal_ctx->empty_fltrt_tbl.base)
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		dma_free_coherent(ipahal_ctx->ipa_pdev,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:			ipahal_ctx->empty_fltrt_tbl.size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:			ipahal_ctx->empty_fltrt_tbl.base,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:			ipahal_ctx->empty_fltrt_tbl.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].tbl_hdr_width;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].lcladdr_alignment;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].rule_max_prio;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		((1U << ipahal_fltrt_objs[ipahal_ctx->hw_type].rule_id_bit_len)
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return BIT(ipahal_fltrt_objs[ipahal_ctx->hw_type].rule_id_bit_len - 1);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return  ipahal_fltrt_objs[ipahal_ctx->hw_type].low_rule_id;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	mem->base = dma_alloc_coherent(ipahal_ctx->ipa_pdev, mem->size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		ipahal_ctx->empty_fltrt_tbl.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	mem->base = dma_alloc_coherent(ipahal_ctx->ipa_pdev, mem->size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		ipahal_ctx->empty_fltrt_tbl.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	params->nhash_hdr.base = dma_alloc_coherent(ipahal_ctx->ipa_pdev,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		params->hash_hdr.base = dma_alloc_coherent(ipahal_ctx->ipa_pdev,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:		ipahal_ctx->empty_fltrt_tbl.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:			ipahal_ctx->ipa_pdev, params->nhash_bdy.size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:			ipahal_ctx->ipa_pdev, params->hash_bdy.size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	tbl_mem->base = dma_alloc_coherent(ipahal_ctx->ipa_pdev, tbl_mem->size,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	rc = ipahal_fltrt_objs[ipahal_ctx->hw_type].rt_generate_hw_rule(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	obj = &ipahal_fltrt_objs[ipahal_ctx->hw_type];
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	rc = ipahal_fltrt_objs[ipahal_ctx->hw_type].flt_generate_hw_rule(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].flt_generate_eq(ipt,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].rt_parse_hw_rule(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_fltrt.c:	return ipahal_fltrt_objs[ipahal_ctx->hw_type].flt_parse_hw_rule(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_hw_stats.c:	return ipahal_hw_stats_objs[ipahal_ctx->hw_type][type].get_offset(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_hw_stats.c:	return ipahal_hw_stats_objs[ipahal_ctx->hw_type][type].
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_hw_stats.c:	return ipahal_hw_stats_objs[ipahal_ctx->hw_type][type].parse_stats(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ipahal_imm_cmd_name_str(cmd), ipahal_ctx->hw_type);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	opcode = ipahal_imm_cmd_objs[ipahal_ctx->hw_type][cmd].opcode;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	return ipahal_imm_cmd_objs[ipahal_ctx->hw_type][cmd].construct(
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	return ipahal_pkt_status_objs[ipahal_ctx->hw_type].size;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_pkt_status_objs[ipahal_ctx->hw_type].parse(unparsed_status,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_ctx->dent = debugfs_create_dir("ipahal", 0);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	if (!ipahal_ctx->dent || IS_ERR(ipahal_ctx->dent)) {
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	debugfs_remove_recursive(ipahal_ctx->dent);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_ctx->dent = NULL;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	if (IS_ERR(ipahal_ctx->dent)) {
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	debugfs_remove_recursive(ipahal_ctx->dent);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.value = hdr_len;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.hdr_addr = is_hdr_proc_ctx ? phys_base :
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->hdr_add.hdr_addr);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.value = hdr_len;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.hdr_addr = is_hdr_proc_ctx ? phys_base :
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->hdr_add.hdr_addr);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.type = IPA_PROC_CTX_TLV_TYPE_PROC_CMD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.value =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.eth_hdr_retained =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.input_ip_version =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.output_ip_version =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		IPAHAL_DBG("command id %d\n", ctx->l2tp_params.tlv.value);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.value = hdr_len;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.hdr_addr = is_hdr_proc_ctx ? phys_base :
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->hdr_add.hdr_addr, ctx->hdr_add.tlv.value);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.type = IPA_PROC_CTX_TLV_TYPE_PROC_CMD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.tlv.value =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.hdr_len_remove =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.eth_hdr_retained =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.hdr_ofst_pkt_size_valid =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.hdr_ofst_pkt_size =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->l2tp_params.l2tp_params.hdr_endianness =
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->l2tp_params.l2tp_params.hdr_ofst_pkt_size_valid,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->l2tp_params.l2tp_params.hdr_ofst_pkt_size);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->l2tp_params.l2tp_params.hdr_endianness);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		IPAHAL_DBG("command id %d\n", ctx->l2tp_params.tlv.value);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.tlv.value = hdr_len;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->hdr_add.hdr_addr = is_hdr_proc_ctx ? phys_base :
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->hdr_add.hdr_addr);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->cmd.type = IPA_PROC_CTX_TLV_TYPE_PROC_CMD;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->cmd.length = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->cmd.value = IPA_HDR_UCP_ETHII_TO_ETHII;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->cmd.value = IPA_HDR_UCP_ETHII_TO_802_3;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->cmd.value = IPA_HDR_UCP_802_3_TO_ETHII;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:			ctx->cmd.value = IPA_HDR_UCP_802_3_TO_802_3;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		IPAHAL_DBG("command id %d\n", ctx->cmd.value);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_ctx->hw_type = ipa_hw_type;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_ctx->base = base;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:	ipahal_ctx->ipa_pdev = ipa_pdev;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal.c:		dma_free_coherent(ipahal_ctx->ipa_pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	if (ipahal_ctx->hw_type <= IPA_HW_v3_1) {
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	return ioread32(ipahal_ctx->base + offset);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	return ioread32(ipahal_ctx->base + offset);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	iowrite32(val, ipahal_ctx->base + offset);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	val = ioread32(ipahal_ctx->base + offset);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	ipahal_reg_objs[ipahal_ctx->hw_type][reg].parse(reg, fields, val);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	ipahal_reg_objs[ipahal_ctx->hw_type][reg].construct(reg, fields, &val);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	iowrite32(val, ipahal_ctx->base + offset);
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset = ipahal_reg_objs[ipahal_ctx->hw_type][reg].offset;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	offset += ipahal_reg_objs[ipahal_ctx->hw_type][reg].n_ofst * n;
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	if (ipahal_ctx->hw_type <= IPA_HW_v3_1) {
drivers/platform/msm/ipa/ipa_v3/ipahal/ipahal_reg.c:	} else if (ipahal_ctx->hw_type <= IPA_HW_v3_5_1) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (ipa3_ctx->skip_ep_cfg_shadow[pipe]) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		&& ipa3_ctx->modem_cfg_emb_pipe_flt)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	alloc_params.tbls_num = ipa3_ctx->ep_flt_num;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash = ipa3_ctx->ip4_flt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash = ipa3_ctx->ip4_flt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_hash = ipa3_ctx->ip6_flt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		lcl_nhash = ipa3_ctx->ip6_flt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	entries = (ipa3_ctx->ep_flt_num) * 2 + 3;
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	*entry = kmem_cache_zalloc(ipa3_ctx->flt_rule_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	kmem_cache_free(ipa3_ctx->flt_rule_cache, *entry);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	kmem_cache_free(ipa3_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	kmem_cache_free(ipa3_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	kmem_cache_free(ipa3_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (ipa3_ctx->ep[*ipa_ep_idx].valid == 0)
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		if (ipa3_ctx->ctrl->ipa3_commit_flt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][rules->ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		if (ipa3_ctx->ctrl->ipa3_commit_flt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		if (ipa3_ctx->ctrl->ipa3_commit_flt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		if (ipa3_ctx->ctrl->ipa3_commit_flt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (ipa3_ctx->ctrl->ipa3_commit_flt(ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:			kmem_cache_free(ipa3_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	struct ipa3_ep_context *ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	ipa3_ctx->ctrl->ipa3_commit_flt(IPA_IP_v4);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	ipa3_ctx->ctrl->ipa3_commit_flt(IPA_IP_v6);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	struct ipa3_ep_context *ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		ipa3_ctx->ctrl->ipa3_commit_flt(IPA_IP_v4);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		tbl = &ipa3_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		ipa3_ctx->ctrl->ipa3_commit_flt(IPA_IP_v6);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || ip_type >= IPA_IP_MAX ||
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:	ipa_sram_mmio = ioremap(ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:			ipa3_ctx->smem_restricted_bytes / 4),
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		ipa3_ctx->smem_sz);
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		if (ipa3_ctx->ep_flt_bitmap & (1 << i))
drivers/platform/msm/ipa/ipa_v3/ipa_flt.c:		sys_tbl_mem = &ipa3_ctx->flt_tbl[pipe_idx][ip_type].
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:		res = gsi_alloc_evt_ring(&ev_props, ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	res = gsi_alloc_channel(&ch_props, ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:		((ipa3_ctx->mhi_evid_limits[1] -
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:		ipa3_ctx->mhi_evid_limits[0]) + 1)) {
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	res = gsi_write_device_scratch(ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	in->start.gsi.evchid += ipa3_ctx->mhi_evid_limits[0];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ipa3_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	if (ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_mhi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->resume_on_connect[client] = false;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (ipa3_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (ipa3_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[ipa_ep_idx].gsi_chan_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->tag_process_before_gating = true;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->resume_on_connect[client] = false;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (ipa3_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->tag_process_before_gating = true;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->resume_on_connect[client] = true;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (ipa3_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (ipa3_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[ipa_ep_idx].gsi_chan_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[ipa_ep_idx].gsi_chan_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->smem_restricted_bytes = smem_sz.shared_mem_baddr;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->smem_sz = smem_sz.shared_mem_sz;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->smem_restricted_bytes *= 8;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->smem_sz *= 8;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->smem_reqd_sz = IPA_MEM_PART(end_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->hdr_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->hdr_proc_ctx_tbl_lcl = 1;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->hdr_proc_ctx_tbl.start_offset =
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip4_rt_tbl_hash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip4_rt_tbl_nhash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip6_rt_tbl_hash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip6_rt_tbl_nhash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip4_flt_tbl_hash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip4_flt_tbl_nhash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip6_flt_tbl_hash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ip6_flt_tbl_nhash_lcl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_5) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	switch (ipa3_ctx->ipa_hw_type) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	switch (ipa3_ctx->ipa_hw_type) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ipa_config_is_mhi)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ipa_config_is_mhi)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		IPAERR("Incorrect IPA version %d\n", ipa3_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ipacm_client[index].client_enum = client;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ipacm_client[index].uplink = uplink;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->uc_wdi_ctx.stats_notify) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->uc_wdi_ctx.stats_notify(IPA_GET_WDI_SAP_STATS,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->uc_wdi_ctx.stats_notify) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->uc_wdi_ctx.stats_notify(IPA_SET_WIFI_QUOTA,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		return ipa3_ctx->ipacm_client[pipe_idx].client_enum;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	return ipa3_ctx->ipacm_client[pipe_idx].uplink;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	client = ipa3_ctx->ep[pipe_idx].client;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	return ipa3_ctx->ep[pipe_idx].client;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	BUG_ON(ipa3_ctx->ep_flt_bitmap);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			if (bitmap != ipa3_ctx->ep_flt_bitmap) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				ipa3_ctx->ep_flt_bitmap = bitmap;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				ipa3_ctx->ep_flt_num++;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	return ipa3_ctx->ep_flt_bitmap & (1U<<pipe_idx);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_TEST(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			[ipa3_ctx->ep[clnt_hdl].client].sequencer_type;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ep[clnt_hdl].cfg.mode.mode == IPA_DMA &&
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ipa_ep_cfg == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_PROD(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_nat == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.nat = *ep_nat;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_conn_track == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.conn_track = *ep_conn_track;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_status == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].status = *ep_status;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || cfg == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.cfg = *cfg;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	qmb_master_sel = ipa3_get_qmb_master_sel(ipa3_ctx->ep[clnt_hdl].client);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.cfg.gen_qmb_master_sel = qmb_master_sel;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->ep[clnt_hdl].cfg.cfg.frag_offload_en,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->ep[clnt_hdl].cfg.cfg.cs_offload_en,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->ep[clnt_hdl].cfg.cfg.cs_metadata_hdr_offset,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->ep[clnt_hdl].cfg.cfg.gen_qmb_master_sel);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				  &ipa3_ctx->ep[clnt_hdl].cfg.cfg);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || metadata_mask == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.metadata_mask = *metadata_mask;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_hdr == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_hdr_ext == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes || ep_ctrl == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0 && ep_ctrl->ipa_ep_suspend) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client))
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_mode == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.mode = *ep_mode;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].dst_pipe_index = ep;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	init_mode.dst_pipe_number = ipa3_ctx->ep[clnt_hdl].dst_pipe_index;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_TEST(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_aggr == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.aggr = *ep_aggr;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_route == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ep[clnt_hdl].cfg.mode.mode == IPA_DMA) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].rt_tbl_idx =
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		init_rt.route_table_index = ipa3_ctx->ep[clnt_hdl].rt_tbl_idx;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_holb == NULL ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ep_holb->tmr_val > ipa3_ctx->ctrl->max_holb_tmr_val ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (IPA_CLIENT_IS_PROD(ipa3_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].holb = *ep_holb;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_deaggr == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:				clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ep[clnt_hdl].valid == 0 || ep_md == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:					clnt_hdl, ipa3_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.meta = *ep_md;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->ep[clnt_hdl].cfg.hdr.hdr_metadata_reg_valid = 1;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		&ipa3_ctx->ep[clnt_hdl].cfg.hdr);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ep[ipa_ep_idx].cfg.meta = meta;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		sizeof(ipa3_ctx->ctrl->mem_partition) / sizeof(u32);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	memset(&ipa3_ctx->ctrl->mem_partition, 0,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		sizeof(ipa3_ctx->ctrl->mem_partition));
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		(u32 *)&ipa3_ctx->ctrl->mem_partition,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_lock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	id = idr_alloc(&ipa3_ctx->ipa_idr, ptr, 0, 0, GFP_NOWAIT);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_unlock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_lock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ptr = idr_find(&ipa3_ctx->ipa_idr, id);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_unlock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_lock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	idr_remove(&ipa3_ctx->ipa_idr, id);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	spin_unlock(&ipa3_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (pipe_num < -1 || pipe_num >= (int)ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		end_pipe = ipa3_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	complete = ipa3_ctx->ipa_initialization_complete;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= 0 && clnt_hdl < ipa3_ctx->ipa_num_pipes)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_lock(&ipa3_ctx->q6_proxy_clk_vote_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->q6_proxy_clk_vote_valid) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->q6_proxy_clk_vote_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->q6_proxy_clk_vote_cnt == 0)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->q6_proxy_clk_vote_valid = false;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_unlock(&ipa3_ctx->q6_proxy_clk_vote_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_lock(&ipa3_ctx->q6_proxy_clk_vote_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (!ipa3_ctx->q6_proxy_clk_vote_valid ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		(ipa3_ctx->q6_proxy_clk_vote_cnt > 0)) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->q6_proxy_clk_vote_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->q6_proxy_clk_vote_valid = true;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	mutex_unlock(&ipa3_ctx->q6_proxy_clk_vote_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		return ipa3_ctx->smem_restricted_bytes;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c: * ipa3_get_modem_cfg_emb_pipe_flt()- Return ipa3_ctx->modem_cfg_emb_pipe_flt
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		return ipa3_ctx->modem_cfg_emb_pipe_flt;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c: * set ipa_ctx->ipa_client_apps_wan_cons_agg_gro
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ipa_client_apps_wan_cons_agg_gro = true;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		return ipa3_ctx->logbuf;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		return ipa3_ctx->logbuf_low;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	*holb = ipa3_ctx->ep[ep_idx].holb;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->tag_process_before_gating = val;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	*res = ipa3_ctx->vlan_mode_iface[iface];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (pipe_idx >= ipa3_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_1) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type <= IPA_HW_v3_1) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v3_5)
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		atomic_set(&ipa3_ctx->transport_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->dma_task_info.mem.size = IPA_GSI_CHANNEL_STOP_PKT_SIZE;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->dma_task_info.mem.base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->dma_task_info.mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		&ipa3_ctx->dma_task_info.mem.phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (!ipa3_ctx->dma_task_info.mem.base) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	cmd.size1 = ipa3_ctx->dma_task_info.mem.size;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	cmd.addr1 = ipa3_ctx->dma_task_info.mem.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	cmd.packet_size = ipa3_ctx->dma_task_info.mem.size;
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_ctx->dma_task_info.cmd_pyld = ipahal_construct_imm_cmd(
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	if (!ipa3_ctx->dma_task_info.cmd_pyld) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->dma_task_info.mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->dma_task_info.mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			ipa3_ctx->dma_task_info.mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		memset(&ipa3_ctx->dma_task_info, 0,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:			sizeof(ipa3_ctx->dma_task_info));
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->dma_task_info.mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->dma_task_info.mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		ipa3_ctx->dma_task_info.mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipahal_destroy_imm_cmd(ipa3_ctx->dma_task_info.cmd_pyld);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	memset(&ipa3_ctx->dma_task_info, 0, sizeof(ipa3_ctx->dma_task_info));
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa3_init_imm_cmd_desc(&desc, ipa3_ctx->dma_task_info.cmd_pyld);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	ipa_reg_mem_base = ipa3_ctx->ipa_wrapper_base + ipahal_get_reg_base();
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	switch (ipa3_ctx->ipa_hw_type) {
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:		IPAERR("unknown HW type %d\n", ipa3_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v3/ipa_utils.c:	return ipa3_ctx->pdev;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem->size = ipa3_ctx->hdr_tbl.end;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	IPADBG_LOW("tbl_sz=%d\n", ipa3_ctx->hdr_tbl.end);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem->base = dma_alloc_coherent(ipa3_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	list_for_each_entry(entry, &ipa3_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			&ipa3_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					hdr_ofst_pkt_size_valid = ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					hdr_ofst_pkt_size = ipa3_ctx->ep[ep].
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					hdr_endianness = ipa3_ctx->ep[ep].
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem->size = (ipa3_ctx->hdr_proc_ctx_tbl.end) ? : 4;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	IPADBG_LOW("tbl_sz=%d\n", ipa3_ctx->hdr_proc_ctx_tbl.end);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem->base = dma_alloc_coherent(ipa3_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	hdr_base_addr = (ipa3_ctx->hdr_tbl_lcl) ? IPA_MEM_PART(apps_hdr_ofst) :
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		dma_free_coherent(ipa3_ctx->pdev, hdr_mem.size, hdr_mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			if (ipa3_ctx->hdr_mem.phys_base)
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				ipa3_ctx->hdr_mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				ipa3_ctx->hdr_mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				ipa3_ctx->hdr_mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			ipa3_ctx->hdr_mem = hdr_mem;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		dma_free_coherent(ipa3_ctx->pdev, ctx_mem.size, ctx_mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			if (ipa3_ctx->hdr_proc_ctx_mem.phys_base)
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					ipa3_ctx->hdr_proc_ctx_mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					ipa3_ctx->hdr_proc_ctx_mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					ipa3_ctx->hdr_proc_ctx_mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			ipa3_ctx->hdr_proc_ctx_mem = ctx_mem;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	struct ipa3_hdr_proc_ctx_tbl *htbl = &ipa3_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		proc_ctx->type, proc_ctx->hdr_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (!HDR_PROC_TYPE_IS_VALID(proc_ctx->type)) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		IPAERR_RL("invalid processing type %d\n", proc_ctx->type);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	hdr_entry = ipa3_id_find(proc_ctx->hdr_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	entry = kmem_cache_zalloc(ipa3_ctx->hdr_proc_ctx_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	entry->type = proc_ctx->type;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	entry->l2tp_params = proc_ctx->l2tp_params;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	needed_len = ipahal_get_proc_ctx_needed_len(proc_ctx->type);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem_size = (ipa3_ctx->hdr_proc_ctx_tbl_lcl) ?
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		offset = kmem_cache_zalloc(ipa3_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	proc_ctx->proc_ctx_hdl = id;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	kmem_cache_free(ipa3_ctx->hdr_proc_ctx_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	struct ipa3_hdr_tbl *htbl = &ipa3_ctx->hdr_tbl;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	entry = kmem_cache_zalloc(ipa3_ctx->hdr_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mem_size = (ipa3_ctx->hdr_tbl_lcl) ? IPA_MEM_PART(apps_hdr_size) :
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			entry->phys_base = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			if (dma_mapping_error(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			offset = kmem_cache_zalloc(ipa3_ctx->hdr_offset_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		dma_unmap_single(ipa3_ctx->pdev, entry->phys_base,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	kmem_cache_free(ipa3_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	struct ipa3_hdr_proc_ctx_tbl *htbl = &ipa3_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	kmem_cache_free(ipa3_ctx->hdr_proc_ctx_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	struct ipa3_hdr_tbl *htbl = &ipa3_ctx->hdr_tbl;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		dma_unmap_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		__ipa3_del_hdr_proc_ctx(entry->proc_ctx->id, false, false);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	kmem_cache_free(ipa3_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			&ipa3_ctx->hdr_tbl.head_hdr_entry_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			dma_unmap_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		kmem_cache_free(ipa3_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:					 &ipa3_ctx->hdr_tbl.head_offset_list[i],
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			kmem_cache_free(ipa3_ctx->hdr_offset_cache, off_entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				&ipa3_ctx->hdr_tbl.head_free_offset_list[i],
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			kmem_cache_free(ipa3_ctx->hdr_offset_cache, off_entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	ipa3_ctx->hdr_tbl.end = 8;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	ipa3_ctx->hdr_tbl.hdr_cnt = 1;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		&ipa3_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:		kmem_cache_free(ipa3_ctx->hdr_proc_ctx_cache, ctx_entry);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:				&ipa3_ctx->hdr_proc_ctx_tbl.head_offset_list[i],
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			kmem_cache_free(ipa3_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			&ipa3_ctx->hdr_proc_ctx_tbl.head_free_offset_list[i],
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:			kmem_cache_free(ipa3_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	ipa3_ctx->hdr_proc_ctx_tbl.end = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	ipa3_ctx->hdr_proc_ctx_tbl.proc_ctx_cnt = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	list_for_each_entry(entry, &ipa3_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	if (ipa3_ctx->ctrl->ipa3_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hdr.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			(proc_ctx->cookie != IPA_PROC_HDR_COOKIE)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			gen_params.hdr_lcl = ipa3_ctx->hdr_proc_ctx_tbl_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			gen_params.hdr_ofst = proc_ctx->offset_entry->offset +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:				ipa3_ctx->hdr_proc_ctx_tbl.start_offset;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		gen_params.hdr_lcl = ipa3_ctx->hdr_tbl_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->reap_rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		kmem_cache_free(ipa3_ctx->rt_tbl_cache, tbl);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash = ipa3_ctx->ip4_rt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash = ipa3_ctx->ip4_rt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash_hdr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash_bdy = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_hash = ipa3_ctx->ip6_rt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		lcl_nhash = ipa3_ctx->ip6_rt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	if (!ipa3_ctx->rt_idx_bitmap[ip]) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		entry = kmem_cache_zalloc(ipa3_ctx->rt_tbl_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			if (!test_bit(i, &ipa3_ctx->rt_idx_bitmap[ip])) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:				set_bit(i, &ipa3_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			!ipa3_ctx->ip4_rt_tbl_hash_lcl :
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			!ipa3_ctx->ip6_rt_tbl_hash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			!ipa3_ctx->ip4_rt_tbl_nhash_lcl :
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			!ipa3_ctx->ip6_rt_tbl_nhash_lcl;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	kmem_cache_free(ipa3_ctx->rt_tbl_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	if (entry->set == &ipa3_ctx->rt_tbl_set[IPA_IP_v4])
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	else if (entry->set == &ipa3_ctx->rt_tbl_set[IPA_IP_v6])
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	rset = &ipa3_ctx->reap_rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		clear_bit(entry->idx, &ipa3_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		clear_bit(entry->idx, &ipa3_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		kmem_cache_free(ipa3_ctx->rt_tbl_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	*entry = kmem_cache_zalloc(ipa3_ctx->rt_rule_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	kmem_cache_free(ipa3_ctx->rt_rule_cache, *entry);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		entry->proc_ctx->ref_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		entry->proc_ctx->ref_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	kmem_cache_free(ipa3_ctx->rt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		__ipa3_release_hdr_proc_ctx(entry->proc_ctx->id);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	kmem_cache_free(ipa3_ctx->rt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	if (ipa3_ctx->ctrl->ipa3_commit_rt(ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	rset = &ipa3_ctx->reap_rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:				__ipa3_release_hdr_proc_ctx(rule->proc_ctx->id);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			kmem_cache_free(ipa3_ctx->rt_rule_cache, rule);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:					  &ipa3_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:					  &ipa3_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:				kmem_cache_free(ipa3_ctx->rt_tbl_cache, tbl);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(lookup->ip))
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	if (entry->set == &ipa3_ctx->rt_tbl_set[IPA_IP_v4])
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	else if (entry->set == &ipa3_ctx->rt_tbl_set[IPA_IP_v6])
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(ip))
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			(proc_ctx->cookie != IPA_PROC_HDR_COOKIE)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		entry->proc_ctx->ref_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		entry->proc_ctx->ref_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		if (ipa3_ctx->ctrl->ipa3_commit_rt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:	ipa_sram_mmio = ioremap(ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:			ipa3_ctx->smem_restricted_bytes / 4),
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		ipa3_ctx->smem_sz);
drivers/platform/msm/ipa/ipa_v3/ipa_rt.c:		set = &ipa3_ctx->rt_tbl_set[ip_type];
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	dma_free_coherent(ipa3_ctx->pdev, IPA_DMA_DUMMY_BUFF_SZ * 4,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_lock(&ipa3_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->enable_ref_cnt > 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->enable_ref_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		ipa3_dma_ctx->enable_ref_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		mutex_unlock(&ipa3_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->enable_ref_cnt = 1;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_unlock(&ipa3_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (atomic_read(&ipa3_dma_ctx->sync_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (atomic_read(&ipa3_dma_ctx->async_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (atomic_read(&ipa3_dma_ctx->uc_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_lock(&ipa3_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->enable_ref_cnt > 1) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->enable_ref_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		ipa3_dma_ctx->enable_ref_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->enable_ref_cnt == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->enable_ref_cnt = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_unlock(&ipa3_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (!ipa3_dma_ctx->enable_ref_cnt) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	cons_sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	prod_sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	xfer_descr = kmem_cache_zalloc(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_lock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->ipa_dma_dummy_dst_sync.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->ipa_dma_dummy_src_sync.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		mutex_unlock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		mutex_lock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_unlock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_lock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	kmem_cache_free(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_unlock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->total_sync_memcpy);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_dec(&ipa3_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->destroy_pending && !ipa3_dma_work_pending())
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		complete(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	mutex_unlock(&ipa3_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	kmem_cache_free(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_dec(&ipa3_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->destroy_pending && !ipa3_dma_work_pending())
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		complete(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (!ipa3_dma_ctx->enable_ref_cnt) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	cons_sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	prod_sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	xfer_descr = kmem_cache_zalloc(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->ipa_dma_dummy_dst_async.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->ipa_dma_dummy_src_async.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	kmem_cache_free(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_dec(&ipa3_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->destroy_pending && !ipa3_dma_work_pending())
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		complete(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (!ipa3_dma_ctx->enable_ref_cnt) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->uc_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->total_uc_memcpy);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_dec(&ipa3_dma_ctx->uc_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->destroy_pending && !ipa3_dma_work_pending())
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		complete(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		ipa3_dma_ctx->destroy_pending = true;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		wait_for_completion(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->enable_ref_cnt > 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	res = ipa3_teardown_sys_pipe(ipa3_dma_ctx->ipa_dma_async_cons_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->ipa_dma_async_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	res = ipa3_teardown_sys_pipe(ipa3_dma_ctx->ipa_dma_sync_cons_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->ipa_dma_sync_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	res = ipa3_teardown_sys_pipe(ipa3_dma_ctx->ipa_dma_async_prod_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->ipa_dma_async_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	res = ipa3_teardown_sys_pipe(ipa3_dma_ctx->ipa_dma_sync_prod_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	ipa3_dma_ctx->ipa_dma_sync_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	kmem_cache_destroy(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	dma_free_coherent(ipa3_ctx->pdev, IPA_DMA_DUMMY_BUFF_SZ * 4,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		ipa3_dma_ctx->ipa_dma_dummy_src_sync.base,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		ipa3_dma_ctx->ipa_dma_dummy_src_sync.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_lock_irqsave(&ipa3_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	spin_unlock_irqrestore(&ipa3_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_inc(&ipa3_dma_ctx->total_async_memcpy);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	atomic_dec(&ipa3_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	kmem_cache_free(ipa3_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:	if (ipa3_dma_ctx->destroy_pending && !ipa3_dma_work_pending())
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		complete(&ipa3_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			(ipa3_dma_ctx->enable_ref_cnt > 0) ?
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			ipa3_dma_ctx->enable_ref_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->total_sync_memcpy));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->total_async_memcpy));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->total_uc_memcpy));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->sync_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->async_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:			atomic_read(&ipa3_dma_ctx->uc_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		atomic_set(&ipa3_dma_ctx->total_async_memcpy, 0);
drivers/platform/msm/ipa/ipa_v3/ipa_dma.c:		atomic_set(&ipa3_dma_ctx->total_sync_memcpy, 0);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (option >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		end_idx = ipa3_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		nbytes = ipa3_ctx->ctrl->ipa3_read_ep_reg(dbg_buff,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (atomic_read(&ipa3_ctx->ipa3_active_clients.cnt))
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->hdr_tbl_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	list_for_each_entry(entry, &ipa3_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	set = &ipa3_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		if (ipa3_ctx->ip6_rt_tbl_hash_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		if (ipa3_ctx->ip6_rt_tbl_nhash_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		if (ipa3_ctx->ip4_rt_tbl_hash_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		if (ipa3_ctx->ip4_rt_tbl_nhash_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:				ofst = entry->proc_ctx->offset_entry->offset;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:					ipa3_ctx->hdr_proc_ctx_tbl.start_offset)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:					!ipa3_ctx->hdr_proc_ctx_tbl_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:					!ipa3_ctx->hdr_tbl_lcl);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	tbl = &ipa3_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->hdr_proc_ctx_tbl_lcl)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			ipa3_ctx->hdr_proc_ctx_tbl.start_offset)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	for (j = 0; j < ipa3_ctx->ipa_num_pipes; j++) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		tbl = &ipa3_ctx->flt_tbl[j][ip];
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->ep_flt_num, ip);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	for (pipe = 0; pipe < ipa3_ctx->ipa_num_pipes; pipe++) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		connect |= (ipa3_ctx->ep[i].valid << i);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.tx_sw_pkts,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.tx_hw_pkts,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.tx_non_linear,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.tx_pkts_compl,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.rx_pkts,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.stat_compl,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.aggr_close,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.wan_aggr_close,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		atomic_read(&ipa3_ctx->ipa3_active_clients.cnt),
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.wan_rx_empty,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.wan_repl_rx_empty,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.lan_rx_empty,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.lan_repl_rx_empty,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.flow_enable,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->stats.flow_disable);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			ipa3_ctx->stats.rx_excp_pkts[i]);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->wc_memb.wlan_comm_total_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		"Tx Comm Buff Avail:", ipa3_ctx->wc_memb.wlan_comm_free_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		"Total Tx Pkts Freed:", ipa3_ctx->wc_memb.total_tx_pkts_freed);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->tx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->rx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:				ipa3_ctx->stats.msg_w[i],
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:				ipa3_ctx->stats.msg_r[i]);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	for (i = 0, pdn_entry = ipa3_ctx->nat_mem.pdn_mem.base;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.table_entries + 1 +
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.expn_table_entries);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->nat_mem.dev.is_dev_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->nat_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->nat_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			&ipa3_ctx->nat_mem.public_ip_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	pos += ipa3_start_read_memory_device(&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.index_table_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.table_entries + 1,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.index_table_expansion_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.expn_table_entries,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	pos += ipa3_finish_read_memory_device(&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->nat_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.table_entries + 1 +
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->nat_mem.dev.expn_table_entries);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->ipv6ct_mem.dev.is_dev_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->ipv6ct_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	pos += ipa3_start_read_memory_device(&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	pos += ipa3_finish_read_memory_device(&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	if (!ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	for (i = 0; i < ipa3_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		if (!ipa3_ctx->ep[i].sys || !ipa3_ctx->ep[i].sys->status_stat)
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		memcpy(stats, ipa3_ctx->ep[i].sys->status_stat, sizeof(*stats));
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->ipa3_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->logbuf_low = ipa_ipc_low_buff;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		ipa3_ctx->logbuf_low = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		dent, &ipa3_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		dent, &ipa3_ctx->enable_clock_scaling);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:		&ipa3_ctx->ctrl->clock_scaling_bw_threshold_nominal);
drivers/platform/msm/ipa/ipa_v3/ipa_debugfs.c:			&ipa3_ctx->ctrl->clock_scaling_bw_threshold_turbo);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:		res = ipa_pm_deactivate_sync(ipa3_teth_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:		res = ipa_pm_deregister(ipa3_teth_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:		ipa3_teth_ctx->modem_pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:			&ipa3_teth_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:		res = ipa_pm_activate_sync(ipa3_teth_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	ipa3_teth_ctx->class = class_create(THIS_MODULE, TETH_BRIDGE_DRV_NAME);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	res = alloc_chrdev_region(&ipa3_teth_ctx->dev_num, 0, 1,
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	ipa3_teth_ctx->dev = device_create(ipa3_teth_ctx->class,
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:			ipa3_teth_ctx->dev_num,
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	if (IS_ERR(ipa3_teth_ctx->dev)) {
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	cdev_init(&ipa3_teth_ctx->cdev, &ipa3_teth_bridge_drv_fops);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	ipa3_teth_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	ipa3_teth_ctx->cdev.ops = &ipa3_teth_bridge_drv_fops;
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	res = cdev_add(&ipa3_teth_ctx->cdev, ipa3_teth_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	ipa3_teth_ctx->modem_pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	device_destroy(ipa3_teth_ctx->class, ipa3_teth_ctx->dev_num);
drivers/platform/msm/ipa/ipa_v3/teth_bridge.c:	unregister_chrdev_region(ipa3_teth_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:				ipa3_ctx->pdev, vma,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		phys_addr = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		dma_alloc_coherent(ipa3_ctx->pdev, IPA_NAT_IPV6CT_TEMP_MEM_SIZE,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if ((ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) &&
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_nat_ipv6ct_destroy_device(&ipa3_ctx->nat_mem.dev);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		dma_free_coherent(ipa3_ctx->pdev, IPA_NAT_IPV6CT_TEMP_MEM_SIZE,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_nat_ipv6ct_destroy_device(&ipa3_ctx->nat_mem.dev);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		ipa3_nat_ipv6ct_destroy_device(&ipa3_ctx->ipv6ct_mem.dev);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		   dma_alloc_coherent(ipa3_ctx->pdev, table_alloc->size,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	struct ipa3_nat_mem *nat_ctx = &(ipa3_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_lock(&nat_ctx->dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	result = ipa3_nat_ipv6ct_allocate_mem(&nat_ctx->dev, table_alloc);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		struct ipa_mem_buffer *pdn_mem = &nat_ctx->pdn_mem;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		pdn_mem->base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	nat_ctx->dev.is_mem_allocated = true;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&nat_ctx->dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (nat_ctx->dev.vaddr) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		dma_free_coherent(ipa3_ctx->pdev, table_alloc->size,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			nat_ctx->dev.vaddr, nat_ctx->dev.dma_handle);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		nat_ctx->dev.vaddr = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&nat_ctx->dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_lock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->ipv6ct_mem.dev, table_alloc);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->ipv6ct_mem.dev.is_mem_allocated = true;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		ipa3_ctx->nat_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		memset(ipa3_ctx->nat_mem.pdn_mem.base, 0, mem_size);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mem_cmd->system_addr = ipa3_ctx->nat_mem.pdn_mem.phys_base;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mem_cmd->local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (!ipa3_ctx->nat_mem.dev.is_mapped) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->nat_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->nat_mem.dev.is_sys_mem) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->nat_mem.dev.dma_handle, &cmd);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		pdn_entries = ipa3_ctx->nat_mem.pdn_mem.base;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.public_ip_addr = init->ip_addr;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	IPADBG("Public IP address:%pI4h\n", &ipa3_ctx->nat_mem.public_ip_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.index_table_addr =
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		 (char *)ipa3_ctx->nat_mem.dev.base_address +
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:				 ipa3_ctx->nat_mem.index_table_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.index_table_expansion_addr =
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	 (char *)ipa3_ctx->nat_mem.dev.base_address + init->index_expn_offset;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:				 ipa3_ctx->nat_mem.index_table_expansion_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.dev.is_hw_init = true;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (!ipa3_ctx->ipv6ct_mem.dev.is_mapped) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->ipv6ct_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipv6ct_mem.dev.is_sys_mem) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->ipv6ct_mem.dev.dma_handle,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->ipv6ct_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->ipv6ct_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->ipv6ct_mem.dev.is_hw_init = true;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	struct ipa3_nat_mem *nat_ctx = &(ipa3_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	struct ipa_pdn_entry *pdn_entries = nat_ctx->pdn_mem.base;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (!nat_ctx->dev.is_mem_allocated) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_lock(&nat_ctx->dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&nat_ctx->dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->nat_mem.dev.table_entries + 1;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->nat_mem.dev.expn_table_entries;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->nat_mem.dev.table_entries + 1;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->nat_mem.dev.expn_table_entries;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->ipv6ct_mem.dev.table_entries + 1;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		entries_num = ipa3_ctx->ipv6ct_mem.dev.expn_table_entries;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		if (!ipa3_ctx->nat_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:				ipa3_ctx->nat_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		if (!ipa3_ctx->ipv6ct_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:				ipa3_ctx->ipv6ct_mem.dev.name);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->pdev, dev->size,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->nat_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		&ipa3_ctx->ipv6ct_mem.dev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if ((ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) &&
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (!ipa3_ctx->nat_mem.dev.is_dev_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_lock(&ipa3_ctx->nat_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->nat_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.public_ip_addr = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.index_table_addr = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_ctx->nat_mem.index_table_expansion_addr = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0 &&
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		ipa3_ctx->nat_mem.dev.is_mem_allocated) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->nat_mem.pdn_mem.size,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->nat_mem.pdn_mem.base,
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:			ipa3_ctx->nat_mem.pdn_mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_nat_ipv6ct_free_mem(&ipa3_ctx->nat_mem.dev);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&ipa3_ctx->nat_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (!ipa3_ctx->ipv6ct_mem.dev.is_dev_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_lock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	if (ipa3_ctx->ipv6ct_mem.dev.is_hw_init) {
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	ipa3_nat_ipv6ct_free_mem(&ipa3_ctx->ipv6ct_mem.dev);
drivers/platform/msm/ipa/ipa_v3/ipa_nat.c:	mutex_unlock(&ipa3_ctx->ipv6ct_mem.dev.lock);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		client = ipa_pm_ctx->clients[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:				client_tput[n++] = ipa_pm_ctx->group_tput
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_lock_irqsave(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->clk_scaling.active_client_bitmask &= ~(1 << hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_unlock_irqrestore(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->clk_scaling.active_client_bitmask);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_lock_irqsave(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->clk_scaling.active_client_bitmask |= (1 << hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_unlock_irqrestore(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->clk_scaling.active_client_bitmask);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	clk = &ipa_pm_ctx->clk_scaling;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_lock_irqsave(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			spin_unlock_irqrestore(&ipa_pm_ctx->clk_scaling.lock,
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	spin_unlock_irqrestore(&ipa_pm_ctx->clk_scaling.lock, flags);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	clk_scaling = &ipa_pm_ctx->clk_scaling;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->aggregated_tput = tput;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	IPA_PM_DBG_LOW("old idx was at %d\n", ipa_pm_ctx->clk_scaling.cur_vote);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (ipa_pm_ctx->clk_scaling.cur_vote != new_th_idx) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->clk_scaling.cur_vote = new_th_idx;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa3_set_clock_plan_from_pm(ipa_pm_ctx->clk_scaling.cur_vote);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	IPA_PM_DBG_LOW("new idx is at %d\n", ipa_pm_ctx->clk_scaling.cur_vote);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		queue_delayed_work(ipa_pm_ctx->wq, &client->deactivate_work,
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		if (ipa_pm_ctx->clients[i] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		if (strlen(name) == strlen(ipa_pm_ctx->clients[i]->name))
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			if (!strcmp(name, ipa_pm_ctx->clients[i]->name))
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	for (i = 0; i < ipa_pm_ctx->clk_scaling.exception_size; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		exception = &ipa_pm_ctx->clk_scaling.exception_list[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		if (strnstr(exception->clients, ipa_pm_ctx->clients[hdl]->name,
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:				mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->clients[hdl]->name);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	for (i = 0; i < ipa_pm_ctx->clk_scaling.exception_size; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		exception = &ipa_pm_ctx->clk_scaling.exception_list[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->wq = create_singlethread_workqueue("ipa_pm_activate");
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (!ipa_pm_ctx->wq) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_init(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	clk_scaling = &ipa_pm_ctx->clk_scaling;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	destroy_workqueue(ipa_pm_ctx->wq);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->clients[*hdl] = kzalloc(sizeof
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (!ipa_pm_ctx->clients[*hdl]) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	client = ipa_pm_ctx->clients[*hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	client = ipa_pm_ctx->clients[hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		if (ipa_pm_ctx->clients_by_pipe[i] == ipa_pm_ctx->clients[hdl])
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			ipa_pm_ctx->clients_by_pipe[i] = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->clients[hdl] = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (ipa_pm_ctx->clients_by_pipe[idx] != NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	ipa_pm_ctx->clients_by_pipe[idx] = ipa_pm_ctx->clients[hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			queue_work(ipa_pm_ctx->wq,
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:				   &ipa_pm_ctx->clk_scaling.work);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	queue_work(ipa_pm_ctx->wq, &client->activate_work);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (hdl >= IPA_PM_MAX_CLIENTS || ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	return ipa_pm_activate_helper(ipa_pm_ctx->clients[hdl], false);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (hdl >= IPA_PM_MAX_CLIENTS || ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	return ipa_pm_activate_helper(ipa_pm_ctx->clients[hdl], true);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (hdl >= IPA_PM_MAX_CLIENTS || ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	client = ipa_pm_ctx->clients[hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		queue_delayed_work(ipa_pm_ctx->wq, &client->deactivate_work,
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		client = ipa_pm_ctx->clients[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (hdl >= IPA_PM_MAX_CLIENTS || ipa_pm_ctx->clients[hdl] == NULL) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	client = ipa_pm_ctx->clients[hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			client = ipa_pm_ctx->clients_by_pipe[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	if (hdl >= IPA_PM_MAX_CLIENTS || ipa_pm_ctx->clients[hdl] == NULL
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	client = ipa_pm_ctx->clients[hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			client->group, ipa_pm_ctx->group_tput[client->group]);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->group_tput[client->group] = throughput;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			client->group, ipa_pm_ctx->group_tput[client->group]);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	struct clk_scaling_db *clk = &ipa_pm_ctx->clk_scaling;
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		ipa_pm_ctx->aggregated_tput, clk->cur_vote);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		client = ipa_pm_ctx->clients[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			tput = ipa_pm_ctx->group_tput[client->group];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:			if (ipa_pm_ctx->clients_by_pipe[j] == client) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_lock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	for (i = 0; i < ipa_pm_ctx->clk_scaling.exception_size; i++) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		exception = &ipa_pm_ctx->clk_scaling.exception_list[i];
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:		for (j = 0; j < ipa_pm_ctx->clk_scaling.threshold_size; j++) {
drivers/platform/msm/ipa/ipa_v3/ipa_pm.c:	mutex_unlock(&ipa_pm_ctx->client_mutex);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	IPAERR("NTN stats ofst=0x%x\n", ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:			   ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ioremap(ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (!ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->tx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->rx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (!stats || !ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:			ipa3_ctx->uc_ntn_ctx.ntn_uc_stats_mmio);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.uc_ready_cb = ipa_ready_cb;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.priv = user_data;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.uc_ready_cb = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ipa3_ctx->uc_ntn_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->uc_ntn_ctx.uc_ready_cb) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.uc_ready_cb(
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:			ipa3_ctx->uc_ntn_ctx.priv);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.uc_ready_cb =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:		ipa3_ctx->uc_ntn_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	cmd.base = dma_alloc_coherent(ipa3_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ep_ul = &ipa3_ctx->ep[ipa_ep_idx_ul];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ep_dl = &ipa3_ctx->ep[ipa_ep_idx_dl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ep_ul = &ipa3_ctx->ep[ipa_ep_idx_ul];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	ep_dl = &ipa3_ctx->ep[ipa_ep_idx_dl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	cmd.base = dma_alloc_coherent(ipa3_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	if (ipa3_ctx->ipa_hw_type >= IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	memset(&ipa3_ctx->ep[ipa_ep_idx_dl], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	memset(&ipa3_ctx->ep[ipa_ep_idx_ul], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_uc_ntn.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	struct ipa3_ep_context *ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		    ipa3_ctx->resume_on_connect[ep->client] ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	struct ipa3_ep_context *ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:			if (ipa3_ctx->apply_rg10_wa && ipa3_uc_state_check()) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:					&ipa3_ctx->uc_loaded_completion_obj,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		dma_alloc_coherent(ipa3_ctx->pdev, chan_props.ring_len,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dma_free_coherent(ipa3_ctx->pdev, chan_dma->size,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	buff = dma_alloc_coherent(ipa3_ctx->pdev, 1, &dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dma_free_coherent(ipa3_ctx->pdev, 1, buff, dma_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dma_free_coherent(ipa3_ctx->pdev, chan_dma.size,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dma_free_coherent(ipa3_ctx->pdev, 1, buff, dma_addr);
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dma_free_coherent(ipa3_ctx->pdev, chan_dma.size,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_AP])
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_AP])
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	memset(&ipa3_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		if (ipa_ep_idx >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:			ipa3_ctx->ep[ipa_ep_idx].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	gsi_dev_hdl = ipa3_ctx->gsi_dev_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ipa3_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	memset(&ipa3_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	gsi_res = gsi_write_device_scratch(ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes  ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0 ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0 ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0 ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	memset(&ipa3_ctx->ep[clnt_hdl], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (dl_clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[dl_clnt_hdl].valid == 0 ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		(!is_dpl && (ul_clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[ul_clnt_hdl].valid == 0))) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dl_ep = &ipa3_ctx->ep[dl_clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ul_ep = &ipa3_ctx->ep[ul_clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes  ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (dl_clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[dl_clnt_hdl].valid == 0 ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		(!is_dpl && (ul_clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[ul_clnt_hdl].valid == 0))) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	dl_ep = &ipa3_ctx->ep[dl_clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ul_ep = &ipa3_ctx->ep[ul_clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	if (!ipa3_ctx->tethered_flow_control) {
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	spin_lock(&ipa3_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_client.c:	spin_unlock(&ipa3_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				dma_unmap_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				dma_unmap_page(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	WARN_ON(src_pipe >= ipa3_ctx->ipa_num_pipes);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (!ipa3_ctx->ep[src_pipe].status.status_en)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	sys = ipa3_ctx->ep[src_pipe].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	tx_pkt = kmem_cache_zalloc(ipa3_ctx->tx_pkt_wrapper_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		tx_pkt = kmem_cache_zalloc(ipa3_ctx->tx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:					dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:					skb_frag_dma_map(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (dma_mapping_error(ipa3_ctx->pdev, tx_pkt->mem.phys_base)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				dma_unmap_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				dma_unmap_page(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (ipa3_ctx->use_ipa_pm &&
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		atomic_inc(&ipa3_ctx->wc_memb.active_clnt_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (ipa3_ctx->modem_cfg_emb_pipe_flt &&
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	memset(&ipa3_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->gsi_evt_comm_ring_rem +=
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_free_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (ipa3_ctx->modem_cfg_emb_pipe_flt &&
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		atomic_dec(&ipa3_ctx->wc_memb.active_clnt_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (!atomic_read(&ipa3_ctx->wc_memb.active_clnt_cnt))
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	IPA_STATS_INC_CNT(ipa3_ctx->stats.tx_pkts_compl);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->ep[ep_idx].client_notify)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[ep_idx].client_notify(ipa3_ctx->ep[ep_idx].priv,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	sys = ipa3_ctx->ep[src_ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	gsi_ep = ipa3_get_gsi_ep_info(ipa3_ctx->ep[src_ep_idx].client);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		desc[data_idx].opcode = ipa3_ctx->pkt_init_imm_opcode;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		desc[data_idx].dma_address = ipa3_ctx->pkt_init_imm[dst_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		IPA_STATS_INC_CNT(ipa3_ctx->stats.tx_sw_pkts);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		IPA_STATS_INC_CNT(ipa3_ctx->stats.tx_hw_pkts);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		IPA_STATS_INC_CNT(ipa3_ctx->stats.tx_non_linear);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (!ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa3_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa3_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (dma_mapping_error(ipa3_ctx->pdev, rx_pkt->data.dma_addr)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.wan_repl_rx_empty);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.lan_repl_rx_empty);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_lock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			&ipa3_ctx->wc_memb.wlan_comm_desc_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			if (ipa3_ctx->wc_memb.wlan_comm_free_cnt > 0)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				ipa3_ctx->wc_memb.wlan_comm_free_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:					&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			ipa3_ctx->wc_memb.wlan_comm_total_cnt <
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->wc_memb.wlan_comm_total_cnt +=
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_lock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		&ipa3_ctx->wc_memb.wlan_comm_desc_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->wc_memb.wlan_comm_free_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->wc_memb.wlan_comm_total_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->wc_memb.total_tx_pkts_freed = 0;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->wc_memb.wlan_comm_free_cnt != 0)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			ipa3_ctx->wc_memb.wlan_comm_free_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->wc_memb.wlan_comm_total_cnt != 0)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			ipa3_ctx->wc_memb.wlan_comm_total_cnt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	rx_len_cached = ipa3_ctx->wc_memb.wlan_comm_total_cnt;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa3_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa3_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (dma_mapping_error(ipa3_ctx->pdev, rx_pkt->data.dma_addr)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		spin_lock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			&ipa3_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_len_cached = ++ipa3_ctx->wc_memb.wlan_comm_total_cnt;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->wc_memb.wlan_comm_free_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		spin_unlock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa3_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa3_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (dma_mapping_error(ipa3_ctx->pdev, rx_pkt->data.dma_addr)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				ipa3_ctx->rx_pkt_wrapper_cache, flag);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			rx_pkt->data.dma_addr = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			if (dma_mapping_error(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			rx_pkt->data.dma_addr = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			if (dma_mapping_error(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.wan_rx_empty);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.lan_rx_empty);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			dma_unmap_single(ipa3_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				ipa3_ctx->stats.rx_excp_pkts);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (status.endp_dest_idx >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			status.endp_src_idx >= ipa3_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.aggr_close);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_DEC_CNT(ipa3_ctx->stats.rx_excp_pkts
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (status.endp_dest_idx == (sys->ep - ipa3_ctx->ep)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.stat_compl);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_DEC_CNT(ipa3_ctx->stats.rx_excp_pkts
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->ipa_client_apps_wan_cons_agg_gro) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		IPA_STATS_INC_CNT(ipa3_ctx->stats.rx_pkts);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (status.endp_dest_idx >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			status.endp_src_idx >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_DEC_CNT(ipa3_ctx->stats.rx_pkts);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			IPA_STATS_INC_CNT(ipa3_ctx->stats.wan_aggr_close);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[src_pipe];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (unlikely(src_pipe >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	rx_pkt = kmem_cache_zalloc(ipa3_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	rx_pkt->sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	dma_unmap_single(ipa3_ctx->pdev, rx_pkt_expected->data.dma_addr,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	kmem_cache_free(ipa3_ctx->rx_pkt_wrapper_cache, rk_pkt);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:					ipa3_ctx->lan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				sys->rx_pool_sz = ipa3_ctx->wan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				if (ipa3_ctx->
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	atomic_inc(&ipa3_ctx->ep[ep_idx].avail_fifo_desc);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->ep[ep_idx].wstats.rx_pkts_status_rcvd++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ep_idx, atomic_read(&ipa3_ctx->ep[ep_idx].avail_fifo_desc));
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[ep_idx].priv);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->ep[ep_idx].client_notify) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[ep_idx].client_notify(ipa3_ctx->ep[ep_idx].priv,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[ep_idx].wstats.rx_hd_reply++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	atomic_inc(&ipa3_ctx->ep[ep_idx].avail_fifo_desc);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->ep[ep_idx].wstats.rx_pkts_status_rcvd++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_lock_bh(&ipa3_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	sys = ipa3_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (unlikely(ipa3_ctx->ep[ep_idx].valid == 0)) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_lock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->wc_memb.total_tx_pkts_freed++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		&ipa3_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->wc_memb.wlan_comm_free_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	spin_unlock_bh(&ipa3_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	*ipa_transport_hdl = ipa3_ctx->gsi_dev_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		atomic_set(&ipa3_ctx->transport_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (ipa3_ctx->use_ipa_pm) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		atomic_set(&ipa3_ctx->transport_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->gsi_dev_hdl, &ipa3_ctx->gsi_evt_comm_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ipa3_ctx->gsi_evt_comm_ring_rem = IPA_COMMON_EVENT_RING_SIZE;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (ipa3_ctx->gsi_evt_comm_ring_rem < 2 * in->desc_fifo_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:				ipa3_ctx->gsi_evt_comm_ring_rem,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->gsi_evt_comm_ring_rem -= (2 * in->desc_fifo_sz);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ep->gsi_evt_ring_hdl = ipa3_ctx->gsi_evt_comm_hdl;
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			ipa3_ctx->gsi_dev_hdl, &ep->gsi_evt_ring_hdl);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_alloc_coherent(ipa3_ctx->pdev, gsi_channel_props.ring_len,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	result = gsi_alloc_channel(&gsi_channel_props, ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	dma_free_coherent(ipa3_ctx->pdev, gsi_channel_props.ring_len,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_free_coherent(ipa3_ctx->pdev, gsi_evt_ring_props.ring_len,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		atomic_set(&ipa3_ctx->transport_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		if (ipa3_ctx->use_ipa_pm)
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:		dma_alloc_coherent(ipa3_ctx->pdev, gsi_channel_props.ring_len,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:			ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_dp.c:	result = gsi_alloc_channel(&gsi_channel_props, ipa3_ctx->gsi_dev_hdl,
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_add_tail(&intf->link, &ipa3_ctx->intf_list);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry_safe(entry, next, &ipa3_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry(entry, &ipa3_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry(entry, &ipa3_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry(entry, &ipa3_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry(entry, &ipa3_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_add_tail(&msg->link, &ipa3_ctx->msg_list);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	IPA_STATS_INC_CNT(ipa3_ctx->stats.msg_w[meta->msg_type]);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	wake_up(&ipa3_ctx->msg_waitq);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_add_tail(&msg->link, &ipa3_ctx->pull_msg_list);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry_safe(entry, next, &ipa3_ctx->pull_msg_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	add_wait_queue(&ipa3_ctx->msg_waitq, &wait);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:		mutex_lock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:		if (!list_empty(&ipa3_ctx->msg_list)) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:			msg = list_first_entry(&ipa3_ctx->msg_list,
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:			mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:				ipa3_ctx->stats.msg_r[msg->meta.msg_type]);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:		mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	remove_wait_queue(&ipa3_ctx->msg_waitq, &wait);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:		mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_lock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	list_for_each_entry(entry, &ipa3_ctx->pull_msg_list, link) {
drivers/platform/msm/ipa/ipa_v3/ipa_intf.c:	mutex_unlock(&ipa3_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	ipa3_ctx->hw_stats.enabled = true;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	memset(&ipa3_ctx->hw_stats.quota, 0, sizeof(ipa3_ctx->hw_stats.quota));
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	ipa3_ctx->hw_stats.quota.init.enabled_bitmask = pipe_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.quota.init, false);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_address = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (dma_mapping_error(ipa3_ctx->pdev, dma_address)) {
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	quota_base.value = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_unmap_single(ipa3_ctx->pdev, dma_address, pyld->len, DMA_TO_DEVICE);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	get_offset.init = ipa3_ctx->hw_stats.quota.init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.quota.init, mem.base, stats);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		if (ipa3_ctx->ep[ep_idx].client != i)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.quota.stats.client[i].num_ipv4_bytes +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.quota.stats.client[i].num_ipv4_pkts +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.quota.stats.client[i].num_ipv6_bytes +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.quota.stats.client[i].num_ipv6_pkts +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		*out = ipa3_ctx->hw_stats.quota.stats;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	stats = &ipa3_ctx->hw_stats.quota.stats.client[client];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	stats = &ipa3_ctx->hw_stats.quota.stats;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	memset(&ipa3_ctx->hw_stats.teth.init, 0,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		sizeof(ipa3_ctx->hw_stats.teth.init));
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		memset(&ipa3_ctx->hw_stats.teth.prod_stats[i], 0,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			sizeof(ipa3_ctx->hw_stats.teth.prod_stats[i]));
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	ipa3_ctx->hw_stats.teth.init.prod_bitmask = in->prod_mask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	memcpy(ipa3_ctx->hw_stats.teth.init.cons_bitmask, in->dst_ep_mask,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		sizeof(ipa3_ctx->hw_stats.teth.init.cons_bitmask));
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.teth.init, false);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_address = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (dma_mapping_error(ipa3_ctx->pdev, dma_address)) {
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	teth_base.value = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_unmap_single(ipa3_ctx->pdev, dma_address, pyld->len, DMA_TO_DEVICE);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	get_offset.init = ipa3_ctx->hw_stats.teth.init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.teth.init, mem.base, stats);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:				&ipa3_ctx->hw_stats.teth;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			if (ipa3_ctx->ep[prod_idx].client != i ||
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			    ipa3_ctx->ep[cons_idx].client != j)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	*out = ipa3_ctx->hw_stats.teth.prod_stats[prod];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	stats = &ipa3_ctx->hw_stats.teth.prod_stats[prod].client[cons];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		stats = &ipa3_ctx->hw_stats.teth.prod_stats[prod].client[i];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		stats = &ipa3_ctx->hw_stats.teth.prod_stats[i];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			ipa3_ctx->hw_stats.flt_rt.flt_v4_init.rule_id_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			ipa3_ctx->hw_stats.flt_rt.rt_v4_init.rule_id_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			ipa3_ctx->hw_stats.flt_rt.flt_v6_init.rule_id_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			ipa3_ctx->hw_stats.flt_rt.rt_v6_init.rule_id_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_address = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (dma_mapping_error(ipa3_ctx->pdev, dma_address)) {
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	flt_rt_base.value = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_unmap_single(ipa3_ctx->pdev, dma_address, pyld->len, DMA_TO_DEVICE);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		get_offset->init = ipa3_ctx->hw_stats.flt_rt.flt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		get_offset->init = ipa3_ctx->hw_stats.flt_rt.rt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		get_offset->init = ipa3_ctx->hw_stats.flt_rt.flt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		get_offset->init = ipa3_ctx->hw_stats.flt_rt.rt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	memset(&ipa3_ctx->hw_stats.drop, 0, sizeof(ipa3_ctx->hw_stats.drop));
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	ipa3_ctx->hw_stats.drop.init.enabled_bitmask = pipe_bitmask;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.drop.init, false);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_address = dma_map_single(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (dma_mapping_error(ipa3_ctx->pdev, dma_address)) {
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->ee);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	drop_base.value = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_unmap_single(ipa3_ctx->pdev, dma_address, pyld->len, DMA_TO_DEVICE);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	get_offset.init = ipa3_ctx->hw_stats.drop.init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mem.base = dma_alloc_coherent(ipa3_ctx->pdev,
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	cmd.local_addr = ipa3_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		&ipa3_ctx->hw_stats.drop.init, mem.base, stats);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		if (ipa3_ctx->ep[ep_idx].client != i)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.drop.stats.client[i].drop_byte_cnt +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		ipa3_ctx->hw_stats.drop.stats.client[i].drop_packet_cnt +=
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	*out = ipa3_ctx->hw_stats.drop.stats;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	dma_free_coherent(ipa3_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	stats = &ipa3_ctx->hw_stats.drop.stats.client[client];
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	stats = &ipa3_ctx->hw_stats.drop.stats;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		if (!(ipa3_ctx->hw_stats.quota.init.enabled_bitmask &
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		if (!(ipa3_ctx->hw_stats.teth.init.prod_bitmask &
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:			if (!(ipa3_ctx->hw_stats.teth.init.cons_bitmask[ep_idx]
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v4_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.flt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		init = &ipa3_ctx->hw_stats.flt_rt.rt_v6_init;
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:				mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_lock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:		if (!(ipa3_ctx->hw_stats.drop.init.enabled_bitmask &
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	mutex_unlock(&ipa3_ctx->lock);
drivers/platform/msm/ipa/ipa_v3/ipa_hw_stats.c:	if (!ipa3_ctx->hw_stats.enabled)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	IPAERR("WDI stats ofst=0x%x\n", ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:			ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ioremap(ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (!ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio->tx_ch_stats.y
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio->rx_ch_stats.y
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (!stats || !ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:			ipa3_ctx->uc_wdi_ctx.wdi_uc_stats_mmio);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->wdi_map_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->wdi_map_cnt++;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:				ipa3_ctx->wdi_map_cnt--;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (ipa3_ctx->wdi_map_cnt == 0)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (wlan_smmu_en && ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC]) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (!wlan_smmu_en && ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC]) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (!wlan_smmu_en && !ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC]) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (wlan_smmu_en && !ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_UC]) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	memset(&ipa3_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_ring_base_pa =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_ring_rp_pa =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_ring_size =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_comp_ring_base_pa =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_comp_ring_wp_pa =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_ctx.rdy_comp_ring_size =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:				ipa3_ctx->uc_ctx.rdy_ring_rp_va =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:				ipa3_ctx->uc_ctx.rdy_comp_ring_wp_va =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	cmd.base = dma_alloc_coherent(ipa3_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		out->uc_door_bell_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		out->uc_door_bell_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.stats_notify = in->wdi_notify;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	memset(&ipa3_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	dma_free_coherent(ipa3_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	memset(&ipa3_ctx->ep[clnt_hdl], 0, sizeof(struct ipa3_ep_context));
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (ipa3_ctx->uc_wdi_ctx.stats_notify)
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.stats_notify = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ep[prod_hdl].valid == 1) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		if (ipa3_ctx->ipa_hw_type < IPA_HW_v4_0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->tag_process_before_gating = true;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (clnt_hdl >= ipa3_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	    ipa3_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ep = &ipa3_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.uc_ready_cb = inout->notify;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.priv = inout->priv;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.uc_ready_cb = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	ipa3_ctx->uc_wdi_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		param->uc_door_bell_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		param->uc_door_bell_pa = ipa3_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (ipa3_ctx->uc_wdi_ctx.uc_ready_cb) {
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.uc_ready_cb(
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:			ipa3_ctx->uc_wdi_ctx.priv);
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.uc_ready_cb =
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:		ipa3_ctx->uc_wdi_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v3/ipa_uc_wdi.c:	if (ipa3_ctx->s1_bypass_arr[IPA_SMMU_CB_WLAN]) {
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:			IPA_IPC_LOGGING(ipa_ctx->logbuf_low, \
drivers/platform/msm/ipa/ipa_v2/ipa_i.h:#define IPA_MEM_PART(x_) (ipa_ctx->ctrl->mem_partition.x_)
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:		if ((ep_suspend_data & bmsk) && (ipa_ctx->ep[i].valid))
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:		suspend_data = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	en = ipa_read_reg(ipa_ctx->mmio, IPA_IRQ_EN_EE_n_ADDR(ipa_ee));
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	reg = ipa_read_reg(ipa_ctx->mmio, IPA_IRQ_STTS_EE_n_ADDR(ipa_ee));
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:				ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:				ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:		reg = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:		queue_work(ipa_ctx->power_mgmt_wq, &ipa_interrupt_defer_work);
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	if (ipa_ctx->ipa_active_clients.cnt == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:		queue_work(ipa_ctx->power_mgmt_wq, &ipa_interrupt_defer_work);
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	val = ipa_read_reg(ipa_ctx->mmio, IPA_IRQ_EN_EE_n_ADDR(ipa_ee));
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	ipa_write_reg(ipa_ctx->mmio, IPA_IRQ_EN_EE_n_ADDR(ipa_ee), val);
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	val = ipa_read_reg(ipa_ctx->mmio, IPA_IRQ_EN_EE_n_ADDR(ipa_ee));
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	ipa_write_reg(ipa_ctx->mmio, IPA_IRQ_EN_EE_n_ADDR(ipa_ee), val);
drivers/platform/msm/ipa/ipa_v2/ipa_interrupts.c:	ipa_write_reg(ipa_ctx->mmio, IPA_IRQ_CLR_EE_n_ADDR(ipa_ee), reg);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	#x "=0x%x\n", ipa_uc_mhi_ctx->mhi_uc_stats_mmio->mhiCmnStats.x))
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	#x "=0x%x\n", ipa_uc_mhi_ctx->mhi_uc_stats_mmio->mhiCnlStats[ch].x))
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (uc_sram_mmio->responseOp == ipa_uc_mhi_ctx->expected_responseOp &&
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	    ipa_uc_mhi_ctx->expected_responseParams) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (ipa_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	} else if (ipa_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		ipa_uc_mhi_ctx->wakeup_request_cb();
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->mhi_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	IPAERR("MHI stats ofst=0x%x\n", ipa_uc_mhi_ctx->mhi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (ipa_uc_mhi_ctx->mhi_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		ipa_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:			ipa_uc_mhi_ctx->mhi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->mhi_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		ioremap(ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		ipa_uc_mhi_ctx->mhi_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (!ipa_uc_mhi_ctx->mhi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->ready_cb = ready_cb;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->wakeup_request_cb = wakeup_request_cb;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	hdlrs.ipa_uc_loaded_hdlr = ipa_uc_mhi_ctx->ready_cb;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:		dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (ipa_ep_idx < 0  || ipa_ep_idx >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseParams = uc_rsp.raw32b;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	ipa_uc_mhi_ctx->expected_responseParams = cmd.raw32b;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_mhi.c:	if (!ipa_uc_mhi_ctx->mhi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	cmd.base = dma_alloc_coherent(ipa_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_rx = &ipa_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_tx = &ipa_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	out->rx_uc_db_pa = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	out->tx_uc_db_pa = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	cmd.base = dma_alloc_coherent(ipa_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_tx = &ipa_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_rx = &ipa_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_tx = &ipa_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_rx = &ipa_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_tx = &ipa_ctx->ep[ipa_ep_idx_tx];
drivers/platform/msm/ipa/ipa_v2/ipa_wdi3_i.c:	ep_rx = &ipa_ctx->ep[ipa_ep_idx_rx];
drivers/platform/msm/ipa/ipa_v2/ipa.c:	start_idx = (ipa_ctx->ipa2_active_clients_logging.log_tail + 1) %
drivers/platform/msm/ipa/ipa_v2/ipa.c:	end_idx = ipa_ctx->ipa2_active_clients_logging.log_head;
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->ipa2_active_clients_logging
drivers/platform/msm/ipa/ipa_v2/ipa.c:	hash_for_each(ipa_ctx->ipa2_active_clients_logging.htable, i,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ipa_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	head = ipa_ctx->ipa2_active_clients_logging.log_head;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	tail = ipa_ctx->ipa2_active_clients_logging.log_tail;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->ipa2_active_clients_logging.log_rdy)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	memset(ipa_ctx->ipa2_active_clients_logging.log_buffer[head], '_',
drivers/platform/msm/ipa/ipa_v2/ipa.c:	strlcpy(ipa_ctx->ipa2_active_clients_logging.log_buffer[head], string,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_tail = tail;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_head = head;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_buffer[0] = kzalloc(
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa2_active_clients_logging.log_buffer == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ipa2_active_clients_logging.log_buffer[i] =
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ipa2_active_clients_logging.log_buffer[0] +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	hash_init(ipa_ctx->ipa2_active_clients_logging.htable);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_rdy = 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_rdy = 0;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kfree(ipa_ctx->ipa2_active_clients_logging.log_buffer[0]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_head = 0;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_tail =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	return ipa_ctx->pdev;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->tethered_flow_control) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ep = &ipa_ctx->ep[ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.flow_enable);
drivers/platform/msm/ipa/ipa_v2/ipa.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.flow_disable);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		mutex_lock(&ipa_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		memcpy(&ipa_ctx->ipa_cne_evt_req_cache[
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->num_ipa_cne_evt_req].wan_msg,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		memcpy(&ipa_ctx->ipa_cne_evt_req_cache[
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->num_ipa_cne_evt_req].msg_meta,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->num_ipa_cne_evt_req++;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->num_ipa_cne_evt_req %= IPA_MAX_NUM_REQ_CACHE;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		mutex_unlock(&ipa_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		memcpy(param, &ipa_ctx->ipa_hw_type, pyld_sz);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	rt_rule_entry->rule.hdr_hdl = ipa_ctx->excp_hdr_hdl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->dflt_v4_rt_rule_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->dflt_v6_rt_rule_hdl = rt_rule_entry->rt_rule_hdl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v1_1) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	} else if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->excp_hdr_hdl = hdr_entry->hdr_hdl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	route.route_def_hdr_table = !ipa_ctx->hdr_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	cmd->local_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v2_0)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	u32 max_cmds = ipa_get_max_flt_rt_cmds(ipa_ctx->ipa_num_pipes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, 4, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	*entry = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (pipe_idx = 0; pipe_idx < ipa_ctx->ipa_num_pipes; pipe_idx++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (!ipa_ctx->ep[pipe_idx].valid ||
drivers/platform/msm/ipa/ipa_v2/ipa.c:		    ipa_ctx->ep[pipe_idx].skip_ep_cfg) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		cmd[num_cmds].local_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		cmd[num_cmds].local_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	desc = kcalloc(ipa_ctx->ipa_num_pipes, sizeof(struct ipa_desc),
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (ipa_ctx->ep[ep_idx].valid &&
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ep[ep_idx].skip_ep_cfg) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			BUG_ON(num_descs >= ipa_ctx->ipa_num_pipes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->uc_ctx.uc_zip_error)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->q6_proxy_clk_vote_valid = true;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->uc_ctx.uc_loaded) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->smem_restricted_bytes / 4);
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->smem_sz - ipa_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smem_sz - ipa_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smem_sz - ipa_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	cmd->hdr_table_dst_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	cmd->hdr_table_dst_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_cmd->local_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:		dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->rt_idx_bitmap[IPA_IP_v4] |= (1 << i);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG("v4 rt bitmap 0x%lx\n", ipa_ctx->rt_idx_bitmap[IPA_IP_v4]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		*entry = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	v4_cmd->ipv4_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->rt_idx_bitmap[IPA_IP_v6] |= (1 << i);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG("v6 rt bitmap 0x%lx\n", ipa_ctx->rt_idx_bitmap[IPA_IP_v6]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		*entry = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	v6_cmd->ipv6_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (i = 0; i <= ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		*entry = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	v4_cmd->ipv4_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (i = 0; i <= ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		*entry = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	v6_cmd->ipv6_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa2_setup_sys_pipe(&sys_in, &ipa_ctx->clnt_hdl_cmd)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_sram();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_hdr();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_rt4();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_rt6();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_flt4();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_init_flt6();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v1_1) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	} else if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa2_setup_sys_pipe(&sys_in, &ipa_ctx->clnt_hdl_data_in)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa2_setup_sys_pipe(&sys_in, &ipa_ctx->clnt_hdl_data_out)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa2_teardown_sys_pipe(ipa_ctx->clnt_hdl_data_in);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->dflt_v6_rt_rule_hdl)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		__ipa_del_rt_rule(ipa_ctx->dflt_v6_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->dflt_v4_rt_rule_hdl)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		__ipa_del_rt_rule(ipa_ctx->dflt_v4_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->excp_hdr_hdl)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		__ipa_del_hdr(ipa_ctx->excp_hdr_hdl, false);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa2_teardown_sys_pipe(ipa_ctx->clnt_hdl_cmd);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa2_teardown_sys_pipe(ipa_ctx->clnt_hdl_data_out);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa2_teardown_sys_pipe(ipa_ctx->clnt_hdl_data_in);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	__ipa_del_rt_rule(ipa_ctx->dflt_v6_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	__ipa_del_rt_rule(ipa_ctx->dflt_v4_rt_rule_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	__ipa_del_hdr(ipa_ctx->excp_hdr_hdl, false);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa2_teardown_sys_pipe(ipa_ctx->clnt_hdl_cmd);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type < IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		IPADBG_LOW("curr_ipa_clk_rate=%d", ipa_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		clk_set_rate(ipa_clk, ipa_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->curr_ipa_clk_rate == ipa_ctx->ctrl->ipa_clk_rate_svs) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	} else if (ipa_ctx->curr_ipa_clk_rate ==
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->ipa_clk_rate_nominal) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (ipa_ctx->ctrl->msm_bus_data_ptr->num_usecases <= 2)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	} else if (ipa_ctx->curr_ipa_clk_rate ==
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->ipa_clk_rate_turbo) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		idx = ipa_ctx->ctrl->msm_bus_data_ptr->num_usecases - 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG("curr %d idx %d\n", ipa_ctx->curr_ipa_clk_rate, idx);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_enable_clks();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_mode != IPA_HW_MODE_VIRTUAL)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (msm_bus_scale_client_update_request(ipa_ctx->ipa_bus_hdl,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_disable_clks();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_mode != IPA_HW_MODE_VIRTUAL)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (msm_bus_scale_client_update_request(ipa_ctx->ipa_bus_hdl,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	hash_for_each_possible(ipa_ctx->ipa2_active_clients_logging.htable,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		hash_add(ipa_ctx->ipa2_active_clients_logging.htable,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_active_clients.cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_active_clients.cnt == 1)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG_LOW("active clients = %d\n", ipa_ctx->ipa_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_active_clients.cnt == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_active_clients.cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG_LOW("active clients = %d\n", ipa_ctx->ipa_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_active_clients.cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG_LOW("active clients = %d\n", ipa_ctx->ipa_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_active_clients.cnt == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (ipa_ctx->tag_process_before_gating) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->tag_process_before_gating = false;
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ipa_active_clients.cnt = 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:			queue_work(ipa_ctx->power_mgmt_wq, &ipa_tag_work);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_irqsave(&ipa_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->wakelock_ref_cnt.cnt & (1 << ref_client))
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ref_client, ipa_ctx->wakelock_ref_cnt.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->wakelock_ref_cnt.cnt |= (1 << ref_client);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->wakelock_ref_cnt.cnt)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		__pm_stay_awake(&ipa_ctx->w_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->wakelock_ref_cnt.cnt, ref_client);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_unlock_irqrestore(&ipa_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_irqsave(&ipa_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->wakelock_ref_cnt.cnt &= ~(1 << ref_client);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->wakelock_ref_cnt.cnt, ref_client);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->wakelock_ref_cnt.cnt == 0)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		__pm_relax(&ipa_ctx->w_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_unlock_irqrestore(&ipa_ctx->wakelock_ref_cnt.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	switch (ipa_ctx->ipa_hw_type) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type < IPA_HW_v2_5)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->enable_clock_scaling) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->clock_scaling_bw_threshold_turbo)
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->clock_scaling_bw_threshold_nominal)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		clk_rate = ipa_ctx->ctrl->ipa_clk_rate_svs;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		clk_rate = ipa_ctx->ctrl->ipa_clk_rate_nominal;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		clk_rate = ipa_ctx->ctrl->ipa_clk_rate_turbo;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (clk_rate == ipa_ctx->curr_ipa_clk_rate) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->curr_ipa_clk_rate = clk_rate;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	IPADBG_LOW("setting clock rate to %u\n", ipa_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_active_clients.cnt > 0) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ipa_active_clients.cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		clk_set_rate(ipa_clk, ipa_ctx->curr_ipa_clk_rate);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (ipa_ctx->ipa_hw_mode != IPA_HW_MODE_VIRTUAL)
drivers/platform/msm/ipa/ipa_v2/ipa.c:			    ipa_ctx->ipa_bus_hdl, ipa_get_bus_vote()))
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v1_1) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	queue_delayed_work(ipa_ctx->sps_power_mgmt_wq,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if ((suspend_data & bmsk) && (ipa_ctx->ep[i].valid)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			if (IPA_CLIENT_IS_APPS_CONS(ipa_ctx->ep[i].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:				mutex_lock(&ipa_ctx->sps_pm.sps_pm_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:					&ipa_ctx->sps_pm.dec_clients)
drivers/platform/msm/ipa/ipa_v2/ipa.c:							ipa_ctx->ep[i].client);
drivers/platform/msm/ipa/ipa_v2/ipa.c:						&ipa_ctx->sps_pm.dec_clients,
drivers/platform/msm/ipa/ipa_v2/ipa.c:				mutex_unlock(&ipa_ctx->sps_pm.sps_pm_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:					ipa_ctx->ep[i].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:					   ipa_ctx->ep[i].client, &holb_cfg);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_lock(&ipa_ctx->sps_pm.sps_pm_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (atomic_read(&ipa_ctx->sps_pm.dec_clients)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (atomic_read(&ipa_ctx->sps_pm.eot_activity)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			atomic_set(&ipa_ctx->sps_pm.dec_clients, 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	atomic_set(&ipa_ctx->sps_pm.eot_activity, 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_unlock(&ipa_ctx->sps_pm.sps_pm_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->logbuf = ipc_log_context_create(IPA_IPC_LOG_PAGES, "ipa", 0);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->logbuf == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->pdev = ipa_dev;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->uc_pdev = ipa_dev;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->smmu_present = smmu_info.present;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->smmu_present)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smmu_s1_bypass = true;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smmu_s1_bypass = smmu_info.s1_bypass;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_wrapper_base = resource_p->ipa_mem_base;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_wrapper_size = resource_p->ipa_mem_size;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_hw_type = resource_p->ipa_hw_type;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_hw_mode = resource_p->ipa_hw_mode;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_uc_monitor_holb =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->use_ipa_teth_bridge = resource_p->use_ipa_teth_bridge;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_bam_remote_mode = resource_p->ipa_bam_remote_mode;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->modem_cfg_emb_pipe_flt = resource_p->modem_cfg_emb_pipe_flt;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_wdi2 = resource_p->ipa_wdi2;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->wan_rx_ring_size = resource_p->wan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->lan_rx_ring_size = resource_p->lan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->skip_uc_pipe_reset = resource_p->skip_uc_pipe_reset;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->use_dma_zone = resource_p->use_dma_zone;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->tethered_flow_control = resource_p->tethered_flow_control;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->use_ipa_pm = resource_p->use_ipa_pm;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_rx_timeout_min_max_calc(&ipa_ctx->ipa_rx_min_timeout_usec,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		&ipa_ctx->ipa_rx_max_timeout_usec,
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ipa_polling_iteration =
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ipa_polling_iteration = MAX_POLLING_ITERATION;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->aggregation_type = IPA_MBIM_16;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->aggregation_byte_limit = 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->aggregation_time_limit = 0;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa2_active_clients_logging.log_rdy = false;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl = kzalloc(sizeof(*ipa_ctx->ctrl), GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->ctrl) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	result = ipa_controller_static_bind(ipa_ctx->ctrl,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	       ipa_ctx->hdr_tbl_lcl, ipa_ctx->ip4_rt_tbl_lcl,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	       ipa_ctx->ip6_rt_tbl_lcl, ipa_ctx->ip4_flt_tbl_lcl,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	       ipa_ctx->ip6_flt_tbl_lcl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ctrl->msm_bus_data_ptr = bus_scale_table;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_mode != IPA_HW_MODE_VIRTUAL) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->ipa_bus_hdl =
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->ctrl->msm_bus_data_ptr);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (!ipa_ctx->ipa_bus_hdl) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	/* Enable ipa_ctx->enable_clock_scaling */
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->enable_clock_scaling = 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->curr_ipa_clk_rate = ipa_ctx->ctrl->ipa_clk_rate_turbo;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->mmio = ioremap(resource_p->ipa_mem_base +
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->ctrl->ipa_reg_base_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_num_pipes = ipa_get_num_pipes();
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ctrl->ipa_sram_read_settings();
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smem_sz, ipa_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->smem_reqd_sz >
drivers/platform/msm/ipa/ipa_v2/ipa.c:		ipa_ctx->smem_sz - ipa_ctx->smem_restricted_bytes) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->smem_reqd_sz, ipa_ctx->smem_sz -
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->smem_restricted_bytes);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->ipa_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->ipa_active_clients.spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->ipa_active_clients.cnt = 1;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->power_mgmt_wq =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->power_mgmt_wq) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->sps_power_mgmt_wq =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->sps_power_mgmt_wq) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	bam_props.num_pipes = ipa_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_hw_mode != IPA_HW_MODE_VIRTUAL)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->ipa_bam_remote_mode == true)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->smmu_s1_bypass)
drivers/platform/msm/ipa/ipa_v2/ipa.c:	result = sps_register_bam_device(&bam_props, &ipa_ctx->bam_handle);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->flt_rule_cache = kmem_cache_create("IPA_FLT",
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->flt_rule_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->rt_rule_cache = kmem_cache_create("IPA_RT",
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->rt_rule_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->hdr_cache = kmem_cache_create("IPA_HDR",
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->hdr_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->hdr_offset_cache =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->hdr_offset_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->hdr_proc_ctx_cache = kmem_cache_create("IPA_HDR_PROC_CTX",
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->hdr_proc_ctx_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->hdr_proc_ctx_offset_cache =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->hdr_proc_ctx_offset_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->rt_tbl_cache = kmem_cache_create("IPA_RT_TBL",
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->rt_tbl_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->tx_pkt_wrapper_cache =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->tx_pkt_wrapper_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->rx_pkt_wrapper_cache =
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->rx_pkt_wrapper_cache) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->dma_pool = dma_pool_create("ipa_tx", ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->dma_pool) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->glob_flt_tbl[IPA_IP_v4].in_sys = !ipa_ctx->ip4_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->glob_flt_tbl[IPA_IP_v6].in_sys = !ipa_ctx->ip6_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->glob_flt_tbl[IPA_IP_v4].head_flt_rule_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->glob_flt_tbl[IPA_IP_v6].head_flt_rule_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->hdr_tbl.head_hdr_entry_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		INIT_LIST_HEAD(&ipa_ctx->hdr_tbl.head_offset_list[i]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		INIT_LIST_HEAD(&ipa_ctx->hdr_tbl.head_free_offset_list[i]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		INIT_LIST_HEAD(&ipa_ctx->hdr_proc_ctx_tbl.head_offset_list[i]);
drivers/platform/msm/ipa/ipa_v2/ipa.c:		INIT_LIST_HEAD(&ipa_ctx->
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->rt_tbl_set[IPA_IP_v4].head_rt_tbl_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->rt_tbl_set[IPA_IP_v6].head_rt_tbl_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		flt_tbl = &ipa_ctx->flt_tbl[i][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v2/ipa.c:		flt_tbl->in_sys = !ipa_ctx->ip4_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:		flt_tbl = &ipa_ctx->flt_tbl[i][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v2/ipa.c:		flt_tbl->in_sys = !ipa_ctx->ip6_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	rset = &ipa_ctx->reap_rt_tbl_set[IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v2/ipa.c:	rset = &ipa_ctx->reap_rt_tbl_set[IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->intf_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->msg_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->pull_msg_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	init_waitqueue_head(&ipa_ctx->msg_waitq);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->nat_mem.lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->ipa_cne_evt_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	idr_init(&ipa_ctx->ipa_idr);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	memset(&ipa_ctx->wc_memb, 0, sizeof(ipa_ctx->wc_memb));
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	INIT_LIST_HEAD(&ipa_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->empty_rt_tbl_mem.size = IPA_ROUTING_RULE_BYTE_SIZE;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->empty_rt_tbl_mem.base =
drivers/platform/msm/ipa/ipa_v2/ipa.c:		dma_alloc_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->empty_rt_tbl_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa.c:				    &ipa_ctx->empty_rt_tbl_mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (!ipa_ctx->empty_rt_tbl_mem.base) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:				ipa_ctx->empty_rt_tbl_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	memset(ipa_ctx->empty_rt_tbl_mem.base, 0,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			ipa_ctx->empty_rt_tbl_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->class = class_create(THIS_MODULE, DRV_NAME);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	result = alloc_chrdev_region(&ipa_ctx->dev_num, 0, 1, DRV_NAME);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->dev = device_create(ipa_ctx->class, NULL, ipa_ctx->dev_num,
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (IS_ERR(ipa_ctx->dev)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	cdev_init(&ipa_ctx->cdev, &ipa_drv_fops);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->cdev.ops = &ipa_drv_fops;  /* from LDD3 */
drivers/platform/msm/ipa/ipa_v2/ipa.c:	result = cdev_add(&ipa_ctx->cdev, ipa_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/ipa.c:			MAJOR(ipa_ctx->dev_num),
drivers/platform/msm/ipa/ipa_v2/ipa.c:			MINOR(ipa_ctx->dev_num));
drivers/platform/msm/ipa/ipa_v2/ipa.c:	wakeup_source_init(&ipa_ctx->w_lock, "IPA_WS");
drivers/platform/msm/ipa/ipa_v2/ipa.c:	spin_lock_init(&ipa_ctx->wakelock_ref_cnt.spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	mutex_init(&ipa_ctx->sps_pm.sps_pm_lock);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->use_ipa_teth_bridge) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->q6_proxy_clk_vote_valid = true;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	cdev_del(&ipa_ctx->cdev);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	device_destroy(ipa_ctx->class, ipa_ctx->dev_num);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	unregister_chrdev_region(ipa_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	if (ipa_ctx->pipe_mem_pool)
drivers/platform/msm/ipa/ipa_v2/ipa.c:		gen_pool_destroy(ipa_ctx->pipe_mem_pool);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			  ipa_ctx->empty_rt_tbl_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			  ipa_ctx->empty_rt_tbl_mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa.c:			  ipa_ctx->empty_rt_tbl_mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	idr_destroy(&ipa_ctx->ipa_idr);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->rx_pkt_wrapper_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->tx_pkt_wrapper_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->rt_tbl_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->hdr_proc_ctx_offset_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->hdr_proc_ctx_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->hdr_offset_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->hdr_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->rt_rule_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kmem_cache_destroy(ipa_ctx->flt_rule_cache);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	sps_deregister_bam_device(ipa_ctx->bam_handle);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	destroy_workqueue(ipa_ctx->sps_power_mgmt_wq);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	destroy_workqueue(ipa_ctx->power_mgmt_wq);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	iounmap(ipa_ctx->mmio);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	msm_bus_scale_unregister_client(ipa_ctx->ipa_bus_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	kfree(ipa_ctx->ctrl);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipc_log_context_destroy(ipa_ctx->logbuf);
drivers/platform/msm/ipa/ipa_v2/ipa.c:	return (ipa_ctx) ? ipa_ctx->use_ipa_pm : false;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	ipa_ctx->uc_pdev = dev;
drivers/platform/msm/ipa/ipa_v2/ipa.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:		if (ipa_ctx->ep[i].sys &&
drivers/platform/msm/ipa/ipa_v2/ipa.c:			atomic_read(&ipa_ctx->ep[i].sys->curr_polling_state)) {
drivers/platform/msm/ipa/ipa_v2/ipa.c:	atomic_set(&ipa_ctx->sps_pm.eot_activity, 0);
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].filter_hdl =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		rule_hdl[i] = ipa_qmi_ctx->q6_ul_filter_rule[i].filter_hdl;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].ip =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].action =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].rt_tbl_idx =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].mux_id =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.rule_eq_bitmap =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tos_eq_present =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tos_eq =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.protocol_eq =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		for (j = 0; j < ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.num_offset_meq_32 =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		for (j = 0; j < ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tc_eq_present =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.tc_eq =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.fl_eq_present =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.fl_eq =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		for (j = 0; j < ipa_qmi_ctx->q6_ul_filter_rule[i].
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.num_offset_meq_128 =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		for (j = 0; j < ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			memcpy(ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			memcpy(ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.metadata_meq32.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib.
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:				ipa_qmi_ctx->q6_ul_filter_rule
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:	memset(ipa_qmi_ctx->q6_ul_filter_rule, 0,
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		sizeof(ipa_qmi_ctx->q6_ul_filter_rule));
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		param->ip = ipa_qmi_ctx->q6_ul_filter_rule[i].ip;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].action;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		= ipa_qmi_ctx->q6_ul_filter_rule[i].rt_tbl_idx;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			&ipa_qmi_ctx->q6_ul_filter_rule[i].eq_attrib,
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule_hdl[i] =
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		if (ipa_qmi_ctx->q6_ul_filter_rule[i].ip == IPA_IP_v4) {
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->q6_ul_filter_rule[i].filter_hdl;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		param->ip = ipa_qmi_ctx->q6_ul_filter_rule[i].ip;
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:		flt_rule_entry.hdl = ipa_qmi_ctx->q6_ul_filter_rule_hdl[i];
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:				 &(ipa_qmi_ctx->q6_ul_filter_rule[i]),
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:			ipa_qmi_ctx->modem_cfg_emb_pipe_flt == false) {
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:					ipa_qmi_ctx->modem_cfg_emb_pipe_flt
drivers/platform/msm/ipa/ipa_v2/rmnet_ipa.c:	if (ipa_qmi_ctx && ipa_qmi_ctx->modem_cfg_emb_pipe_flt == false)
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (!ipa_ctx->uc_ctx.uc_event_top_ofst) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_event_top_ofst =
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_sram_mmio->eventParams;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		if (ipa_ctx->uc_ctx.uc_event_top_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				ipa_ctx->uc_ctx.uc_event_top_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_event_top_mmio = ioremap(
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_event_top_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		if (!ipa_ctx->uc_ctx.uc_event_top_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:					(ipa_ctx->uc_ctx.uc_event_top_mmio);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		if (ipa_ctx->uc_ctx.uc_sram_mmio->eventParams !=
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_event_top_ofst) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				ipa_ctx->uc_ctx.uc_sram_mmio->
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				ipa_ctx->uc_ctx.uc_event_top_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_event_top_ofst = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (!ipa_ctx->uc_ctx.uc_inited) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (!ipa_ctx->uc_ctx.uc_loaded) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	return ipa_ctx->uc_ctx.uc_loaded;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	feature = EXTRACT_UC_FEATURE(ipa_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			feature, ipa_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			(ipa_ctx->uc_ctx.uc_sram_mmio);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		evt.raw32b = ipa_ctx->uc_ctx.uc_sram_mmio->eventParams;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_failed = true;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_error_type = evt.params.errorType;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_zip_error = true;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	} else if (ipa_ctx->uc_ctx.uc_sram_mmio->eventOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_sram_mmio->eventParams);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				ipa_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio->cmdOp =
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_write_reg(ipa_ctx->mmio, IPA_IRQ_EE_UC_n_OFFS(0), 0x1);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	feature = EXTRACT_UC_FEATURE(ipa_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			feature, ipa_ctx->uc_ctx.uc_sram_mmio->eventOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_sram_mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			&ipa_ctx->uc_ctx.uc_status);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			complete_all(&ipa_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.uc_loaded = true;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		if (ipa_ctx->ipa_hw_type == IPA_HW_v2_6L)
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	} else if (ipa_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		uc_rsp.raw32b = ipa_ctx->uc_ctx.uc_sram_mmio->responseParams;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		    ipa_ctx->uc_ctx.pending_cmd) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_status = uc_rsp.params.status;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			complete_all(&ipa_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			       ipa_ctx->uc_ctx.pending_cmd,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		       ipa_ctx->uc_ctx.uc_sram_mmio->responseOp);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->uc_ctx.uc_inited) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mutex_init(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->smem_restricted_bytes / 4);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio = ioremap(phys_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (!ipa_ctx->uc_ctx.uc_sram_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_inited = true;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	iounmap(ipa_ctx->uc_ctx.uc_sram_mmio);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mutex_lock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	init_completion(&ipa_ctx->uc_ctx.uc_completion);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio->cmdParams = cmd;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio->cmdOp = opcode;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.pending_cmd = opcode;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio->responseOp = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_sram_mmio->responseParams = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.uc_status = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_write_reg(ipa_ctx->mmio, IPA_IRQ_EE_UC_n_OFFS(0), 0x1);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			if (ipa_ctx->uc_ctx.uc_sram_mmio->responseOp ==
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				uc_rsp.raw32b = ipa_ctx->uc_ctx.uc_sram_mmio->
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				    ipa_ctx->uc_ctx.pending_cmd) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:					ipa_ctx->uc_ctx.pending_cmd = -1;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			if (ipa_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:					ipa_hw_error_str(ipa_ctx->
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		if (wait_for_completion_timeout(&ipa_ctx->uc_ctx.uc_completion,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			if (ipa_ctx->uc_ctx.uc_failed) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:					ipa_hw_error_str(ipa_ctx->
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->uc_ctx.uc_status != expected_status) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_status) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:				mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:			ipa_ctx->uc_ctx.uc_status, expected_status);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		ipa_ctx->uc_ctx.pending_cmd = -1;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	ipa_ctx->uc_ctx.pending_cmd = -1;
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mutex_lock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mutex_unlock(&ipa_ctx->uc_ctx.uc_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	if (ipa_ctx->ipa_hw_type != IPA_HW_v2_6L ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:		!ipa_ctx->ipa_uc_monitor_holb) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	mem.base = dma_alloc_coherent(ipa_ctx->pdev, mem.size, &mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa_uc.c:	dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base, mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:	} else if (req->source_pipe_index >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		memcpy(&(ipa_qmi_ctx->ipa_install_fltr_rule_req_msg_cache[
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:			ipa_qmi_ctx->num_ipa_install_fltr_rule_req_msg]),
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		ipa_qmi_ctx->num_ipa_install_fltr_rule_req_msg++;
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		ipa_qmi_ctx->num_ipa_install_fltr_rule_req_msg %= 10;
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:	} else if (req->source_pipe_index >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:	} else if (req->embedded_pipe_index >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		memcpy(&(ipa_qmi_ctx->ipa_fltr_installed_notif_req_msg_cache[
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:			ipa_qmi_ctx->num_ipa_fltr_installed_notif_req_msg]),
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		ipa_qmi_ctx->num_ipa_fltr_installed_notif_req_msg++;
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:		ipa_qmi_ctx->num_ipa_fltr_installed_notif_req_msg %= 10;
drivers/platform/msm/ipa/ipa_v2/ipa_qmi_service.c:	ipa_qmi_ctx->modem_cfg_emb_pipe_flt =
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			   dma_alloc_coherent(ipa_ctx->pdev, flt_tbl_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:				   dma_alloc_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base, mem->phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		dma_free_coherent(ipa_ctx->pdev, tbl->prev_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			dma_free_coherent(ipa_ctx->pdev, tbl->curr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			dma_free_coherent(ipa_ctx->pdev, tbl->prev_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:				dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		avail = ipa_ctx->ip4_flt_tbl_lcl ? IPA_MEM_v1_RAM_V4_FLT_SIZE :
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		avail = ipa_ctx->ip6_flt_tbl_lcl ? IPA_MEM_v1_RAM_V6_FLT_SIZE :
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base, mem->phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	head1->base = dma_alloc_coherent(ipa_ctx->pdev, head1->size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		*entr = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	head2->base = dma_alloc_coherent(ipa_ctx->pdev, head2->size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		*entr = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, head2->size, head2->base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, head1->size, head1->base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	gfp_t flag = GFP_ATOMIC | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		avail = ipa_ctx->ip4_flt_tbl_lcl ?
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		local_addrb = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		lcl = ipa_ctx->ip4_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		avail = ipa_ctx->ip6_flt_tbl_lcl ?
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		local_addrb = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		lcl = ipa_ctx->ip6_flt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		if (ipa_ctx->skip_ep_cfg_shadow[i]) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			&& ipa_ctx->modem_cfg_emb_pipe_flt)) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	for (i = 11; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		if (ipa_ctx->skip_ep_cfg_shadow[i]) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			ipa_ctx->modem_cfg_emb_pipe_flt) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			local_addrh = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		dma_free_coherent(ipa_ctx->pdev, body.size, body.base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, head1.size, head1.base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	dma_free_coherent(ipa_ctx->pdev, head2.size, head2.base,
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	entry = kmem_cache_zalloc(ipa_ctx->flt_rule_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	kmem_cache_free(ipa_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	kmem_cache_free(ipa_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	if (ipa_ctx->ep[ipa_ep_idx].valid == 0)
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->flt_tbl[ipa_ep_idx][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		if (ipa_ctx->ctrl->ipa_commit_flt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		if (ipa_ctx->ctrl->ipa_commit_flt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		if (ipa_ctx->ctrl->ipa_commit_flt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	if (ipa_ctx->ctrl->ipa_commit_flt(ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		kmem_cache_free(ipa_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[i][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:				mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:			kmem_cache_free(ipa_ctx->flt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	struct ipa_ep_context *ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	ipa_ctx->ctrl->ipa_commit_flt(IPA_IP_v4);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	tbl = &ipa_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	ipa_ctx->ctrl->ipa_commit_flt(IPA_IP_v6);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	struct ipa_ep_context *ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v4];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		ipa_ctx->ctrl->ipa_commit_flt(IPA_IP_v4);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		tbl = &ipa_ctx->flt_tbl[ipa_ep_idx][IPA_IP_v6];
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:		ipa_ctx->ctrl->ipa_commit_flt(IPA_IP_v6);
drivers/platform/msm/ipa/ipa_v2/ipa_flt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	if (sps_pipe_pending_desc(ipa_ctx->bam_handle,
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	res = sps_pipe_disable(ipa_ctx->bam_handle, ipa_ep_index);
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	ipa_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	if (ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_mhi.c:	ipa_ctx->ep[clnt_hdl].valid = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	mutex_lock(&ipa_ctx->ipa_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock_irqsave(&ipa_ctx->ipa_active_clients.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ipa_active_clients.mutex_locked = true;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock_irqrestore(&ipa_ctx->ipa_active_clients.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock_irqsave(&ipa_ctx->ipa_active_clients.spinlock, *flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_active_clients.mutex_locked) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		spin_unlock_irqrestore(&ipa_ctx->ipa_active_clients.spinlock,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock_irqrestore(&ipa_ctx->ipa_active_clients.spinlock, *flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock_irqsave(&ipa_ctx->ipa_active_clients.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ipa_active_clients.mutex_locked = false;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock_irqrestore(&ipa_ctx->ipa_active_clients.spinlock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	mutex_unlock(&ipa_ctx->ipa_active_clients.mutex);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->resume_on_connect[client] = false;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		if (ipa_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			if (ipa_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->tag_process_before_gating = true;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_active_clients.cnt == 1) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->resume_on_connect[client] = false;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		if (ipa_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			if (ipa_ctx->ep[ipa_ep_idx].valid) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ipa_active_clients.cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		       ipa_ctx->ipa_active_clients.cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->resume_on_connect[client] = true;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		if (ipa_ctx->ep[ipa_ep_idx].client == client &&
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			if (ipa_ctx->ep[ipa_ep_idx].valid &&
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			!ipa_ctx->ep[ipa_ep_idx].disconnect_in_progress) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_restricted_bytes = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_sz = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_reqd_sz = IPA_MEM_v1_RAM_END_OFST;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->hdr_tbl_lcl = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_flt_tbl_lcl = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_flt_tbl_lcl = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_restricted_bytes = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_sz = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_reqd_sz = IPA_MEM_PART(end_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->hdr_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_restricted_bytes = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_sz = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_reqd_sz = IPA_MEM_PART(end_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->hdr_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->hdr_proc_ctx_tbl_lcl = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->hdr_proc_ctx_tbl.start_offset =
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_restricted_bytes = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_sz = ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->smem_reqd_sz = IPA_MEM_PART(end_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->hdr_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_rt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip4_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ip6_flt_tbl_lcl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_ROUTE_OFST_v1_1, reg_val);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_ROUTE_OFST_v1_1, reg_val);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_route(route);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, ipa_filter_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_COMP_SW_RESET_OFST, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_COMP_SW_RESET_OFST, 0);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_COMP_CFG_OFST, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_version = ipa_read_reg(ipa_ctx->mmio, IPA_VERSION_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_write_reg(ipa_ctx->mmio, IPA_BCR_OFST, IPA_BCR_REG_VAL);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	switch (ipa_ctx->ipa_hw_type) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ipacm_client[index].client_enum = client;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ipacm_client[index].uplink = uplink;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->uc_wdi_ctx.stats_notify) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->uc_wdi_ctx.stats_notify(IPA_GET_WDI_SAP_STATS,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->uc_wdi_ctx.stats_notify) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->uc_wdi_ctx.stats_notify(IPA_SET_WIFI_QUOTA,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_ctx->ipacm_client[pipe_idx].client_enum;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	return ipa_ctx->ipacm_client[pipe_idx].uplink;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (pipe_idx >= ipa_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	client = ipa_ctx->ep[pipe_idx].client;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (pipe_idx >= ipa_ctx->ipa_num_pipes || pipe_idx < 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	return ipa_ctx->ep[pipe_idx].client;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ipa_ep_cfg == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (IPA_CLIENT_IS_PROD(ipa_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_nat == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.nat = *ep_nat;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_nat(clnt_hdl, ep_nat);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_status == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].status = *ep_status;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_status(clnt_hdl, ep_status);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_ENDP_INIT_CFG_n_OFST(clnt_hdl),
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || cfg == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.cfg = *cfg;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_cfg(clnt_hdl, cfg);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || metadata_mask == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.metadata_mask = *metadata_mask;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_metadata_mask(clnt_hdl, metadata_mask);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_hdr == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:				clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_hdr(clnt_hdl, &ep->cfg.hdr);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_hdr_ext == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:				clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_hdr_ext(clnt_hdl, &ep->cfg.hdr_ext);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes || ep_ctrl == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_COUNTER_CFG_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_COUNTER_CFG_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_mode == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.mode = *ep_mode;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].dst_pipe_index = ep;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_mode(clnt_hdl,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			ipa_ctx->ep[clnt_hdl].dst_pipe_index,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_aggr == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.aggr = *ep_aggr;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_aggr(clnt_hdl, ep_aggr);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_route == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (IPA_CLIENT_IS_CONS(ipa_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ep[clnt_hdl].cfg.mode.mode == IPA_DMA) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0)
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ep[clnt_hdl].rt_tbl_idx =
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ep[clnt_hdl].rt_tbl_idx = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_route(clnt_hdl,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			ipa_ctx->ep[clnt_hdl].rt_tbl_idx);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_holb == NULL ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ep_holb->tmr_val > ipa_ctx->ctrl->max_holb_tmr_val ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (IPA_CLIENT_IS_PROD(ipa_ctx->ep[clnt_hdl].client)) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (!ipa_ctx->ctrl->ipa_cfg_ep_holb) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].holb = *ep_holb;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_holb(clnt_hdl, ep_holb);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	    ipa_ctx->ep[clnt_hdl].valid == 0 || ep_deaggr == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:				clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_deaggr(clnt_hdl, &ep->cfg.deaggr);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ep[clnt_hdl].valid == 0 || ep_md == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:					clnt_hdl, ipa_ctx->ep[clnt_hdl].valid);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.meta = *ep_md;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_metadata(clnt_hdl, ep_md);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ep[clnt_hdl].cfg.hdr.hdr_metadata_reg_valid = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->ctrl->ipa_cfg_ep_hdr(clnt_hdl, &ipa_ctx->ep[clnt_hdl].cfg.hdr);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ep[ipa_ep_idx].cfg.meta = meta;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->pipe_mem_pool = pool;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (!ipa_ctx->pipe_mem_pool || !size) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:				ipa_ctx->pipe_mem_pool);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	vaddr = gen_pool_alloc(ipa_ctx->pipe_mem_pool, size);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->pipe_mem_pool && size)
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		gen_pool_free(ipa_ctx->pipe_mem_pool, ofst, size);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_QCNCM_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_QCNCM_OFST, (mode & 0x1) |
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_QCNCM_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_QCNCM_OFST, sig[0] << 20 |
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_SINGLE_NDP_MODE_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_SINGLE_NDP_MODE_OFST,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	reg_val = ipa_read_reg(ipa_ctx->mmio, IPA_AGGREGATION_SPARE_REG_1_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_write_reg(ipa_ctx->mmio, IPA_AGGREGATION_SPARE_REG_1_OFST,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		if (ipa_ctx->ipa_hw_type < IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			sps_get_bam_debug_info(ipa_ctx->bam_handle, 5,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			sps_get_bam_debug_info(ipa_ctx->bam_handle, 93, 0,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:			sps_get_bam_debug_info(ipa_ctx->bam_handle, 93,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	id = idr_alloc(&ipa_ctx->ipa_idr, ptr, 0, 0, GFP_NOWAIT);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ptr = idr_find(&ipa_ctx->ipa_idr, id);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_lock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	idr_remove(&ipa_ctx->ipa_idr, id);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	spin_unlock(&ipa_ctx->idr_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		aggr_init = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (pipe_num < -1 || pipe_num >= (int)ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		end_pipe = ipa_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (clnt_hdl >= 0 && clnt_hdl < ipa_ctx->ipa_num_pipes)
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa2_is_ready() && ipa_ctx->q6_proxy_clk_vote_valid) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->q6_proxy_clk_vote_valid = false;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa2_is_ready() && !ipa_ctx->q6_proxy_clk_vote_valid) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->q6_proxy_clk_vote_valid = true;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_ctx->smem_restricted_bytes;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c: * ipa2_get_modem_cfg_emb_pipe_flt()- Return ipa_ctx->modem_cfg_emb_pipe_flt
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_ctx->modem_cfg_emb_pipe_flt;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v2_6L)
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_read_reg(ipa_ctx->mmio, IPA_ENABLED_PIPES_OFST);
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c: * set ipa_ctx->ipa_client_apps_wan_cons_agg_gro
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ipa_client_apps_wan_cons_agg_gro = true;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_ctx->logbuf;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_ctx->logbuf_low;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	*holb = ipa_ctx->ep[ep_idx].holb;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ipa_ctx->tag_process_before_gating = val;
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v2_6L &&
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		ipa_ctx->ipa_uc_monitor_holb) {
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:		return ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_utils.c:	return ipa_ctx->pdev;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem->size = ipa_ctx->hdr_tbl.end;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	IPADBG_LOW("tbl_sz=%d\n", ipa_ctx->hdr_tbl.end);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	list_for_each_entry(entry, &ipa_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			&ipa_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.value = entry->hdr->hdr_len;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.hdr_addr = (entry->hdr->is_hdr_proc_ctx) ?
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->hdr_add.hdr_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.type = IPA_PROC_CTX_TLV_TYPE_HDR_ADD;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.length = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.tlv.value = entry->hdr->hdr_len;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->hdr_add.hdr_addr = (entry->hdr->is_hdr_proc_ctx) ?
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->hdr_add.hdr_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->cmd.type = IPA_PROC_CTX_TLV_TYPE_PROC_CMD;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->cmd.length = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->cmd.value = IPA_HDR_UCP_ETHII_TO_ETHII;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->cmd.value = IPA_HDR_UCP_ETHII_TO_802_3;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->cmd.value = IPA_HDR_UCP_802_3_TO_ETHII;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ctx->cmd.value = IPA_HDR_UCP_802_3_TO_802_3;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			IPADBG_LOW("command id %d\n", ctx->cmd.value);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.type = IPA_PROC_CTX_TLV_TYPE_END;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.length = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ctx->end.value = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem->size = (ipa_ctx->hdr_proc_ctx_tbl.end) ? : 4;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	IPADBG_LOW("tbl_sz=%d\n", ipa_ctx->hdr_proc_ctx_tbl.end);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	hdr_base_addr = (ipa_ctx->hdr_tbl_lcl) ? IPA_MEM_PART(apps_hdr_ofst) :
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		if (ipa_ctx->hdr_mem.phys_base) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_free_coherent(ipa_ctx->pdev, ipa_ctx->hdr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					  ipa_ctx->hdr_mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					  ipa_ctx->hdr_mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		ipa_ctx->hdr_mem = *mem;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	gfp_t flag = GFP_ATOMIC | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_cmd->local_addr = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			if (ipa_ctx->hdr_mem.phys_base)
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:						ipa_ctx->hdr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:						ipa_ctx->hdr_mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:						ipa_ctx->hdr_mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ipa_ctx->hdr_mem = mem;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_free_coherent(ipa_ctx->pdev, mem.size, mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	gfp_t flag = GFP_ATOMIC | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_cmd_ctx->system_addr = aligned_ctx_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_cmd_ctx->size = aligned_ctx_mem.size;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_cmd_ctx->local_addr =
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_proc_ctx_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_free_coherent(ipa_ctx->pdev, ctx_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			if (ipa_ctx->hdr_proc_ctx_mem.phys_base)
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					ipa_ctx->hdr_proc_ctx_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					ipa_ctx->hdr_proc_ctx_mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					ipa_ctx->hdr_proc_ctx_mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ipa_ctx->hdr_proc_ctx_mem = ctx_mem;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_free_coherent(ipa_ctx->pdev, ctx_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->hdr_tbl_lcl) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_free_coherent(ipa_ctx->pdev, hdr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			if (ipa_ctx->hdr_mem.phys_base)
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ipa_ctx->hdr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ipa_ctx->hdr_mem.base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				ipa_ctx->hdr_mem.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ipa_ctx->hdr_mem = hdr_mem;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_free_coherent(ipa_ctx->pdev, hdr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	struct ipa_hdr_proc_ctx_tbl *htbl = &ipa_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		proc_ctx->type, proc_ctx->hdr_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (!HDR_PROC_TYPE_IS_VALID(proc_ctx->type)) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		IPAERR_RL("invalid processing type %d\n", proc_ctx->type);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	hdr_entry = ipa_id_find(proc_ctx->hdr_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	entry = kmem_cache_zalloc(ipa_ctx->hdr_proc_ctx_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	entry->type = proc_ctx->type;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	needed_len = (proc_ctx->type == IPA_HDR_PROC_NONE) ?
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem_size = (ipa_ctx->hdr_proc_ctx_tbl_lcl) ?
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		offset = kmem_cache_zalloc(ipa_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	proc_ctx->proc_ctx_hdl = id;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	kmem_cache_free(ipa_ctx->hdr_proc_ctx_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	struct ipa_hdr_tbl *htbl = &ipa_ctx->hdr_tbl;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	entry = kmem_cache_zalloc(ipa_ctx->hdr_cache, flag);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mem_size = (ipa_ctx->hdr_tbl_lcl) ? IPA_MEM_PART(apps_hdr_size) :
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			if (ipa_ctx->ipa_hw_type != IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				entry->phys_base = dma_map_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				if (dma_mapping_error(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			offset = kmem_cache_zalloc(ipa_ctx->hdr_offset_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_unmap_single(ipa_ctx->pdev, entry->phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	kmem_cache_free(ipa_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	struct ipa_hdr_proc_ctx_tbl *htbl = &ipa_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	kmem_cache_free(ipa_ctx->hdr_proc_ctx_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	struct ipa_hdr_tbl *htbl = &ipa_ctx->hdr_tbl;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		dma_unmap_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		__ipa_del_hdr_proc_ctx(entry->proc_ctx->id, false, false);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	kmem_cache_free(ipa_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->ipa_hw_type <= IPA_HW_v2_0 ||
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	    ipa_ctx->ipa_hw_type == IPA_HW_v2_6L) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ipa_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->ipa_hw_type <= IPA_HW_v2_0 ||
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	    ipa_ctx->ipa_hw_type == IPA_HW_v2_6L) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			ipa_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			&ipa_ctx->hdr_tbl.head_hdr_entry_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			dma_unmap_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		kmem_cache_free(ipa_ctx->hdr_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:					 &ipa_ctx->hdr_tbl.head_offset_list[i],
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			kmem_cache_free(ipa_ctx->hdr_offset_cache, off_entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				&ipa_ctx->hdr_tbl.head_free_offset_list[i],
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			kmem_cache_free(ipa_ctx->hdr_offset_cache, off_entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	ipa_ctx->hdr_tbl.end = 8;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	ipa_ctx->hdr_tbl.hdr_cnt = 1;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		&ipa_ctx->hdr_proc_ctx_tbl.head_proc_ctx_entry_list,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:		kmem_cache_free(ipa_ctx->hdr_proc_ctx_cache, ctx_entry);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:				&ipa_ctx->hdr_proc_ctx_tbl.head_offset_list[i],
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			kmem_cache_free(ipa_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			    &ipa_ctx->hdr_proc_ctx_tbl.head_free_offset_list[i],
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:			kmem_cache_free(ipa_ctx->hdr_proc_ctx_offset_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	ipa_ctx->hdr_proc_ctx_tbl.end = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	ipa_ctx->hdr_proc_ctx_tbl.proc_ctx_cnt = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	list_for_each_entry(entry, &ipa_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	if (ipa_ctx->ctrl->ipa_commit_hdr()) {
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_hdr.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	rule_hdr->u.hdr.system = !ipa_ctx->hdr_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		rule_hdr->u.hdr_v2_5.system = !ipa_ctx->hdr_proc_ctx_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		BUG_ON(proc_ctx->offset_entry->offset & 31);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			(proc_ctx->offset_entry->offset +
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			ipa_ctx->hdr_proc_ctx_tbl.start_offset) >> 5;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		rule_hdr->u.hdr_v2_5.system = !ipa_ctx->hdr_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	u32 bitmap = ipa_ctx->rt_idx_bitmap[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			res = ipa_ctx->ctrl->ipa_generate_rt_hw_rule(
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				res = ipa_ctx->ctrl->ipa_generate_rt_hw_rule(
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			   dma_alloc_coherent(ipa_ctx->pdev, rt_tbl_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				res = ipa_ctx->ctrl->ipa_generate_rt_hw_rule(
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	dma_free_coherent(ipa_ctx->pdev, rt_tbl_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		ipa_write_32(ipa_ctx->empty_rt_tbl_mem.phys_base,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base, mem->phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			dma_free_coherent(ipa_ctx->pdev, tbl->prev_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->reap_rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			dma_free_coherent(ipa_ctx->pdev, tbl->curr_mem.size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			kmem_cache_free(ipa_ctx->rt_tbl_cache, tbl);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		avail = ipa_ctx->ip4_rt_tbl_lcl ? IPA_MEM_v1_RAM_V4_RT_SIZE :
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		avail = ipa_ctx->ip6_rt_tbl_lcl ? IPA_MEM_v1_RAM_V6_RT_SIZE :
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base, mem->phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	head->base = dma_alloc_coherent(ipa_ctx->pdev, head->size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		*entr = ipa_ctx->empty_rt_tbl_mem.phys_base;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		mem->base = dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		dma_free_coherent(ipa_ctx->pdev, mem->size, mem->base,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	dma_free_coherent(ipa_ctx->pdev, head->size, head->base,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		avail = ipa_ctx->ip4_rt_tbl_lcl ?
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		local_addr1 = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		local_addr2 = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		lcl = ipa_ctx->ip4_rt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		avail = ipa_ctx->ip6_rt_tbl_lcl ?
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		local_addr1 = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		local_addr2 = ipa_ctx->smem_restricted_bytes +
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		lcl = ipa_ctx->ip6_rt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	dma_free_coherent(ipa_ctx->pdev, head.size, head.base, head.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		dma_free_coherent(ipa_ctx->pdev, body.size, body.base,
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		entry = kmem_cache_zalloc(ipa_ctx->rt_tbl_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			if (!test_bit(i, &ipa_ctx->rt_idx_bitmap[ip])) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				set_bit(i, &ipa_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			!ipa_ctx->ip4_rt_tbl_lcl : !ipa_ctx->ip6_rt_tbl_lcl;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	kmem_cache_free(ipa_ctx->rt_tbl_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	if (entry->set == &ipa_ctx->rt_tbl_set[IPA_IP_v4])
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	else if (entry->set == &ipa_ctx->rt_tbl_set[IPA_IP_v6])
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		clear_bit(entry->idx, &ipa_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		kmem_cache_free(ipa_ctx->rt_tbl_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				&ipa_ctx->reap_rt_tbl_set[ip].head_rt_tbl_list);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		clear_bit(entry->idx, &ipa_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			(proc_ctx->cookie != IPA_PROC_HDR_COOKIE)) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	entry = kmem_cache_zalloc(ipa_ctx->rt_rule_cache, GFP_KERNEL);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		entry->proc_ctx->ref_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		entry->proc_ctx->ref_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	kmem_cache_free(ipa_ctx->rt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		if (ipa_ctx->ctrl->ipa_commit_rt(rules->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		__ipa_release_hdr_proc_ctx(entry->proc_ctx->id);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	kmem_cache_free(ipa_ctx->rt_rule_cache, entry);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		if (ipa_ctx->ctrl->ipa_commit_rt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	if (ipa_ctx->ctrl->ipa_commit_rt(ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	rset = &ipa_ctx->reap_rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				__ipa_release_hdr_proc_ctx(rule->proc_ctx->id);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			kmem_cache_free(ipa_ctx->rt_rule_cache, rule);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:			mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:					  &ipa_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:				kmem_cache_free(ipa_ctx->rt_tbl_cache, tbl);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:					  &ipa_ctx->rt_idx_bitmap[ip]);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		if (ipa_ctx->ctrl->ipa_commit_rt(lookup->ip))
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	if (entry->set == &ipa_ctx->rt_tbl_set[IPA_IP_v4])
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	else if (entry->set == &ipa_ctx->rt_tbl_set[IPA_IP_v6])
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		if (ipa_ctx->ctrl->ipa_commit_rt(ip))
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:		if (ipa_ctx->ctrl->ipa_commit_rt(hdls->ip)) {
drivers/platform/msm/ipa/ipa_v2/ipa_rt.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_lock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->is_enabled) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		mutex_unlock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->is_enabled = true;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_unlock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (atomic_read(&ipa_dma_ctx->sync_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (atomic_read(&ipa_dma_ctx->async_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (atomic_read(&ipa_dma_ctx->uc_memcpy_pending_cnt)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_lock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (!ipa_dma_ctx->is_enabled) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		mutex_unlock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		mutex_unlock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->is_enabled = false;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_unlock(&ipa_dma_ctx->enable_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (!ipa_dma_ctx->is_enabled) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (atomic_read(&ipa_dma_ctx->sync_memcpy_pending_cnt) >=
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		atomic_dec(&ipa_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	cons_sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	prod_sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	xfer_descr = kmem_cache_zalloc(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_lock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		mutex_unlock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		mutex_lock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_unlock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_lock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	kmem_cache_free(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_unlock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->total_sync_memcpy);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_dec(&ipa_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->destroy_pending && !ipa_dma_work_pending())
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		complete(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	mutex_unlock(&ipa_dma_ctx->sync_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	kmem_cache_free(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_dec(&ipa_dma_ctx->sync_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->destroy_pending && !ipa_dma_work_pending())
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		complete(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (!ipa_dma_ctx->is_enabled) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (atomic_read(&ipa_dma_ctx->async_memcpy_pending_cnt) >=
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		atomic_dec(&ipa_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	cons_sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	prod_sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	xfer_descr = kmem_cache_zalloc(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	kmem_cache_free(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache, xfer_descr);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_dec(&ipa_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->destroy_pending && !ipa_dma_work_pending())
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		complete(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (!ipa_dma_ctx->is_enabled) {
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->uc_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->pending_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->total_uc_memcpy);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_dec(&ipa_dma_ctx->uc_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->destroy_pending && !ipa_dma_work_pending())
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		complete(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		ipa_dma_ctx->destroy_pending = true;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		wait_for_completion(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	res = ipa2_teardown_sys_pipe(ipa_dma_ctx->ipa_dma_async_cons_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->ipa_dma_async_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	res = ipa2_teardown_sys_pipe(ipa_dma_ctx->ipa_dma_sync_cons_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->ipa_dma_sync_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	res = ipa2_teardown_sys_pipe(ipa_dma_ctx->ipa_dma_async_prod_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->ipa_dma_async_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	res = ipa2_teardown_sys_pipe(ipa_dma_ctx->ipa_dma_sync_prod_hdl);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	ipa_dma_ctx->ipa_dma_sync_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	kmem_cache_destroy(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_lock_irqsave(&ipa_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	spin_unlock_irqrestore(&ipa_dma_ctx->async_lock, flags);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_inc(&ipa_dma_ctx->total_async_memcpy);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	atomic_dec(&ipa_dma_ctx->async_memcpy_pending_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	kmem_cache_free(ipa_dma_ctx->ipa_dma_xfer_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:	if (ipa_dma_ctx->destroy_pending && !ipa_dma_work_pending())
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		complete(&ipa_dma_ctx->done);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			(ipa_dma_ctx->is_enabled) ? "Enabled" : "Disabled");
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			atomic_read(&ipa_dma_ctx->total_sync_memcpy));
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			atomic_read(&ipa_dma_ctx->total_async_memcpy));
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			atomic_read(&ipa_dma_ctx->sync_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			atomic_read(&ipa_dma_ctx->async_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:			atomic_read(&ipa_dma_ctx->uc_memcpy_pending_cnt));
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		atomic_set(&ipa_dma_ctx->total_async_memcpy, 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dma.c:		atomic_set(&ipa_dma_ctx->total_sync_memcpy, 0);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_VERSION_OFST),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_COMP_HW_VERSION_OFST),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_ROUTE_OFST_v1_1),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_FILTER_OFST_v1_1),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_VERSION_OFST),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_COMP_HW_VERSION_OFST),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_ROUTE_OFST_v1_1),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg(ipa_ctx->mmio, IPA_FILTER_OFST_v1_1),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_read_reg_field(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	nbytes = ipa_ctx->ctrl->ipa_read_gen_reg(dbg_buff, IPA_MAX_MSG_LEN);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (option >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		pipe, ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		end_idx = ipa_ctx->ipa_num_pipes;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		nbytes = ipa_ctx->ctrl->ipa_read_ep_reg(dbg_buff,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (ipa_ctx->ipa_active_clients.cnt)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (ipa_ctx->hdr_tbl_lcl)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	list_for_each_entry(entry, &ipa_ctx->hdr_tbl.head_hdr_entry_list,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	set = &ipa_ctx->rt_tbl_set[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		if (ipa_ctx->ip6_rt_tbl_lcl)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		if (ipa_ctx->ip4_rt_tbl_lcl)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ofst = entry->proc_ctx->offset_entry->offset;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:					ipa_ctx->hdr_proc_ctx_tbl.start_offset)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:					!ipa_ctx->hdr_tbl_lcl);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:					!ipa_ctx->hdr_tbl_lcl);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	tbl = &ipa_ctx->hdr_proc_ctx_tbl;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (ipa_ctx->hdr_proc_ctx_tbl_lcl)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->hdr_proc_ctx_tbl.start_offset)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	tbl = &ipa_ctx->glob_flt_tbl[ip];
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	for (j = 0; j < ipa_ctx->ipa_num_pipes; j++) {
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		tbl = &ipa_ctx->flt_tbl[j][ip];
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		connect |= (ipa_ctx->ep[i].valid << i);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) {
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_sw_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_hw_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_non_linear,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_pkts_compl,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.rx_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.stat_compl,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.aggr_close,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.wan_aggr_close,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->ipa_active_clients.cnt,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.wan_rx_empty,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.wan_repl_rx_empty,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.lan_rx_empty,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.lan_repl_rx_empty,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.flow_enable,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.flow_disable);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->stats.rx_excp_pkts[i]);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_sw_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.tx_hw_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.rx_pkts,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.rx_repl_repost,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->stats.rx_q_len,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->ipa_active_clients.cnt,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->stats.rx_excp_pkts[i]);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->wc_memb.wlan_comm_total_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		"Tx Comm Buff Avail:", ipa_ctx->wc_memb.wlan_comm_free_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		"Total Tx Pkts Freed:", ipa_ctx->wc_memb.total_tx_pkts_freed);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->tx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->rx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_write_reg(ipa_ctx->mmio, IPA_DEBUG_CNT_CTRL_N_OFST_v1_1(0),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_write_reg(ipa_ctx->mmio, IPA_DEBUG_CNT_CTRL_N_OFST_v1_1(0),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_write_reg(ipa_ctx->mmio, IPA_DEBUG_CNT_CTRL_N_OFST_v2_0(0),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_write_reg(ipa_ctx->mmio, IPA_DEBUG_CNT_CTRL_N_OFST_v2_0(0),
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	ipa_ctx->ctrl->ipa_write_dbg_cnt(option);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	regval = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	regval = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	nbytes = ipa_ctx->ctrl->ipa_read_dbg_cnt(dbg_buff, IPA_MAX_MSG_LEN);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->stats.msg_w[i],
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->stats.msg_r[i]);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->nat_mem.lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	value = ipa_ctx->nat_mem.public_ip_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->nat_mem.size_base_tables);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:				ipa_ctx->nat_mem.size_expansion_tables-1);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (!ipa_ctx->nat_mem.is_sys_mem)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			tbl_size = ipa_ctx->nat_mem.size_base_tables;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			base_tbl = (u32 *)ipa_ctx->nat_mem.ipv4_rules_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			tbl_size = ipa_ctx->nat_mem.size_expansion_tables-1;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			 (u32 *)ipa_ctx->nat_mem.ipv4_expansion_rules_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			tbl_size = ipa_ctx->nat_mem.size_base_tables;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			indx_tbl = (u32 *)ipa_ctx->nat_mem.index_table_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			tbl_size = ipa_ctx->nat_mem.size_expansion_tables-1;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			 (u32 *)ipa_ctx->nat_mem.index_table_expansion_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->nat_mem.lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	if (ipa_ctx->ipa_hw_type < IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	for (i = 0; i < ipa_ctx->ipa_num_pipes; i++) {
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		if (!ipa_ctx->ep[i].sys || !ipa_ctx->ep[i].sys->status_stat)
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		memcpy(stats, ipa_ctx->ep[i].sys->status_stat, sizeof(*stats));
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->ipa_rx_min_timeout_usec);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->ipa_rx_max_timeout_usec);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	ipa_rx_timeout_min_max_calc(&ipa_ctx->ipa_rx_min_timeout_usec,
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		&ipa_ctx->ipa_rx_max_timeout_usec, polltime);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			ipa_ctx->ipa_polling_iteration);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->ipa_polling_iteration = iteration_cnt;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->ipa_polling_iteration = MAX_POLLING_ITERATION;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->logbuf_low = ipa_ipc_low_buff;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		ipa_ctx->logbuf_low = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:			dent, &ipa_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		dent, &ipa_ctx->enable_clock_scaling);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		&ipa_ctx->ctrl->clock_scaling_bw_threshold_nominal);
drivers/platform/msm/ipa/ipa_v2/ipa_debugfs.c:		&ipa_ctx->ctrl->clock_scaling_bw_threshold_turbo);
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	teth_ctx->class = class_create(THIS_MODULE, TETH_BRIDGE_DRV_NAME);
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	res = alloc_chrdev_region(&teth_ctx->dev_num, 0, 1,
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	teth_ctx->dev = device_create(teth_ctx->class, NULL, teth_ctx->dev_num,
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	if (IS_ERR(teth_ctx->dev)) {
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	cdev_init(&teth_ctx->cdev, &teth_bridge_drv_fops);
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	teth_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	teth_ctx->cdev.ops = &teth_bridge_drv_fops;
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	res = cdev_add(&teth_ctx->cdev, teth_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	device_destroy(teth_ctx->class, teth_ctx->dev_num);
drivers/platform/msm/ipa/ipa_v2/teth_bridge.c:	unregister_chrdev_region(teth_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_lock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->is_sys_mem) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		if (nat_ctx->is_mapped) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		IPADBG("map sz=0x%zx\n", nat_ctx->size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 ipa_ctx->pdev, vma,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 nat_ctx->vaddr, nat_ctx->dma_handle,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 nat_ctx->size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		ipa_ctx->nat_mem.nat_base_address = nat_ctx->vaddr;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		phys_addr = ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		ipa_ctx->nat_mem.nat_base_address = (void *)vma->vm_start;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_mapped = true;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_unlock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	struct ipa_nat_mem *nat_ctx = &(ipa_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->tmp_vaddr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		dma_alloc_coherent(ipa_ctx->pdev, IPA_NAT_TEMP_MEM_SIZE,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				&nat_ctx->tmp_dma_handle, gfp_flags);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->tmp_vaddr == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->is_tmp_mem = false;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_tmp_mem = true;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	struct ipa_nat_mem *nat_ctx = &(ipa_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_lock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->class = class_create(THIS_MODULE, NAT_DEV_NAME);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (IS_ERR(nat_ctx->class)) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	result = alloc_chrdev_region(&nat_ctx->dev_num,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->dev =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	   device_create(nat_ctx->class, NULL, nat_ctx->dev_num, nat_ctx,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (IS_ERR(nat_ctx->dev)) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		IPAERR("device_create err:%ld\n", PTR_ERR(nat_ctx->dev));
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	cdev_init(&nat_ctx->cdev, &ipa_nat_fops);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->cdev.ops = &ipa_nat_fops;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	result = cdev_add(&nat_ctx->cdev, nat_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			MAJOR(nat_ctx->dev_num),
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			MINOR(nat_ctx->dev_num));
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_dev = true;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	device_destroy(nat_ctx->class, nat_ctx->dev_num);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	unregister_chrdev_region(nat_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	class_destroy(nat_ctx->class);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->vaddr) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			 ipa_ctx->pdev, nat_ctx->size,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			 nat_ctx->vaddr, nat_ctx->dma_handle);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->vaddr = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->dma_handle = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->size = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_unlock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	struct ipa_nat_mem *nat_ctx = &(ipa_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_lock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->is_dev != true) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->is_dev_init == true) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			nat_ctx->is_dev_init == true) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->is_sys_mem = true;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->vaddr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		   dma_alloc_coherent(ipa_ctx->pdev, mem->size,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				   &nat_ctx->dma_handle, gfp_flags);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		if (nat_ctx->vaddr == NULL) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->size = mem->size;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->is_sys_mem = false;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_dev_init = true;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_unlock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (tmp > ipa_ctx->nat_mem.size) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			tmp, ipa_ctx->nat_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (tmp > ipa_ctx->nat_mem.size) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			tmp, ipa_ctx->nat_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (tmp > ipa_ctx->nat_mem.size) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			tmp, ipa_ctx->nat_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (tmp > ipa_ctx->nat_mem.size) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			tmp, ipa_ctx->nat_mem.size);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (ipa_ctx->nat_mem.vaddr) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		offset = UINT_MAX - ipa_ctx->nat_mem.dma_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				&ipa_ctx->nat_mem.dma_handle);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			ipa_ctx->nat_mem.dma_handle + init->ipv4_rules_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		   ipa_ctx->nat_mem.dma_handle + init->expn_rules_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			ipa_ctx->nat_mem.dma_handle + init->index_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		   ipa_ctx->nat_mem.dma_handle + init->index_expn_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.public_ip_addr = init->ip_addr;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	IPADBG("Table ip address:0x%x", ipa_ctx->nat_mem.public_ip_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.ipv4_rules_addr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	 (char *)ipa_ctx->nat_mem.nat_base_address + init->ipv4_rules_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 ipa_ctx->nat_mem.ipv4_rules_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.ipv4_expansion_rules_addr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	 (char *)ipa_ctx->nat_mem.nat_base_address + init->expn_rules_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 ipa_ctx->nat_mem.ipv4_expansion_rules_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.index_table_addr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		 (char *)ipa_ctx->nat_mem.nat_base_address + init->index_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 ipa_ctx->nat_mem.index_table_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.index_table_expansion_addr =
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	 (char *)ipa_ctx->nat_mem.nat_base_address + init->index_expn_offset;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				 ipa_ctx->nat_mem.index_table_expansion_addr);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.size_base_tables  = init->table_entries;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.size_expansion_tables = init->expn_table_entries;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				(ipa_ctx->nat_mem.size_base_tables + 1) *
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				ipa_ctx->nat_mem.size_expansion_tables *
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				(ipa_ctx->nat_mem.size_base_tables + 1) *
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:				ipa_ctx->nat_mem.size_expansion_tables *
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_lock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (nat_ctx->is_sys_mem) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			 ipa_ctx->pdev, nat_ctx->size,
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:			 nat_ctx->vaddr, nat_ctx->dma_handle);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->size = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		nat_ctx->vaddr = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_mapped = false;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_sys_mem = false;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	nat_ctx->is_dev_init = false;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	mutex_unlock(&nat_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	if (ipa_ctx->nat_mem.is_tmp_mem) {
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:		base_addr = ipa_ctx->nat_mem.tmp_dma_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.size_base_tables = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.size_expansion_tables = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.public_ip_addr = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.ipv4_rules_addr = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.ipv4_expansion_rules_addr = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.index_table_addr = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_ctx->nat_mem.index_table_expansion_addr = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_nat.c:	ipa_nat_free_mem_and_device(&ipa_ctx->nat_mem);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	IPAERR("NTN stats ofst=0x%x\n", ipa_ctx->uc_ntn_ctx.ntn_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	if (ipa_ctx->uc_ntn_ctx.ntn_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:			ipa_ctx->uc_ntn_ctx.ntn_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ioremap(ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.ntn_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	if (!ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->tx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio->rx_ch_stats[0].y
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	if (!stats || !ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:			ipa_ctx->uc_ntn_ctx.ntn_uc_stats_mmio);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.uc_ready_cb = ipa_ready_cb;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.priv = user_data;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.uc_ready_cb = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ipa_ctx->uc_ntn_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	if (ipa_ctx->uc_ntn_ctx.uc_ready_cb) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.uc_ready_cb(
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:			ipa_ctx->uc_ntn_ctx.priv);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.uc_ready_cb =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:		ipa_ctx->uc_ntn_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	cmd.base = dma_alloc_coherent(ipa_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ep_ul = &ipa_ctx->ep[ipa_ep_idx_ul];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ep_dl = &ipa_ctx->ep[ipa_ep_idx_dl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ep_ul = &ipa_ctx->ep[ipa_ep_idx_ul];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	ep_dl = &ipa_ctx->ep[ipa_ep_idx_dl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	cmd.base = dma_alloc_coherent(ipa_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	memset(&ipa_ctx->ep[ipa_ep_idx_dl], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	memset(&ipa_ctx->ep[ipa_ep_idx_ul], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_uc_ntn.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	struct ipa_ep_context *ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if ((ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) &&
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	     ipa_ctx->resume_on_connect[ep->client] ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	struct ipa_ep_context *ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if ((ipa_ctx->ipa_hw_type >= IPA_HW_v2_0) &&
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	aggr_init = ipa_read_reg(ipa_ctx->mmio,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		if (ipa_ctx->peer_bam_map_cnt == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			ipa_ctx->peer_bam_iova = cb->va_end;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			ipa_ctx->peer_bam_pa = base;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			ipa_ctx->peer_bam_map_size = size;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			ipa_ctx->peer_bam_dev = dev;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			WARN_ON(dev != ipa_ctx->peer_bam_dev);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->peer_bam_map_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ep->connect.dest_iova = ipa_ctx->peer_bam_iova;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ep->connect.source = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ep->connect.source_iova = ipa_ctx->peer_bam_iova;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ep->connect.destination = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:				dma_alloc_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			dma_alloc_coherent(ipa_ctx->pdev, mem_buff_ptr->size,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	memset(&ipa_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass &&
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if ((ipa_ctx->ipa_hw_type == IPA_HW_v2_0 ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->ipa_hw_type == IPA_HW_v2_5 ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->ipa_hw_type == IPA_HW_v2_6L) &&
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	sps->ipa_bam_hdl = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ipa_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	memset(&ipa_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		WARN_ON(dev != ipa_ctx->peer_bam_dev);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->peer_bam_map_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		if (ipa_ctx->peer_bam_map_cnt == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			len = roundup(ipa_ctx->peer_bam_map_size +
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:					ipa_ctx->peer_bam_pa -
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:					rounddown(ipa_ctx->peer_bam_pa,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:			dma_free_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->tethered_flow_control && ep->qmi_request_sent) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	memset(&ipa_ctx->ep[clnt_hdl], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (!ipa_ctx->tethered_flow_control) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:		ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_client.c:	if (ipa_ctx->ipa_hw_type > IPA_HW_v2_5 || ipa_ctx->skip_uc_pipe_reset) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_unmap_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_unmap_page(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_pool_free(ipa_ctx->dma_pool,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_unmap_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		kmem_cache_free(ipa_ctx->tx_pkt_wrapper_cache, tx_pkt_expected);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	WARN_ON(src_pipe >= ipa_ctx->ipa_num_pipes);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (!ipa_ctx->ep[src_pipe].status.status_en)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	sys = ipa_ctx->ep[src_pipe].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	tx_pkt = kmem_cache_zalloc(ipa_ctx->tx_pkt_wrapper_cache, mem_flag);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		dma_address = dma_map_single(ipa_ctx->pdev, desc->pyld,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (dma_mapping_error(ipa_ctx->pdev, dma_address)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_unmap_single(ipa_ctx->pdev, dma_address, desc->len, DMA_TO_DEVICE);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	flag = mem_flag | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		transfer.iovec = dma_pool_alloc(ipa_ctx->dma_pool, mem_flag,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		dma_addr  = dma_map_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev, dma_addr)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		tx_pkt = kmem_cache_zalloc(ipa_ctx->tx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:					dma_map_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:					skb_frag_dma_map(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev, tx_pkt->mem.phys_base)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_unmap_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				dma_unmap_page(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		kmem_cache_free(ipa_ctx->tx_pkt_wrapper_cache, tx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			dma_pool_free(ipa_ctx->dma_pool, transfer.iovec,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			dma_unmap_single(ipa_ctx->pdev, transfer.iovec_phys,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			atomic_set(&ipa_ctx->sps_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			atomic_set(&ipa_ctx->sps_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			atomic_set(&ipa_ctx->sps_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			usleep_range(ipa_ctx->ipa_rx_min_timeout_usec,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:					ipa_ctx->ipa_rx_max_timeout_usec);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	} while (inactive_cycles <= ipa_ctx->ipa_polling_iteration);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep->connect.source = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep->connect.dest_pipe_index = ipa_ctx->a5_pipe_index++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep->connect.destination = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep->connect.src_pipe_index = ipa_ctx->a5_pipe_index++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep->connect.desc.base = dma_alloc_coherent(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		atomic_inc(&ipa_ctx->wc_memb.active_clnt_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (ipa_ctx->modem_cfg_emb_pipe_flt &&
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_free_coherent(ipa_ctx->pdev, ep->connect.desc.size,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	memset(&ipa_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_free_coherent(ipa_ctx->pdev, ep->connect.desc.size,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (ipa_ctx->modem_cfg_emb_pipe_flt &&
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		atomic_dec(&ipa_ctx->wc_memb.active_clnt_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (!atomic_read(&ipa_ctx->wc_memb.active_clnt_cnt))
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	IPA_STATS_INC_CNT(ipa_ctx->stats.tx_pkts_compl);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->ep[ep_idx].client_notify)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->ep[ep_idx].client_notify(ipa_ctx->ep[ep_idx].priv,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	gfp_t flag = GFP_ATOMIC | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	sys = ipa_ctx->ep[src_ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		IPA_STATS_INC_CNT(ipa_ctx->stats.tx_sw_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		IPA_STATS_INC_CNT(ipa_ctx->stats.tx_hw_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		IPA_STATS_INC_CNT(ipa_ctx->stats.tx_non_linear);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	gfp_t flag = GFP_KERNEL | (ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.wan_repl_rx_empty);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.lan_repl_rx_empty);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_lock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			&ipa_ctx->wc_memb.wlan_comm_desc_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			if (ipa_ctx->wc_memb.wlan_comm_free_cnt > 0)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				ipa_ctx->wc_memb.wlan_comm_free_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			ipa_ctx->wc_memb.wlan_comm_total_cnt <
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->wc_memb.wlan_comm_total_cnt +=
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_lock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		&ipa_ctx->wc_memb.wlan_comm_desc_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->wc_memb.wlan_comm_free_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->wc_memb.wlan_comm_total_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->wc_memb.total_tx_pkts_freed = 0;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->wc_memb.wlan_comm_free_cnt != 0)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			ipa_ctx->wc_memb.wlan_comm_free_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->wc_memb.wlan_comm_total_cnt != 0)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			ipa_ctx->wc_memb.wlan_comm_total_cnt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		(ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	rx_len_cached = ipa_ctx->wc_memb.wlan_comm_total_cnt;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		spin_lock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			&ipa_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_len_cached = ++ipa_ctx->wc_memb.wlan_comm_total_cnt;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->wc_memb.wlan_comm_free_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		(ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt = kmem_cache_zalloc(ipa_ctx->rx_pkt_wrapper_cache,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa_ctx->pdev, ptr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		rx_pkt->data.dma_addr = dma_map_single(ipa_ctx->pdev,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (dma_mapping_error(ipa_ctx->pdev, rx_pkt->data.dma_addr)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				IPA_STATS_INC_CNT(ipa_ctx->stats.wan_rx_empty);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				IPA_STATS_INC_CNT(ipa_ctx->stats.lan_rx_empty);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			dma_unmap_single(ipa_ctx->pdev, rx_pkt->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				ipa_ctx->stats.rx_excp_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (status->endp_dest_idx >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			status->endp_src_idx >= ipa_ctx->ipa_num_pipes) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.aggr_close);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				ipa_ctx->stats.rx_excp_pkts[MAX_NUM_EXCP - 1]);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (status->endp_dest_idx == (sys->ep - ipa_ctx->ep)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.stat_compl);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:				ipa_ctx->stats.rx_excp_pkts[MAX_NUM_EXCP - 1]);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->ipa_client_apps_wan_cons_agg_gro) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		IPA_STATS_INC_CNT(ipa_ctx->stats.rx_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		if (status->endp_dest_idx >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			status->endp_src_idx >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_DEC_CNT(ipa_ctx->stats.rx_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			IPA_STATS_INC_CNT(ipa_ctx->stats.wan_aggr_close);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	IPA_STATS_INC_CNT(ipa_ctx->stats.rx_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	IPA_STATS_EXCP_CNT(mux_hdr->flags, ipa_ctx->stats.rx_excp_pkts);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[src_pipe];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_lock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (unlikely(src_pipe >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock(&ipa_ctx->disconnect_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[src_pipe];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (unlikely(src_pipe >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		(ipa_ctx->use_dma_zone ? GFP_DMA : 0);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->rx_pkt_wrapper_cache, flag);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	rx_pkt->sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	dma_unmap_single(ipa_ctx->pdev, rx_pkt_expected->data.dma_addr,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	kmem_cache_free(ipa_ctx->rx_pkt_wrapper_cache, rx_pkt_expected);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			atomic_set(&ipa_ctx->sps_pm.eot_activity, 1);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			   ipa_ctx->lan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			sys->rx_pool_sz = ipa_ctx->wan_rx_ring_size;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:			if (ipa_ctx->ipa_client_apps_wan_cons_agg_gro) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->ipa_hw_type == IPA_HW_v1_1) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	} else if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_0)
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	IPAERR("Unsupported HW type %d\n", ipa_ctx->ipa_hw_type);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	atomic_inc(&ipa_ctx->ep[ep_idx].avail_fifo_desc);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->ep[ep_idx].wstats.rx_pkts_status_rcvd++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ep_idx, atomic_read(&ipa_ctx->ep[ep_idx].avail_fifo_desc));
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->ep[ep_idx].priv);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (ipa_ctx->ep[ep_idx].client_notify) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->ep[ep_idx].client_notify(ipa_ctx->ep[ep_idx].priv,
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		ipa_ctx->ep[ep_idx].wstats.rx_hd_reply++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	atomic_inc(&ipa_ctx->ep[ep_idx].avail_fifo_desc);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->ep[ep_idx].wstats.rx_pkts_status_rcvd++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_lock_bh(&ipa_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	sys = ipa_ctx->ep[ep_idx].sys;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (unlikely(ipa_ctx->ep[ep_idx].valid == 0)) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.ipa_tx_mul_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_lock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->wc_memb.total_tx_pkts_freed++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:		&ipa_ctx->wc_memb.wlan_comm_desc_list);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->wc_memb.wlan_comm_free_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	spin_unlock_bh(&ipa_ctx->wc_memb.wlan_spinlock);
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	*ipa_bam_hdl = ipa_ctx->bam_handle;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ipa_ctx->skip_ep_cfg_shadow[ipa_ep_idx] = ep->skip_ep_cfg;
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_dp.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_add_tail(&intf->link, &ipa_ctx->intf_list);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry_safe(entry, next, &ipa_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry(entry, &ipa_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry(entry, &ipa_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:				mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry(entry, &ipa_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:				mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry(entry, &ipa_ctx->intf_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:				mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_add_tail(&msg->link, &ipa_ctx->msg_list);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	IPA_STATS_INC_CNT(ipa_ctx->stats.msg_w[meta->msg_type]);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	wake_up(&ipa_ctx->msg_waitq);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_add_tail(&msg->link, &ipa_ctx->pull_msg_list);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry_safe(entry, next, &ipa_ctx->pull_msg_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	add_wait_queue(&ipa_ctx->msg_waitq, &wait);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:		mutex_lock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:		if (!list_empty(&ipa_ctx->msg_list)) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:			msg = list_first_entry(&ipa_ctx->msg_list,
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:			mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:				ipa_ctx->stats.msg_r[msg->meta.msg_type]);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:		mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	remove_wait_queue(&ipa_ctx->msg_waitq, &wait);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:		mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_lock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	list_for_each_entry(entry, &ipa_ctx->pull_msg_list, link) {
drivers/platform/msm/ipa/ipa_v2/ipa_intf.c:	mutex_unlock(&ipa_ctx->msg_lock);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.wdi_uc_stats_ofst = uc_event_top_mmio->
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	IPAERR("WDI stats ofst=0x%x\n", ipa_ctx->uc_wdi_ctx.wdi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (ipa_ctx->uc_wdi_ctx.wdi_uc_stats_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->ctrl->ipa_reg_base_ofst +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->smem_sz) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:			ipa_ctx->uc_wdi_ctx.wdi_uc_stats_ofst);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ioremap(ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.wdi_uc_stats_ofst,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (!ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio->tx_ch_stats.y
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio->rx_ch_stats.y
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (!stats || !ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:			ipa_ctx->uc_wdi_ctx.wdi_uc_stats_mmio);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->wdi_map_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->wdi_map_cnt++;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2)
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->wdi_map_cnt--;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (ipa_ctx->wdi_map_cnt == 0)
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (wlan_smmu_en && ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (!wlan_smmu_en && ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (!wlan_smmu_en && !ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (wlan_smmu_en && !ipa_ctx->smmu_s1_bypass) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[ipa_ep_idx];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	memset(&ipa_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2)
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:			ipa_ctx->uc_ctx.rdy_ring_rp_va =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:			ipa_ctx->uc_ctx.rdy_comp_ring_wp_va =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_ring_base_pa =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_ring_rp_pa =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_ring_size =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_comp_ring_base_pa =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_comp_ring_wp_pa =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_ctx.rdy_comp_ring_size =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (!in->u.ul.rdy_ring_rp_va && ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wdi2);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (!in->u.ul.rdy_comp_ring_wp_va && ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wdi2);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	cmd.base = dma_alloc_coherent(ipa_ctx->uc_pdev, cmd.size,
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.stats_notify = in->wdi_notify;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	memset(&ipa_ctx->ep[ipa_ep_idx], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	dma_free_coherent(ipa_ctx->uc_pdev, cmd.size, cmd.base, cmd.phys_base);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	memset(&ipa_ctx->ep[clnt_hdl], 0, sizeof(struct ipa_ep_context));
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (ipa_ctx->uc_wdi_ctx.stats_notify)
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.stats_notify = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ep[prod_hdl].valid == 1) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_wdi2) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->tag_process_before_gating = true;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (clnt_hdl >= ipa_ctx->ipa_num_pipes ||
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	    ipa_ctx->ep[clnt_hdl].valid == 0) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ep = &ipa_ctx->ep[clnt_hdl];
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.uc_ready_cb = inout->notify;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.priv = inout->priv;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.uc_ready_cb = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	ipa_ctx->uc_wdi_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		if (ipa_ctx->ipa_hw_type >= IPA_HW_v2_5) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:				ipa_ctx->ipa_wrapper_base +
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:	if (ipa_ctx->uc_wdi_ctx.uc_ready_cb) {
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.uc_ready_cb(
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:			ipa_ctx->uc_wdi_ctx.priv);
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.uc_ready_cb =
drivers/platform/msm/ipa/ipa_v2/ipa_uc_wdi.c:		ipa_ctx->uc_wdi_ctx.priv = NULL;
drivers/platform/msm/ipa/ipa_api.c: * ipa_get_modem_cfg_emb_pipe_flt()- Return ipa_ctx->modem_cfg_emb_pipe_flt
drivers/platform/msm/ipa/ipa_api.c: * ipa_get_transport_type()- Return ipa_ctx->transport_prototype
drivers/platform/msm/ipa/ipa_api.c: * ipa_ctx->ipa_client_apps_wan_cons_agg_gro
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	res = ipa_pm_register(&params, &ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	res = ipa_pm_associate_ipa_cons_to_client(ntn_ctx->pm_hdl,
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ipa_pm_deregister(ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ntn_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ipa_pm_deactivate_sync(ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ipa_pm_deregister(ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	memcpy(ntn_ctx->netdev_name, inp->netdev_name, IPA_RESOURCE_NAME_MAX);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->hdr_len = inp->hdr_info[0].hdr_len;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->notify = inp->notify;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->priv = inp->priv;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (ipa_commit_partial_hdr(hdr, ntn_ctx->netdev_name, inp->hdr_info)) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->partial_hdr_hdl[IPA_IP_v4] = hdr->hdr[IPA_IP_v4].hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->partial_hdr_hdl[IPA_IP_v6] = hdr->hdr[IPA_IP_v6].hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	init_completion(&ntn_ctx->ntn_completion);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->state = IPA_UC_OFFLOAD_STATE_INITIALIZED;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ctx->proto = inp->proto;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (ctx->state != IPA_UC_OFFLOAD_STATE_INVALID) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (ctx->proto == IPA_UC_NTN) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	} else if (ntn_ctx->state != IPA_UC_OFFLOAD_STATE_UP) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		IPA_UC_OFFLOAD_ERR("Invalid State: %d\n", ntn_ctx->state);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (!(offload_ctx && offload_ctx->proto > IPA_UC_INVALID &&
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		  offload_ctx->proto < IPA_UC_MAX_PROT_SIZE)) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (offload_ctx->state != IPA_UC_OFFLOAD_STATE_INITIALIZED)
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		IPA_UC_OFFLOAD_ERR("Invalid State: %d\n", offload_ctx->state);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		complete_all(&offload_ctx->ntn_completion);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	prev_state = ntn_ctx->state;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		result = ipa_pm_activate_sync(ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:			if (wait_for_completion_timeout(&ntn_ctx->ntn_completion
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->state = IPA_UC_OFFLOAD_STATE_UP;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	result = ipa_setup_uc_ntn_pipes(inp, ntn_ctx->notify,
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ntn_ctx->priv, ntn_ctx->hdr_len, outp);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ntn_ctx->state = prev_state;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (offload_ctx->state != IPA_UC_OFFLOAD_STATE_INITIALIZED) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		IPA_UC_OFFLOAD_ERR("Invalid state %d\n", offload_ctx->state);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	switch (offload_ctx->proto) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		IPA_UC_OFFLOAD_ERR("Invalid Proto :%d\n", offload_ctx->proto);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	ntn_ctx->state = IPA_UC_OFFLOAD_STATE_INITIALIZED;
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		ret = ipa_pm_deactivate_sync(ntn_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (offload_ctx->state != IPA_UC_OFFLOAD_STATE_UP) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	switch (offload_ctx->proto) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	hdr->hdl[0].hdl = ntn_ctx->partial_hdr_hdl[0];
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	hdr->hdl[1].hdl = ntn_ctx->partial_hdr_hdl[1];
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (ipa_deregister_intf(ntn_ctx->netdev_name)) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	if (offload_ctx->state != IPA_UC_OFFLOAD_STATE_INITIALIZED) {
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:		IPA_UC_OFFLOAD_ERR("Invalid State %d\n", offload_ctx->state);
drivers/platform/msm/ipa/ipa_clients/ipa_uc_offload.c:	switch (offload_ctx->proto) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	state = ipa3_usb_ctx->ttype_ctx[ttype].state;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].state = new_state;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if ((rm_ctx->cons_state == IPA_USB_CONS_GRANTED) ||
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested_released) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested_released =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (rm_ctx->cons_requested) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				rm_ctx->cons_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_state = IPA_USB_CONS_GRANTED;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	state = ipa3_usb_ctx->ttype_ctx[ttype].state;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	cb = ipa3_usb_ctx->ttype_ctx[ttype].ipa_usb_notify_cb;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	user_data = ipa3_usb_ctx->ttype_ctx[ttype].user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa_rm_resource_str(rm_ctx->prod_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		complete_all(&rm_ctx->prod_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa_rm_resource_str(rm_ctx->prod_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		complete_all(&rm_ctx->prod_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->ttype_ctx[ttype].state));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	switch (ipa3_usb_ctx->ttype_ctx[ttype].state) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_state = IPA_USB_CONS_GRANTED;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_requested = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (rm_ctx->cons_state == IPA_USB_CONS_GRANTED)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (!rm_ctx->cons_requested) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			queue_work(ipa3_usb_ctx->wq, remote_wakeup_work);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_requested = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].state));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	switch (ipa3_usb_ctx->ttype_ctx[ttype].state) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (rm_ctx->cons_requested)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested_released = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (rm_ctx->cons_requested)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested_released = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (rm_ctx->cons_requested)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			rm_ctx->cons_requested = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->ttype_ctx[ttype].state));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx->cons_state = IPA_USB_CONS_RELEASED;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_state_to_string(ttype_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ttype_ctx->state == IPA_USB_SUSPENDED)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		queue_work(ipa3_usb_ctx->wq,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ttype_ctx->pm_ctx.remote_wakeup_work);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = teth_bridge_init(&ipa3_usb_ctx->teth_bridge_params);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		&ipa3_usb_ctx->ttype_ctx[ttype];
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->num_init_prot > 0)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	memset(&ttype_ctx->pm_ctx.reg_params, 0,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		sizeof(ttype_ctx->pm_ctx.reg_params));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ttype_ctx->pm_ctx.reg_params.name = (ttype == IPA_USB_TRANSPORT_DPL) ?
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ttype_ctx->pm_ctx.reg_params.callback = ipa3_usb_pm_cb;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ttype_ctx->pm_ctx.reg_params.user_data = ttype_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ttype_ctx->pm_ctx.reg_params.group = IPA_PM_GROUP_DEFAULT;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = ipa_pm_register(&ttype_ctx->pm_ctx.reg_params,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		&ttype_ctx->pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = ipa_pm_associate_ipa_cons_to_client(ttype_ctx->pm_ctx.hdl,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa_pm_deregister(ttype_ctx->pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	memset(&ttype_ctx->pm_ctx.reg_params, 0,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		sizeof(ttype_ctx->pm_ctx.reg_params));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		&ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = ipa_pm_deregister(pm_ctx->hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	memset(&pm_ctx->reg_params, 0, sizeof(pm_ctx->reg_params));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (!rm_ctx->prod_valid) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.name = IPA3_USB_IS_TTYPE_DPL(ttype) ?
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.floor_voltage = IPA_VOLTAGE_SVS2;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.reg_params.user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.reg_params.notify_cb =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.request_resource = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_params.release_resource = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		result = ipa_rm_create_resource(&rm_ctx->prod_params);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa_rm_resource_str(rm_ctx->prod_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_valid = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa_rm_resource_str(rm_ctx->prod_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (!rm_ctx->cons_valid) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.name = IPA3_USB_IS_TTYPE_DPL(ttype) ?
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.floor_voltage = IPA_VOLTAGE_SVS2;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.reg_params.user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.reg_params.notify_cb = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.request_resource =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_params.release_resource =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		result = ipa_rm_create_resource(&rm_ctx->cons_params);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa_rm_resource_str(rm_ctx->cons_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->cons_valid = true;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa_rm_resource_str(rm_ctx->cons_params.name));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		rm_ctx->prod_valid = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa_rm_delete_resource(rm_ctx->prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (!ipa3_usb_ctx->ttype_ctx[ttype].ipa_usb_notify_cb) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].ipa_usb_notify_cb =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->ttype_ctx[ttype].ipa_usb_notify_cb !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data = user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			memcpy(ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			memcpy(ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			result = rndis_ipa_init(&ipa3_usb_ctx->
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			memcpy(ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			memcpy(ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			result = ecm_ipa_init(&ipa3_usb_ctx->
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->num_init_prot++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data = user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->num_init_prot++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data = user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		|| (ipa3_usb_ctx->num_init_prot == 0)) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.prod_valid =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_valid =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[params->teth_prot].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[params->teth_prot].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->smmu_reg_map.cnt == 0) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->smmu_reg_map.addr = gevntcount_r;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->smmu_reg_map.addr, true);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			if (gevntcount_r != ipa3_usb_ctx->smmu_reg_map.addr) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->smmu_reg_map.cnt++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (gevntcount_r != ipa3_usb_ctx->smmu_reg_map.addr) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->smmu_reg_map.cnt == 1) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->smmu_reg_map.addr, false);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->smmu_reg_map.cnt--;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		chan_params.priv = ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		chan_params.priv = ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_bridge_params.private_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_bridge_params.usb_notify_cb;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_bridge_params.skip_ep_cfg;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->ttype_ctx[ttype].ch_params = *params;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		&ipa3_usb_ctx->ttype_ctx[ttype].ch_params, false);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rsrc_str = ipa_rm_resource_str(rm_ctx->prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	init_completion(&rm_ctx->prod_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = ipa_rm_request_resource(rm_ctx->prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		result = wait_for_completion_timeout(&rm_ctx->prod_comp,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rm_ctx = &ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	rsrc_str = ipa_rm_resource_str(rm_ctx->prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	init_completion(&rm_ctx->prod_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	result = ipa_rm_release_resource(rm_ctx->prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		result = wait_for_completion_timeout(&rm_ctx->prod_comp,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->teth_prot_ctx[params->teth_prot].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	teth_conn_params = &(ipa3_usb_ctx->ttype_ctx[ttype].teth_conn_params);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[IPA_USB_RNDIS].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[IPA_USB_ECM].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[IPA_USB_DIAG].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[IPA_USB_DIAG].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->ttype_ctx[ttype].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->ttype_ctx[ttype].teth_conn_params.ipa_to_usb_clnt_hdl
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].teth_conn_params.
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->ttype_ctx[ttype].teth_conn_params.params
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.prod_params.name,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa_rm_resource_str(ipa3_usb_ctx->
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_params.name,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa_rm_resource_str(ipa3_usb_ctx->
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_TETH].state);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_DPL].state);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_TETH].rm_ctx.cons_valid)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_TETH].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_DPL].rm_ctx.cons_valid)
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_DPL].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[i].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		} else if (ipa3_usb_ctx->teth_prot_ctx[i].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->dent = debugfs_create_dir("ipa_usb", 0);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (IS_ERR(ipa3_usb_ctx->dent)) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->dfile_state_info = debugfs_create_file("state_info",
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			read_only_mode, ipa3_usb_ctx->dent, 0,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (!ipa3_usb_ctx->dfile_state_info ||
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		IS_ERR(ipa3_usb_ctx->dfile_state_info)) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	debugfs_remove_recursive(ipa3_usb_ctx->dent);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->dent = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (IS_ERR(ipa3_usb_ctx->dent)) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	debugfs_remove_recursive(ipa3_usb_ctx->dent);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[ttype].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[ttype].state != IPA_USB_SUSPENDED) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	orig_state = ipa3_usb_ctx->ttype_ctx[ttype].state;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->qmi_req_id);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:				ipa3_usb_ctx->teth_prot_ctx[teth_prot].
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->num_init_prot--;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->num_init_prot--;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		if (ipa3_usb_ctx->teth_prot_ctx[teth_prot].state !=
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].user_data =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[teth_prot].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		(ipa3_usb_ctx->num_init_prot == 0)) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.prod_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.prod_valid =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_params.name);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_valid =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].ipa_usb_notify_cb = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->qmi_req_id);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->qmi_req_id, IPA3_USB_IS_TTYPE_DPL(ttype));
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_state ==
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_requested) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		queue_work(ipa3_usb_ctx->wq,
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (ipa3_usb_ctx->ttype_ctx[ttype].rm_ctx.cons_requested) {
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		queue_work(ipa3_usb_ctx->wq, IPA3_USB_IS_TTYPE_DPL(ttype) ?
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->qmi_req_id);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_lock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	prev_state = ipa3_usb_ctx->ttype_ctx[ttype].state;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			ipa3_usb_ctx->ttype_ctx[ttype].pm_ctx.hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_unlock(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->teth_prot_ctx[i].state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->num_init_prot = 0;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	init_completion(&ipa3_usb_ctx->dev_ready_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->qmi_req_id = 0;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_init(&ipa3_usb_ctx->state_lock);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->dl_data_pending = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	mutex_init(&ipa3_usb_ctx->general_mutex);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:			&ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_TETH].pm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		pm_ctx->hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		pm_ctx->remote_wakeup_work =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		pm_ctx = &ipa3_usb_ctx->ttype_ctx[IPA_USB_TRANSPORT_DPL].pm_ctx;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		pm_ctx->hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		pm_ctx->remote_wakeup_work =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[i].rm_ctx.prod_valid = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[i].rm_ctx.cons_valid = false;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		init_completion(&ipa3_usb_ctx->ttype_ctx[i].rm_ctx.prod_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[i].user_data = NULL;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_lock_irqsave(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[i].state = IPA_USB_INVALID;
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:		ipa3_usb_ctx->ttype_ctx[i].rm_ctx.cons_state =
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	spin_unlock_irqrestore(&ipa3_usb_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	ipa3_usb_ctx->wq = create_singlethread_workqueue("ipa_usb_wq");
drivers/platform/msm/ipa/ipa_clients/ipa_usb.c:	if (!ipa3_usb_ctx->wq) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net = net;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->outstanding_high = DEFAULT_OUTSTANDING_HIGH;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->outstanding_low = DEFAULT_OUTSTANDING_LOW;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	atomic_set(&ecm_ipa_ctx->outstanding_pkts, 0);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->device_ready_notify = params->device_ready_notify;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ipa_is_vlan_mode(IPA_VLAN_IF_ECM, &ecm_ipa_ctx->is_vlan_mode)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ECM_IPA_DEBUG("is vlan mode %d\n", ecm_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	netif_stop_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = ECM_IPA_INITIALIZED;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	next_state = ecm_ipa_next_state(ecm_ipa_ctx->state, ECM_IPA_CONNECT);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->ipa_to_usb_hdl = ipa_to_usb_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->usb_to_ipa_hdl = usb_to_ipa_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->ipa_to_usb_client = ipa_get_client_mapping(ipa_to_usb_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->ipa_to_usb_client < 0) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			ecm_ipa_ctx->ipa_to_usb_client);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		      ecm_ipa_ctx->ipa_to_usb_client);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->usb_to_ipa_client = ipa_get_client_mapping(usb_to_ipa_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->usb_to_ipa_client < 0) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			ecm_ipa_ctx->usb_to_ipa_client);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		      ecm_ipa_ctx->usb_to_ipa_client);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->ipa_rm_resource_name_cons =
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		if (ecm_ipa_ctx->ipa_rm_resource_name_cons < 0) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:				      ecm_ipa_ctx->ipa_rm_resource_name_cons);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			      ecm_ipa_ctx->ipa_rm_resource_name_cons);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->ipa_rm_resource_name_prod =
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		if (ecm_ipa_ctx->ipa_rm_resource_name_prod < 0) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:				      ecm_ipa_ctx->ipa_rm_resource_name_prod);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			      ecm_ipa_ctx->ipa_rm_resource_name_prod);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	netif_carrier_on(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	strlcpy(ecm_msg->name, ecm_ipa_ctx->net->name,
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_msg->ifindex = ecm_ipa_ctx->net->ifindex;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (!netif_carrier_ok(ecm_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->state == ECM_IPA_CONNECTED_AND_UP)
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	next_state = ecm_ipa_next_state(ecm_ipa_ctx->state, ECM_IPA_OPEN);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->state == ECM_IPA_CONNECTED_AND_UP)
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		atomic_read(&ecm_ipa_ctx->outstanding_pkts));
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (unlikely(ecm_ipa_ctx->state != ECM_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (atomic_read(&ecm_ipa_ctx->outstanding_pkts) >=
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:					ecm_ipa_ctx->outstanding_high) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			ecm_ipa_ctx->outstanding_high);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->is_vlan_mode)
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ret = ipa_tx_dp(ecm_ipa_ctx->ipa_to_usb_client, skb, NULL);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	atomic_inc(&ecm_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (unlikely(ecm_ipa_ctx->state != ECM_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	skb->dev = ecm_ipa_ctx->net;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	skb->protocol = eth_type_trans(skb, ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net->stats.rx_packets++;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net->stats.rx_bytes += packet_len;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	next_state = ecm_ipa_next_state(ecm_ipa_ctx->state, ECM_IPA_STOP);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	next_state = ecm_ipa_next_state(ecm_ipa_ctx->state, ECM_IPA_DISCONNECT);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	netif_carrier_off(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	strlcpy(ecm_msg->name, ecm_ipa_ctx->net->name,
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_msg->ifindex = ecm_ipa_ctx->net->ifindex;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	netif_stop_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		atomic_read(&ecm_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net->stats.tx_errors += outstanding_dropped_pkts;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	atomic_set(&ecm_ipa_ctx->outstanding_pkts, 0);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	next_state = ecm_ipa_next_state(ecm_ipa_ctx->state, ECM_IPA_CLEANUP);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	unregister_netdev(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	free_netdev(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->device_ready_notify) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->device_ready_notify();
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	netif_start_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ipv4_hdr, dst_mac, src_mac, ecm_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ipv6_hdr, dst_mac, src_mac, ecm_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->eth_ipv4_hdr_hdl = ipv4_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->eth_ipv6_hdr_hdl = ipv6_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipv4->hdl = ecm_ipa_ctx->eth_ipv4_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipv6->hdl = ecm_ipa_ctx->eth_ipv6_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (ecm_ipa_ctx->is_vlan_mode)
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipv4_property->dst_pipe = ecm_ipa_ctx->ipa_to_usb_client;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipv6_property->dst_pipe = ecm_ipa_ctx->ipa_to_usb_client;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	rx_ipv4_property->src_pipe = ecm_ipa_ctx->usb_to_ipa_client;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	rx_ipv6_property->src_pipe = ecm_ipa_ctx->usb_to_ipa_client;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			netif_queue_stopped(ecm_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		netif_start_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->ipa_rm_resource_name_cons);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		(ecm_ipa_ctx->ipa_rm_resource_name_prod,
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:				 ecm_ipa_ctx->ipa_rm_resource_name_cons);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipa_rm_delete_dependency(ecm_ipa_ctx->ipa_rm_resource_name_prod,
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (netif_queue_stopped(ecm_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		netif_start_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	pm_reg.name = ecm_ipa_ctx->net->name;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	result = ipa_pm_register(&pm_reg, &ecm_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipa_pm_deactivate_sync(ecm_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ipa_pm_deregister(ecm_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		return ipa_pm_activate(ecm_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ipa_pm_deferred_deactivate(ecm_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		atomic_read(&ecm_ipa_ctx->outstanding_pkts));
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (unlikely(ecm_ipa_ctx->state != ECM_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			ecm_ipa_state_string(ecm_ipa_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net->stats.tx_packets++;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->net->stats.tx_bytes += skb->len;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	atomic_dec(&ecm_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		(netif_queue_stopped(ecm_ipa_ctx->net) &&
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		netif_carrier_ok(ecm_ipa_ctx->net) &&
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		atomic_read(&ecm_ipa_ctx->outstanding_pkts)
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		< (ecm_ipa_ctx->outstanding_low)) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:			ecm_ipa_ctx->outstanding_low);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		netif_wake_queue(ecm_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		atomic_read(&ecm_ipa_ctx->outstanding_pkts));
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	file->private_data = &ecm_ipa_ctx->outstanding_pkts;
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	ecm_ipa_ctx->directory = debugfs_create_dir("ecm_ipa", NULL);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	if (!ecm_ipa_ctx->directory) {
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->directory, &ecm_ipa_ctx->outstanding_high);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->directory, &ecm_ipa_ctx->outstanding_low);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:		ecm_ipa_ctx->directory, &ecm_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	debugfs_remove_recursive(ecm_ipa_ctx->directory);
drivers/platform/msm/ipa/ipa_clients/ecm_ipa.c:	debugfs_remove_recursive(ecm_ipa_ctx->directory);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		mutex_init(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		INIT_LIST_HEAD(&ipa_wdi3_ctx->head_intf_list);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	mutex_lock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	list_for_each_entry(entry, &ipa_wdi3_ctx->head_intf_list, link)
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:			mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	list_add(&new_intf->link, &ipa_wdi3_ctx->head_intf_list);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	init_completion(&ipa_wdi3_ctx->wdi3_completion);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	mutex_lock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	list_for_each_entry_safe(entry, next, &ipa_wdi3_ctx->head_intf_list,
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:				mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	mutex_unlock(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		complete_all(&ipa_wdi3_ctx->wdi3_completion);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		mutex_init(&ipa_wdi3_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		INIT_LIST_HEAD(&ipa_wdi3_ctx->head_intf_list);
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	ipa_wdi3_ctx->notify = in->notify;
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:	ipa_wdi3_ctx->priv = in->priv;
drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.c:		if (wait_for_completion_timeout(&ipa_wdi3_ctx->wdi3_completion,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	(memcmp(&(daddr), &odu_bridge_ctx->llv6_addr, sizeof((daddr))) \
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->send_dl_skb(priv, (struct sk_buff *)data);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->stats.num_dl_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->tx_dp_notify(odu_bridge_ctx->priv,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->stats.num_lan_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->send_dl_skb(priv, skb);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->stats.num_dl_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_prod_params.desc_fifo_sz = odu_bridge_ctx->ipa_sys_desc_size;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_prod_params.priv = odu_bridge_ctx->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_prod_params.notify = odu_bridge_ctx->tx_dp_notify;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_emb_cons_params.desc_fifo_sz = odu_bridge_ctx->ipa_sys_desc_size;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_emb_cons_params.priv = odu_bridge_ctx->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->odu_prod_hdl, odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_teardown_sys_pipe(odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_prod_params.priv = odu_bridge_ctx->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_prod_params.notify = odu_bridge_ctx->tx_dp_notify;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_teth_cons_params.priv = odu_bridge_ctx->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->odu_teth_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_emb_cons_params.priv = odu_bridge_ctx->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->odu_prod_hdl, odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->odu_teth_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_teardown_sys_pipe(odu_bridge_ctx->odu_teth_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_teth_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_teardown_sys_pipe(odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_teardown_sys_pipe(odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_teardown_sys_pipe(odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_emb_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_teardown_sys_pipe(odu_bridge_ctx->odu_prod_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_prod_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_teardown_sys_pipe(odu_bridge_ctx->odu_teth_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_teth_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_teardown_sys_pipe(odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_emb_cons_hdl = 0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (!odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_lock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->mode == ODU_BRIDGE_MODE_ROUTER) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->is_connected = false;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_unlock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_lock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->mode == ODU_BRIDGE_MODE_ROUTER) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->is_connected = true;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_unlock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_lock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->mode == mode) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		if (odu_bridge_ctx->mode == ODU_BRIDGE_MODE_ROUTER) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->mode = mode;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_unlock(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	memcpy(&odu_bridge_ctx->llv6_addr, &llv6_addr_host,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:				sizeof(odu_bridge_ctx->llv6_addr));
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ODU_BRIDGE_DBG_LOW("LLV6 addr: %pI6c\n", &odu_bridge_ctx->llv6_addr);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			    odu_bridge_ctx->stats.num_ul_packets);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			    odu_bridge_ctx->stats.num_dl_packets);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			    odu_bridge_ctx->stats.num_lan_packets);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	switch (odu_bridge_ctx->mode) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	switch (odu_bridge_ctx->mode) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->stats.num_ul_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->tx_dp_notify(odu_bridge_ctx->priv,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->tx_dp_notify(odu_bridge_ctx->priv,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->stats.num_ul_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->stats.num_lan_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->tx_dp_notify(odu_bridge_ctx->priv,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->stats.num_ul_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:			odu_bridge_ctx->stats.num_lan_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->stats.num_ul_packets++;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ODU_BRIDGE_ERR("Unsupported mode: %d\n", odu_bridge_ctx->mode);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	memcpy(eth_ipv4->h_source, odu_bridge_ctx->device_ethaddr, ETH_ALEN);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	memcpy(eth_ipv6->h_source, odu_bridge_ctx->device_ethaddr, ETH_ALEN);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_br_ipv4_hdr_hdl = ipv4_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->odu_br_ipv6_hdr_hdl = ipv6_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipv4->hdl = odu_bridge_ctx->odu_br_ipv4_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipv6->hdl = odu_bridge_ctx->odu_br_ipv6_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_register_intf(odu_bridge_ctx->netdev_name, &tx_properties,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = ipa_deregister_intf(odu_bridge_ctx->netdev_name);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->class = class_create(THIS_MODULE, ODU_BRIDGE_DRV_NAME);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (!odu_bridge_ctx->class) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = alloc_chrdev_region(&odu_bridge_ctx->dev_num, 0, 1,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->dev = device_create(odu_bridge_ctx->class, NULL,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->dev_num, odu_bridge_ctx, ODU_BRIDGE_DRV_NAME);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (IS_ERR(odu_bridge_ctx->dev)) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	cdev_init(&odu_bridge_ctx->cdev, &odu_bridge_drv_fops);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->cdev.owner = THIS_MODULE;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->cdev.ops = &odu_bridge_drv_fops;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	res = cdev_add(&odu_bridge_ctx->cdev, odu_bridge_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	strlcpy(odu_bridge_ctx->netdev_name, params->netdev_name,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->priv = params->priv;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->tx_dp_notify = params->tx_dp_notify;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->send_dl_skb = params->send_dl_skb;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	memcpy(odu_bridge_ctx->device_ethaddr, params->device_ethaddr,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->ipa_sys_desc_size = params->ipa_desc_size;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->mode = ODU_BRIDGE_MODE_ROUTER;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	mutex_init(&odu_bridge_ctx->lock);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	device_destroy(odu_bridge_ctx->class, odu_bridge_ctx->dev_num);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	unregister_chrdev_region(odu_bridge_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	class_destroy(odu_bridge_ctx->class);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	cdev_del(&odu_bridge_ctx->cdev);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	device_destroy(odu_bridge_ctx->class, odu_bridge_ctx->dev_num);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	unregister_chrdev_region(odu_bridge_ctx->dev_num, 1);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	class_destroy(odu_bridge_ctx->class);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipc_log_context_destroy(odu_bridge_ctx->logbuf);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipc_log_context_destroy(odu_bridge_ctx->logbuf_low);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		complete(&odu_bridge_ctx->rm_comp);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	reinit_completion(&odu_bridge_ctx->rm_comp);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		wait_for_completion(&odu_bridge_ctx->rm_comp);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	reinit_completion(&odu_bridge_ctx->rm_comp);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_suspended)
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->wakeup_request(odu_bridge_ctx->priv);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_suspended)
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		odu_bridge_ctx->wakeup_request(odu_bridge_ctx->priv);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		&odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ret = ipa_pm_associate_ipa_cons_to_client(odu_bridge_ctx->pm_hdl,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_pm_deregister(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	init_completion(&odu_bridge_ctx->rm_comp);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->wakeup_request = params->wakeup_request;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ret = ipa_pm_activate_sync(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		return ipa_pm_set_perf_profile(odu_bridge_ctx->pm_hdl,
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ret = ipa_pm_deactivate_sync(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (!odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (odu_bridge_ctx->is_suspended) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ret = ipa_stop_gsi_channel(odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ret = ipa_pm_deactivate_sync(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ipa_start_gsi_channel(odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->is_suspended = true;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (!odu_bridge_ctx->is_connected) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	if (!odu_bridge_ctx->is_suspended) {
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:		ret = ipa_pm_activate_sync(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ret = ipa_start_gsi_channel(odu_bridge_ctx->odu_emb_cons_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->is_suspended = false;
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_pm_deactivate_sync(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	ipa_pm_deregister(odu_bridge_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/odu_bridge.c:	odu_bridge_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	((ipa_mhi_client_ctx->assert_bit40)?(IPA_MHI_HOST_ADDR(addr)):(addr))
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->use_ipadma) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (!ipa_mhi_client_ctx->test_mode)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (!ipa_mhi_client_ctx->test_mode)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		MHI_STATE_STR(ipa_mhi_client_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->ul_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->dl_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_INITIALIZED ||
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	    ipa_mhi_client_ctx->state == IPA_MHI_STATE_READY) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_SUSPENDED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->ul_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->dl_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		&ipa_mhi_client_ctx->use_ipadma);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->wakeup_notified) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	queue_work(ipa_mhi_client_ctx->wq, &ipa_mhi_notify_wakeup_work);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->wakeup_notified = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	IPA_MHI_DBG("%s\n", MHI_STATE_STR(ipa_mhi_client_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->rm_cons_state = IPA_MHI_RM_STATE_REQUESTED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_STARTED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->rm_cons_state = IPA_MHI_RM_STATE_GRANTED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	} else if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_SUSPENDED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	} else if (ipa_mhi_client_ctx->state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->trigger_wakeup = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->rm_cons_state = IPA_MHI_RM_STATE_RELEASED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	complete_all(&ipa_mhi_client_ctx->rm_cons_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		complete_all(&ipa_mhi_client_ctx->rm_prod_granted_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->cb_notify(ipa_mhi_client_ctx->cb_priv,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->cb_notify(ipa_mhi_client_ctx->cb_priv,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	queue_work(ipa_mhi_client_ctx->wq, &ipa_mhi_notify_ready_work);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			MHI_STATE_STR(ipa_mhi_client_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	switch (ipa_mhi_client_ctx->state) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			if (ipa_mhi_client_ctx->trigger_wakeup) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->trigger_wakeup = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->wakeup_notified = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->trigger_wakeup = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			if (ipa_mhi_client_ctx->rm_cons_state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->rm_cons_state =
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			if (ipa_mhi_client_ctx->trigger_wakeup) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->trigger_wakeup = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->trigger_wakeup = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->wakeup_notified = false;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			if (ipa_mhi_client_ctx->rm_cons_state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->rm_cons_state =
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		IPA_MHI_ERR("Invalid state %d\n", ipa_mhi_client_ctx->state);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->state = new_state;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			MHI_STATE_STR(ipa_mhi_client_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_SUSPENDED)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	else if (ipa_mhi_client_ctx->state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->trigger_wakeup = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	reinit_completion(&ipa_mhi_client_ctx->rm_prod_granted_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			&ipa_mhi_client_ctx->rm_prod_granted_comp,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->host_ctrl_addr = params->host_ctrl_addr;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->host_data_addr = params->host_data_addr;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->channel_context_array_addr =
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->event_context_array_addr =
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->host_ctrl_addr);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->host_data_addr);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->channel_context_array_addr);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->event_context_array_addr);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		res = ipa_pm_activate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		res = ipa_pm_activate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->first_ch_idx;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->first_ch_idx;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->first_er_idx;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	init_params.uC.mmio_addr = ipa_mhi_client_ctx->mmio_addr;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	init_params.uC.msi = &ipa_mhi_client_ctx->msi;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channels = ipa_mhi_client_ctx->ul_channels;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channels = ipa_mhi_client_ctx->dl_channels;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	channels[ch_idx].index = ipa_mhi_client_ctx->total_channels++;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (ipa_mhi_client_ctx->ul_channels[ch_idx].valid &&
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->ul_channels[ch_idx].client)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			return &ipa_mhi_client_ctx->ul_channels[ch_idx];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (ipa_mhi_client_ctx->dl_channels[ch_idx].valid &&
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->dl_channels[ch_idx].client)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			return &ipa_mhi_client_ctx->dl_channels[ch_idx];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->event_context_array_addr +
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			if (!ipa_mhi_client_ctx->ul_channels[i].valid)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:					&ipa_mhi_client_ctx->ul_channels[i]);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->ul_channels[i].client);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (!ipa_mhi_client_ctx->ul_channels[i].valid)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->ul_channels[i].client);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (!ipa_mhi_client_ctx->dl_channels[i].valid)
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		if (ipa_mhi_client_ctx->dl_channels[i].state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->dl_channels[i].client);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->dl_channels[i].client);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->qmi_req_id, false);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_disable_force_clear(ipa_mhi_client_ctx->qmi_req_id);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			ipa_mhi_client_ctx->state != IPA_MHI_STATE_STARTED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->channel_context_array_addr +
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		internal.start.gsi.msi = &ipa_mhi_client_ctx->msi;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->assert_bit40;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	reinit_completion(&ipa_mhi_client_ctx->rm_cons_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->rm_cons_state != IPA_MHI_RM_STATE_GRANTED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		&ipa_mhi_client_ctx->rm_cons_comp,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->ul_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_mhi_suspend_channels(ipa_mhi_client_ctx->ul_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->qmi_req_id, false);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				if (ipa_mhi_client_ctx->test_mode) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_disable_force_clear(ipa_mhi_client_ctx->qmi_req_id);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->ul_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->dl_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->ul_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		channel = &ipa_mhi_client_ctx->dl_channels[i];
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_mhi_suspend_channels(ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:			(ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->trigger_wakeup = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		res = ipa_pm_deactivate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		res = ipa_pm_deactivate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_resume_channels(true, ipa_mhi_client_ctx->ul_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_disable_force_clear(ipa_mhi_client_ctx->qmi_req_id)) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->qmi_req_id++;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->rm_cons_state == IPA_MHI_RM_STATE_REQUESTED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->rm_cons_state = IPA_MHI_RM_STATE_GRANTED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		res = ipa_pm_activate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_activate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:					ipa_mhi_client_ctx->ul_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:					ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_suspend_channels(ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_suspend_channels(ipa_mhi_client_ctx->ul_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_pm_deactivate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_suspend_channels(ipa_mhi_client_ctx->dl_channels);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_mhi_destroy_channels(ipa_mhi_client_ctx->ul_channels,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_mhi_destroy_channels(ipa_mhi_client_ctx->dl_channels,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state != IPA_MHI_STATE_INITIALIZED  &&
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->state != IPA_MHI_STATE_READY) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_pm_deactivate_sync(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_pm_deregister(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_pm_deactivate_sync(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_pm_deregister(ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->modem_pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	destroy_workqueue(ipa_mhi_client_ctx->wq);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	IPA_MHI_DBG("%s\n", MHI_STATE_STR(ipa_mhi_client_ctx->state));
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_irqsave(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (ipa_mhi_client_ctx->state == IPA_MHI_STATE_SUSPENDED) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	} else if (ipa_mhi_client_ctx->state ==
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:		ipa_mhi_client_ctx->trigger_wakeup = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_unlock_irqrestore(&ipa_mhi_client_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_pm_register(&params, &ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_pm_associate_ipa_cons_to_client(ipa_mhi_client_ctx->pm_hdl,
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_pm_set_perf_profile(ipa_mhi_client_ctx->pm_hdl, 1000);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	res = ipa_pm_register(&params, &ipa_mhi_client_ctx->modem_pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_pm_deregister(ipa_mhi_client_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->state = IPA_MHI_STATE_INITIALIZED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->cb_notify = params->notify;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->cb_priv = params->priv;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->rm_cons_state = IPA_MHI_RM_STATE_RELEASED;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	init_completion(&ipa_mhi_client_ctx->rm_prod_granted_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	spin_lock_init(&ipa_mhi_client_ctx->state_lock);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	init_completion(&ipa_mhi_client_ctx->rm_cons_comp);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->msi = params->msi;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->mmio_addr = params->mmio_addr;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->first_ch_idx = params->first_ch_idx;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->first_er_idx = params->first_er_idx;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->qmi_req_id = 0;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->use_ipadma = true;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->assert_bit40 = !!params->assert_bit40;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->test_mode = params->test_mode;
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	ipa_mhi_client_ctx->wq = create_singlethread_workqueue("ipa_mhi_wq");
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	if (!ipa_mhi_client_ctx->wq) {
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	destroy_workqueue(ipa_mhi_client_ctx->wq);
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:				ipa_mhi_client_ctx->state !=
drivers/platform/msm/ipa/ipa_clients/ipa_mhi_client.c:	*flag = ipa_mhi_client_ctx->use_ipadma ? true : false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_init(&rndis_ipa_ctx->state_lock);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net = net;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->tx_filter = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->rx_filter = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->icmp_filter = true;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->rm_enable = true;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->tx_dropped = 0;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->rx_dropped = 0;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->tx_dump_enable = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->rx_dump_enable = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->deaggregation_enable = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->outstanding_high = DEFAULT_OUTSTANDING_HIGH;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->outstanding_low = DEFAULT_OUTSTANDING_LOW;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	atomic_set(&rndis_ipa_ctx->outstanding_pkts, 0);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(rndis_ipa_ctx->device_ethaddr, params->device_ethaddr,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		sizeof(rndis_ipa_ctx->device_ethaddr));
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(rndis_ipa_ctx->host_ethaddr, params->host_ethaddr,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		sizeof(rndis_ipa_ctx->host_ethaddr));
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(&rndis_ipa_ctx->xmit_error_delayed_work,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->error_msec_sleep_time =
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->device_ready_notify = params->device_ready_notify;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(net->dev_addr, rndis_ipa_ctx->device_ethaddr);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->is_vlan_mode)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	RNDIS_IPA_DEBUG("is_vlan_mode %d\n", rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = RNDIS_IPA_INITIALIZED;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->ipa_to_usb_hdl = ipa_to_usb_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->usb_to_ipa_hdl = usb_to_ipa_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->deaggregation_enable = true;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->deaggregation_enable = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->net->mtu,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->deaggregation_enable,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_stop_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_carrier_on(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (!netif_carrier_ok(rndis_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	next_state = rndis_ipa_next_state(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	next_state = rndis_ipa_next_state(rndis_ipa_ctx->state, RNDIS_IPA_OPEN);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		atomic_read(&rndis_ipa_ctx->outstanding_pkts));
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->tx_dump_enable))
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->state != RNDIS_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->tx_dropped++;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (atomic_read(&rndis_ipa_ctx->outstanding_pkts) >=
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:				rndis_ipa_ctx->outstanding_high) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:				rndis_ipa_ctx->outstanding_high);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	atomic_inc(&rndis_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		atomic_read(&rndis_ipa_ctx->outstanding_pkts));
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->state != RNDIS_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_state_string(rndis_ipa_ctx->state));
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.tx_packets++;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.tx_bytes += skb->len;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	atomic_dec(&rndis_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(netif_queue_stopped(rndis_ipa_ctx->net) &&
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		netif_carrier_ok(rndis_ipa_ctx->net) &&
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		atomic_read(&rndis_ipa_ctx->outstanding_pkts) <
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:					(rndis_ipa_ctx->outstanding_low)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:				rndis_ipa_ctx->outstanding_low);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		netif_wake_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	int outstanding = atomic_read(&rndis_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (netif_queue_stopped(rndis_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		netif_start_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->rx_dump_enable))
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->state != RNDIS_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (!rndis_ipa_ctx->deaggregation_enable)
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	skb->dev = rndis_ipa_ctx->net;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	skb->protocol = eth_type_trans(skb, rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->rx_dropped++;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.rx_packets++;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.rx_bytes += packet_len;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	next_state = rndis_ipa_next_state(rndis_ipa_ctx->state, RNDIS_IPA_STOP);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (rndis_ipa_ctx->during_xmit_error) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:			&rndis_ipa_ctx->xmit_error_delayed_work);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->during_xmit_error = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_carrier_off(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_stop_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		atomic_read(&rndis_ipa_ctx->outstanding_pkts);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.tx_dropped += outstanding_dropped_pkts;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	atomic_set(&rndis_ipa_ctx->outstanding_pkts, 0);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	next_state = rndis_ipa_next_state(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	retval = rndis_ipa_deregister_properties(rndis_ipa_ctx->net->name);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	unregister_netdev(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_lock_irqsave(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	next_state = rndis_ipa_next_state(rndis_ipa_ctx->state,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->state = next_state;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	spin_unlock_irqrestore(&rndis_ipa_ctx->state_lock, flags);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	free_netdev(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (rndis_ipa_ctx->device_ready_notify) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->device_ready_notify();
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_start_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_stop_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->net->stats.tx_errors++;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->error_msec_sleep_time + rand_dealy_msec);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->xmit_error_delayed_work, delay_jiffies);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		netif_start_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:			rndis_ipa_ctx->error_msec_sleep_time +
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->during_xmit_error = true;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (unlikely(rndis_ipa_ctx->state != RNDIS_IPA_CONNECTED_AND_UP)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:			rndis_ipa_ctx->state);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->during_xmit_error = false;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	netif_start_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		ipv4_hdr, dst_mac, src_mac, rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		ipv6_hdr, dst_mac, src_mac, rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->eth_ipv4_hdr_hdl = ipv4_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->eth_ipv6_hdr_hdl = ipv6_hdr->hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	ipv4->hdl = rndis_ipa_ctx->eth_ipv4_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	ipv6->hdl = rndis_ipa_ctx->eth_ipv6_hdr_hdl;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (netif_queue_stopped(rndis_ipa_ctx->net)) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		netif_start_queue(rndis_ipa_ctx->net);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	pm_reg.name = rndis_ipa_ctx->net->name;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	result = ipa_pm_register(&pm_reg, &rndis_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	ipa_pm_deactivate_sync(rndis_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	ipa_pm_deregister(rndis_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->pm_hdl = ~0;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		return ipa_pm_activate(rndis_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		ipa_pm_deferred_deactivate(rndis_ipa_ctx->pm_hdl);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (rndis_ipa_ctx->is_vlan_mode)
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	return rndis_ipa_ctx->rx_filter;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (likely(!rndis_ipa_ctx->tx_filter))
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if ((!rndis_ipa_ctx->icmp_filter) && is_icmp)
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	return rndis_ipa_ctx->rm_enable;
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	rndis_ipa_ctx->directory = debugfs_create_dir(DEBUGFS_DIR_NAME, NULL);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	if (!rndis_ipa_ctx->directory) {
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->tx_filter);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->rx_filter);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->icmp_filter);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->rm_enable);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->outstanding_high);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->outstanding_low);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, (u8 *)&rndis_ipa_ctx->state);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->tx_dropped);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory, &rndis_ipa_ctx->rx_dropped);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->tx_dump_enable);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->rx_dump_enable);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->deaggregation_enable);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->error_msec_sleep_time);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->during_xmit_error);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		rndis_ipa_ctx->directory,
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:		&rndis_ipa_ctx->is_vlan_mode);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	debugfs_remove_recursive(rndis_ipa_ctx->directory);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	debugfs_remove_recursive(rndis_ipa_ctx->directory);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	result = ipa_cfg_ep(rndis_ipa_ctx->usb_to_ipa_hdl, &ipa_to_usb_ep_cfg);
drivers/platform/msm/ipa/ipa_clients/rndis_ipa.c:	file->private_data = &rndis_ipa_ctx->outstanding_pkts;
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	result = ipa_rm_dep_graph_add(ipa_rm_ctx->dep_graph, resource);
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	result = ipa_rm_dep_graph_remove(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:						ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:						ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:			  ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:			spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:			spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:		spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:		spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:		result = queue_work(ipa_rm_ctx->ipa_rm_wq,
drivers/platform/msm/ipa/ipa_rm.c:		result = queue_work(ipa_rm_ctx->ipa_rm_wq,
drivers/platform/msm/ipa/ipa_rm.c:		result = queue_work(ipa_rm_ctx->ipa_rm_wq,
drivers/platform/msm/ipa/ipa_rm.c:	ipa_rm_ctx->ipa_rm_wq = create_singlethread_workqueue("ipa_rm_wq");
drivers/platform/msm/ipa/ipa_rm.c:	if (!ipa_rm_ctx->ipa_rm_wq) {
drivers/platform/msm/ipa/ipa_rm.c:	result = ipa_rm_dep_graph_create(&(ipa_rm_ctx->dep_graph));
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_init(&ipa_rm_ctx->ipa_rm_lock);
drivers/platform/msm/ipa/ipa_rm.c:	destroy_workqueue(ipa_rm_ctx->ipa_rm_wq);
drivers/platform/msm/ipa/ipa_rm.c:	spin_lock_irqsave(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:				ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:			sum_bw_prod += ipa_rm_ctx->prof_vote.bw_resources[i];
drivers/platform/msm/ipa/ipa_rm.c:			sum_bw_cons += ipa_rm_ctx->prof_vote.bw_resources[i];
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.curr_volt,
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.curr_bw);
drivers/platform/msm/ipa/ipa_rm.c:	spin_unlock_irqrestore(&ipa_rm_ctx->ipa_rm_lock, flags);
drivers/platform/msm/ipa/ipa_rm.c:	queue_work(ipa_rm_ctx->ipa_rm_wq, &work->work);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_dep_graph_get_resource(ipa_rm_ctx->dep_graph,
drivers/platform/msm/ipa/ipa_rm.c:	old_volt = ipa_rm_ctx->prof_vote.curr_volt;
drivers/platform/msm/ipa/ipa_rm.c:	old_bw = ipa_rm_ctx->prof_vote.curr_bw;
drivers/platform/msm/ipa/ipa_rm.c:	bw_ptr = &ipa_rm_ctx->prof_vote.bw_resources[resource_name];
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.volt[resource_name] =
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.volt[resource_name] = 0;
drivers/platform/msm/ipa/ipa_rm.c:	ipa_rm_ctx->prof_vote.curr_volt = IPA_VOLTAGE_UNSPECIFIED;
drivers/platform/msm/ipa/ipa_rm.c:		if (ipa_rm_ctx->prof_vote.volt[i] >
drivers/platform/msm/ipa/ipa_rm.c:				ipa_rm_ctx->prof_vote.curr_volt) {
drivers/platform/msm/ipa/ipa_rm.c:			ipa_rm_ctx->prof_vote.curr_volt =
drivers/platform/msm/ipa/ipa_rm.c:				ipa_rm_ctx->prof_vote.volt[i];
drivers/platform/msm/ipa/ipa_rm.c:			sum_bw_prod += ipa_rm_ctx->prof_vote.bw_resources[i];
drivers/platform/msm/ipa/ipa_rm.c:			sum_bw_cons += ipa_rm_ctx->prof_vote.bw_resources[i];
drivers/platform/msm/ipa/ipa_rm.c:	ipa_rm_ctx->prof_vote.curr_bw = min(sum_bw_prod, sum_bw_cons);
drivers/platform/msm/ipa/ipa_rm.c:	if (ipa_rm_ctx->prof_vote.curr_volt == old_volt &&
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.curr_bw == old_bw) {
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.curr_volt,
drivers/platform/msm/ipa/ipa_rm.c:		ipa_rm_ctx->prof_vote.curr_bw);
drivers/platform/msm/ipa/ipa_rm.c:	ipa_rm_perf_profile_notify_to_ipa(ipa_rm_ctx->prof_vote.curr_volt,
drivers/platform/msm/ipa/ipa_rm.c:			ipa_rm_ctx->prof_vote.curr_bw);
drivers/platform/msm/ipa/ipa_rm.c:	ipa_rm_dep_graph_delete(ipa_rm_ctx->dep_graph);
drivers/platform/msm/ipa/ipa_rm.c:	destroy_workqueue(ipa_rm_ctx->ipa_rm_wq);
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->pcidev == pcidev)
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_init_vreg(dev, &ctx->vdd, "vdd");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vdd.max_uV = VDD_MAX_UV;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vdd.min_uV = VDD_MIN_UV;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vdd.max_uA = VDD_MAX_UA;
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_init_vreg(dev, &ctx->vddio, "vddio");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vddio.max_uV = VDDIO_MAX_UV;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vddio.min_uV = VDDIO_MIN_UV;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->vddio.max_uA = VDDIO_MAX_UA;
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_release_vreg(dev, &ctx->vdd);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_release_vreg(ctx->dev, &ctx->vdd);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_release_vreg(ctx->dev, &ctx->vddio);
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_enable_vreg(ctx, &ctx->vdd);
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_enable_vreg(ctx, &ctx->vddio);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_disable_vreg(ctx, &ctx->vdd);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->vdd.reg && !ctx->vddio.reg)
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_disable_vreg(ctx, &ctx->vdd);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_disable_vreg(ctx, &ctx->vddio);
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_enable_clk(ctx, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_enable_clk(ctx, &ctx->rf_clk3_pin);
drivers/platform/msm/msm_11ad/msm_11ad.c:		msm_11ad_disable_clk(ctx, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct device *dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_init_clk(dev, &ctx->rf_clk3, "rf_clk3_clk");
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_11ad_init_clk(dev, &ctx->rf_clk3_pin, "rf_clk3_pin_clk");
drivers/platform/msm/msm_11ad/msm_11ad.c:		msm_11ad_release_clk(ctx->dev, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_release_clk(ctx->dev, &ctx->rf_clk3_pin);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_release_clk(ctx->dev, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_disable_clk(ctx, &ctx->rf_clk3_pin);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_11ad_disable_clk(ctx, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:	struct pci_dev *pdev = ctx->pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "PCIE20_CAP_LINKCTRLSTATUS read returns 0x%x\n", val);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_dbg(ctx->dev, "ASPM_L1 is already %s\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "writing PCIE20_CAP_LINKCTRLSTATUS (val 0x%x)\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->gpio_en, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->sleep_clk_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->sleep_clk_en, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_enable_vregs failed :%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_enable_clocks failed :%d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->sleep_clk_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->sleep_clk_en, 1);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->gpio_en, 1);
drivers/platform/msm/msm_11ad/msm_11ad.c:	pcidev = ctx->pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_pcie_shadow_control(ctx->pcidev, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "pci_save_state failed :%d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->pristine_state = pci_store_saved_state(pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_pcie_pm_control(SUSPEND) failed :%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	pcidev = ctx->pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "disable device and save config\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->pristine_state = pci_store_saved_state(pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "moving to D3\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_pcie_pm_control(SUSPEND) failed :%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	pcidev = ctx->pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_pcie_pm_control(RESUME) failed :%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->pristine_state)
drivers/platform/msm/msm_11ad/msm_11ad.c:		pci_load_saved_state(ctx->pcidev, ctx->pristine_state);
drivers/platform/msm/msm_11ad/msm_11ad.c:	pci_restore_state(ctx->pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	msm_pcie_shadow_control(ctx->pcidev, 1);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->l1_enabled_in_enum) {
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	pcidev = ctx->pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_pcie_pm_control(RESUME) failed :%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "restore state and enable device\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	pci_load_saved_state(pcidev, ctx->pristine_state);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "pci_enable_device failed (%d)\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "pci set master\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	int smmu_bypass = !ctx->smmu_s1_en;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->use_smmu)
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_info(ctx->dev, "Initialize SMMU, bypass=%d, fastmap=%d, coherent=%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		 smmu_bypass, ctx->smmu_fast_map, ctx->smmu_coherent);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->mapping = arm_iommu_create_mapping(&platform_bus_type,
drivers/platform/msm/msm_11ad/msm_11ad.c:						ctx->smmu_base, ctx->smmu_size);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (IS_ERR_OR_NULL(ctx->mapping)) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = PTR_ERR(ctx->mapping) ?: -ENODEV;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Failed to create IOMMU mapping (%d)\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = iommu_domain_set_attr(ctx->mapping->domain,
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Set atomic attribute to SMMU failed (%d)\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = iommu_domain_set_attr(ctx->mapping->domain,
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev, "Set bypass attribute to SMMU failed (%d)\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->smmu_coherent) {
drivers/platform/msm/msm_11ad/msm_11ad.c:			arch_setup_dma_ops(&ctx->pcidev->dev, 0, 0, NULL, true);
drivers/platform/msm/msm_11ad/msm_11ad.c:			rc = iommu_domain_set_attr(ctx->mapping->domain,
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->smmu_fast_map) {
drivers/platform/msm/msm_11ad/msm_11ad.c:			rc = iommu_domain_set_attr(ctx->mapping->domain,
drivers/platform/msm/msm_11ad/msm_11ad.c:						   &ctx->smmu_fast_map);
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_err(ctx->dev, "Set fast attribute to SMMU failed (%d)\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = arm_iommu_attach_device(&ctx->pcidev->dev, ctx->mapping);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "arm_iommu_attach_device failed (%d)\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_info(ctx->dev, "attached to IOMMU\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	arm_iommu_release_mapping(ctx->mapping);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->mapping = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->recovery_in_progress) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->rops.fw_recovery && ctx->wil_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_info(ctx->dev, "requesting FW recovery\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:			rc = ctx->rops.fw_recovery(ctx->wil_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->recovery_in_progress = false;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->rops.ramdump && ctx->wil_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		int rc = ctx->rops.ramdump(ctx->wil_handle, ctx->ramdump_addr,
drivers/platform/msm/msm_11ad/msm_11ad.c:					   ctx->ramdump_size);
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev, "ramdump failed : %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->dump_data.version = WIGIG_DUMP_FORMAT_VER;
drivers/platform/msm/msm_11ad/msm_11ad.c:	strlcpy(ctx->dump_data.name, WIGIG_SUBSYS_NAME,
drivers/platform/msm/msm_11ad/msm_11ad.c:		sizeof(ctx->dump_data.name));
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->dump_data.magic = WIGIG_DUMP_MAGIC_VER_V1;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->recovery_in_progress) {
drivers/platform/msm/msm_11ad/msm_11ad.c:	segment.v_address = ctx->ramdump_addr;
drivers/platform/msm/msm_11ad/msm_11ad.c:	segment.size = ctx->ramdump_size;
drivers/platform/msm/msm_11ad/msm_11ad.c:	return do_ramdump(ctx->ramdump_dev, &segment, 1);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->recovery_in_progress)
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->ramdump_dev) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		destroy_ramdump_device(ctx->ramdump_dev);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->ramdump_dev = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	kfree(ctx->ramdump_addr);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->ramdump_addr = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->subsys_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		subsystem_put(ctx->subsys_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->subsys_handle = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->subsys) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		subsys_unregister(ctx->subsys);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->subsys = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.name = "WIGIG";
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.owner = THIS_MODULE;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.shutdown = msm_11ad_ssr_shutdown;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.powerup = msm_11ad_ssr_powerup;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.ramdump = msm_11ad_ssr_ramdump;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.crash_shutdown = msm_11ad_ssr_crash_shutdown;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsysdesc.dev = ctx->dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsys = subsys_register(&ctx->subsysdesc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (IS_ERR(ctx->subsys)) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = PTR_ERR(ctx->subsys);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "subsys_register failed :%d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->ramdump_addr = kmalloc(ctx->ramdump_size, GFP_KERNEL);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->ramdump_addr) {
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->dump_data.addr = virt_to_phys(ctx->ramdump_addr);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->dump_data.len = ctx->ramdump_size;
drivers/platform/msm/msm_11ad/msm_11ad.c:	dump_entry.addr = virt_to_phys(&ctx->dump_data);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Dump table setup failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->ramdump_dev = create_ramdump_device(ctx->subsysdesc.name,
drivers/platform/msm/msm_11ad/msm_11ad.c:						 ctx->subsysdesc.dev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->ramdump_dev) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Create ramdump device failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->use_cpu_boost = true;
drivers/platform/msm/msm_11ad/msm_11ad.c:		cpumask_clear(&ctx->boost_cpu);
drivers/platform/msm/msm_11ad/msm_11ad.c:		cpumask_set_cpu(boost_cpu, &ctx->boost_cpu);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_info(ctx->dev, "CPU boost: will use core %d\n", boost_cpu);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->use_cpu_boost = false;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_info(ctx->dev, "CPU boost disabled, uniform topology\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->dev = dev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	 *	qcom,wigig-en = <&tlmm 94 0>; (ctx->gpio_en)
drivers/platform/msm/msm_11ad/msm_11ad.c:	 *	qcom,sleep-clk-en = <&pm8994_gpios 18 0>; (ctx->sleep_clk_en)
drivers/platform/msm/msm_11ad/msm_11ad.c:	 * cell-index = <1>; (ctx->rc_index)
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->gpio_en = of_get_named_gpio(of_node, gpio_en_name, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en < 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_warn(ctx->dev, "GPIO <%s> not found, enable GPIO not used\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->sleep_clk_en = of_get_named_gpio(of_node, sleep_clk_en_name, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->sleep_clk_en < 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_warn(ctx->dev, "GPIO <%s> not found, sleep clock not used\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Parent PCIE device not found\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = of_property_read_u32(rc_node, "cell-index", &ctx->rc_index);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Parent PCIE device index not found\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->use_smmu = of_property_read_bool(of_node, "qcom,smmu-support");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->keep_radio_on_during_sleep = of_property_read_bool(of_node,
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->bus_scale = msm_bus_cl_get_pdata(pdev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->bus_scale) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Unable to read bus-scaling from DT\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->smmu_s1_en = of_property_read_bool(of_node, "qcom,smmu-s1-en");
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->smmu_s1_en) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_fast_map = of_property_read_bool(
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_coherent = of_property_read_bool(
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_base = SMMU_BASE;
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_size = SMMU_SIZE;
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_base = smmu_mapping[0];
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_size = smmu_mapping[1];
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "smmu_base=0x%x smmu_sise=0x%x\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->smmu_base, ctx->smmu_size);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_init_vregs failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_enable_vregs failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_init_clocks failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_enable_clocks failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = gpio_request(ctx->gpio_en, gpio_en_name);
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev, "failed to request GPIO %d <%s>\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:				ctx->gpio_en, gpio_en_name);
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = gpio_direction_output(ctx->gpio_en, 1);
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev, "failed to set GPIO %d <%s>\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:				ctx->gpio_en, gpio_en_name);
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_pcie_enumerate(ctx->rc_index);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Parent PCIE enumeration failed\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:			if (pci_domain_nr(pcidev->bus) == ctx->rc_index) {
drivers/platform/msm/msm_11ad/msm_11ad.c:				ctx->ramdump_size = wigig_pci_tbl[i].ramdump_sz;
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Wigig device not found\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->pcidev = pcidev;
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "Wigig device %4x:%4x found\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->pcidev->vendor, ctx->pcidev->device);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_pcie_pm_control(RESUME) failed:%d\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:	pci_restore_state(ctx->pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->l1_enabled_in_enum = val & PCI_EXP_LNKCTL_ASPM_L1;
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_dbg(ctx->dev, "L1 is %s in enumeration\n",
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->l1_enabled_in_enum ? "enabled" : "disabled");
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->l1_enabled_in_enum) {
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->sleep_clk_en >= 0) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = gpio_request(ctx->sleep_clk_en, "msm_11ad");
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:				ctx->sleep_clk_en, sleep_clk_en_name);
drivers/platform/msm/msm_11ad/msm_11ad.c:			ctx->sleep_clk_en = -EINVAL;
drivers/platform/msm/msm_11ad/msm_11ad.c:			gpio_direction_output(ctx->sleep_clk_en, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "msm_11ad_ssr_init failed: %d\n", rc);
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_info(ctx->dev, "msm_11ad discovered. %p {\n"
drivers/platform/msm/msm_11ad/msm_11ad.c:		 "}\n", ctx, ctx->gpio_en, ctx->sleep_clk_en, ctx->rc_index,
drivers/platform/msm/msm_11ad/msm_11ad.c:		 ctx->use_smmu, ctx->pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	list_add_tail(&ctx->list, &dev_list);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->gpio_en, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_free(ctx->gpio_en);
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->gpio_en = -EINVAL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	list_del(&ctx->list);
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_info(ctx->dev, "%s: pdev %p pcidev %p\n", __func__, pdev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		 ctx->pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	kfree(ctx->pristine_state);
drivers/platform/msm/msm_11ad/msm_11ad.c:	pci_dev_put(ctx->pcidev);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->gpio_en >= 0) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_direction_output(ctx->gpio_en, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_free(ctx->gpio_en);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->sleep_clk_en >= 0)
drivers/platform/msm/msm_11ad/msm_11ad.c:		gpio_free(ctx->sleep_clk_en);
drivers/platform/msm/msm_11ad/msm_11ad.c:		irq_modify_status(ctx->pcidev->irq, IRQ_NO_BALANCING, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = irq_set_affinity_hint(ctx->pcidev->irq, &ctx->boost_cpu);
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_warn(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		irq_modify_status(ctx->pcidev->irq, 0, IRQ_NO_BALANCING);
drivers/platform/msm/msm_11ad/msm_11ad.c:		desc = irq_to_desc(ctx->pcidev->irq);
drivers/platform/msm/msm_11ad/msm_11ad.c:				  &ctx->boost_cpu))
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_warn(ctx->dev, "failed to set CPU boost affinity\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	irq_modify_status(ctx->pcidev->irq, IRQ_NO_BALANCING, 0);
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = irq_set_affinity_hint(ctx->pcidev->irq, NULL);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_warn(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	for (i = 0; i < ctx->bus_scale->num_usecases; i++) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		usecase = &ctx->bus_scale->usecase[i];
drivers/platform/msm/msm_11ad/msm_11ad.c:	rc = msm_bus_scale_client_update_request(ctx->msm_bus_handle, vote);
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->use_cpu_boost) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		bool was_boosted = ctx->is_cpu_boosted;
drivers/platform/msm/msm_11ad/msm_11ad.c:					dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_dbg(ctx->dev, "CPU boost enabled\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:					dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_dbg(ctx->dev, "CPU boost disabled\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:			ctx->is_cpu_boosted = needs_boost;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->msm_bus_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		msm_bus_scale_unregister_client(ctx->msm_bus_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->msm_bus_handle = 0;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->use_smmu) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		arm_iommu_detach_device(&ctx->pcidev->dev);
drivers/platform/msm/msm_11ad/msm_11ad.c:		arm_iommu_release_mapping(ctx->mapping);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->mapping = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	memset(&ctx->rops, 0, sizeof(ctx->rops));
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->wil_handle = NULL;
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->subsys) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_info(ctx->dev, "SSR requested\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->recovery_in_progress = true;
drivers/platform/msm/msm_11ad/msm_11ad.c:		subsys_set_crash_status(ctx->subsys, CRASH_STATUS_ERR_FATAL);
drivers/platform/msm/msm_11ad/msm_11ad.c:		rc = subsystem_restart_dev(ctx->subsys);
drivers/platform/msm/msm_11ad/msm_11ad.c:			dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:			ctx->recovery_in_progress = false;
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->features &
drivers/platform/msm/msm_11ad/msm_11ad.c:			rc = msm_11ad_enable_clk(ctx, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->l1_enabled_in_enum) {
drivers/platform/msm/msm_11ad/msm_11ad.c:				dev_err(ctx->dev,
drivers/platform/msm/msm_11ad/msm_11ad.c:		if (ctx->features &
drivers/platform/msm/msm_11ad/msm_11ad.c:			msm_11ad_disable_clk(ctx, &ctx->rf_clk3);
drivers/platform/msm/msm_11ad/msm_11ad.c:		 ctx->keep_radio_on_during_sleep ? "allowed" : "not allowed");
drivers/platform/msm/msm_11ad/msm_11ad.c:	capa = (ctx->keep_radio_on_during_sleep ?
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->features = features;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->msm_bus_handle =
drivers/platform/msm/msm_11ad/msm_11ad.c:		msm_bus_scale_register_client(ctx->bus_scale);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (!ctx->msm_bus_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		dev_err(ctx->dev, "Failed msm_bus registration\n");
drivers/platform/msm/msm_11ad/msm_11ad.c:	dev_info(ctx->dev, "msm_bus handle 0x%x\n", ctx->msm_bus_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		msm_bus_scale_unregister_client(ctx->msm_bus_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->msm_bus_handle = 0;
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->rops = *rops;
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->wil_handle = wil_handle;
drivers/platform/msm/msm_11ad/msm_11ad.c:	ctx->subsys_handle = subsystem_get(ctx->subsysdesc.name);
drivers/platform/msm/msm_11ad/msm_11ad.c:	if (ctx->subsys_handle) {
drivers/platform/msm/msm_11ad/msm_11ad.c:		subsystem_put(ctx->subsys_handle);
drivers/platform/msm/msm_11ad/msm_11ad.c:		ctx->subsys_handle = NULL;
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	curr = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel((curr & ~mask) | (val & mask), gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	ch = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(ch, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			if (i >= gsi_ctx->max_ch || i >= GSI_CHAN_MAX) {
drivers/platform/msm/gsi/gsi.c:			ctx = &gsi_ctx->chan[i];
drivers/platform/msm/gsi/gsi.c:			val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			ctx->state = (val &
drivers/platform/msm/gsi/gsi.c:			GSIDBG("ch %u state updated to %u\n", i, ctx->state);
drivers/platform/msm/gsi/gsi.c:			complete(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->ch_dbg[i].cmd_completed++;
drivers/platform/msm/gsi/gsi.c:	ch = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(ch, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			if (i >= gsi_ctx->max_ev || i >= GSI_EVT_RING_MAX) {
drivers/platform/msm/gsi/gsi.c:			ctx = &gsi_ctx->evtr[i];
drivers/platform/msm/gsi/gsi.c:			val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			ctx->state = (val &
drivers/platform/msm/gsi/gsi.c:			GSIDBG("evt %u state updated to %u\n", i, ctx->state);
drivers/platform/msm/gsi/gsi.c:			complete(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:		per_notify.user_data = gsi_ctx->per.user_data;
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->per.notify_cb(&per_notify);
drivers/platform/msm/gsi/gsi.c:		if (log->virt_idx >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:		ch = &gsi_ctx->chan[log->virt_idx];
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:					gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:		if (log->virt_idx >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:		ev = &gsi_ctx->evtr[log->virt_idx];
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:			BUG_ON(log->ee != gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	complete(&gsi_ctx->gen_ee_cmd_compl);
drivers/platform/msm/gsi/gsi.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	notify.user_data = gsi_ctx->per.user_data;
drivers/platform/msm/gsi/gsi.c:		err = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		if (gsi_ctx->per.ver >= GSI_VER_1_2)
drivers/platform/msm/gsi/gsi.c:			gsi_writel(0, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		gsi_writel(clr, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->per.notify_cb(&notify);
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->per.notify_cb(&notify);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	ctx->wp_local += ctx->elem_sz;
drivers/platform/msm/gsi/gsi.c:	if (ctx->wp_local == ctx->end)
drivers/platform/msm/gsi/gsi.c:		ctx->wp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->rp_local += ctx->elem_sz;
drivers/platform/msm/gsi/gsi.c:	if (ctx->rp_local == ctx->end)
drivers/platform/msm/gsi/gsi.c:		ctx->rp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	BUG_ON(addr < ctx->base || addr >= ctx->end);
drivers/platform/msm/gsi/gsi.c:	return (uint32_t)(addr - ctx->base)/ctx->elem_sz;
drivers/platform/msm/gsi/gsi.c:	if (ch_id >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ch_ctx = &gsi_ctx->chan[ch_id];
drivers/platform/msm/gsi/gsi.c:	BUG_ON(ch_ctx->props.prot != GSI_CHAN_PROT_GPI);
drivers/platform/msm/gsi/gsi.c:	while (ch_ctx->ring.rp_local != rp) {
drivers/platform/msm/gsi/gsi.c:		gsi_incr_ring_rp(&ch_ctx->ring);
drivers/platform/msm/gsi/gsi.c:		ch_ctx->stats.completed++;
drivers/platform/msm/gsi/gsi.c:	gsi_incr_ring_rp(&ch_ctx->ring);
drivers/platform/msm/gsi/gsi.c:	ch_ctx->stats.completed++;
drivers/platform/msm/gsi/gsi.c:	ch_ctx->ring.rp = ch_ctx->ring.rp_local;
drivers/platform/msm/gsi/gsi.c:	rp_idx = gsi_find_idx_from_addr(&ch_ctx->ring, rp);
drivers/platform/msm/gsi/gsi.c:	notify->xfer_user_data = ch_ctx->user_data[rp_idx];
drivers/platform/msm/gsi/gsi.c:	notify->chan_user_data = ch_ctx->props.chan_user_data;
drivers/platform/msm/gsi/gsi.c:		if (atomic_read(&ch_ctx->poll_mode)) {
drivers/platform/msm/gsi/gsi.c:		ch_ctx->props.xfer_cb(notify);
drivers/platform/msm/gsi/gsi.c:	idx = gsi_find_idx_from_addr(&ctx->ring, ctx->ring.rp_local);
drivers/platform/msm/gsi/gsi.c:	evt = (struct gsi_xfer_compl_evt *)(ctx->ring.base_va +
drivers/platform/msm/gsi/gsi.c:			idx * ctx->ring.elem_sz);
drivers/platform/msm/gsi/gsi.c:	gsi_incr_ring_rp(&ctx->ring);
drivers/platform/msm/gsi/gsi.c:	gsi_incr_ring_wp(&ctx->ring);
drivers/platform/msm/gsi/gsi.c:	ctx->stats.completed++;
drivers/platform/msm/gsi/gsi.c:	val = ((ctx->ring.wp_local >> 32) &
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_DOORBELL_1_OFFS(ctx->id,
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	val = (ctx->ring.wp_local &
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_DOORBELL_0_OFFS(ctx->id,
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr && ctx->props.dir == GSI_CHAN_DIR_FROM_GSI)
drivers/platform/msm/gsi/gsi.c:		gsi_ring_evt_doorbell(ctx->evtr);
drivers/platform/msm/gsi/gsi.c:	ctx->ring.wp = ctx->ring.wp_local;
drivers/platform/msm/gsi/gsi.c:	val = ((ctx->ring.wp_local >> 32) &
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_k_DOORBELL_1_OFFS(ctx->props.ch_id,
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	val = (ctx->ring.wp_local &
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_k_DOORBELL_0_OFFS(ctx->props.ch_id,
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	ch = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	msk = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(ch & msk, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			if (i >= gsi_ctx->max_ev || i >= GSI_EVT_RING_MAX) {
drivers/platform/msm/gsi/gsi.c:			ctx = &gsi_ctx->evtr[i];
drivers/platform/msm/gsi/gsi.c:			if (ctx->props.intr == GSI_INTR_MSI)
drivers/platform/msm/gsi/gsi.c:			BUG_ON(ctx->props.intf != GSI_EVT_CHTYPE_GPI_EV);
drivers/platform/msm/gsi/gsi.c:			spin_lock_irqsave(&ctx->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:			rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			rp |= ctx->ring.rp & 0xFFFFFFFF00000000;
drivers/platform/msm/gsi/gsi.c:			ctx->ring.rp = rp;
drivers/platform/msm/gsi/gsi.c:			while (ctx->ring.rp_local != rp) {
drivers/platform/msm/gsi/gsi.c:				if (ctx->props.exclusive &&
drivers/platform/msm/gsi/gsi.c:					atomic_read(&ctx->chan->poll_mode)) {
drivers/platform/msm/gsi/gsi.c:			spin_unlock_irqrestore(&ctx->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:	ch = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(ch, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	ch = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(ch, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	notify.user_data = gsi_ctx->per.user_data;
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->per.notify_cb)
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->per.notify_cb(&notify);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	int ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:		type = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->per.req_clk_cb) {
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->per.req_clk_cb(gsi_ctx->per.user_data, &granted);
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.rel_clk_cb(gsi_ctx->per.user_data);
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_0_EE_n_GSI_HW_PARAM_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_2_EE_n_GSI_HW_PARAM_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_3_EE_n_GSI_HW_PARAM_2_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V2_0_EE_n_GSI_HW_PARAM_2_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_0_EE_n_GSI_HW_PARAM_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_2_EE_n_GSI_HW_PARAM_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V1_3_EE_n_GSI_HW_PARAM_2_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_V2_0_EE_n_GSI_HW_PARAM_2_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (!gsi_ctx->per_registered) {
drivers/platform/msm/gsi/gsi.c:	spin_lock_irqsave(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->per.rel_clk_cb(gsi_ctx->per.user_data);
drivers/platform/msm/gsi/gsi.c:	spin_unlock_irqrestore(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->per_registered) {
drivers/platform/msm/gsi/gsi.c:	spin_lock_init(&gsi_ctx->slock);
drivers/platform/msm/gsi/gsi.c:		res = devm_request_irq(gsi_ctx->dev, props->irq,
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->base = devm_ioremap_nocache(gsi_ctx->dev, props->phys_addr,
drivers/platform/msm/gsi/gsi.c:	if (!gsi_ctx->base) {
drivers/platform/msm/gsi/gsi.c:		devm_free_irq(gsi_ctx->dev, props->irq, gsi_ctx);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->per = *props;
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->per_registered = true;
drivers/platform/msm/gsi/gsi.c:	mutex_init(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	atomic_set(&gsi_ctx->num_chan, 0);
drivers/platform/msm/gsi/gsi.c:	atomic_set(&gsi_ctx->num_evt_ring, 0);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->max_ch = gsi_get_max_channels(gsi_ctx->per.ver);
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->max_ch == 0) {
drivers/platform/msm/gsi/gsi.c:		devm_iounmap(gsi_ctx->dev, gsi_ctx->base);
drivers/platform/msm/gsi/gsi.c:		devm_free_irq(gsi_ctx->dev, props->irq, gsi_ctx);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->max_ev = gsi_get_max_event_rings(gsi_ctx->per.ver);
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->max_ev == 0) {
drivers/platform/msm/gsi/gsi.c:		devm_iounmap(gsi_ctx->dev, gsi_ctx->base);
drivers/platform/msm/gsi/gsi.c:		devm_free_irq(gsi_ctx->dev, props->irq, gsi_ctx);
drivers/platform/msm/gsi/gsi.c:	    props->mhi_er_id_limits[0] > (gsi_ctx->max_ev - 1)) {
drivers/platform/msm/gsi/gsi.c:		devm_iounmap(gsi_ctx->dev, gsi_ctx->base);
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->base = NULL;
drivers/platform/msm/gsi/gsi.c:		devm_free_irq(gsi_ctx->dev, props->irq, gsi_ctx);
drivers/platform/msm/gsi/gsi.c:			props->mhi_er_id_limits[0], gsi_ctx->max_ev);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->evt_bmap = ~((1 << gsi_ctx->max_ev) - 1);
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->evt_bmap |=
drivers/platform/msm/gsi/gsi.c:	gsi_writel(props->intr, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_CNTXT_INTSET_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_STATUS_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->enabled = true;
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->per.ver >= GSI_VER_1_2)
drivers/platform/msm/gsi/gsi.c:		gsi_writel(0, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_ERROR_LOG_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (!gsi_ctx->per_registered) {
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->scratch.word0.s.mhi_base_chan_idx =
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->scratch.word0.s.max_usb_pkt_size =
drivers/platform/msm/gsi/gsi.c:	gsi_writel(gsi_ctx->scratch.word0.val,
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_CNTXT_SCRATCH_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (!gsi_ctx->per_registered) {
drivers/platform/msm/gsi/gsi.c:	if (!force && atomic_read(&gsi_ctx->num_chan)) {
drivers/platform/msm/gsi/gsi.c:				atomic_read(&gsi_ctx->num_chan));
drivers/platform/msm/gsi/gsi.c:	if (!force && atomic_read(&gsi_ctx->num_evt_ring)) {
drivers/platform/msm/gsi/gsi.c:				atomic_read(&gsi_ctx->num_evt_ring));
drivers/platform/msm/gsi/gsi.c:	__gsi_config_type_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	__gsi_config_ch_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	__gsi_config_evt_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	__gsi_config_ieob_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	__gsi_config_glob_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	__gsi_config_gen_irq(gsi_ctx->per.ee, ~0, 0);
drivers/platform/msm/gsi/gsi.c:	devm_free_irq(gsi_ctx->dev, gsi_ctx->per.irq, gsi_ctx);
drivers/platform/msm/gsi/gsi.c:	devm_iounmap(gsi_ctx->dev, gsi_ctx->base);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	ctx->base_va = (uintptr_t)props->ring_base_vaddr;
drivers/platform/msm/gsi/gsi.c:	ctx->base = props->ring_base_addr;
drivers/platform/msm/gsi/gsi.c:	ctx->wp = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->rp = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->wp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->rp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->len = props->ring_len;
drivers/platform/msm/gsi/gsi.c:	ctx->elem_sz = props->re_size;
drivers/platform/msm/gsi/gsi.c:	ctx->max_num_elem = ctx->len / ctx->elem_sz - 1;
drivers/platform/msm/gsi/gsi.c:	ctx->end = ctx->base + (ctx->max_num_elem + 1) * ctx->elem_sz;
drivers/platform/msm/gsi/gsi.c:	spin_lock_irqsave(&ctx->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:	memset((void *)ctx->ring.base_va, 0, ctx->ring.len);
drivers/platform/msm/gsi/gsi.c:	ctx->ring.wp_local = ctx->ring.base +
drivers/platform/msm/gsi/gsi.c:		ctx->ring.max_num_elem * ctx->ring.elem_sz;
drivers/platform/msm/gsi/gsi.c:	spin_unlock_irqrestore(&ctx->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:			props->evchid > gsi_ctx->per.mhi_er_id_limits[1] ||
drivers/platform/msm/gsi/gsi.c:			props->evchid < gsi_ctx->per.mhi_er_id_limits[0])) {
drivers/platform/msm/gsi/gsi.c:	ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:		mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		evt_id = find_first_zero_bit(&gsi_ctx->evt_bmap,
drivers/platform/msm/gsi/gsi.c:			mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		set_bit(evt_id, &gsi_ctx->evt_bmap);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_id];
drivers/platform/msm/gsi/gsi.c:	mutex_init(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	init_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	atomic_set(&ctx->chan_ref_cnt, 0);
drivers/platform/msm/gsi/gsi.c:	ctx->props = *props;
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:			clear_bit(evt_id, &gsi_ctx->evt_bmap);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				evt_id, ctx->state);
drivers/platform/msm/gsi/gsi.c:			clear_bit(evt_id, &gsi_ctx->evt_bmap);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	gsi_program_evt_ring_ctx(props, evt_id, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	spin_lock_init(&ctx->ring.slock);
drivers/platform/msm/gsi/gsi.c:	gsi_init_evt_ring(props, &ctx->ring);
drivers/platform/msm/gsi/gsi.c:	ctx->id = evt_id;
drivers/platform/msm/gsi/gsi.c:	atomic_inc(&gsi_ctx->num_evt_ring);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	spin_lock_irqsave(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(1 << evt_id, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		__gsi_config_ieob_irq(gsi_ctx->per.ee, 1 << evt_id, 0);
drivers/platform/msm/gsi/gsi.c:		__gsi_config_ieob_irq(gsi_ctx->per.ee, 1 << ctx->id, ~0);
drivers/platform/msm/gsi/gsi.c:	spin_unlock_irqrestore(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val.data.word1, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val.data.word2, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->evtr[evt_ring_hdl].state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	ctx->scratch = val;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (atomic_read(&ctx->chan_ref_cnt)) {
drivers/platform/msm/gsi/gsi.c:			atomic_read(&ctx->chan_ref_cnt));
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_NOT_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (!ctx->props.evchid_valid) {
drivers/platform/msm/gsi/gsi.c:		mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		clear_bit(evt_ring_hdl, &gsi_ctx->evt_bmap);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	atomic_dec(&gsi_ctx->num_evt_ring);
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->evtr[evt_ring_hdl].state);
drivers/platform/msm/gsi/gsi.c:	*db_addr_wp_lsb = gsi_ctx->per.phys_addr +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_EV_CH_k_DOORBELL_0_OFFS(evt_ring_hdl, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	*db_addr_wp_msb = gsi_ctx->per.phys_addr +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_EV_CH_k_DOORBELL_1_OFFS(evt_ring_hdl, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->evtr[evt_ring_hdl].state);
drivers/platform/msm/gsi/gsi.c:	ctx->ring.wp_local = value;
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				ctx->state);
drivers/platform/msm/gsi/gsi.c:	gsi_program_evt_ring_ctx(&ctx->props, evt_ring_hdl, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	gsi_init_evt_ring(&ctx->props, &ctx->ring);
drivers/platform/msm/gsi/gsi.c:	__gsi_write_evt_ring_scratch(evt_ring_hdl, ctx->scratch);
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.intf == GSI_EVT_CHTYPE_GPI_EV)
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_EVT_RING_STATE_NOT_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	*props = ctx->props;
drivers/platform/msm/gsi/gsi.c:	*scr = ctx->scratch;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (evt_ring_hdl >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->evtr[evt_ring_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_EVT_RING_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.exclusive != props->exclusive) {
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	ctx->props = *props;
drivers/platform/msm/gsi/gsi.c:		ctx->scratch = *scr;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	ctx->base_va = (uintptr_t)props->ring_base_vaddr;
drivers/platform/msm/gsi/gsi.c:	ctx->base = props->ring_base_addr;
drivers/platform/msm/gsi/gsi.c:	ctx->wp = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->rp = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->wp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->rp_local = ctx->base;
drivers/platform/msm/gsi/gsi.c:	ctx->len = props->ring_len;
drivers/platform/msm/gsi/gsi.c:	ctx->elem_sz = props->re_size;
drivers/platform/msm/gsi/gsi.c:	ctx->max_num_elem = ctx->len / ctx->elem_sz - 1;
drivers/platform/msm/gsi/gsi.c:	ctx->end = ctx->base + (ctx->max_num_elem + 1) *
drivers/platform/msm/gsi/gsi.c:		ctx->elem_sz;
drivers/platform/msm/gsi/gsi.c:	if (props->ch_id >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:			&gsi_ctx->evtr[props->evt_ring_hdl].chan_ref_cnt) &&
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->evtr[props->evt_ring_hdl].props.exclusive) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[props->ch_id];
drivers/platform/msm/gsi/gsi.c:	if (ctx->allocated) {
drivers/platform/msm/gsi/gsi.c:	user_data = devm_kzalloc(gsi_ctx->dev,
drivers/platform/msm/gsi/gsi.c:	mutex_init(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	init_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	atomic_set(&ctx->poll_mode, GSI_CHAN_MODE_CALLBACK);
drivers/platform/msm/gsi/gsi.c:	ctx->props = *props;
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[props->ch_id].ch_allocate++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		devm_kfree(gsi_ctx->dev, user_data);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				props->ch_id, ctx->state);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		devm_kfree(gsi_ctx->dev, user_data);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:		ctx->evtr = &gsi_ctx->evtr[erindex];
drivers/platform/msm/gsi/gsi.c:		atomic_inc(&ctx->evtr->chan_ref_cnt);
drivers/platform/msm/gsi/gsi.c:		if (ctx->evtr->props.exclusive)
drivers/platform/msm/gsi/gsi.c:			ctx->evtr->chan = ctx;
drivers/platform/msm/gsi/gsi.c:	gsi_program_chan_ctx(props, gsi_ctx->per.ee, erindex);
drivers/platform/msm/gsi/gsi.c:	spin_lock_init(&ctx->ring.slock);
drivers/platform/msm/gsi/gsi.c:	gsi_init_chan_ring(props, &ctx->ring);
drivers/platform/msm/gsi/gsi.c:		ctx->props.max_re_expected = ctx->ring.max_num_elem;
drivers/platform/msm/gsi/gsi.c:	ctx->user_data = user_data;
drivers/platform/msm/gsi/gsi.c:	ctx->allocated = true;
drivers/platform/msm/gsi/gsi.c:	ctx->stats.dp.last_timestamp = jiffies_to_msecs(jiffies);
drivers/platform/msm/gsi/gsi.c:	atomic_inc(&gsi_ctx->num_chan);
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val.data.word1, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val.data.word2, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val.data.word3, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	reg = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_writel(reg, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->chan[chan_hdl].state != GSI_CHAN_STATE_ALLOCATED &&
drivers/platform/msm/gsi/gsi.c:		gsi_ctx->chan[chan_hdl].state != GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->chan[chan_hdl].state);
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	ctx->scratch = val;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->chan[chan_hdl].state == GSI_CHAN_STATE_NOT_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				gsi_ctx->chan[chan_hdl].state);
drivers/platform/msm/gsi/gsi.c:	*db_addr_wp_lsb = gsi_ctx->per.phys_addr +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_DOORBELL_0_OFFS(chan_hdl, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	*db_addr_wp_msb = gsi_ctx->per.phys_addr +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_DOORBELL_1_OFFS(chan_hdl, gsi_ctx->per.ee);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_ALLOCATED &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOP_IN_PROC &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[chan_hdl].ch_start++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STARTED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("chan=%lu unexpected state=%u\n", chan_hdl, ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STARTED &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOP_IN_PROC &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_ERROR) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[chan_hdl].ch_stop++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl,
drivers/platform/msm/gsi/gsi.c:		val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:		ctx->state = (val &
drivers/platform/msm/gsi/gsi.c:		if (ctx->state == GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STOPPED &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOP_IN_PROC) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("chan=%lu unexpected state=%u\n", chan_hdl, ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_CHAN_STATE_STOP_IN_PROC) {
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STARTED &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOP_IN_PROC) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[chan_hdl].ch_db_stop++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl,
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STOPPED &&
drivers/platform/msm/gsi/gsi.c:		ctx->state != GSI_CHAN_STATE_STOP_IN_PROC) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("chan=%lu unexpected state=%u\n", chan_hdl, ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_CHAN_STATE_STOP_IN_PROC) {
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STOPPED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[chan_hdl].ch_reset++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.dir == GSI_CHAN_DIR_FROM_GSI && !reset_done) {
drivers/platform/msm/gsi/gsi.c:	gsi_program_chan_ctx(&ctx->props, gsi_ctx->per.ee,
drivers/platform/msm/gsi/gsi.c:			ctx->evtr ? ctx->evtr->id : GSI_NO_EVT_ERINDEX);
drivers/platform/msm/gsi/gsi.c:	gsi_init_chan_ring(&ctx->props, &ctx->ring);
drivers/platform/msm/gsi/gsi.c:	__gsi_write_channel_scratch(chan_hdl, ctx->scratch);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&ctx->compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ch_dbg[chan_hdl].ch_de_alloc++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&ctx->compl, GSI_CMD_TIMEOUT);
drivers/platform/msm/gsi/gsi.c:		mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_NOT_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:				ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	devm_kfree(gsi_ctx->dev, ctx->user_data);
drivers/platform/msm/gsi/gsi.c:	ctx->allocated = false;
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr)
drivers/platform/msm/gsi/gsi.c:		atomic_dec(&ctx->evtr->chan_ref_cnt);
drivers/platform/msm/gsi/gsi.c:	atomic_dec(&gsi_ctx->num_chan);
drivers/platform/msm/gsi/gsi.c:		elapsed = now - ctx->stats.dp.last_timestamp;
drivers/platform/msm/gsi/gsi.c:		if (ctx->stats.dp.empty_time < elapsed)
drivers/platform/msm/gsi/gsi.c:			ctx->stats.dp.empty_time = elapsed;
drivers/platform/msm/gsi/gsi.c:	if (used <= ctx->props.max_re_expected / 3)
drivers/platform/msm/gsi/gsi.c:		++ctx->stats.dp.ch_below_lo;
drivers/platform/msm/gsi/gsi.c:	else if (used <= 2 * ctx->props.max_re_expected / 3)
drivers/platform/msm/gsi/gsi.c:		++ctx->stats.dp.ch_below_hi;
drivers/platform/msm/gsi/gsi.c:		++ctx->stats.dp.ch_above_hi;
drivers/platform/msm/gsi/gsi.c:	ctx->stats.dp.last_timestamp = now;
drivers/platform/msm/gsi/gsi.c:	int ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:	if (!ctx->evtr) {
drivers/platform/msm/gsi/gsi.c:		rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_GSI_CH_k_CNTXT_4_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi.c:		rp |= ctx->ring.rp & 0xFFFFFFFF00000000;
drivers/platform/msm/gsi/gsi.c:		ctx->ring.rp = rp;
drivers/platform/msm/gsi/gsi.c:		rp = ctx->ring.rp_local;
drivers/platform/msm/gsi/gsi.c:	start = gsi_find_idx_from_addr(&ctx->ring, rp);
drivers/platform/msm/gsi/gsi.c:	end = gsi_find_idx_from_addr(&ctx->ring, ctx->ring.wp_local);
drivers/platform/msm/gsi/gsi.c:		used = ctx->ring.max_num_elem + 1 - (start - end);
drivers/platform/msm/gsi/gsi.c:	*num_free_re = ctx->ring.max_num_elem - used;
drivers/platform/msm/gsi/gsi.c:	ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch || !info) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr) {
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->evtr->ring.slock;
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->ring.slock;
drivers/platform/msm/gsi/gsi.c:	rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_4_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi.c:	rp |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_5_OFFS(ctx->props.ch_id, ee))) << 32;
drivers/platform/msm/gsi/gsi.c:	ctx->ring.rp = rp;
drivers/platform/msm/gsi/gsi.c:	wp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_6_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi.c:	wp |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_7_OFFS(ctx->props.ch_id, ee))) << 32;
drivers/platform/msm/gsi/gsi.c:	ctx->ring.wp = wp;
drivers/platform/msm/gsi/gsi.c:		rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_CNTXT_4_OFFS(ctx->evtr->id, ee));
drivers/platform/msm/gsi/gsi.c:		rp |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_CNTXT_5_OFFS(ctx->evtr->id, ee)))
drivers/platform/msm/gsi/gsi.c:		wp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_CNTXT_6_OFFS(ctx->evtr->id, ee));
drivers/platform/msm/gsi/gsi.c:		wp |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_CNTXT_7_OFFS(ctx->evtr->id, ee)))
drivers/platform/msm/gsi/gsi.c:	ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch || !is_empty) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.prot != GSI_CHAN_PROT_GPI) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("op not supported for protocol %u\n", ctx->props.prot);
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr)
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->evtr->ring.slock;
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->ring.slock;
drivers/platform/msm/gsi/gsi.c:	rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_4_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi.c:	rp |= ctx->ring.rp & 0xFFFFFFFF00000000;
drivers/platform/msm/gsi/gsi.c:	ctx->ring.rp = rp;
drivers/platform/msm/gsi/gsi.c:	wp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_CH_k_CNTXT_6_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi.c:	wp |= ctx->ring.wp & 0xFFFFFFFF00000000;
drivers/platform/msm/gsi/gsi.c:	ctx->ring.wp = wp;
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.dir == GSI_CHAN_DIR_FROM_GSI)
drivers/platform/msm/gsi/gsi.c:		*is_empty = (ctx->ring.rp_local == rp) ? true : false;
drivers/platform/msm/gsi/gsi.c:			chan_hdl, rp, wp, ctx->ring.rp_local);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch || !num_xfers || !xfer) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.prot != GSI_CHAN_PROT_GPI) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("op not supported for protocol %u\n", ctx->props.prot);
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr)
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->evtr->ring.slock;
drivers/platform/msm/gsi/gsi.c:		slock = &ctx->ring.slock;
drivers/platform/msm/gsi/gsi.c:	wp_rollback = ctx->ring.wp_local;
drivers/platform/msm/gsi/gsi.c:		idx = gsi_find_idx_from_addr(&ctx->ring, ctx->ring.wp_local);
drivers/platform/msm/gsi/gsi.c:		tre_ptr = (struct gsi_tre *)(ctx->ring.base_va +
drivers/platform/msm/gsi/gsi.c:				idx * ctx->ring.elem_sz);
drivers/platform/msm/gsi/gsi.c:		ctx->user_data[idx] = xfer[i].xfer_user_data;
drivers/platform/msm/gsi/gsi.c:		gsi_incr_ring_wp(&ctx->ring);
drivers/platform/msm/gsi/gsi.c:		ctx->ring.wp_local = wp_rollback;
drivers/platform/msm/gsi/gsi.c:	ctx->stats.queued += num_xfers;
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.prot != GSI_CHAN_PROT_GPI) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("op not supported for protocol %u\n", ctx->props.prot);
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_STARTED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->ring.wp == ctx->ring.wp_local)
drivers/platform/msm/gsi/gsi.c:	ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch || !notify) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.prot != GSI_CHAN_PROT_GPI) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("op not supported for protocol %u\n", ctx->props.prot);
drivers/platform/msm/gsi/gsi.c:	if (!ctx->evtr) {
drivers/platform/msm/gsi/gsi.c:	spin_lock_irqsave(&ctx->evtr->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr->ring.rp == ctx->evtr->ring.rp_local) {
drivers/platform/msm/gsi/gsi.c:		rp = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_EV_CH_k_CNTXT_4_OFFS(ctx->evtr->id, ee));
drivers/platform/msm/gsi/gsi.c:		rp |= ctx->ring.rp & 0xFFFFFFFF00000000;
drivers/platform/msm/gsi/gsi.c:		ctx->evtr->ring.rp = rp;
drivers/platform/msm/gsi/gsi.c:	if (ctx->evtr->ring.rp == ctx->evtr->ring.rp_local) {
drivers/platform/msm/gsi/gsi.c:		spin_unlock_irqrestore(&ctx->evtr->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:		ctx->stats.poll_empty++;
drivers/platform/msm/gsi/gsi.c:	gsi_process_evt_re(ctx->evtr, notify, false);
drivers/platform/msm/gsi/gsi.c:	spin_unlock_irqrestore(&ctx->evtr->ring.slock, flags);
drivers/platform/msm/gsi/gsi.c:	ctx->stats.poll_ok++;
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.prot != GSI_CHAN_PROT_GPI) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("op not supported for protocol %u\n", ctx->props.prot);
drivers/platform/msm/gsi/gsi.c:	if (!ctx->evtr || !ctx->evtr->props.exclusive) {
drivers/platform/msm/gsi/gsi.c:	if (atomic_read(&ctx->poll_mode))
drivers/platform/msm/gsi/gsi.c:	spin_lock_irqsave(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:		__gsi_config_ieob_irq(gsi_ctx->per.ee, 1 << ctx->evtr->id, 0);
drivers/platform/msm/gsi/gsi.c:		atomic_set(&ctx->poll_mode, mode);
drivers/platform/msm/gsi/gsi.c:		ctx->stats.callback_to_poll++;
drivers/platform/msm/gsi/gsi.c:		atomic_set(&ctx->poll_mode, mode);
drivers/platform/msm/gsi/gsi.c:		__gsi_config_ieob_irq(gsi_ctx->per.ee, 1 << ctx->evtr->id, ~0);
drivers/platform/msm/gsi/gsi.c:		ctx->stats.poll_to_callback++;
drivers/platform/msm/gsi/gsi.c:	spin_unlock_irqrestore(&gsi_ctx->slock, flags);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state == GSI_CHAN_STATE_NOT_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	*props = ctx->props;
drivers/platform/msm/gsi/gsi.c:	*scr = ctx->scratch;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_hdl >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi.c:	ctx = &gsi_ctx->chan[chan_hdl];
drivers/platform/msm/gsi/gsi.c:	if (ctx->state != GSI_CHAN_STATE_ALLOCATED) {
drivers/platform/msm/gsi/gsi.c:		GSIERR("bad state %d\n", ctx->state);
drivers/platform/msm/gsi/gsi.c:	if (ctx->props.ch_id != props->ch_id ||
drivers/platform/msm/gsi/gsi.c:		ctx->props.evt_ring_hdl != props->evt_ring_hdl) {
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	ctx->props = *props;
drivers/platform/msm/gsi/gsi.c:		ctx->scratch = *scr;
drivers/platform/msm/gsi/gsi.c:	gsi_program_chan_ctx(&ctx->props, gsi_ctx->per.ee,
drivers/platform/msm/gsi/gsi.c:			ctx->evtr ? ctx->evtr->id : GSI_NO_EVT_ERINDEX);
drivers/platform/msm/gsi/gsi.c:	gsi_init_chan_ring(&ctx->props, &ctx->ring);
drivers/platform/msm/gsi/gsi.c:	__gsi_write_channel_scratch(chan_hdl, ctx->scratch);
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	if (chan_idx >= gsi_ctx->max_ch || !code) {
drivers/platform/msm/gsi/gsi.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	reinit_completion(&gsi_ctx->gen_ee_cmd_compl);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->scratch.word0.val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_CNTXT_SCRATCH_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->scratch.word0.s.generic_ee_cmd_return_code = 0;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(gsi_ctx->scratch.word0.val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:			GSI_EE_n_CNTXT_SCRATCH_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->gen_ee_cmd_dbg.halt_channel++;
drivers/platform/msm/gsi/gsi.c:	gsi_writel(val, gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_GSI_EE_GENERIC_CMD_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	res = wait_for_completion_timeout(&gsi_ctx->gen_ee_cmd_compl,
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->scratch.word0.val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi.c:		GSI_EE_n_CNTXT_SCRATCH_0_OFFS(gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->scratch.word0.s.generic_ee_cmd_return_code ==
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->scratch.word0.s.generic_ee_cmd_return_code == 0) {
drivers/platform/msm/gsi/gsi.c:	*code = gsi_ctx->scratch.word0.s.generic_ee_cmd_return_code;
drivers/platform/msm/gsi/gsi.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->ipc_logbuf = ipc_log_context_create(GSI_IPC_LOG_PAGES,
drivers/platform/msm/gsi/gsi.c:	if (gsi_ctx->ipc_logbuf == NULL)
drivers/platform/msm/gsi/gsi.c:	gsi_ctx->dev = dev;
drivers/platform/msm/gsi/gsi.c:	init_completion(&gsi_ctx->gen_ee_cmd_compl);
drivers/platform/msm/gsi/gsi.h:		dev_dbg(gsi_ctx->dev, "%s:%d " fmt, __func__, __LINE__, \
drivers/platform/msm/gsi/gsi.h:			GSI_IPC_LOGGING(gsi_ctx->ipc_logbuf, \
drivers/platform/msm/gsi/gsi.h:			GSI_IPC_LOGGING(gsi_ctx->ipc_logbuf_low, \
drivers/platform/msm/gsi/gsi.h:		dev_dbg(gsi_ctx->dev, "%s:%d " fmt, __func__, __LINE__, \
drivers/platform/msm/gsi/gsi.h:			GSI_IPC_LOGGING(gsi_ctx->ipc_logbuf_low, \
drivers/platform/msm/gsi/gsi.h:		dev_err(gsi_ctx->dev, "%s:%d " fmt, __func__, __LINE__, \
drivers/platform/msm/gsi/gsi.h:			GSI_IPC_LOGGING(gsi_ctx->ipc_logbuf, \
drivers/platform/msm/gsi/gsi.h:			GSI_IPC_LOGGING(gsi_ctx->ipc_logbuf_low, \
drivers/platform/msm/gsi/gsi_dbg.c:	if (arg1 >= gsi_ctx->max_ev) {
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_0_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_1_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_2_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_3_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_4_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_5_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_6_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_7_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_8_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_9_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_10_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_11_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_12_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_CNTXT_13_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_SCRATCH_0_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_EV_CH_k_SCRATCH_1_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:		ctx = &gsi_ctx->evtr[arg1];
drivers/platform/msm/gsi/gsi_dbg.c:		if (ctx->props.ring_base_vaddr) {
drivers/platform/msm/gsi/gsi_dbg.c:			for (i = 0; i < ctx->props.ring_len / 16; i++)
drivers/platform/msm/gsi/gsi_dbg.c:				arg1, ctx->props.ring_base_addr + i * 16,
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:	if (arg1 >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_0_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_1_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_2_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_3_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_4_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_5_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_6_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_7_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:			gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_QOS_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_SCRATCH_0_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_SCRATCH_1_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_SCRATCH_2_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:	val = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_SCRATCH_3_OFFS(arg1, gsi_ctx->per.ee));
drivers/platform/msm/gsi/gsi_dbg.c:		ctx = &gsi_ctx->chan[arg1];
drivers/platform/msm/gsi/gsi_dbg.c:		if (ctx->props.ring_base_vaddr) {
drivers/platform/msm/gsi/gsi_dbg.c:			for (i = 0; i < ctx->props.ring_len / 16; i++)
drivers/platform/msm/gsi/gsi_dbg.c:				arg1, ctx->props.ring_base_addr + i * 16,
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:				*(u32 *)((u8 *)ctx->props.ring_base_vaddr +
drivers/platform/msm/gsi/gsi_dbg.c:	if (!ctx->allocated)
drivers/platform/msm/gsi/gsi_dbg.c:	PRT_STAT("CH%2d:\n", ctx->props.ch_id);
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.queued,
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.completed);
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.callback_to_poll,
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.poll_to_callback);
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.invalid_tre_error);
drivers/platform/msm/gsi/gsi_dbg.c:		ctx->stats.poll_ok, ctx->stats.poll_empty);
drivers/platform/msm/gsi/gsi_dbg.c:	if (ctx->evtr)
drivers/platform/msm/gsi/gsi_dbg.c:			ctx->evtr->stats.completed);
drivers/platform/msm/gsi/gsi_dbg.c:	PRT_STAT("ch_below_lo=%lu\n", ctx->stats.dp.ch_below_lo);
drivers/platform/msm/gsi/gsi_dbg.c:	PRT_STAT("ch_below_hi=%lu\n", ctx->stats.dp.ch_below_hi);
drivers/platform/msm/gsi/gsi_dbg.c:	PRT_STAT("ch_above_hi=%lu\n", ctx->stats.dp.ch_above_hi);
drivers/platform/msm/gsi/gsi_dbg.c:	PRT_STAT("time_empty=%lums\n", ctx->stats.dp.empty_time);
drivers/platform/msm/gsi/gsi_dbg.c:		max = gsi_ctx->max_ch;
drivers/platform/msm/gsi/gsi_dbg.c:	} else if (ch_id < 0 || ch_id >= gsi_ctx->max_ch ||
drivers/platform/msm/gsi/gsi_dbg.c:		   !gsi_ctx->chan[ch_id].allocated) {
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_dump_ch_stats(&gsi_ctx->chan[ch_id]);
drivers/platform/msm/gsi/gsi_dbg.c:	gsi_ctx->dp_stat_wq =
drivers/platform/msm/gsi/gsi_dbg.c:	if (!gsi_ctx->dp_stat_wq) {
drivers/platform/msm/gsi/gsi_dbg.c:	flush_workqueue(gsi_ctx->dp_stat_wq);
drivers/platform/msm/gsi/gsi_dbg.c:	destroy_workqueue(gsi_ctx->dp_stat_wq);
drivers/platform/msm/gsi/gsi_dbg.c:	gsi_ctx->dp_stat_wq = NULL;
drivers/platform/msm/gsi/gsi_dbg.c:	if (ch_id < 0 || ch_id >= gsi_ctx->max_ch ||
drivers/platform/msm/gsi/gsi_dbg.c:	    !gsi_ctx->chan[ch_id].allocated) {
drivers/platform/msm/gsi/gsi_dbg.c:	if (gsi_ctx->chan[ch_id].enable_dp_stats == enable) {
drivers/platform/msm/gsi/gsi_dbg.c:	gsi_ctx->chan[ch_id].enable_dp_stats = enable;
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->num_ch_dp_stats++;
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->num_ch_dp_stats--;
drivers/platform/msm/gsi/gsi_dbg.c:		if (gsi_ctx->num_ch_dp_stats == 1) {
drivers/platform/msm/gsi/gsi_dbg.c:		queue_delayed_work(gsi_ctx->dp_stat_wq,
drivers/platform/msm/gsi/gsi_dbg.c:	} else if (!enable && gsi_ctx->num_ch_dp_stats == 0) {
drivers/platform/msm/gsi/gsi_dbg.c:		if (ch_id >= gsi_ctx->max_ch)
drivers/platform/msm/gsi/gsi_dbg.c:			gsi_ctx->chan[ch_id].props.max_re_expected);
drivers/platform/msm/gsi/gsi_dbg.c:	if (ch_id >= gsi_ctx->max_ch) {
drivers/platform/msm/gsi/gsi_dbg.c:	gsi_ctx->chan[ch_id].props.max_re_expected = max_elem;
drivers/platform/msm/gsi/gsi_dbg.c:	for (ch_id = 0; ch_id < gsi_ctx->max_ch; ch_id++) {
drivers/platform/msm/gsi/gsi_dbg.c:		if (gsi_ctx->chan[ch_id].print_dp_stats)
drivers/platform/msm/gsi/gsi_dbg.c:			gsi_dump_ch_stats(&gsi_ctx->chan[ch_id]);
drivers/platform/msm/gsi/gsi_dbg.c:	queue_delayed_work(gsi_ctx->dp_stat_wq, &gsi_print_dp_stats_work,
drivers/platform/msm/gsi/gsi_dbg.c:	int ee = gsi_ctx->per.ee;
drivers/platform/msm/gsi/gsi_dbg.c:	rp_hw = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_4_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi_dbg.c:	rp_hw |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_5_OFFS(ctx->props.ch_id, ee)))
drivers/platform/msm/gsi/gsi_dbg.c:	wp_hw = gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_6_OFFS(ctx->props.ch_id, ee));
drivers/platform/msm/gsi/gsi_dbg.c:	wp_hw |= ((uint64_t)gsi_readl(gsi_ctx->base +
drivers/platform/msm/gsi/gsi_dbg.c:		GSI_EE_n_GSI_CH_k_CNTXT_7_OFFS(ctx->props.ch_id, ee)))
drivers/platform/msm/gsi/gsi_dbg.c:	start_hw = gsi_find_idx_from_addr(&ctx->ring, rp_hw);
drivers/platform/msm/gsi/gsi_dbg.c:	end_hw = gsi_find_idx_from_addr(&ctx->ring, wp_hw);
drivers/platform/msm/gsi/gsi_dbg.c:		used_hw = ctx->ring.max_num_elem + 1 - (start_hw - end_hw);
drivers/platform/msm/gsi/gsi_dbg.c:	TDBG("ch %d used %d\n", ctx->props.ch_id, used_hw);
drivers/platform/msm/gsi/gsi_dbg.c:	for (ch_id = 0; ch_id < gsi_ctx->max_ch; ch_id++) {
drivers/platform/msm/gsi/gsi_dbg.c:		if (gsi_ctx->chan[ch_id].allocated &&
drivers/platform/msm/gsi/gsi_dbg.c:		    gsi_ctx->chan[ch_id].enable_dp_stats)
drivers/platform/msm/gsi/gsi_dbg.c:			gsi_dbg_update_ch_dp_stats(&gsi_ctx->chan[ch_id]);
drivers/platform/msm/gsi/gsi_dbg.c:	queue_delayed_work(gsi_ctx->dp_stat_wq, &gsi_update_dp_stats_work,
drivers/platform/msm/gsi/gsi_dbg.c:		max = gsi_ctx->max_ch;
drivers/platform/msm/gsi/gsi_dbg.c:	} else if (ch_id < 0 || ch_id >= gsi_ctx->max_ch ||
drivers/platform/msm/gsi/gsi_dbg.c:		   !gsi_ctx->chan[ch_id].allocated) {
drivers/platform/msm/gsi/gsi_dbg.c:		memset(&gsi_ctx->chan[ch_id].stats, 0,
drivers/platform/msm/gsi/gsi_dbg.c:			sizeof(gsi_ctx->chan[ch_id].stats));
drivers/platform/msm/gsi/gsi_dbg.c:	if (ch_id < 0 || ch_id >= gsi_ctx->max_ch ||
drivers/platform/msm/gsi/gsi_dbg.c:	    !gsi_ctx->chan[ch_id].allocated) {
drivers/platform/msm/gsi/gsi_dbg.c:	if (gsi_ctx->chan[ch_id].print_dp_stats == enable) {
drivers/platform/msm/gsi/gsi_dbg.c:	gsi_ctx->chan[ch_id].print_dp_stats = enable;
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->num_ch_dp_stats++;
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->num_ch_dp_stats--;
drivers/platform/msm/gsi/gsi_dbg.c:		if (gsi_ctx->num_ch_dp_stats == 1) {
drivers/platform/msm/gsi/gsi_dbg.c:		queue_delayed_work(gsi_ctx->dp_stat_wq,
drivers/platform/msm/gsi/gsi_dbg.c:	} else if (!enable && gsi_ctx->num_ch_dp_stats == 0) {
drivers/platform/msm/gsi/gsi_dbg.c:	mutex_lock(&gsi_ctx->mlock);
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->ipc_logbuf_low = gsi_ipc_logbuf_low;
drivers/platform/msm/gsi/gsi_dbg.c:		gsi_ctx->ipc_logbuf_low = NULL;
drivers/platform/msm/gsi/gsi_dbg.c:	mutex_unlock(&gsi_ctx->mlock);
drivers/firewire/core-iso.c:	ctx->card = card;
drivers/firewire/core-iso.c:	ctx->type = type;
drivers/firewire/core-iso.c:	ctx->channel = channel;
drivers/firewire/core-iso.c:	ctx->speed = speed;
drivers/firewire/core-iso.c:	ctx->header_size = header_size;
drivers/firewire/core-iso.c:	ctx->callback.sc = callback;
drivers/firewire/core-iso.c:	ctx->callback_data = callback_data;
drivers/firewire/core-iso.c:	ctx->card->driver->free_iso_context(ctx);
drivers/firewire/core-iso.c:	return ctx->card->driver->start_iso(ctx, cycle, sync, tags);
drivers/firewire/core-iso.c:	return ctx->card->driver->set_iso_channels(ctx, channels);
drivers/firewire/core-iso.c:	return ctx->card->driver->queue_iso(ctx, packet, buffer, payload);
drivers/firewire/core-iso.c:	ctx->card->driver->flush_queue_iso(ctx);
drivers/firewire/core-iso.c:	return ctx->card->driver->flush_iso_completions(ctx);
drivers/firewire/core-iso.c:	return ctx->card->driver->stop_iso(ctx);
drivers/firewire/core-cdev.c:	if (ctx->type == FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL && payload & 3)
drivers/firewire/core-cdev.c:		switch (ctx->type) {
drivers/firewire/core-cdev.c:			    u.packet.header_length % ctx->header_size != 0)
drivers/firewire/core-cdev.c:		if (u.packet.skip && ctx->type == FW_ISO_CONTEXT_TRANSMIT &&
drivers/firewire/ohci.c:	return page_private(ctx->pages[i]);
drivers/firewire/ohci.c:	d = &ctx->descriptors[index];
drivers/firewire/ohci.c:	d = &ctx->descriptors[ctx->last_buffer_index];
drivers/firewire/ohci.c:	ctx->last_buffer_index = index;
drivers/firewire/ohci.c:	reg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);
drivers/firewire/ohci.c:	vunmap(ctx->buffer);
drivers/firewire/ohci.c:		if (ctx->pages[i]) {
drivers/firewire/ohci.c:			dma_unmap_page(ctx->ohci->card.device,
drivers/firewire/ohci.c:			__free_page(ctx->pages[i]);
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->ohci;
drivers/firewire/ohci.c:	if (reg_read(ohci, CONTROL_CLEAR(ctx->regs)) & CONTEXT_RUN) {
drivers/firewire/ohci.c:		reg_write(ohci, CONTROL_CLEAR(ctx->regs), CONTEXT_RUN);
drivers/firewire/ohci.c:	return ar_next_buffer_index(ctx->last_buffer_index);
drivers/firewire/ohci.c:	unsigned int i, next_i, last = ctx->last_buffer_index;
drivers/firewire/ohci.c:	res_count = ACCESS_ONCE(ctx->descriptors[i].res_count);
drivers/firewire/ohci.c:				ctx->descriptors[next_i].res_count);
drivers/firewire/ohci.c:					ctx->descriptors[next_i].res_count);
drivers/firewire/ohci.c:		dma_sync_single_for_cpu(ctx->ohci->card.device,
drivers/firewire/ohci.c:		dma_sync_single_for_cpu(ctx->ohci->card.device,
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->ohci;
drivers/firewire/ohci.c:		dma_sync_single_for_device(ctx->ohci->card.device,
drivers/firewire/ohci.c:	p = ctx->pointer;
drivers/firewire/ohci.c:	end = ctx->buffer + end_buffer_index * PAGE_SIZE + end_buffer_offset;
drivers/firewire/ohci.c:		void *buffer_end = ctx->buffer + AR_BUFFERS * PAGE_SIZE;
drivers/firewire/ohci.c:	ctx->pointer = p;
drivers/firewire/ohci.c:	ctx->pointer = NULL;
drivers/firewire/ohci.c:	ctx->regs        = regs;
drivers/firewire/ohci.c:	ctx->ohci        = ohci;
drivers/firewire/ohci.c:	tasklet_init(&ctx->tasklet, ar_context_tasklet, (unsigned long)ctx);
drivers/firewire/ohci.c:		ctx->pages[i] = alloc_page(GFP_KERNEL | GFP_DMA32);
drivers/firewire/ohci.c:		if (!ctx->pages[i])
drivers/firewire/ohci.c:		dma_addr = dma_map_page(ohci->card.device, ctx->pages[i],
drivers/firewire/ohci.c:			__free_page(ctx->pages[i]);
drivers/firewire/ohci.c:			ctx->pages[i] = NULL;
drivers/firewire/ohci.c:		set_page_private(ctx->pages[i], dma_addr);
drivers/firewire/ohci.c:		pages[i]              = ctx->pages[i];
drivers/firewire/ohci.c:		pages[AR_BUFFERS + i] = ctx->pages[i];
drivers/firewire/ohci.c:	ctx->buffer = vmap(pages, ARRAY_SIZE(pages), VM_MAP, PAGE_KERNEL);
drivers/firewire/ohci.c:	if (!ctx->buffer)
drivers/firewire/ohci.c:	ctx->descriptors     = ohci->misc_buffer     + descriptors_offset;
drivers/firewire/ohci.c:	ctx->descriptors_bus = ohci->misc_buffer_bus + descriptors_offset;
drivers/firewire/ohci.c:		d = &ctx->descriptors[i];
drivers/firewire/ohci.c:		d->branch_address = cpu_to_le32(ctx->descriptors_bus +
drivers/firewire/ohci.c:	ctx->pointer = ctx->buffer;
drivers/firewire/ohci.c:	reg_write(ctx->ohci, COMMAND_PTR(ctx->regs), ctx->descriptors_bus | 1);
drivers/firewire/ohci.c:	reg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_RUN);
drivers/firewire/ohci.c:	desc = list_entry(ctx->buffer_list.next,
drivers/firewire/ohci.c:	last = ctx->last;
drivers/firewire/ohci.c:		ctx->current_bus = address;
drivers/firewire/ohci.c:		if (!ctx->callback(ctx, d, last))
drivers/firewire/ohci.c:			spin_lock_irqsave(&ctx->ohci->lock, flags);
drivers/firewire/ohci.c:			list_move_tail(&old_desc->list, &ctx->buffer_list);
drivers/firewire/ohci.c:			spin_unlock_irqrestore(&ctx->ohci->lock, flags);
drivers/firewire/ohci.c:		ctx->last = last;
drivers/firewire/ohci.c:	if (ctx->total_allocation >= 16*1024*1024)
drivers/firewire/ohci.c:	desc = dma_alloc_coherent(ctx->ohci->card.device, PAGE_SIZE,
drivers/firewire/ohci.c:	list_add_tail(&desc->list, &ctx->buffer_list);
drivers/firewire/ohci.c:	ctx->total_allocation += PAGE_SIZE;
drivers/firewire/ohci.c:	ctx->ohci = ohci;
drivers/firewire/ohci.c:	ctx->regs = regs;
drivers/firewire/ohci.c:	ctx->total_allocation = 0;
drivers/firewire/ohci.c:	INIT_LIST_HEAD(&ctx->buffer_list);
drivers/firewire/ohci.c:	ctx->buffer_tail = list_entry(ctx->buffer_list.next,
drivers/firewire/ohci.c:	tasklet_init(&ctx->tasklet, context_tasklet, (unsigned long)ctx);
drivers/firewire/ohci.c:	ctx->callback = callback;
drivers/firewire/ohci.c:	memset(ctx->buffer_tail->buffer, 0, sizeof(*ctx->buffer_tail->buffer));
drivers/firewire/ohci.c:	ctx->buffer_tail->buffer->control = cpu_to_le16(DESCRIPTOR_OUTPUT_LAST);
drivers/firewire/ohci.c:	ctx->buffer_tail->buffer->transfer_status = cpu_to_le16(0x8011);
drivers/firewire/ohci.c:	ctx->buffer_tail->used += sizeof(*ctx->buffer_tail->buffer);
drivers/firewire/ohci.c:	ctx->last = ctx->buffer_tail->buffer;
drivers/firewire/ohci.c:	ctx->prev = ctx->buffer_tail->buffer;
drivers/firewire/ohci.c:	ctx->prev_z = 1;
drivers/firewire/ohci.c:	struct fw_card *card = &ctx->ohci->card;
drivers/firewire/ohci.c:	list_for_each_entry_safe(desc, tmp, &ctx->buffer_list, list)
drivers/firewire/ohci.c:	struct descriptor_buffer *desc = ctx->buffer_tail;
drivers/firewire/ohci.c:		if (desc->list.next == &ctx->buffer_list) {
drivers/firewire/ohci.c:		ctx->buffer_tail = desc;
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->ohci;
drivers/firewire/ohci.c:	reg_write(ohci, COMMAND_PTR(ctx->regs),
drivers/firewire/ohci.c:		  le32_to_cpu(ctx->last->branch_address));
drivers/firewire/ohci.c:	reg_write(ohci, CONTROL_CLEAR(ctx->regs), ~0);
drivers/firewire/ohci.c:	reg_write(ohci, CONTROL_SET(ctx->regs), CONTEXT_RUN | extra);
drivers/firewire/ohci.c:	ctx->running = true;
drivers/firewire/ohci.c:	struct descriptor_buffer *desc = ctx->buffer_tail;
drivers/firewire/ohci.c:	d_branch = find_branch_descriptor(ctx->prev, ctx->prev_z);
drivers/firewire/ohci.c:	if (unlikely(ctx->ohci->quirks & QUIRK_IR_WAKE) &&
drivers/firewire/ohci.c:	    d_branch != ctx->prev &&
drivers/firewire/ohci.c:	    (ctx->prev->control & cpu_to_le16(DESCRIPTOR_CMD)) ==
drivers/firewire/ohci.c:		ctx->prev->branch_address = cpu_to_le32(d_bus | z);
drivers/firewire/ohci.c:	ctx->prev = d;
drivers/firewire/ohci.c:	ctx->prev_z = z;
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->ohci;
drivers/firewire/ohci.c:	reg_write(ohci, CONTROL_CLEAR(ctx->regs), CONTEXT_RUN);
drivers/firewire/ohci.c:	ctx->running = false;
drivers/firewire/ohci.c:		reg = reg_read(ohci, CONTROL_SET(ctx->regs));
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->ohci;
drivers/firewire/ohci.c:	if (ctx->running)
drivers/firewire/ohci.c:		reg_write(ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);
drivers/firewire/ohci.c:	tasklet_disable(&ctx->tasklet);
drivers/firewire/ohci.c:	ctx->flushing = true;
drivers/firewire/ohci.c:	ctx->flushing = false;
drivers/firewire/ohci.c:	tasklet_enable(&ctx->tasklet);
drivers/firewire/ohci.c:	if (ctx == &ctx->ohci->at_request_ctx) {
drivers/firewire/ohci.c:		packet->callback(packet, &ctx->ohci->card, packet->ack);
drivers/firewire/ohci.c:		handle_local_rom(ctx->ohci, packet, csr);
drivers/firewire/ohci.c:		handle_local_lock(ctx->ohci, packet, csr);
drivers/firewire/ohci.c:		if (ctx == &ctx->ohci->at_request_ctx)
drivers/firewire/ohci.c:			fw_core_handle_request(&ctx->ohci->card, packet);
drivers/firewire/ohci.c:			fw_core_handle_response(&ctx->ohci->card, packet);
drivers/firewire/ohci.c:	if (ctx == &ctx->ohci->at_response_ctx) {
drivers/firewire/ohci.c:		packet->callback(packet, &ctx->ohci->card, packet->ack);
drivers/firewire/ohci.c:	spin_lock_irqsave(&ctx->ohci->lock, flags);
drivers/firewire/ohci.c:	if (HEADER_GET_DESTINATION(packet->header[0]) == ctx->ohci->node_id &&
drivers/firewire/ohci.c:	    ctx->ohci->generation == packet->generation) {
drivers/firewire/ohci.c:		spin_unlock_irqrestore(&ctx->ohci->lock, flags);
drivers/firewire/ohci.c:	spin_unlock_irqrestore(&ctx->ohci->lock, flags);
drivers/firewire/ohci.c:		packet->callback(packet, &ctx->ohci->card, packet->ack);
drivers/firewire/ohci.c:	tasklet_disable(&ctx->tasklet);
drivers/firewire/ohci.c:	tasklet_enable(&ctx->tasklet);
drivers/firewire/ohci.c:	ctx->base.callback.sc(&ctx->base, ctx->last_timestamp,
drivers/firewire/ohci.c:			      ctx->header_length, ctx->header,
drivers/firewire/ohci.c:			      ctx->base.callback_data);
drivers/firewire/ohci.c:	ctx->header_length = 0;
drivers/firewire/ohci.c:	if (ctx->header_length + ctx->base.header_size > PAGE_SIZE) {
drivers/firewire/ohci.c:		if (ctx->base.drop_overflow_headers)
drivers/firewire/ohci.c:	ctx_hdr = ctx->header + ctx->header_length;
drivers/firewire/ohci.c:	ctx->last_timestamp = (u16)le32_to_cpu((__force __le32)dma_hdr[0]);
drivers/firewire/ohci.c:	if (ctx->base.header_size > 0)
drivers/firewire/ohci.c:	if (ctx->base.header_size > 4)
drivers/firewire/ohci.c:	if (ctx->base.header_size > 8)
drivers/firewire/ohci.c:		memcpy(&ctx_hdr[2], &dma_hdr[2], ctx->base.header_size - 8);
drivers/firewire/ohci.c:	ctx->header_length += ctx->base.header_size;
drivers/firewire/ohci.c:		ctx->mc_buffer_bus = buffer_dma;
drivers/firewire/ohci.c:		ctx->mc_completed = completed;
drivers/firewire/ohci.c:		ctx->base.callback.mc(&ctx->base,
drivers/firewire/ohci.c:				      ctx->base.callback_data);
drivers/firewire/ohci.c:		ctx->mc_completed = 0;
drivers/firewire/ohci.c:	dma_sync_single_range_for_cpu(ctx->context.ohci->card.device,
drivers/firewire/ohci.c:				      ctx->mc_buffer_bus & PAGE_MASK,
drivers/firewire/ohci.c:				      ctx->mc_buffer_bus & ~PAGE_MASK,
drivers/firewire/ohci.c:				      ctx->mc_completed, DMA_FROM_DEVICE);
drivers/firewire/ohci.c:	ctx->base.callback.mc(&ctx->base,
drivers/firewire/ohci.c:			      ctx->mc_buffer_bus + ctx->mc_completed,
drivers/firewire/ohci.c:			      ctx->base.callback_data);
drivers/firewire/ohci.c:	ctx->mc_completed = 0;
drivers/firewire/ohci.c:	if (ctx->header_length + 4 > PAGE_SIZE) {
drivers/firewire/ohci.c:		if (ctx->base.drop_overflow_headers)
drivers/firewire/ohci.c:	ctx_hdr = ctx->header + ctx->header_length;
drivers/firewire/ohci.c:	ctx->last_timestamp = le16_to_cpu(last->res_count);
drivers/firewire/ohci.c:	ctx->header_length += 4;
drivers/firewire/ohci.c:	ctx->header_length = 0;
drivers/firewire/ohci.c:	ctx->header = (void *) __get_free_page(GFP_KERNEL);
drivers/firewire/ohci.c:	if (ctx->header == NULL) {
drivers/firewire/ohci.c:	ret = context_init(&ctx->context, ohci, regs, callback);
drivers/firewire/ohci.c:		ctx->mc_completed = 0;
drivers/firewire/ohci.c:	return &ctx->base;
drivers/firewire/ohci.c:	free_page((unsigned long)ctx->header);
drivers/firewire/ohci.c:	struct fw_ohci *ohci = ctx->context.ohci;
drivers/firewire/ohci.c:	if (ctx->context.last->branch_address == 0)
drivers/firewire/ohci.c:	switch (ctx->base.type) {
drivers/firewire/ohci.c:		context_run(&ctx->context, match);
drivers/firewire/ohci.c:		match = (tags << 28) | (sync << 8) | ctx->base.channel;
drivers/firewire/ohci.c:		reg_write(ohci, CONTEXT_MATCH(ctx->context.regs), match);
drivers/firewire/ohci.c:		context_run(&ctx->context, control);
drivers/firewire/ohci.c:		ctx->sync = sync;
drivers/firewire/ohci.c:		ctx->tags = tags;
drivers/firewire/ohci.c:	switch (ctx->base.type) {
drivers/firewire/ohci.c:	context_stop(&ctx->context);
drivers/firewire/ohci.c:	tasklet_kill(&ctx->context.tasklet);
drivers/firewire/ohci.c:	context_release(&ctx->context);
drivers/firewire/ohci.c:	free_page((unsigned long)ctx->header);
drivers/firewire/ohci.c:		if (ctx->context.running)
drivers/firewire/ohci.c:			ohci_start_iso(&ctx->base, 0, ctx->sync, ctx->tags);
drivers/firewire/ohci.c:		if (ctx->context.running)
drivers/firewire/ohci.c:			ohci_start_iso(&ctx->base, 0, ctx->sync, ctx->tags);
drivers/firewire/ohci.c:	d = context_get_descriptors(&ctx->context, z + header_z, &d_bus);
drivers/firewire/ohci.c:					IT_HEADER_CHANNEL(ctx->base.channel) |
drivers/firewire/ohci.c:					IT_HEADER_SPEED(ctx->base.speed));
drivers/firewire/ohci.c:		dma_sync_single_range_for_device(ctx->context.ohci->card.device,
drivers/firewire/ohci.c:	context_append(&ctx->context, d, z, header_z);
drivers/firewire/ohci.c:	struct device *device = ctx->context.ohci->card.device;
drivers/firewire/ohci.c:	packet_count = packet->header_length / ctx->base.header_size;
drivers/firewire/ohci.c:	header_size  = max(ctx->base.header_size, (size_t)8);
drivers/firewire/ohci.c:		d = context_get_descriptors(&ctx->context,
drivers/firewire/ohci.c:		context_append(&ctx->context, d, z, header_z);
drivers/firewire/ohci.c:		d = context_get_descriptors(&ctx->context, 1, &d_bus);
drivers/firewire/ohci.c:		dma_sync_single_range_for_device(ctx->context.ohci->card.device,
drivers/firewire/ohci.c:		context_append(&ctx->context, d, 1, 0);
drivers/firewire/ohci.c:	spin_lock_irqsave(&ctx->context.ohci->lock, flags);
drivers/firewire/ohci.c:	spin_unlock_irqrestore(&ctx->context.ohci->lock, flags);
drivers/firewire/ohci.c:	reg_write(ctx->ohci, CONTROL_SET(ctx->regs), CONTEXT_WAKE);
drivers/firewire/ohci.c:	tasklet_disable(&ctx->context.tasklet);
drivers/firewire/ohci.c:	if (!test_and_set_bit_lock(0, &ctx->flushing_completions)) {
drivers/firewire/ohci.c:		context_tasklet((unsigned long)&ctx->context);
drivers/firewire/ohci.c:			if (ctx->header_length != 0)
drivers/firewire/ohci.c:			if (ctx->mc_completed != 0)
drivers/firewire/ohci.c:		clear_bit_unlock(0, &ctx->flushing_completions);
drivers/firewire/ohci.c:	tasklet_enable(&ctx->context.tasklet);
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.chan->center_freq, ctx->def.width,
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.center_freq1, ctx->def.center_freq2);
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.chan->center_freq, ctx->def.width,
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.center_freq1, ctx->def.center_freq2);
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.chan->center_freq, ctx->def.width,
drivers/net/wireless/mac80211_hwsim.c:		    ctx->def.center_freq1, ctx->def.center_freq2);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	brcmf_dbg(TRACE, "enter: dev=%s\n", dev_name(fwctx->dev));
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:		if (!data && !(fwctx->flags & BRCMF_FW_REQ_NV_OPTIONAL))
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:					     fwctx->domain_nr, fwctx->bus_nr);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	if (!nvram && !(fwctx->flags & BRCMF_FW_REQ_NV_OPTIONAL))
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->done(fwctx->dev, 0, fwctx->code, nvram, nvram_length);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	brcmf_dbg(TRACE, "failed: dev=%s\n", dev_name(fwctx->dev));
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	release_firmware(fwctx->code);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->done(fwctx->dev, -ENOENT, NULL, NULL, 0);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	brcmf_dbg(TRACE, "enter: dev=%s\n", dev_name(fwctx->dev));
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	if (!(fwctx->flags & BRCMF_FW_REQUEST_NVRAM))
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->code = fw;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	ret = request_firmware_nowait(THIS_MODULE, true, fwctx->nvram_name,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:				      fwctx->dev, GFP_KERNEL, fwctx,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	brcmf_dbg(TRACE, "failed: dev=%s\n", dev_name(fwctx->dev));
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->done(fwctx->dev, ret, fw, NULL, 0);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->dev = dev;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->flags = flags;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->done = fw_cb;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:		fwctx->nvram_name = nvram;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->domain_nr = domain_nr;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwctx->bus_nr = bus_nr;
drivers/net/wireless/broadcom/b43/main.c:	ctx->blob = firmware;
drivers/net/wireless/broadcom/b43/main.c:	complete(&ctx->dev->fw_load_complete);
drivers/net/wireless/broadcom/b43/main.c:		if ((fw->type == ctx->req_type) &&
drivers/net/wireless/broadcom/b43/main.c:	switch (ctx->req_type) {
drivers/net/wireless/broadcom/b43/main.c:		snprintf(ctx->fwname, sizeof(ctx->fwname),
drivers/net/wireless/broadcom/b43/main.c:		snprintf(ctx->fwname, sizeof(ctx->fwname),
drivers/net/wireless/broadcom/b43/main.c:		init_completion(&ctx->dev->fw_load_complete);
drivers/net/wireless/broadcom/b43/main.c:		err = request_firmware_nowait(THIS_MODULE, 1, ctx->fwname,
drivers/net/wireless/broadcom/b43/main.c:					      ctx->dev->dev->dev, GFP_KERNEL,
drivers/net/wireless/broadcom/b43/main.c:		wait_for_completion(&ctx->dev->fw_load_complete);
drivers/net/wireless/broadcom/b43/main.c:		if (ctx->blob)
drivers/net/wireless/broadcom/b43/main.c:	err = request_firmware(&ctx->blob, ctx->fwname,
drivers/net/wireless/broadcom/b43/main.c:			       ctx->dev->dev->dev);
drivers/net/wireless/broadcom/b43/main.c:		snprintf(ctx->errors[ctx->req_type],
drivers/net/wireless/broadcom/b43/main.c:			 sizeof(ctx->errors[ctx->req_type]),
drivers/net/wireless/broadcom/b43/main.c:			 ctx->fwname);
drivers/net/wireless/broadcom/b43/main.c:		snprintf(ctx->errors[ctx->req_type],
drivers/net/wireless/broadcom/b43/main.c:			 sizeof(ctx->errors[ctx->req_type]),
drivers/net/wireless/broadcom/b43/main.c:			 ctx->fwname, err);
drivers/net/wireless/broadcom/b43/main.c:	if (ctx->blob->size < sizeof(struct b43_fw_header))
drivers/net/wireless/broadcom/b43/main.c:	hdr = (struct b43_fw_header *)(ctx->blob->data);
drivers/net/wireless/broadcom/b43/main.c:		if (size != ctx->blob->size - sizeof(struct b43_fw_header))
drivers/net/wireless/broadcom/b43/main.c:	fw->data = ctx->blob;
drivers/net/wireless/broadcom/b43/main.c:	fw->type = ctx->req_type;
drivers/net/wireless/broadcom/b43/main.c:	snprintf(ctx->errors[ctx->req_type],
drivers/net/wireless/broadcom/b43/main.c:		 sizeof(ctx->errors[ctx->req_type]),
drivers/net/wireless/broadcom/b43/main.c:		 "Firmware file \"%s\" format error.\n", ctx->fwname);
drivers/net/wireless/broadcom/b43/main.c:	release_firmware(ctx->blob);
drivers/net/wireless/broadcom/b43/main.c:	struct b43_wldev *dev = ctx->dev;
drivers/net/wireless/broadcom/b43/main.c:	struct b43_firmware *fw = &ctx->dev->fw;
drivers/net/wireless/broadcom/b43/main.c:	const u8 rev = ctx->dev->dev->core_rev;
drivers/net/wireless/broadcom/b43/main.c:	fw->opensource = (ctx->req_type == B43_FWTYPE_OPENSOURCE);
drivers/net/wireless/broadcom/b43/main.c:	err = ctx->fatal_failure = -EOPNOTSUPP;
drivers/net/wireless/broadcom/b43/main.c:	err = ctx->fatal_failure = -EOPNOTSUPP;
drivers/net/wireless/broadcom/b43/main.c:	err = ctx->fatal_failure = -EOPNOTSUPP;
drivers/net/wireless/broadcom/b43/main.c:	 * already is in ctx->errors. Return and let our caller decide
drivers/net/wireless/broadcom/b43/main.c:	ctx->dev = dev;
drivers/net/wireless/broadcom/b43/main.c:	ctx->req_type = B43_FWTYPE_PROPRIETARY;
drivers/net/wireless/broadcom/b43/main.c:	if (ctx->fatal_failure)
drivers/net/wireless/broadcom/b43/main.c:	ctx->req_type = B43_FWTYPE_OPENSOURCE;
drivers/net/wireless/broadcom/b43/main.c:	if(ctx->fatal_failure)
drivers/net/wireless/broadcom/b43/main.c:		errmsg = ctx->errors[i];
drivers/net/wireless/intersil/hostap/hostap_download.c:	hfa384x_from_aux(ctx->local->dev, (unsigned long)v - 1, 0x80, ctx->page);
drivers/net/wireless/intersil/hostap/hostap_download.c:	seq_write(m, ctx->page, 0x80);
drivers/net/wireless/intersil/hostap/hostap_download.c:	prism2_enable_aux_port(ctx->local->dev, 1);
drivers/net/wireless/intersil/hostap/hostap_download.c:	prism2_enable_aux_port(ctx->local->dev, 0);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (!atomic_dec_and_test(&ctx->refcount))
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	WARN_ON(!ctx->done.done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	BUG_ON(ctx->outurb->status == -EINPROGRESS);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	BUG_ON(timer_pending(&ctx->timer));
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	usb_free_urb(ctx->outurb);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	kfree(ctx->buf);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->outurb->transfer_flags |= URB_ASYNC_UNLINK;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (usb_unlink_urb(ctx->outurb) == -EINPROGRESS) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->state = EZUSB_CTX_REQ_TIMEOUT;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->state = EZUSB_CTX_RESP_TIMEOUT;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		dev_dbg(&ctx->outurb->dev->dev, "couldn't unlink\n");
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		atomic_inc(&ctx->refcount);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->killed = 1;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->buf = kmalloc(BULK_BUF_SIZE, GFP_ATOMIC);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (!ctx->buf) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->outurb = usb_alloc_urb(0, GFP_ATOMIC);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (!ctx->outurb) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		kfree(ctx->buf);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->upriv = upriv;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->state = EZUSB_CTX_START;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->out_rid = out_rid;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->in_rid = in_rid;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	atomic_set(&ctx->refcount, 1);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	init_completion(&ctx->done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	setup_timer(&ctx->timer, ezusb_request_timerfn, (u_long)ctx);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	struct ezusb_priv *upriv = ctx->upriv;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	list_del_init(&ctx->list);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	switch (ctx->state) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		if ((ctx->out_rid == EZUSB_RID_TX) && upriv->dev) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			if (ctx->state != EZUSB_CTX_COMPLETE)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ezusb_complete_all(&ctx->done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			ezusb_complete_all(&ctx->done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (!ctx->upriv->udev)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	list_move_tail(&ctx->list, &upriv->req_active);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (ctx->state == EZUSB_CTX_QUEUED) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		atomic_inc(&ctx->refcount);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		result = usb_submit_urb(ctx->outurb, GFP_ATOMIC);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			ctx->state = EZUSB_CTX_REQSUBMIT_FAIL;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->state = EZUSB_CTX_REQ_SUBMITTED;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ezusb_mod_timer(ctx->upriv, &ctx->timer,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (!ctx->upriv->udev) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	atomic_inc(&ctx->refcount);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	list_add_tail(&ctx->list, &upriv->req_pending);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->state = EZUSB_CTX_QUEUED;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	struct ezusb_priv *upriv = ctx->upriv;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	del_timer(&ctx->timer);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (ctx->killed) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	state = ctx->state;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			if (ctx->in_rid) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:				ctx->state = EZUSB_CTX_REQ_COMPLETE;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:				ezusb_mod_timer(upriv, &ctx->timer,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			ctx->state = EZUSB_CTX_COMPLETE;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			ctx->state = EZUSB_CTX_REQ_FAILED;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	urb->transfer_buffer = ctx->buf;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->buf = (void *) ans;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	ctx->buf_length = urb->actual_length;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	state = ctx->state;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->state = EZUSB_CTX_RESP_RECEIVED;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->state = EZUSB_CTX_COMPLETE;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		del_timer(&ctx->timer);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		del_timer(&ctx->timer);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->outurb->transfer_flags |= URB_ASYNC_UNLINK;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		usb_unlink_urb(ctx->outurb);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	switch (ctx->state) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			while (!ctx->done.done && msecs--)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			wait_event_interruptible(ctx->done.wait,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:						 ctx->done.done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req_size = ezusb_fill_req(ctx->buf, length, ctx->out_rid, data,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	usb_fill_bulk_urb(ctx->outurb, upriv->udev, upriv->write_pipe,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			  ctx->buf, req_size,
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (ctx->in_rid)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (ctx->in_rid)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	state = ctx->state;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		retval = ctx->outurb->status;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		if (!ctx->in_rid)
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	if (ctx->in_rid) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		struct ezusb_packet *ans = ctx->buf;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		if (exp_len != ctx->buf_length) {
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			    ctx->in_rid, exp_len, ctx->buf_length);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	memset(ctx->buf, 0, BULK_BUF_SIZE);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	buf = ctx->buf->data;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	tx_size = ALIGN(buf - ctx->buf->data, 2);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		atomic_inc(&ctx->refcount);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		ctx->outurb->transfer_flags |= URB_ASYNC_UNLINK;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		err = usb_unlink_urb(ctx->outurb);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:			wait_for_completion(&ctx->done);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		del_timer_sync(&ctx->timer);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		if (!list_empty(&ctx->list))
drivers/net/wireless/ath/wil6210/txrx.c:	switch (ctx->mapped_as) {
drivers/net/wireless/ath/wil6210/txrx.c:			if (ctx->skb)
drivers/net/wireless/ath/wil6210/txrx.c:				dev_kfree_skb_any(ctx->skb);
drivers/net/wireless/ath/wil6210/txrx.c:			kfree_skb(ctx->skb);
drivers/net/wireless/ath/wil6210/txrx.c:					hdr_ctx->nr_frags = sg_desc_cnt;
drivers/net/wireless/ath/wil6210/txrx.c:				first_ctx->nr_frags = sg_desc_cnt - 1;
drivers/net/wireless/ath/wil6210/txrx.c:		int lf = (vring->swtail + ctx->nr_frags) % vring->size;
drivers/net/wireless/ath/wil6210/txrx.c:			skb = ctx->skb;
drivers/net/wireless/ath/ath9k/channel.c:		cfg80211_chandef_create(&ctx->chandef, chan, NL80211_CHAN_HT20);
drivers/net/wireless/ath/ath9k/channel.c:		INIT_LIST_HEAD(&ctx->vifs);
drivers/net/wireless/ath/ath9k/channel.c:		ctx->txpower = ATH_TXPOWER_MAX;
drivers/net/wireless/ath/ath9k/channel.c:		ctx->flush_timeout = HZ / 5; /* 200ms */
drivers/net/wireless/ath/ath9k/channel.c:		for (j = 0; j < ARRAY_SIZE(ctx->acq); j++)
drivers/net/wireless/ath/ath9k/channel.c:			INIT_LIST_HEAD(&ctx->acq[j]);
drivers/net/wireless/ath/ath9k/channel.c:		memcpy(&ctx->chandef, chandef, sizeof(*chandef));
drivers/net/wireless/ath/ath9k/channel.c:		if (!ctx->active)
drivers/net/wireless/ath/ath9k/channel.c:		list_for_each_entry(avp, &ctx->vifs, list) {
drivers/net/wireless/ath/ath9k/channel.c:			ctx->flush_timeout =
drivers/net/wireless/ath/ath9k/channel.c:			ctx->flush_timeout =
drivers/net/wireless/ath/ath9k/channel.c:	list_for_each_entry(avp, &ctx->vifs, list) {
drivers/net/wireless/ath/ath9k/channel.c:	ctx->active = active;
drivers/net/wireless/ath/ath9k/channel.c:		if (!ctx->assigned || list_empty(&ctx->vifs))
drivers/net/wireless/ath/ath9k/channel.c:		ictx->flush_timeout = HZ / 5;
drivers/net/wireless/ath/ath9k/channel.c:	ictx->flush_timeout = usecs_to_jiffies(sc->sched.channel_switch_time);
drivers/net/wireless/ath/ath9k/channel.c:	if (ctx->active && sc->sched.extend_absence) {
drivers/net/wireless/ath/ath9k/channel.c:	if (ctx->active && sc->sched.beacon_miss >= 2) {
drivers/net/wireless/ath/ath9k/channel.c:	if (ctx->active && avp->noa_duration)
drivers/net/wireless/ath/ath9k/channel.c:		if (ctx->active && sc->sched.state == ATH_CHANCTX_STATE_IDLE) {
drivers/net/wireless/ath/ath9k/channel.c:		if (!ctx->active && avp->noa_duration &&
drivers/net/wireless/ath/ath9k/channel.c:		if (ctx->active &&
drivers/net/wireless/ath/ath9k/channel.c:		if (ctx->active && sc->sched.force_noa_update)
drivers/net/wireless/ath/ath9k/channel.c:		if (!ctx->assigned)
drivers/net/wireless/ath/ath9k/channel.c:			ctx->chandef = *chandef;
drivers/net/wireless/ath/ath9k/channel.c:		ctx->chandef = *chandef;
drivers/net/wireless/ath/ath9k/channel.c:		if (!ctx->assigned || list_empty(&ctx->vifs))
drivers/net/wireless/ath/ath9k/channel.c:		if (active && !ctx->active)
drivers/net/wireless/ath/ath9k/channel.c:		if (ctx->switch_after_beacon)
drivers/net/wireless/ath/ath9k/channel.c:		if (ctx->active) {
drivers/net/wireless/ath/ath9k/channel.c:	INIT_LIST_HEAD(&ctx->vifs);
drivers/net/wireless/ath/ath9k/channel.c:	ctx->txpower = ATH_TXPOWER_MAX;
drivers/net/wireless/ath/ath9k/channel.c:	cfg80211_chandef_create(&ctx->chandef, chan, NL80211_CHAN_HT20);
drivers/net/wireless/ath/ath9k/channel.c:	for (i = 0; i < ARRAY_SIZE(ctx->acq); i++)
drivers/net/wireless/ath/ath9k/channel.c:		INIT_LIST_HEAD(&ctx->acq[i]);
drivers/net/wireless/ath/ath9k/channel.c:					     ctx->hw_queue_base + i);
drivers/net/wireless/ath/ath9k/channel.c:					     ctx->hw_queue_base + i);
drivers/net/wireless/ath/ath9k/beacon.c:	avp->chanctx->tsf_val += tsfadjust;
drivers/net/wireless/ath/ath9k/beacon.c:		offset = ath9k_hw_get_tsf_offset(&avp->chanctx->tsf_ts, NULL);
drivers/net/wireless/ath/ath9k/beacon.c:		ath9k_hw_settsf64(sc->sc_ah, avp->chanctx->tsf_val + offset);
drivers/net/wireless/ath/ath9k/beacon.c:	struct ath_beacon_config *cur_conf = &ctx->beacon;
drivers/net/wireless/ath/ath9k/beacon.c:	cur_conf = &ctx->beacon;
drivers/net/wireless/ath/ath9k/xmit.c:	list = &ctx->acq[TID_TO_WME_AC(tid->tidno)];
drivers/net/wireless/ath/ath9k/ath9k.h:	struct ath_chanctx **ptr = (void *) ctx->drv_priv;
drivers/net/wireless/ath/ath9k/main.c:	init_channel = ath9k_cmn_get_channel(hw, ah, &ctx->chandef);
drivers/net/wireless/ath/ath9k/main.c:	list_for_each_entry(avp, &ctx->vifs, list) {
drivers/net/wireless/ath/ath9k/main.c:		if (ctx->nvifs_assigned != 1)
drivers/net/wireless/ath/ath9k/main.c:	list_for_each_entry(avp, &ctx->vifs, list)
drivers/net/wireless/ath/ath9k/main.c:	ctx->switch_after_beacon = false;
drivers/net/wireless/ath/ath9k/main.c:			ctx->switch_after_beacon = true;
drivers/net/wireless/ath/ath9k/main.c:		bool changed = (iter_data.primary_sta != ctx->primary_sta);
drivers/net/wireless/ath/ath9k/main.c:			ctx->primary_sta = iter_data.primary_sta;
drivers/net/wireless/ath/ath9k/main.c:			ctx->primary_sta = NULL;
drivers/net/wireless/ath/ath9k/main.c:		list_add_tail(&avp->list, &avp->chanctx->vifs);
drivers/net/wireless/ath/ath9k/main.c:			ath_chanctx_set_channel(sc, ctx, &ctx->chandef);
drivers/net/wireless/ath/ath9k/main.c:		ctx->offchannel = !!(conf->flags & IEEE80211_CONF_OFFCHANNEL);
drivers/net/wireless/ath/ath9k/main.c:		ctx->rxfilter = *total_flags;
drivers/net/wireless/ath/ath9k/main.c:	getrawmonotonic(&avp->chanctx->tsf_ts);
drivers/net/wireless/ath/ath9k/main.c:	avp->chanctx->tsf_val = tsf;
drivers/net/wireless/ath/ath9k/main.c:	getrawmonotonic(&avp->chanctx->tsf_ts);
drivers/net/wireless/ath/ath9k/main.c:	avp->chanctx->tsf_val = 0;
drivers/net/wireless/ath/ath9k/main.c:		if (ctx->assigned)
drivers/net/wireless/ath/ath9k/main.c:		ctx->assigned = true;
drivers/net/wireless/ath/ath9k/main.c:		ctx->hw_queue_base = pos * IEEE80211_NUM_ACS;
drivers/net/wireless/ath/ath9k/main.c:	ctx->assigned = false;
drivers/net/wireless/ath/ath9k/main.c:	ctx->hw_queue_base = 0;
drivers/net/wireless/ath/ath9k/main.c:	ctx->nvifs_assigned++;
drivers/net/wireless/ath/ath9k/main.c:	list_add_tail(&avp->list, &ctx->vifs);
drivers/net/wireless/ath/ath9k/main.c:		vif->hw_queue[i] = ctx->hw_queue_base + i;
drivers/net/wireless/ath/ath9k/main.c:	ctx->nvifs_assigned--;
drivers/net/wireless/ath/ath9k/main.c:		cur_conf = &go_ctx->beacon;
drivers/net/wireless/ath/ath9k/main.c:		*dbm = avp->chanctx->cur_txpower;
drivers/net/wireless/ath/ath9k/debug.c:		if (list_empty(&ctx->vifs))
drivers/net/wireless/ath/ath9k/debug.c:			   i++, (int)(ctx->assigned), iter_data.naps,
drivers/net/wireless/ath/ath10k/mac.c:			def = &vifs[0].new_ctx->def;
drivers/net/wireless/ath/ath10k/mac.c:		ar->rx_channel = ctx->def.chan;
drivers/net/wireless/ath/ath10k/mac.c:			   vifs[i].old_ctx->def.chan->center_freq,
drivers/net/wireless/ath/ath10k/mac.c:			   vifs[i].new_ctx->def.chan->center_freq,
drivers/net/wireless/ath/ath10k/mac.c:			   vifs[i].old_ctx->def.width,
drivers/net/wireless/ath/ath10k/mac.c:			   vifs[i].new_ctx->def.width);
drivers/net/wireless/ath/ath10k/mac.c:		ret = ath10k_vdev_restart(arvif, &vifs[i].new_ctx->def);
drivers/net/wireless/ath/ath10k/mac.c:		   ctx->def.chan->center_freq, ctx->def.width, ctx);
drivers/net/wireless/ath/ath10k/mac.c:		   ctx->def.chan->center_freq, ctx->def.width, ctx);
drivers/net/wireless/ath/ath10k/mac.c:		   ctx->def.chan->center_freq, ctx->def.width, ctx, changed);
drivers/net/wireless/ath/ath10k/mac.c:	ret = ath10k_vdev_start(arvif, &ctx->def);
drivers/net/wireless/ath/ath10k/mac.c:			    ctx->def.chan->center_freq, ret);
drivers/net/wireless/ti/wlcore/main.c:		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
drivers/net/wireless/ti/wlcore/main.c:		     cfg80211_get_chandef_type(&ctx->def));
drivers/net/wireless/ti/wlcore/main.c:		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
drivers/net/wireless/ti/wlcore/main.c:		     cfg80211_get_chandef_type(&ctx->def));
drivers/net/wireless/ti/wlcore/main.c:		ctx->def.chan->center_freq);
drivers/net/wireless/ti/wlcore/main.c:		     channel, cfg80211_get_chandef_type(&ctx->def), changed);
drivers/net/wireless/ti/wlcore/main.c:		    ctx->radar_enabled && !wlvif->radar_enabled &&
drivers/net/wireless/ti/wlcore/main.c:		    ctx->def.chan->dfs_state == NL80211_DFS_USABLE) {
drivers/net/wireless/ti/wlcore/main.c:		ctx->def.chan->center_freq);
drivers/net/wireless/ti/wlcore/main.c:		     cfg80211_get_chandef_type(&ctx->def),
drivers/net/wireless/ti/wlcore/main.c:		     ctx->radar_enabled, ctx->def.chan->dfs_state);
drivers/net/wireless/ti/wlcore/main.c:	wlvif->band = ctx->def.chan->band;
drivers/net/wireless/ti/wlcore/main.c:	wlvif->channel_type = cfg80211_get_chandef_type(&ctx->def);
drivers/net/wireless/ti/wlcore/main.c:	if (ctx->radar_enabled &&
drivers/net/wireless/ti/wlcore/main.c:	    ctx->def.chan->dfs_state == NL80211_DFS_USABLE) {
drivers/net/wireless/ti/wlcore/main.c:		     ieee80211_frequency_to_channel(ctx->def.chan->center_freq),
drivers/net/wireless/ti/wlcore/main.c:		     cfg80211_get_chandef_type(&ctx->def));
drivers/net/wireless/ti/wlcore/main.c:		new_ctx->def.chan->center_freq);
drivers/net/wireless/ti/wlcore/main.c:		     cfg80211_get_chandef_type(&new_ctx->def));
drivers/net/wireless/ti/wlcore/main.c:	wlvif->band = new_ctx->def.chan->band;
drivers/net/wireless/ti/wlcore/main.c:	wlvif->channel_type = cfg80211_get_chandef_type(&new_ctx->def);
drivers/net/wireless/ti/wlcore/main.c:	if (new_ctx->radar_enabled) {
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	u16 *phy_ctxt_id = (u16 *)ctx->drv_priv;
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	ret = iwl_mvm_phy_ctxt_changed(mvm, phy_ctxt, &ctx->min_def,
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:				       ctx->rx_chains_static,
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:				       ctx->rx_chains_dynamic);
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	u16 *phy_ctxt_id = (u16 *)ctx->drv_priv;
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	u16 *phy_ctxt_id = (u16 *)ctx->drv_priv;
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	iwl_mvm_phy_ctxt_changed(mvm, phy_ctxt, &ctx->min_def,
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:				 ctx->rx_chains_static,
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:				 ctx->rx_chains_dynamic);
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	u16 *phy_ctxt_id = (u16 *)ctx->drv_priv;
drivers/net/wireless/intel/iwlwifi/mvm/d3.c:	chandef = ctx->def;
drivers/net/wireless/intel/iwlwifi/mvm/d3.c:	chains_static = ctx->rx_chains_static;
drivers/net/wireless/intel/iwlwifi/mvm/d3.c:	chains_dynamic = ctx->rx_chains_dynamic;
drivers/net/wireless/intel/iwlwifi/mvm/mac-ctxt.c:	iwl_mvm_ack_rates(mvm, vif, chanctx ? chanctx->def.chan->band
drivers/net/wireless/intel/iwlwifi/mvm/tdls.c:			chandef = &chanctx->def;
drivers/net/wireless/intel/iwlwifi/dvm/rx.c:	struct iwl_rxon_cmd *rxon = (void *)&ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rx.c:		ctx->staging.channel = csa->channel;
drivers/net/wireless/intel/iwlwifi/dvm/rx.c:					      ctx->active.bssid_addr))
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:			if (ctx->vif && ctx->vif->type == NL80211_IFTYPE_AP &&
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:			ieee80211_disable_rssi_reports(ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		if (ctx->vif && ctx->vif->type == NL80211_IFTYPE_STATION &&
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		if (ctx->vif)
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:			ieee80211_disable_rssi_reports(ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	ieee80211_enable_rssi_reports(found_ctx->vif,
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:			if (ctx->vif && ctx->vif->type == NL80211_IFTYPE_STATION)
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:				ieee80211_request_smps(ctx->vif, smps_request);
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	if (!ctx->vif || (ctx->vif->type != NL80211_IFTYPE_STATION)) {
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	ave_rssi = ieee80211_ave_rssi(ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	ctx->staging.rx_chain = cpu_to_le16(rx_chain);
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		ctx->staging.rx_chain |= RXON_RX_CHAIN_MIMO_FORCE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		ctx->staging.rx_chain &= ~RXON_RX_CHAIN_MIMO_FORCE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:			ctx->staging.rx_chain,
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	     !sta && !ctx->key_mapping_keys)
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		.bssid = ctx->active.bssid_addr,
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	memcpy(&rxon, &ctx->active, sizeof(rxon));
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:	memcpy(&ctx->staging, &rxon, sizeof(rxon));
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		ctx->key_mapping_keys = 0;
drivers/net/wireless/intel/iwlwifi/dvm/lib.c:		ieee80211_iter_keys(priv->hw, ctx->vif,
drivers/net/wireless/intel/iwlwifi/dvm/tt.c:					rxon = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	if (!ctx->ht.enabled || !ctx->ht.is_40mhz)
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		sta_id = ctx->ap_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		sta_id = ctx->bcast_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	station->sta.station_flags = ctx->station_flags;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	station->ctxid = ctx->ctxid;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	else if (ctx && ctx->vif && ctx->vif->p2p)
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		if (ctx && ctx->ctxid != priv->stations[i].ctxid)
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		if (ctx->ctxid != priv->stations[i].ctxid)
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	if (ctx->ht.enabled)
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		       ctx->active.channel);
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		.id = ctx->wep_key_cmd,
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		if (ctx->wep_keys[i].key_size) {
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		wep_cmd->key[i].key_size = ctx->wep_keys[i].key_size;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		memcpy(&wep_cmd->key[i].key[3], ctx->wep_keys[i].key,
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:				ctx->wep_keys[i].key_size);
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	memset(&ctx->wep_keys[keyconf->keyidx], 0, sizeof(ctx->wep_keys[0]));
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	ctx->wep_keys[keyconf->keyidx].key_size = keyconf->keylen;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	memcpy(&ctx->wep_keys[keyconf->keyidx].key, &keyconf->key,
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		return vif_priv->ctx->ap_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	u8 sta_id = iwlagn_key_sta_id(priv, ctx->vif, sta);
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	ctx->key_mapping_keys--;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	u8 sta_id = iwlagn_key_sta_id(priv, ctx->vif, sta);
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	ctx->key_mapping_keys++;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:			addr = ctx->active.bssid_addr;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:		ctx->key_mapping_keys--;
drivers/net/wireless/intel/iwlwifi/dvm/sta.c:	u8 sta_id = ctx->bcast_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/scan.c:		switch (ctx->staging.dev_type) {
drivers/net/wireless/intel/iwlwifi/dvm/scan.c:		limits[n_active++] = ctx->beacon_int ?: IWL_PASSIVE_DWELL_BASE;
drivers/net/wireless/intel/iwlwifi/dvm/scan.c:				le16_to_cpu(ctx->staging.channel);
drivers/net/wireless/intel/iwlwifi/dvm/scan.c:	scan->tx_cmd.sta_id = ctx->bcast_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:		sta_id = ctx->bcast_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:	txq_id = iwlagn_alloc_agg_txq(priv, ctx->ac_to_queue[tid_to_ac[tid]]);
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:	fifo = ctx->ac_to_fifo[tid_to_ac[tid]];
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:	sta = ieee80211_find_sta(ctx->vif, addr1);
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:			    ctx->vif &&
drivers/net/wireless/intel/iwlwifi/dvm/tx.c:			    ctx->vif->type == NL80211_IFTYPE_STATION) {
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		hw->wiphy->interface_modes |= ctx->interface_modes;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		hw->wiphy->interface_modes |= ctx->exclusive_interface_modes;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (!ctx->vif || ctx->vif->type != NL80211_IFTYPE_STATION ||
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	/* we'll clear ctx->vif during iwlagn_prepare_restart() */
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	memset((void *)&ctx->active, 0, sizeof(ctx->active));
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:			is_default_wep_key = !ctx->key_mapping_keys;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (le16_to_cpu(ctx->active.channel) == ch)
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.is_40mhz = false;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.extension_chan_offset = IEEE80211_HT_PARAM_CHA_SEC_NONE;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.extension_chan_offset = IEEE80211_HT_PARAM_CHA_SEC_BELOW;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.is_40mhz = true;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.extension_chan_offset = IEEE80211_HT_PARAM_CHA_SEC_ABOVE;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->ht.is_40mhz = true;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if ((le16_to_cpu(ctx->staging.channel) != ch))
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->staging.flags = 0;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	iwl_set_flags_for_band(priv, ctx, channel->band, ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ieee80211_chswitch_done(ctx->vif, false);
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (ctx->vif)
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ieee80211_chswitch_done(ctx->vif, is_success);
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->staging.filter_flags &= ~filter_nand;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		ctx->staging.filter_flags |= filter_or;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->qos_data.def_qos_parm.ac[q].cw_min =
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->qos_data.def_qos_parm.ac[q].cw_max =
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->qos_data.def_qos_parm.ac[q].aifsn = params->aifs;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->qos_data.def_qos_parm.ac[q].edca_txop =
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->qos_data.def_qos_parm.ac[q].reserved1 = 0;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	struct ieee80211_vif *vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->is_active = true;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		if (!ctx->always_active)
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:			ctx->is_active = false;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		vif->hw_queue[ac] = ctx->ac_to_queue[ac];
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		vif->cab_queue = ctx->mcast_queue;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->vif = vif;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->vif = NULL;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:		if (!ctx->always_active)
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:			ctx->is_active = false;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	WARN_ON(ctx->vif != vif);
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	ctx->vif = NULL;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (ctx->ctxid != IWL_RXON_CTX_BSS) {
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (!ctx->vif || !iwl_is_ready_rf(priv)) {
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	interface_modes = ctx->interface_modes | ctx->exclusive_interface_modes;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (ctx->exclusive_interface_modes & BIT(newtype)) {
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	u16 beacon_interval = le16_to_cpu(ctx->timing.beacon_interval);
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	struct ieee80211_vif *vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:		      ctx->active.channel, ch);
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	cmd.rxon_flags = ctx->staging.flags;
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	cmd.rxon_filter_flags = ctx->staging.filter_flags;
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	u16 beacon_interval = le16_to_cpu(ctx->timing.beacon_interval);
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	struct ieee80211_vif *vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:		      ctx->active.channel, ch);
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	cmd->rxon_flags = ctx->staging.flags;
drivers/net/wireless/intel/iwlwifi/dvm/devices.c:	cmd->rxon_filter_flags = ctx->staging.filter_flags;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	memset(&ctx->staging, 0, sizeof(ctx->staging));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (!ctx->vif) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.dev_type = ctx->unused_devtype;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	switch (ctx->vif->type) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.dev_type = ctx->ap_devtype;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.dev_type = ctx->station_devtype;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.filter_flags = RXON_FILTER_ACCEPT_GRP_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.dev_type = ctx->ibss_devtype;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags = RXON_FLG_SHORT_PREAMBLE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.filter_flags = RXON_FILTER_BCON_AWARE_MSK |
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.dev_type = RXON_DEV_TYPE_SNIFFER;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->vif->type);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_SHORT_PREAMBLE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SHORT_PREAMBLE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.channel =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	iwl_set_flags_for_band(priv, ctx, priv->band, ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.flags &= ~(RXON_FLG_CHANNEL_MODE_MIXED |
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->vif)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		memcpy(ctx->staging.node_addr, ctx->vif->addr, ETH_ALEN);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.ofdm_ht_single_stream_basic_rates = 0xff;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.ofdm_ht_dual_stream_basic_rates = 0xff;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.ofdm_ht_triple_stream_basic_rates = 0xff;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->rxon_cmd,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->rxon_cmd,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->rxon_cmd, 0,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (!ctx->is_active)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->qos_data.def_qos_parm.qos_flags = 0;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->qos_data.qos_active)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->qos_data.def_qos_parm.qos_flags |=
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->ht.enabled)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->qos_data.def_qos_parm.qos_flags |= QOS_PARAM_FLG_TGN_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		      ctx->qos_data.qos_active,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		      ctx->qos_data.def_qos_parm.qos_flags);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->qos_cmd, 0,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			       &ctx->qos_data.def_qos_parm);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	const struct iwl_rxon_cmd *rxon1 = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	const struct iwl_rxon_cmd *rxon2 = &ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.flags = ctx->staging.flags;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.filter_flags = ctx->staging.filter_flags;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.ofdm_basic_rates = ctx->staging.ofdm_basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.cck_basic_rates = ctx->staging.cck_basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	    ctx->staging.ofdm_ht_single_stream_basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	    ctx->staging.ofdm_ht_dual_stream_basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.rx_chain_select_flags = ctx->staging.rx_chain;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		 ctx->staging.ofdm_ht_triple_stream_basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon_assoc.acquisition_data = ctx->staging.acquisition_data;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->rxon_assoc_cmd,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct ieee80211_vif *vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	memset(&ctx->timing, 0, sizeof(struct iwl_rxon_time_cmd));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->timing.timestamp = cpu_to_le64(priv->timestamp);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->timing.listen_interval = cpu_to_le16(conf->listen_interval);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->timing.atim_window = 0;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->ctxid == IWL_RXON_CTX_PAN &&
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	    (!ctx->vif || ctx->vif->type != NL80211_IFTYPE_STATION) &&
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->timing.beacon_interval =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		beacon_int = le16_to_cpu(ctx->timing.beacon_interval);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	} else if (ctx->ctxid == IWL_RXON_CTX_BSS &&
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		   (!iwl_is_associated_ctx(ctx) || !ctx->vif ||
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		    !ctx->vif->bss_conf.beacon_int)) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->timing.beacon_interval =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		beacon_int = le16_to_cpu(ctx->timing.beacon_interval);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->timing.beacon_interval = cpu_to_le16(beacon_int);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->beacon_int = beacon_int;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->timing.beacon_init_val = cpu_to_le32(interval_tm - rem);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->timing.dtim_period = vif ? (vif->bss_conf.dtim_period ?: 1) : 1;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			le16_to_cpu(ctx->timing.beacon_interval),
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			le32_to_cpu(ctx->timing.beacon_init_val),
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			le16_to_cpu(ctx->timing.atim_window));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	return iwl_dvm_send_cmd_pdu(priv, ctx->rxon_timing_cmd,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:				0, sizeof(ctx->timing), &ctx->timing);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *active = (void *)&ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->ctxid == IWL_RXON_CTX_BSS) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ret = iwlagn_disable_bss(priv, ctx, &ctx->staging);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ret = iwlagn_disable_pan(priv, ctx, &ctx->staging);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		if (ctx->vif) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ret = iwlagn_disconn_pan(priv, ctx, &ctx->staging);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	memcpy(active, &ctx->staging, sizeof(*active));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		memcmp(&ctx->active, &ctx->staging, sizeof(ctx->staging));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *active = (void *)&ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->ctxid == IWL_RXON_CTX_BSS) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->vif && (ctx->vif->type == NL80211_IFTYPE_AP)) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ret = iwlagn_update_beacon(priv, ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ret = iwl_dvm_send_cmd_pdu(priv, ctx->rxon_cmd, 0,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		      sizeof(struct iwl_rxon_cmd), &ctx->staging);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	memcpy(active, &ctx->staging, sizeof(*active));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->vif && (ctx->vif->type == NL80211_IFTYPE_ADHOC))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		if (iwlagn_update_beacon(priv, ctx->vif))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *rxon = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (!ctx->ht.enabled) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	rxon->flags |= cpu_to_le32(ctx->ht.protection <<
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		if (ctx->ht.protection ==
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			switch (ctx->ht.extension_chan_offset) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			switch (ctx->ht.extension_chan_offset) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			le32_to_cpu(rxon->flags), ctx->ht.protection,
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->ht.extension_chan_offset);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if ((le16_to_cpu(ctx->staging.channel) == channel) &&
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.channel = cpu_to_le16(channel);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_BAND_24G_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_BAND_24G_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &=
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SHORT_SLOT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.flags |= RXON_FLG_SHORT_SLOT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.flags &= ~RXON_FLG_SHORT_SLOT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_BAND_24G_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_AUTO_DETECT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_CCK_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *rxon = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *rxon = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	const struct iwl_rxon_cmd *staging = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	const struct iwl_rxon_cmd *active = &ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *rxon = &ctx->staging;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->vif) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		unsigned long basic = ctx->vif->bss_conf.basic_rates;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.cck_basic_rates = cck;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.ofdm_basic_rates = ofdm;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct iwl_rxon_cmd *active = (void *)&ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	bool new_assoc = !!(ctx->staging.filter_flags & RXON_FILTER_ASSOC_MSK);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (!ctx->is_active)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.flags |= RXON_FLG_TSF2HOST_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SELF_CTS_EN;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if ((ctx->vif && ctx->vif->bss_conf.use_short_slot) ||
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	    !(ctx->staging.flags & RXON_FLG_BAND_24G_MSK))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SHORT_SLOT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_SHORT_SLOT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	iwl_print_rx_config_cmd(priv, ctx->ctxid);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	    (priv->switch_channel != ctx->staging.channel)) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		memcpy(active, &ctx->staging, sizeof(*active));
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		       le16_to_cpu(ctx->staging.channel),
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		       ctx->staging.bssid_addr);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.extension_chan_offset =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.is_40mhz = true;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.extension_chan_offset =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.is_40mhz = true;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.extension_chan_offset =
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.is_40mhz = false;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			if (ctx->ht.enabled != conf_is_ht(conf))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:				ctx->ht.enabled = conf_is_ht(conf);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			if (ctx->ht.enabled) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:				if (!ctx->ht.is_40mhz ||
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:				ctx->ht.is_40mhz = false;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->ht.protection = IEEE80211_HT_OP_MODE_PROTECTION_NONE;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			if (le16_to_cpu(ctx->staging.channel) !=
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:				ctx->staging.flags = 0;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:					       ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		if (!memcmp(&ctx->staging, &ctx->active, sizeof(ctx->staging)))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	struct ieee80211_vif *vif = ctx->vif;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->ht_need_multiple_chains = need_multiple;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (unlikely(!ctx->vif)) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->qos_data.qos_active = bss_conf->qos;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	ctx->staging.assoc_id = cpu_to_le16(vif->bss_conf.aid);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SHORT_PREAMBLE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_SHORT_PREAMBLE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags |= RXON_FILTER_ASSOC_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags &= ~RXON_FILTER_ASSOC_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			if (ctx->ctxid == IWL_RXON_CTX_BSS)
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (ctx->ht.enabled) {
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.protection = bss_conf->ht_operation_mode &
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->ht.non_gf_sta_present = !!(bss_conf->ht_operation_mode &
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_TGG_PROTECT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_TGG_PROTECT_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags |= RXON_FLG_SELF_CTS_EN;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		ctx->staging.flags &= ~RXON_FLG_SELF_CTS_EN;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	memcpy(ctx->staging.bssid_addr, bss_conf->bssid, ETH_ALEN);
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags |= RXON_FILTER_ASSOC_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags &= ~RXON_FILTER_ASSOC_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags |= RXON_FILTER_BCON_AWARE_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:			ctx->staging.filter_flags &=
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:	if (force || memcmp(&ctx->staging, &ctx->active, sizeof(ctx->staging)))
drivers/net/wireless/intel/iwlwifi/dvm/rxon.c:		if (memcmp(&ctx->staging, &ctx->active, sizeof(ctx->staging)))
drivers/net/wireless/intel/iwlwifi/dvm/debugfs.c:				 ctx->ctxid);
drivers/net/wireless/intel/iwlwifi/dvm/debugfs.c:				ctx->qos_data.def_qos_parm.ac[i].cw_min,
drivers/net/wireless/intel/iwlwifi/dvm/debugfs.c:				ctx->qos_data.def_qos_parm.ac[i].cw_max,
drivers/net/wireless/intel/iwlwifi/dvm/debugfs.c:				ctx->qos_data.def_qos_parm.ac[i].aifsn,
drivers/net/wireless/intel/iwlwifi/dvm/debugfs.c:				ctx->qos_data.def_qos_parm.ac[i].edca_txop);
drivers/net/wireless/intel/iwlwifi/dvm/dev.h:		if (priv->valid_contexts & BIT(ctx->ctxid))
drivers/net/wireless/intel/iwlwifi/dvm/dev.h:	return (ctx->active.filter_flags & RXON_FILTER_ASSOC_MSK) ? 1 : 0;
drivers/net/wireless/intel/iwlwifi/dvm/main.c:		if (ctx->active.rx_chain != ctx->staging.rx_chain)
drivers/net/wireless/intel/iwlwifi/dvm/main.c:	tx_beacon_cmd->tx.sta_id = priv->beacon_ctx->bcast_sta_id;
drivers/net/wireless/intel/iwlwifi/dvm/main.c:	if (priv->beacon_ctx->vif->type != NL80211_IFTYPE_AP) {
drivers/net/wireless/intel/iwlwifi/dvm/main.c:	beacon = ieee80211_beacon_get(priv->hw, priv->beacon_ctx->vif);
drivers/net/wireless/intel/iwlwifi/dvm/main.c:				(struct iwl_rxon_cmd *)&ctx->active;
drivers/net/wireless/intel/iwlwifi/dvm/main.c:		ctx->staging.filter_flags |= RXON_FILTER_ASSOC_MSK;
drivers/net/wireless/intel/iwlwifi/dvm/main.c:		memset(ctx->wep_keys, 0, sizeof(ctx->wep_keys));
drivers/net/wireless/intel/iwlwifi/dvm/main.c:		ctx->key_mapping_keys = 0;
drivers/net/wireless/intel/iwlwifi/dvm/calib.c:	rxon_band24 = !!(ctx->staging.flags & RXON_FLG_BAND_24G_MSK);
drivers/net/wireless/intel/iwlwifi/dvm/calib.c:	rxon_chnum = le16_to_cpu(ctx->staging.channel);
drivers/net/wireless/marvell/mwifiex/usb.c:	struct mwifiex_adapter *adapter = ctx->adapter;
drivers/net/wireless/marvell/mwifiex/usb.c:	if (card->rx_cmd_ep != ctx->ep) {
drivers/net/wireless/marvell/mwifiex/usb.c:		ctx->skb = dev_alloc_skb(size);
drivers/net/wireless/marvell/mwifiex/usb.c:		if (!ctx->skb) {
drivers/net/wireless/marvell/mwifiex/usb.c:	usb_fill_bulk_urb(ctx->urb, card->udev,
drivers/net/wireless/marvell/mwifiex/usb.c:			  usb_rcvbulkpipe(card->udev, ctx->ep), ctx->skb->data,
drivers/net/wireless/marvell/mwifiex/usb.c:	if (card->rx_cmd_ep == ctx->ep)
drivers/net/wireless/marvell/mwifiex/usb.c:	if (usb_submit_urb(ctx->urb, GFP_ATOMIC)) {
drivers/net/wireless/marvell/mwifiex/usb.c:		dev_kfree_skb_any(ctx->skb);
drivers/net/wireless/marvell/mwifiex/usb.c:		ctx->skb = NULL;
drivers/net/wireless/marvell/mwifiex/usb.c:		if (card->rx_cmd_ep == ctx->ep)
drivers/net/wireless/marvell/mwifiex/pcie.c:	struct pci_dev *pdev = ctx->dev;
drivers/net/wireless/marvell/mwifiex/pcie.c:		mwifiex_interrupt_status(adapter, ctx->msg_id);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	struct mwifiex_rx_reorder_tbl *rx_reorder_tbl_ptr = ctx->ptr;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	struct mwifiex_private *priv = ctx->priv;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	ctx->timer_is_set = false;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	mwifiex_dbg(ctx->priv->adapter, INFO, "info: flush data %d\n", seq_num);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	start_win = (ctx->ptr->start_win + seq_num + 1) & (MAX_TID_VALUE - 1);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	mwifiex_11n_dispatch_pkt_until_start_win(ctx->priv, ctx->ptr,
drivers/net/usb/cdc_ncm.c:	max = min_t(u32, CDC_NCM_NTB_MAX_SIZE_RX, le32_to_cpu(ctx->ncm_parm.dwNtbInMaxSize));
drivers/net/usb/cdc_ncm.c:			 le32_to_cpu(ctx->ncm_parm.dwNtbInMaxSize), min);
drivers/net/usb/cdc_ncm.c:	min = ctx->max_datagram_size + ctx->max_ndp_size + sizeof(struct usb_cdc_ncm_nth16);
drivers/net/usb/cdc_ncm.c:	max = min_t(u32, CDC_NCM_NTB_MAX_SIZE_TX, le32_to_cpu(ctx->ncm_parm.dwNtbOutMaxSize));
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, "%u\n", ctx->min_tx_pkt);
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, "%u\n", ctx->rx_max);
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, "%u\n", ctx->tx_max);
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, "%u\n", ctx->timer_interval / (u32)NSEC_PER_USEC);
drivers/net/usb/cdc_ncm.c:	ctx->min_tx_pkt = val;
drivers/net/usb/cdc_ncm.c:	cdc_ncm_update_rxtx_max(dev, val, ctx->tx_max);
drivers/net/usb/cdc_ncm.c:	cdc_ncm_update_rxtx_max(dev, ctx->rx_max, val);
drivers/net/usb/cdc_ncm.c:	spin_lock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	ctx->timer_interval = val * NSEC_PER_USEC;
drivers/net/usb/cdc_ncm.c:	if (!ctx->timer_interval)
drivers/net/usb/cdc_ncm.c:		ctx->tx_timer_pending = 0;
drivers/net/usb/cdc_ncm.c:	spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, "%c\n", ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END ? 'Y' : 'N');
drivers/net/usb/cdc_ncm.c:	if (enable == (ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END))
drivers/net/usb/cdc_ncm.c:	if (enable && !ctx->delayed_ndp16) {
drivers/net/usb/cdc_ncm.c:		ctx->delayed_ndp16 = kzalloc(ctx->max_ndp_size, GFP_KERNEL);
drivers/net/usb/cdc_ncm.c:		if (!ctx->delayed_ndp16)
drivers/net/usb/cdc_ncm.c:	spin_lock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:		ctx->drvflags |= CDC_NCM_FLAG_NDP_TO_END;
drivers/net/usb/cdc_ncm.c:		ctx->drvflags &= ~CDC_NCM_FLAG_NDP_TO_END;
drivers/net/usb/cdc_ncm.c:	spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	return sprintf(buf, format "\n", tocpu(ctx->ncm_parm.name));	\
drivers/net/usb/cdc_ncm.c:	u8 iface_no = ctx->control->cur_altsetting->desc.bInterfaceNumber;
drivers/net/usb/cdc_ncm.c:	if (val != ctx->rx_max) {
drivers/net/usb/cdc_ncm.c:			ctx->rx_max = val;
drivers/net/usb/cdc_ncm.c:	if (dev->rx_urb_size != ctx->rx_max) {
drivers/net/usb/cdc_ncm.c:		dev->rx_urb_size = ctx->rx_max;
drivers/net/usb/cdc_ncm.c:	if (val != ctx->tx_max)
drivers/net/usb/cdc_ncm.c:	if (val != le32_to_cpu(ctx->ncm_parm.dwNtbOutMaxSize) &&
drivers/net/usb/cdc_ncm.c:	if (netif_running(dev->net) && val > ctx->tx_max) {
drivers/net/usb/cdc_ncm.c:		if (ctx->tx_curr_skb) {
drivers/net/usb/cdc_ncm.c:			dev_kfree_skb_any(ctx->tx_curr_skb);
drivers/net/usb/cdc_ncm.c:			ctx->tx_curr_skb = NULL;
drivers/net/usb/cdc_ncm.c:		ctx->tx_max = val;
drivers/net/usb/cdc_ncm.c:		ctx->tx_max = val;
drivers/net/usb/cdc_ncm.c:	dev->hard_mtu = ctx->tx_max;
drivers/net/usb/cdc_ncm.c:	ctx->min_tx_pkt = clamp_t(u16, ctx->tx_max - 3 * usb_maxpacket(dev->udev, dev->out, 1),
drivers/net/usb/cdc_ncm.c:				  CDC_NCM_MIN_TX_PKT, ctx->tx_max);
drivers/net/usb/cdc_ncm.c:	if (cdc_ncm_comm_intf_is_mbim(dev->intf->cur_altsetting) && ctx->mbim_desc)
drivers/net/usb/cdc_ncm.c:		return ctx->mbim_desc->bmNetworkCapabilities;
drivers/net/usb/cdc_ncm.c:	if (ctx->func_desc)
drivers/net/usb/cdc_ncm.c:		return ctx->func_desc->bmNetworkCapabilities;
drivers/net/usb/cdc_ncm.c:	if (cdc_ncm_comm_intf_is_mbim(dev->intf->cur_altsetting) && ctx->mbim_desc)
drivers/net/usb/cdc_ncm.c:		return le16_to_cpu(ctx->mbim_desc->wMaxSegmentSize);
drivers/net/usb/cdc_ncm.c:	if (ctx->ether_desc)
drivers/net/usb/cdc_ncm.c:		return le16_to_cpu(ctx->ether_desc->wMaxSegmentSize);
drivers/net/usb/cdc_ncm.c:	u8 iface_no = ctx->control->cur_altsetting->desc.bInterfaceNumber;
drivers/net/usb/cdc_ncm.c:			      0, iface_no, &ctx->ncm_parm,
drivers/net/usb/cdc_ncm.c:			      sizeof(ctx->ncm_parm));
drivers/net/usb/cdc_ncm.c:	if (le16_to_cpu(ctx->ncm_parm.bmNtbFormatsSupported) &
drivers/net/usb/cdc_ncm.c:	ctx->rx_max = le32_to_cpu(ctx->ncm_parm.dwNtbInMaxSize);
drivers/net/usb/cdc_ncm.c:	ctx->tx_max = le32_to_cpu(ctx->ncm_parm.dwNtbOutMaxSize);
drivers/net/usb/cdc_ncm.c:	ctx->tx_remainder = le16_to_cpu(ctx->ncm_parm.wNdpOutPayloadRemainder);
drivers/net/usb/cdc_ncm.c:	ctx->tx_modulus = le16_to_cpu(ctx->ncm_parm.wNdpOutDivisor);
drivers/net/usb/cdc_ncm.c:	ctx->tx_ndp_modulus = le16_to_cpu(ctx->ncm_parm.wNdpOutAlignment);
drivers/net/usb/cdc_ncm.c:	ctx->tx_max_datagrams = le16_to_cpu(ctx->ncm_parm.wNtbOutMaxDatagrams);
drivers/net/usb/cdc_ncm.c:		ctx->rx_max, ctx->tx_max, ctx->tx_remainder, ctx->tx_modulus,
drivers/net/usb/cdc_ncm.c:		ctx->tx_ndp_modulus, ctx->tx_max_datagrams, cdc_ncm_flags(dev));
drivers/net/usb/cdc_ncm.c:	if ((ctx->tx_max_datagrams == 0) ||
drivers/net/usb/cdc_ncm.c:			(ctx->tx_max_datagrams > CDC_NCM_DPT_DATAGRAMS_MAX))
drivers/net/usb/cdc_ncm.c:		ctx->tx_max_datagrams = CDC_NCM_DPT_DATAGRAMS_MAX;
drivers/net/usb/cdc_ncm.c:	ctx->max_ndp_size = sizeof(struct usb_cdc_ncm_ndp16) + (ctx->tx_max_datagrams + 1) * sizeof(struct usb_cdc_ncm_dpe16);
drivers/net/usb/cdc_ncm.c:	ctx->timer_interval = CDC_NCM_TIMER_INTERVAL_USEC * NSEC_PER_USEC;
drivers/net/usb/cdc_ncm.c:	u8 iface_no = ctx->control->cur_altsetting->desc.bInterfaceNumber;
drivers/net/usb/cdc_ncm.c:	ctx->max_datagram_size = clamp_t(u32, new_size,
drivers/net/usb/cdc_ncm.c:	if (le16_to_cpu(max_datagram_size) == ctx->max_datagram_size)
drivers/net/usb/cdc_ncm.c:	max_datagram_size = cpu_to_le16(ctx->max_datagram_size);
drivers/net/usb/cdc_ncm.c:	dev->net->mtu = min_t(int, dev->net->mtu, ctx->max_datagram_size - cdc_ncm_eth_hlen(dev));
drivers/net/usb/cdc_ncm.c:	if (ctx->mbim_extended_desc) {
drivers/net/usb/cdc_ncm.c:		mbim_mtu = le16_to_cpu(ctx->mbim_extended_desc->wMTU);
drivers/net/usb/cdc_ncm.c:	val = ctx->tx_ndp_modulus;
drivers/net/usb/cdc_ncm.c:	    (val != ((-val) & val)) || (val >= ctx->tx_max)) {
drivers/net/usb/cdc_ncm.c:		ctx->tx_ndp_modulus = USB_CDC_NCM_NDP_ALIGN_MIN_SIZE;
drivers/net/usb/cdc_ncm.c:	val = ctx->tx_modulus;
drivers/net/usb/cdc_ncm.c:	    (val != ((-val) & val)) || (val >= ctx->tx_max)) {
drivers/net/usb/cdc_ncm.c:		ctx->tx_modulus = USB_CDC_NCM_NDP_ALIGN_MIN_SIZE;
drivers/net/usb/cdc_ncm.c:	if (ctx->tx_remainder >= ctx->tx_modulus) {
drivers/net/usb/cdc_ncm.c:		ctx->tx_remainder = 0;
drivers/net/usb/cdc_ncm.c:	ctx->tx_remainder = ((ctx->tx_remainder - cdc_ncm_eth_hlen(dev)) &
drivers/net/usb/cdc_ncm.c:			     (ctx->tx_modulus - 1));
drivers/net/usb/cdc_ncm.c:		       le32_to_cpu(ctx->ncm_parm.dwNtbInMaxSize));
drivers/net/usb/cdc_ncm.c:		       le32_to_cpu(ctx->ncm_parm.dwNtbOutMaxSize));
drivers/net/usb/cdc_ncm.c:	if (ctx->tx_rem_skb != NULL) {
drivers/net/usb/cdc_ncm.c:		dev_kfree_skb_any(ctx->tx_rem_skb);
drivers/net/usb/cdc_ncm.c:		ctx->tx_rem_skb = NULL;
drivers/net/usb/cdc_ncm.c:	if (ctx->tx_curr_skb != NULL) {
drivers/net/usb/cdc_ncm.c:		dev_kfree_skb_any(ctx->tx_curr_skb);
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_skb = NULL;
drivers/net/usb/cdc_ncm.c:	kfree(ctx->delayed_ndp16);
drivers/net/usb/cdc_ncm.c:	hrtimer_init(&ctx->tx_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
drivers/net/usb/cdc_ncm.c:	ctx->tx_timer.function = &cdc_ncm_tx_timer_cb;
drivers/net/usb/cdc_ncm.c:	ctx->bh.data = (unsigned long)dev;
drivers/net/usb/cdc_ncm.c:	ctx->bh.func = cdc_ncm_txpath_bh;
drivers/net/usb/cdc_ncm.c:	atomic_set(&ctx->stop, 0);
drivers/net/usb/cdc_ncm.c:	spin_lock_init(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	ctx->control = intf;
drivers/net/usb/cdc_ncm.c:		ctx->data = usb_ifnum_to_if(dev->udev,
drivers/net/usb/cdc_ncm.c:	ctx->ether_desc = hdr.usb_cdc_ether_desc;
drivers/net/usb/cdc_ncm.c:	ctx->func_desc = hdr.usb_cdc_ncm_desc;
drivers/net/usb/cdc_ncm.c:	ctx->mbim_desc = hdr.usb_cdc_mbim_desc;
drivers/net/usb/cdc_ncm.c:	ctx->mbim_extended_desc = hdr.usb_cdc_mbim_extended_desc;
drivers/net/usb/cdc_ncm.c:		ctx->data = usb_ifnum_to_if(dev->udev, intf->cur_altsetting->desc.bInterfaceNumber + 1);
drivers/net/usb/cdc_ncm.c:	if (!ctx->data) {
drivers/net/usb/cdc_ncm.c:		if (!ctx->mbim_desc) {
drivers/net/usb/cdc_ncm.c:		if (!ctx->ether_desc || !ctx->func_desc) {
drivers/net/usb/cdc_ncm.c:	if (ctx->data != ctx->control) {
drivers/net/usb/cdc_ncm.c:		temp = usb_driver_claim_interface(driver, ctx->data, dev);
drivers/net/usb/cdc_ncm.c:	iface_no = ctx->data->cur_altsetting->desc.bInterfaceNumber;
drivers/net/usb/cdc_ncm.c:	ctx->drvflags = drvflags;
drivers/net/usb/cdc_ncm.c:	if (!(ctx->drvflags & CDC_MBIM_FLAG_AVOID_ALTSETTING_TOGGLE))
drivers/net/usb/cdc_ncm.c:	if (ctx->drvflags & CDC_NCM_FLAG_RESET_NTB16) {
drivers/net/usb/cdc_ncm.c:	cdc_ncm_find_endpoints(dev, ctx->data);
drivers/net/usb/cdc_ncm.c:	cdc_ncm_find_endpoints(dev, ctx->control);
drivers/net/usb/cdc_ncm.c:	usb_set_intfdata(ctx->data, dev);
drivers/net/usb/cdc_ncm.c:	usb_set_intfdata(ctx->control, dev);
drivers/net/usb/cdc_ncm.c:	if (ctx->ether_desc) {
drivers/net/usb/cdc_ncm.c:		temp = usbnet_get_ethernet_addr(dev, ctx->ether_desc->iMACAddress);
drivers/net/usb/cdc_ncm.c:	if (ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END) {
drivers/net/usb/cdc_ncm.c:		ctx->delayed_ndp16 = kzalloc(ctx->max_ndp_size, GFP_KERNEL);
drivers/net/usb/cdc_ncm.c:		if (!ctx->delayed_ndp16)
drivers/net/usb/cdc_ncm.c:	usb_set_intfdata(ctx->control, NULL);
drivers/net/usb/cdc_ncm.c:	usb_set_intfdata(ctx->data, NULL);
drivers/net/usb/cdc_ncm.c:	if (ctx->data != ctx->control)
drivers/net/usb/cdc_ncm.c:		usb_driver_release_interface(driver, ctx->data);
drivers/net/usb/cdc_ncm.c:	atomic_set(&ctx->stop, 1);
drivers/net/usb/cdc_ncm.c:	if (hrtimer_active(&ctx->tx_timer))
drivers/net/usb/cdc_ncm.c:		hrtimer_cancel(&ctx->tx_timer);
drivers/net/usb/cdc_ncm.c:	tasklet_kill(&ctx->bh);
drivers/net/usb/cdc_ncm.c:	if (ctx->control == ctx->data)
drivers/net/usb/cdc_ncm.c:		ctx->data = NULL;
drivers/net/usb/cdc_ncm.c:	if (intf == ctx->control && ctx->data) {
drivers/net/usb/cdc_ncm.c:		usb_set_intfdata(ctx->data, NULL);
drivers/net/usb/cdc_ncm.c:		usb_driver_release_interface(driver, ctx->data);
drivers/net/usb/cdc_ncm.c:		ctx->data = NULL;
drivers/net/usb/cdc_ncm.c:	} else if (intf == ctx->data && ctx->control) {
drivers/net/usb/cdc_ncm.c:		usb_set_intfdata(ctx->control, NULL);
drivers/net/usb/cdc_ncm.c:		usb_driver_release_interface(driver, ctx->control);
drivers/net/usb/cdc_ncm.c:		ctx->control = NULL;
drivers/net/usb/cdc_ncm.c:	if (ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END) {
drivers/net/usb/cdc_ncm.c:		if (ctx->delayed_ndp16->dwSignature == sign)
drivers/net/usb/cdc_ncm.c:			return ctx->delayed_ndp16;
drivers/net/usb/cdc_ncm.c:		else if (ctx->delayed_ndp16->dwSignature)
drivers/net/usb/cdc_ncm.c:	if (!(ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END))
drivers/net/usb/cdc_ncm.c:		cdc_ncm_align_tail(skb, ctx->tx_ndp_modulus, 0, ctx->tx_max);
drivers/net/usb/cdc_ncm.c:	if ((ctx->tx_max - skb->len - reserve) < ctx->max_ndp_size)
drivers/net/usb/cdc_ncm.c:	if (!(ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END))
drivers/net/usb/cdc_ncm.c:		ndp16 = (struct usb_cdc_ncm_ndp16 *)memset(skb_put(skb, ctx->max_ndp_size), 0, ctx->max_ndp_size);
drivers/net/usb/cdc_ncm.c:		ndp16 = ctx->delayed_ndp16;
drivers/net/usb/cdc_ncm.c:	if (ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END)
drivers/net/usb/cdc_ncm.c:		delayed_ndp_size = ctx->max_ndp_size;
drivers/net/usb/cdc_ncm.c:		swap(skb, ctx->tx_rem_skb);
drivers/net/usb/cdc_ncm.c:		swap(sign, ctx->tx_rem_sign);
drivers/net/usb/cdc_ncm.c:	skb_out = ctx->tx_curr_skb;
drivers/net/usb/cdc_ncm.c:		skb_out = alloc_skb(ctx->tx_max, GFP_ATOMIC);
drivers/net/usb/cdc_ncm.c:		nth16->wSequence = cpu_to_le16(ctx->tx_seq++);
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_frame_num = 0;
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_frame_payload = 0;
drivers/net/usb/cdc_ncm.c:	for (n = ctx->tx_curr_frame_num; n < ctx->tx_max_datagrams; n++) {
drivers/net/usb/cdc_ncm.c:			skb = ctx->tx_rem_skb;
drivers/net/usb/cdc_ncm.c:			sign = ctx->tx_rem_sign;
drivers/net/usb/cdc_ncm.c:			ctx->tx_rem_skb = NULL;
drivers/net/usb/cdc_ncm.c:		ndp16 = cdc_ncm_ndp(ctx, skb_out, sign, skb->len + ctx->tx_modulus + ctx->tx_remainder);
drivers/net/usb/cdc_ncm.c:		cdc_ncm_align_tail(skb_out,  ctx->tx_modulus, ctx->tx_remainder, ctx->tx_max);
drivers/net/usb/cdc_ncm.c:		if (!ndp16 || skb_out->len + skb->len + delayed_ndp_size > ctx->tx_max) {
drivers/net/usb/cdc_ncm.c:				if (ctx->tx_rem_skb != NULL) {
drivers/net/usb/cdc_ncm.c:					dev_kfree_skb_any(ctx->tx_rem_skb);
drivers/net/usb/cdc_ncm.c:				ctx->tx_rem_skb = skb;
drivers/net/usb/cdc_ncm.c:				ctx->tx_rem_sign = sign;
drivers/net/usb/cdc_ncm.c:				ctx->tx_reason_ntb_full++;	/* count reason for transmitting */
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_frame_payload += skb->len;	/* count real tx payload data */
drivers/net/usb/cdc_ncm.c:			ctx->tx_reason_ndp_full++;	/* count reason for transmitting */
drivers/net/usb/cdc_ncm.c:	ctx->tx_curr_frame_num = n;
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_skb = skb_out;
drivers/net/usb/cdc_ncm.c:	} else if ((n < ctx->tx_max_datagrams) && (ready2send == 0) && (ctx->timer_interval > 0)) {
drivers/net/usb/cdc_ncm.c:		ctx->tx_curr_skb = skb_out;
drivers/net/usb/cdc_ncm.c:			ctx->tx_timer_pending = CDC_NCM_TIMER_PENDING_CNT;
drivers/net/usb/cdc_ncm.c:		if (n == ctx->tx_max_datagrams)
drivers/net/usb/cdc_ncm.c:			ctx->tx_reason_max_datagram++;	/* count reason for transmitting */
drivers/net/usb/cdc_ncm.c:	if (ctx->drvflags & CDC_NCM_FLAG_NDP_TO_END) {
drivers/net/usb/cdc_ncm.c:		cdc_ncm_align_tail(skb_out, ctx->tx_ndp_modulus, 0, ctx->tx_max);
drivers/net/usb/cdc_ncm.c:		memcpy(skb_put(skb_out, ctx->max_ndp_size), ctx->delayed_ndp16, ctx->max_ndp_size);
drivers/net/usb/cdc_ncm.c:		ndp16 = memset(ctx->delayed_ndp16, 0, ctx->max_ndp_size);
drivers/net/usb/cdc_ncm.c:	/* If collected data size is less or equal ctx->min_tx_pkt
drivers/net/usb/cdc_ncm.c:	    skb_out->len > ctx->min_tx_pkt)
drivers/net/usb/cdc_ncm.c:		memset(skb_put(skb_out, ctx->tx_max - skb_out->len), 0,
drivers/net/usb/cdc_ncm.c:		       ctx->tx_max - skb_out->len);
drivers/net/usb/cdc_ncm.c:	else if (skb_out->len < ctx->tx_max && (skb_out->len % dev->maxpacket) == 0)
drivers/net/usb/cdc_ncm.c:	ctx->tx_curr_skb = NULL;
drivers/net/usb/cdc_ncm.c:	ctx->tx_overhead += skb_out->len - ctx->tx_curr_frame_payload;
drivers/net/usb/cdc_ncm.c:	ctx->tx_ntbs++;
drivers/net/usb/cdc_ncm.c:				(long)ctx->tx_curr_frame_payload - skb_out->len);
drivers/net/usb/cdc_ncm.c:	if (ctx->tx_curr_skb != NULL && n > 0)
drivers/net/usb/cdc_ncm.c:	if (!(hrtimer_active(&ctx->tx_timer) || atomic_read(&ctx->stop)))
drivers/net/usb/cdc_ncm.c:		hrtimer_start(&ctx->tx_timer,
drivers/net/usb/cdc_ncm.c:				ktime_set(0, ctx->timer_interval),
drivers/net/usb/cdc_ncm.c:	if (!atomic_read(&ctx->stop))
drivers/net/usb/cdc_ncm.c:		tasklet_schedule(&ctx->bh);
drivers/net/usb/cdc_ncm.c:	spin_lock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	if (ctx->tx_timer_pending != 0) {
drivers/net/usb/cdc_ncm.c:		ctx->tx_timer_pending--;
drivers/net/usb/cdc_ncm.c:		spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:		ctx->tx_reason_timeout++;	/* count reason for transmitting */
drivers/net/usb/cdc_ncm.c:		spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:		spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	spin_lock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_ncm.c:	if (len > ctx->rx_max) {
drivers/net/usb/cdc_ncm.c:			  ctx->rx_max);
drivers/net/usb/cdc_ncm.c:	if ((ctx->rx_seq + 1) != le16_to_cpu(nth16->wSequence) &&
drivers/net/usb/cdc_ncm.c:	    (ctx->rx_seq || le16_to_cpu(nth16->wSequence)) &&
drivers/net/usb/cdc_ncm.c:	    !((ctx->rx_seq == 0xffff) && !le16_to_cpu(nth16->wSequence))) {
drivers/net/usb/cdc_ncm.c:			  ctx->rx_seq, le16_to_cpu(nth16->wSequence));
drivers/net/usb/cdc_ncm.c:	ctx->rx_seq = le16_to_cpu(nth16->wSequence);
drivers/net/usb/cdc_ncm.c:				(len > ctx->rx_max) || (len < ETH_HLEN)) {
drivers/net/usb/cdc_ncm.c:	ctx->rx_overhead += skb_in->len - payload;
drivers/net/usb/cdc_ncm.c:	ctx->rx_ntbs++;
drivers/net/usb/huawei_cdc_ncm.c:		subdriver = usb_cdc_wdm_register(ctx->control,
drivers/net/usb/huawei_cdc_ncm.c:		drvstate->subdriver->disconnect(ctx->control);
drivers/net/usb/huawei_cdc_ncm.c:	if (intf == ctx->control &&
drivers/net/usb/huawei_cdc_ncm.c:		(intf == ctx->control &&
drivers/net/usb/cdc_mbim.c:	if (ctx->mbim_desc && dev->status)
drivers/net/usb/cdc_mbim.c:		subdriver = usb_cdc_wdm_register(ctx->control,
drivers/net/usb/cdc_mbim.c:						 le16_to_cpu(ctx->mbim_desc->wMaxControlMessage),
drivers/net/usb/cdc_mbim.c:		info->subdriver->disconnect(ctx->control);
drivers/net/usb/cdc_mbim.c:	spin_lock_bh(&ctx->mtx);
drivers/net/usb/cdc_mbim.c:	spin_unlock_bh(&ctx->mtx);
drivers/net/usb/cdc_mbim.c:		if (((offset + len) > skb_in->len) || (len > ctx->rx_max)) {
drivers/net/usb/cdc_mbim.c:	ctx->rx_overhead += skb_in->len - payload;
drivers/net/usb/cdc_mbim.c:	ctx->rx_ntbs++;
drivers/net/usb/cdc_mbim.c:	if (intf == ctx->control && info->subdriver && info->subdriver->suspend)
drivers/net/usb/cdc_mbim.c:	bool callsub = (intf == ctx->control && info->subdriver && info->subdriver->resume);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	if (ctx->free)
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	u8 *tx_buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	ctx->msg.complete = complete;
drivers/net/ieee802154/at86rf230.c:	rc = spi_async(lp->spi, &ctx->msg);
drivers/net/ieee802154/at86rf230.c:	ctx->buf[0] = (reg & CMD_REG_MASK) | CMD_REG | CMD_WRITE;
drivers/net/ieee802154/at86rf230.c:	ctx->buf[1] = val;
drivers/net/ieee802154/at86rf230.c:	ctx->msg.complete = complete;
drivers/net/ieee802154/at86rf230.c:	rc = spi_async(lp->spi, &ctx->msg);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	const u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	if (trx_state != ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:			if (ctx->to_state == STATE_RX_AACK_ON)
drivers/net/ieee802154/at86rf230.c:			if (ctx->to_state == STATE_TX_ON ||
drivers/net/ieee802154/at86rf230.c:			    ctx->to_state == STATE_TRX_OFF) {
drivers/net/ieee802154/at86rf230.c:				u8 state = ctx->to_state;
drivers/net/ieee802154/at86rf230.c:							     ctx->complete);
drivers/net/ieee802154/at86rf230.c:			 ctx->from_state, ctx->to_state, trx_state);
drivers/net/ieee802154/at86rf230.c:	if (ctx->complete)
drivers/net/ieee802154/at86rf230.c:		ctx->complete(context);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	switch (ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:		ctx->to_state = STATE_TX_ON;
drivers/net/ieee802154/at86rf230.c:		ctx->to_state = STATE_TRX_OFF;
drivers/net/ieee802154/at86rf230.c:	switch (ctx->from_state) {
drivers/net/ieee802154/at86rf230.c:		switch (ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:		switch (ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:		switch (ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:	at86rf230_async_state_timer(&ctx->timer);
drivers/net/ieee802154/at86rf230.c:	hrtimer_start(&ctx->timer, tim, HRTIMER_MODE_REL);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	if (trx_state == ctx->to_state) {
drivers/net/ieee802154/at86rf230.c:		if (ctx->complete)
drivers/net/ieee802154/at86rf230.c:			ctx->complete(context);
drivers/net/ieee802154/at86rf230.c:	ctx->from_state = trx_state;
drivers/net/ieee802154/at86rf230.c:	at86rf230_async_write_reg(lp, RG_TRX_STATE, ctx->to_state, ctx,
drivers/net/ieee802154/at86rf230.c:	ctx->to_state = state;
drivers/net/ieee802154/at86rf230.c:	ctx->complete = complete;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:		u8 trac = TRAC_MASK(ctx->buf[1]);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	const u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	ctx->trx.len = AT86RF2XX_MAX_BUF;
drivers/net/ieee802154/at86rf230.c:	ctx->msg.complete = at86rf230_rx_read_frame_complete;
drivers/net/ieee802154/at86rf230.c:	rc = spi_async(lp->spi, &ctx->msg);
drivers/net/ieee802154/at86rf230.c:		ctx->trx.len = 2;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	const u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	ctx->free = true;
drivers/net/ieee802154/at86rf230.c:	ctx->buf[0] = (RG_IRQ_STATUS & CMD_REG_MASK) | CMD_REG;
drivers/net/ieee802154/at86rf230.c:	ctx->msg.complete = at86rf230_irq_status;
drivers/net/ieee802154/at86rf230.c:	rc = spi_async(lp->spi, &ctx->msg);
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	ctx->trx.len = 2;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	u8 *buf = ctx->buf;
drivers/net/ieee802154/at86rf230.c:	ctx->trx.len = skb->len + 2;
drivers/net/ieee802154/at86rf230.c:	ctx->msg.complete = at86rf230_write_frame_complete;
drivers/net/ieee802154/at86rf230.c:	rc = spi_async(lp->spi, &ctx->msg);
drivers/net/ieee802154/at86rf230.c:		ctx->trx.len = 2;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ieee802154/at86rf230.c:	struct at86rf230_local *lp = ctx->lp;
drivers/net/ethernet/broadcom/cnic.c:	map = ctx->kwqe_data_mapping;
drivers/net/ethernet/broadcom/cnic.c:	return ctx->kwqe_data;
drivers/net/ethernet/broadcom/cnic.c:	if (ctx->ulp_proto_id == CNIC_ULP_ISCSI) {
drivers/net/ethernet/broadcom/cnic.c:		struct cnic_iscsi *iscsi = ctx->proto.iscsi;
drivers/net/ethernet/broadcom/cnic.c:		cnic_free_id(&cp->cid_tbl, ctx->cid);
drivers/net/ethernet/broadcom/cnic.c:		cnic_free_id(&cp->fcoe_cid_tbl, ctx->cid);
drivers/net/ethernet/broadcom/cnic.c:	ctx->cid = 0;
drivers/net/ethernet/broadcom/cnic.c:	struct cnic_iscsi *iscsi = ctx->proto.iscsi;
drivers/net/ethernet/broadcom/cnic.c:	if (ctx->ulp_proto_id == CNIC_ULP_FCOE) {
drivers/net/ethernet/broadcom/cnic.c:		ctx->cid = cid;
drivers/net/ethernet/broadcom/cnic.c:	ctx->cid = cid;
drivers/net/ethernet/broadcom/cnic.c:	struct cnic_iscsi *iscsi = ctx->proto.iscsi;
drivers/net/ethernet/broadcom/cnic.c:	u32 cid = ctx->cid;
drivers/net/ethernet/broadcom/cnic.c:	ctx->ctx_flags = 0;
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_ag_context.hq_prod = 1;
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.first_burst_length =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.max_send_pdu_length =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.sq_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.sq_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.sq_curr_pbe.lo = req2->sq_first_pte.hi;
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.sq_curr_pbe.hi = req2->sq_first_pte.lo;
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.hq_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.hq_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.hq_curr_pbe_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.hq_curr_pbe_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.r2tq_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.r2tq_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.r2tq_curr_pbe_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.r2tq_curr_pbe_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.task_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.task_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.task_pbl_cache_idx =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.flags.flags |=
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.iscsi.flags.flags |=
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.common.ethernet.reserved_vlan_type =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.common.flags =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_st_context.common.flags =
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.iscsi.hdr_bytes_2_fetch = ISCSI_HEADER_SIZE;
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.iscsi.rq_db_phy_addr.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.iscsi.rq_db_phy_addr.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.iscsi.iscsi_conn_id = req1->iscsi_conn_id;
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.tcp.cwnd = 0x5A8;
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.tcp.flags2 |=
drivers/net/ethernet/broadcom/cnic.c:	ictx->tstorm_st_context.tcp.ooo_support_mode =
drivers/net/ethernet/broadcom/cnic.c:	ictx->timers_context.flags |= TIMERS_BLOCK_CONTEXT_CONN_VALID_FLG;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.rq.pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.rq.pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.rq.curr_pbe.lo = req3->qp_first_pte[0].hi;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.rq.curr_pbe.hi = req3->qp_first_pte[0].lo;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.r2tq.pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.r2tq.pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.r2tq.curr_pbe.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.r2tq.curr_pbe.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.cq_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.cq_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.cq[0].cq_sn = ISCSI_INITIAL_SN;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.cq[0].curr_pbe.lo = req2->cq_first_pte.hi;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.ring.cq[0].curr_pbe.hi = req2->cq_first_pte.lo;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.task_pbe_cache_index =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.task_pdu_cache_index =
drivers/net/ethernet/broadcom/cnic.c:		ictx->ustorm_st_context.ring.cq[i].cq_sn = ISCSI_INITIAL_SN;
drivers/net/ethernet/broadcom/cnic.c:		ictx->ustorm_st_context.ring.cq[i].curr_pbe.lo =
drivers/net/ethernet/broadcom/cnic.c:		ictx->ustorm_st_context.ring.cq[i].curr_pbe.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.task_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.task_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.tce_phy_addr.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.tce_phy_addr.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.iscsi_conn_id = req1->iscsi_conn_id;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.num_cqs = cp->num_cqs;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.negotiated_rx |= ISCSI_DEF_MAX_RECV_SEG_LEN;
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.negotiated_rx_and_flags |=
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_st_context.negotiated_rx |=
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.hq_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.hq_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.hq_curr_pbe.lo = iscsi->hq_info.pgtbl[0];
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.hq_curr_pbe.hi = iscsi->hq_info.pgtbl[1];
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.task_pbl_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.task_pbl_base.hi =
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.cq_db_base.lo =
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.cq_db_base.hi = req1->cq_page_table_addr_hi;
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.iscsi_conn_id = req1->iscsi_conn_id;
drivers/net/ethernet/broadcom/cnic.c:	ictx->cstorm_st_context.cq_proc_en_bit_map = (1 << cp->num_cqs) - 1;
drivers/net/ethernet/broadcom/cnic.c:		ictx->cstorm_st_context.cq_c_prod_sqn_arr.sqn[i] =
drivers/net/ethernet/broadcom/cnic.c:		ictx->cstorm_st_context.cq_c_sqn_2_notify_arr.sqn[i] =
drivers/net/ethernet/broadcom/cnic.c:	ictx->xstorm_ag_context.cdu_reserved =
drivers/net/ethernet/broadcom/cnic.c:	ictx->ustorm_ag_context.cdu_usage =
drivers/net/ethernet/broadcom/cnic.c:	if (test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags)) {
drivers/net/ethernet/broadcom/cnic.c:	init_waitqueue_head(&ctx->waitq);
drivers/net/ethernet/broadcom/cnic.c:	ctx->wait_cond = 0;
drivers/net/ethernet/broadcom/cnic.c:	hw_cid = BNX2X_HW_CID(bp, ctx->cid);
drivers/net/ethernet/broadcom/cnic.c:		wait_event_timeout(ctx->waitq, ctx->wait_cond, CNIC_RAMROD_TMO);
drivers/net/ethernet/broadcom/cnic.c:		if (unlikely(test_bit(CTX_FL_CID_ERROR, &ctx->ctx_flags)))
drivers/net/ethernet/broadcom/cnic.c:	if (!test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:	if (!time_after(jiffies, ctx->timestamp + (2 * HZ))) {
drivers/net/ethernet/broadcom/cnic.c:		unsigned long delta = ctx->timestamp + (2 * HZ) - jiffies;
drivers/net/ethernet/broadcom/cnic.c:		set_bit(CTX_FL_DELETE_WAIT, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:		clear_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:		set_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:	if (test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:	cid = ctx->cid;
drivers/net/ethernet/broadcom/cnic.c:		fctx->xstorm_ag_context.cdu_reserved = val;
drivers/net/ethernet/broadcom/cnic.c:		fctx->ustorm_ag_context.cdu_usage = val;
drivers/net/ethernet/broadcom/cnic.c:		set_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:	init_waitqueue_head(&ctx->waitq);
drivers/net/ethernet/broadcom/cnic.c:	ctx->wait_cond = 0;
drivers/net/ethernet/broadcom/cnic.c:		wait_event_timeout(ctx->waitq, ctx->wait_cond, CNIC_RAMROD_TMO);
drivers/net/ethernet/broadcom/cnic.c:		if (ctx->wait_cond)
drivers/net/ethernet/broadcom/cnic.c:	set_bit(CTX_FL_DELETE_WAIT, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:		while (test_bit(CTX_FL_DELETE_WAIT, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:			if (!test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:		if (test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:				   ctx->cid);
drivers/net/ethernet/broadcom/cnic.c:				set_bit(CTX_FL_CID_ERROR, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:			ctx->wait_cond = 1;
drivers/net/ethernet/broadcom/cnic.c:			wake_up(&ctx->waitq);
drivers/net/ethernet/broadcom/cnic.c:		if (test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:	ctx->timestamp = jiffies;
drivers/net/ethernet/broadcom/cnic.c:	ctx->wait_cond = 1;
drivers/net/ethernet/broadcom/cnic.c:	wake_up(&ctx->waitq);
drivers/net/ethernet/broadcom/cnic.c:		ctx->timestamp = jiffies;
drivers/net/ethernet/broadcom/cnic.c:		if (!test_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags) ||
drivers/net/ethernet/broadcom/cnic.c:		    !test_bit(CTX_FL_DELETE_WAIT, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:		if (!time_after(jiffies, ctx->timestamp + (2 * HZ))) {
drivers/net/ethernet/broadcom/cnic.c:		if (!test_and_clear_bit(CTX_FL_DELETE_WAIT, &ctx->ctx_flags))
drivers/net/ethernet/broadcom/cnic.c:			if (ctx->ulp_proto_id == CNIC_ULP_ISCSI)
drivers/net/ethernet/broadcom/cnic.c:			clear_bit(CTX_FL_OFFLD_START, &ctx->ctx_flags);
drivers/net/ethernet/broadcom/cnic.c:		dma_addr_t map = ctx->mapping;
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (ena_rx_ctx->frag) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (unlikely((ena_rx_ctx->l3_proto == ENA_ETH_IO_L3_PROTO_IPV4) &&
drivers/net/ethernet/amazon/ena/ena_netdev.c:		     (ena_rx_ctx->l3_csum_err))) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (likely((ena_rx_ctx->l4_proto == ENA_ETH_IO_L4_PROTO_TCP) ||
drivers/net/ethernet/amazon/ena/ena_netdev.c:		   (ena_rx_ctx->l4_proto == ENA_ETH_IO_L4_PROTO_UDP))) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:		if (unlikely(ena_rx_ctx->l4_csum_err)) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:		if (likely((ena_rx_ctx->l4_proto == ENA_ETH_IO_L4_PROTO_TCP) ||
drivers/net/ethernet/amazon/ena/ena_netdev.c:			   (ena_rx_ctx->l4_proto == ENA_ETH_IO_L4_PROTO_UDP)))
drivers/net/ethernet/amazon/ena/ena_netdev.c:		if (ena_rx_ctx->frag)
drivers/net/ethernet/amazon/ena/ena_netdev.c:		skb_set_hash(skb, ena_rx_ctx->hash, hash_type);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	struct ena_com_tx_meta *ena_meta = &ena_tx_ctx->ena_meta;
drivers/net/ethernet/amazon/ena/ena_netdev.c:		ena_tx_ctx->l4_csum_enable = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->tso_enable = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l4_csum_partial = 0;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->tso_enable = 0;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l4_csum_partial = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l3_proto = ENA_ETH_IO_L3_PROTO_IPV4;
drivers/net/ethernet/amazon/ena/ena_netdev.c:				ena_tx_ctx->df = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:				ena_tx_ctx->l3_csum_enable = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l3_proto = ENA_ETH_IO_L3_PROTO_IPV6;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l4_proto = ENA_ETH_IO_L4_PROTO_TCP;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			ena_tx_ctx->l4_proto = ENA_ETH_IO_L4_PROTO_UDP;
drivers/net/ethernet/amazon/ena/ena_netdev.c:		ena_tx_ctx->meta_valid = 1;
drivers/net/ethernet/amazon/ena/ena_netdev.c:		ena_tx_ctx->meta_valid = 0;
drivers/net/ethernet/amazon/ena/ena_netdev.c:	rc = ether_addr_equal(get_feat_ctx->dev_attr.mac_addr,
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if ((get_feat_ctx->max_queues.max_cq_num < adapter->num_queues) ||
drivers/net/ethernet/amazon/ena/ena_netdev.c:	    (get_feat_ctx->max_queues.max_sq_num < adapter->num_queues)) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (get_feat_ctx->dev_attr.max_mtu < netdev->mtu) {
drivers/net/ethernet/amazon/ena/ena_netdev.c:	aenq_groups &= get_feat_ctx->aenq.supported_groups;
drivers/net/ethernet/amazon/ena/ena_netdev.c:		io_sq_num = get_feat_ctx->max_queues.max_llq_num;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			io_sq_num = get_feat_ctx->max_queues.max_sq_num;
drivers/net/ethernet/amazon/ena/ena_netdev.c:		io_sq_num = get_feat_ctx->max_queues.max_sq_num;
drivers/net/ethernet/amazon/ena/ena_netdev.c:			     get_feat_ctx->max_queues.max_cq_num);
drivers/net/ethernet/amazon/ena/ena_netdev.c:	if (has_mem_bar && (get_feat_ctx->max_queues.max_llq_num > 0))
drivers/net/ethernet/amazon/ena/ena_netdev.c:			   get_feat_ctx->max_queues.max_cq_depth);
drivers/net/ethernet/amazon/ena/ena_netdev.c:			   get_feat_ctx->max_queues.max_sq_depth);
drivers/net/ethernet/amazon/ena/ena_netdev.c:				   get_feat_ctx->max_queues.max_llq_depth);
drivers/net/ethernet/amazon/ena/ena_netdev.c:				 get_feat_ctx->max_queues.max_packet_tx_descs);
drivers/net/ethernet/amazon/ena/ena_netdev.c:				 get_feat_ctx->max_queues.max_packet_rx_descs);
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	if (ena_tx_ctx->meta_valid) {
drivers/net/ethernet/amazon/ena/ena_eth_com.c:			    &ena_tx_ctx->ena_meta,
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	struct ena_com_tx_meta *ena_meta = &ena_tx_ctx->ena_meta;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->l3_proto = cdesc->status &
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->l4_proto =
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->l3_csum_err =
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->l4_csum_err =
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->hash = cdesc->hash;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->frag =
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	pr_debug("ena_rx_ctx->l3_proto %d ena_rx_ctx->l4_proto %d\nena_rx_ctx->l3_csum_err %d ena_rx_ctx->l4_csum_err %d\nhash frag %d frag: %d cdesc_status: %x\n",
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		 ena_rx_ctx->l3_proto, ena_rx_ctx->l4_proto,
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		 ena_rx_ctx->l3_csum_err, ena_rx_ctx->l4_csum_err,
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		 ena_rx_ctx->hash, ena_rx_ctx->frag, cdesc->status);
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	struct ena_com_buf *ena_bufs = ena_tx_ctx->ena_bufs;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	void *push_header = ena_tx_ctx->push_header;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	u16 header_len = ena_tx_ctx->header_len;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	u16 num_bufs = ena_tx_ctx->num_bufs;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	have_meta = ena_tx_ctx->meta_valid && ena_com_meta_desc_changed(io_sq,
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	desc->meta_ctrl |= (ena_tx_ctx->req_id <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	desc->meta_ctrl |= (ena_tx_ctx->df <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	desc->len_ctrl |= ((ena_tx_ctx->req_id >> 10) <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	if (ena_tx_ctx->meta_valid) {
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= (ena_tx_ctx->tso_enable <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= ena_tx_ctx->l3_proto &
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= (ena_tx_ctx->l4_proto <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= (ena_tx_ctx->l3_csum_enable <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= (ena_tx_ctx->l4_csum_enable <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		desc->meta_ctrl |= (ena_tx_ctx->l4_csum_partial <<
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	struct ena_com_rx_buf_info *ena_buf = &ena_rx_ctx->ena_bufs[0];
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		ena_rx_ctx->descs = nb_hw_desc;
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	if (unlikely(nb_hw_desc > ena_rx_ctx->max_bufs)) {
drivers/net/ethernet/amazon/ena/ena_eth_com.c:		       ena_rx_ctx->max_bufs);
drivers/net/ethernet/amazon/ena/ena_eth_com.c:	ena_rx_ctx->descs = nb_hw_desc;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->occupied = false;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->status = ENA_CMD_SUBMITTED;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->comp_size = (u32)comp_size_in_bytes;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->user_cqe = comp;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->cmd_opcode = cmd->aq_common_descriptor.opcode;
drivers/net/ethernet/amazon/ena/ena_com.c:	reinit_completion(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:			init_completion(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:		set_dev_node(ena_dev->dmadev, ctx->numa_node);
drivers/net/ethernet/amazon/ena/ena_com.c:		set_dev_node(ena_dev->dmadev, ctx->numa_node);
drivers/net/ethernet/amazon/ena/ena_com.c:	set_dev_node(ena_dev->dmadev, ctx->numa_node);
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->status = ENA_CMD_COMPLETED;
drivers/net/ethernet/amazon/ena/ena_com.c:	comp_ctx->comp_status = cqe->acq_common_descriptor.status;
drivers/net/ethernet/amazon/ena/ena_com.c:	if (comp_ctx->user_cqe)
drivers/net/ethernet/amazon/ena/ena_com.c:		memcpy(comp_ctx->user_cqe, (void *)cqe, comp_ctx->comp_size);
drivers/net/ethernet/amazon/ena/ena_com.c:		complete(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:	while (comp_ctx->status == ENA_CMD_SUBMITTED) {
drivers/net/ethernet/amazon/ena/ena_com.c:	if (unlikely(comp_ctx->status == ENA_CMD_ABORTED)) {
drivers/net/ethernet/amazon/ena/ena_com.c:	WARN(comp_ctx->status != ENA_CMD_COMPLETED, "Invalid comp status %d\n",
drivers/net/ethernet/amazon/ena/ena_com.c:	     comp_ctx->status);
drivers/net/ethernet/amazon/ena/ena_com.c:	ret = ena_com_comp_status_to_errno(comp_ctx->comp_status);
drivers/net/ethernet/amazon/ena/ena_com.c:	wait_for_completion_timeout(&comp_ctx->wait_event,
drivers/net/ethernet/amazon/ena/ena_com.c:	if (unlikely(comp_ctx->status == ENA_CMD_SUBMITTED)) {
drivers/net/ethernet/amazon/ena/ena_com.c:		if (comp_ctx->status == ENA_CMD_COMPLETED)
drivers/net/ethernet/amazon/ena/ena_com.c:			       comp_ctx->cmd_opcode);
drivers/net/ethernet/amazon/ena/ena_com.c:			       comp_ctx->cmd_opcode, comp_ctx->status);
drivers/net/ethernet/amazon/ena/ena_com.c:	ret = ena_com_comp_status_to_errno(comp_ctx->comp_status);
drivers/net/ethernet/amazon/ena/ena_com.c:		comp_ctx->status = ENA_CMD_ABORTED;
drivers/net/ethernet/amazon/ena/ena_com.c:		complete(&comp_ctx->wait_event);
drivers/net/ethernet/amazon/ena/ena_com.c:	if (ctx->qid >= ENA_TOTAL_NUM_QUEUES) {
drivers/net/ethernet/amazon/ena/ena_com.c:		       ctx->qid, ENA_TOTAL_NUM_QUEUES);
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq = &ena_dev->io_sq_queues[ctx->qid];
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq = &ena_dev->io_cq_queues[ctx->qid];
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq->q_depth = ctx->queue_size;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq->direction = ctx->direction;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq->qid = ctx->qid;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_cq->msix_vector = ctx->msix_vector;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq->q_depth = ctx->queue_size;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq->direction = ctx->direction;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq->qid = ctx->qid;
drivers/net/ethernet/amazon/ena/ena_com.c:	io_sq->mem_queue_type = ctx->mem_queue_type;
drivers/net/ethernet/amazon/ena/ena_com.c:	if (ctx->direction == ENA_COM_IO_QUEUE_DIRECTION_TX)
drivers/net/ethernet/amazon/ena/ena_com.c:	memcpy(&get_feat_ctx->dev_attr, &get_resp.u.dev_attr,
drivers/net/ethernet/amazon/ena/ena_com.c:	memcpy(&get_feat_ctx->max_queues, &get_resp.u.max_queue,
drivers/net/ethernet/amazon/ena/ena_com.c:	memcpy(&get_feat_ctx->aenq, &get_resp.u.aenq,
drivers/net/ethernet/amazon/ena/ena_com.c:	memcpy(&get_feat_ctx->offload, &get_resp.u.offload,
drivers/net/ethernet/amazon/ena/ena_com.c:	struct ena_admin_aq_get_stats_cmd *get_cmd = &ctx->get_cmd;
drivers/net/ethernet/amazon/ena/ena_com.c:	struct ena_admin_acq_get_stats_resp *get_resp = &ctx->get_resp;
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->skb = skb;
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->dma = pci_map_single(np->pci_dev,
drivers/net/ethernet/nvidia/forcedeth.c:						  np->put_rx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->dma_len = skb_tailroom(skb);
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx.orig->buf = cpu_to_le32(np->put_rx_ctx->dma);
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->skb = skb;
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->dma = pci_map_single(np->pci_dev,
drivers/net/ethernet/nvidia/forcedeth.c:						  np->put_rx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx_ctx->dma_len = skb_tailroom(skb);
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx.ex->bufhigh = cpu_to_le32(dma_high(np->put_rx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_rx.ex->buflow = cpu_to_le32(dma_low(np->put_rx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma = pci_map_single(np->pci_dev, skb->data + offset, bcnt,
drivers/net/ethernet/nvidia/forcedeth.c:					  np->put_tx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma_len = bcnt;
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma_single = 1;
drivers/net/ethernet/nvidia/forcedeth.c:		put_tx->buf = cpu_to_le32(np->put_tx_ctx->dma);
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma = skb_frag_dma_map(
drivers/net/ethernet/nvidia/forcedeth.c:			if (dma_mapping_error(&np->pci_dev->dev, np->put_tx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma_len = bcnt;
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma_single = 0;
drivers/net/ethernet/nvidia/forcedeth.c:			put_tx->buf = cpu_to_le32(np->put_tx_ctx->dma);
drivers/net/ethernet/nvidia/forcedeth.c:	prev_tx_ctx->skb = skb;
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma = pci_map_single(np->pci_dev, skb->data + offset, bcnt,
drivers/net/ethernet/nvidia/forcedeth.c:					  np->put_tx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma_len = bcnt;
drivers/net/ethernet/nvidia/forcedeth.c:		np->put_tx_ctx->dma_single = 1;
drivers/net/ethernet/nvidia/forcedeth.c:		put_tx->bufhigh = cpu_to_le32(dma_high(np->put_tx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:		put_tx->buflow = cpu_to_le32(dma_low(np->put_tx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma = skb_frag_dma_map(
drivers/net/ethernet/nvidia/forcedeth.c:			if (dma_mapping_error(&np->pci_dev->dev, np->put_tx_ctx->dma)) {
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma_len = bcnt;
drivers/net/ethernet/nvidia/forcedeth.c:			np->put_tx_ctx->dma_single = 0;
drivers/net/ethernet/nvidia/forcedeth.c:			put_tx->bufhigh = cpu_to_le32(dma_high(np->put_tx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:			put_tx->buflow = cpu_to_le32(dma_low(np->put_tx_ctx->dma));
drivers/net/ethernet/nvidia/forcedeth.c:	prev_tx_ctx->skb = skb;
drivers/net/ethernet/nvidia/forcedeth.c:			start_tx_ctx->first_tx_desc = start_tx;
drivers/net/ethernet/nvidia/forcedeth.c:			start_tx_ctx->next_tx_ctx = np->put_tx_ctx;
drivers/net/ethernet/nvidia/forcedeth.c:					np->stat_tx_bytes += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:				bytes_compl += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:				dev_kfree_skb_any(np->get_tx_ctx->skb);
drivers/net/ethernet/nvidia/forcedeth.c:				np->get_tx_ctx->skb = NULL;
drivers/net/ethernet/nvidia/forcedeth.c:					np->stat_tx_bytes += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:				bytes_compl += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:				dev_kfree_skb_any(np->get_tx_ctx->skb);
drivers/net/ethernet/nvidia/forcedeth.c:				np->get_tx_ctx->skb = NULL;
drivers/net/ethernet/nvidia/forcedeth.c:				np->stat_tx_bytes += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:			bytes_cleaned += np->get_tx_ctx->skb->len;
drivers/net/ethernet/nvidia/forcedeth.c:			dev_kfree_skb_any(np->get_tx_ctx->skb);
drivers/net/ethernet/nvidia/forcedeth.c:			np->get_tx_ctx->skb = NULL;
drivers/net/ethernet/nvidia/forcedeth.c:		pci_unmap_single(np->pci_dev, np->get_rx_ctx->dma,
drivers/net/ethernet/nvidia/forcedeth.c:				np->get_rx_ctx->dma_len,
drivers/net/ethernet/nvidia/forcedeth.c:		skb = np->get_rx_ctx->skb;
drivers/net/ethernet/nvidia/forcedeth.c:		np->get_rx_ctx->skb = NULL;
drivers/net/ethernet/nvidia/forcedeth.c:		pci_unmap_single(np->pci_dev, np->get_rx_ctx->dma,
drivers/net/ethernet/nvidia/forcedeth.c:				np->get_rx_ctx->dma_len,
drivers/net/ethernet/nvidia/forcedeth.c:		skb = np->get_rx_ctx->skb;
drivers/net/ethernet/nvidia/forcedeth.c:		np->get_rx_ctx->skb = NULL;
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = spi_write(ctx->spi, &bank_opcode, 1);
drivers/net/ethernet/microchip/encx24j600-regmap.c:		ctx->bank = bank;
drivers/net/ethernet/microchip/encx24j600-regmap.c:	return spi_sync(ctx->spi, &m);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	mutex_lock(&ctx->mutex);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	mutex_unlock(&ctx->mutex);
drivers/net/ethernet/microchip/encx24j600-regmap.c:		if ((banked_reg < 0x16) && (ctx->bank != bank))
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = spi_write_then_read(ctx->spi, tx_buf, i, val, len);
drivers/net/ethernet/microchip/encx24j600-regmap.c:		if ((banked_reg < 0x16) && (ctx->bank != bank))
drivers/net/ethernet/microchip/encx24j600-regmap.c:	return spi_sync(ctx->spi, &m);
drivers/net/ethernet/microchip/encx24j600-regmap.c:		return spi_write(ctx->spi, &reg, 1);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	return spi_write_then_read(ctx->spi, &reg, sizeof(reg), data, count);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_write(ctx->regmap, MIREGADR, reg);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_write(ctx->regmap, MICMD, MIIRD);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	while ((ret = regmap_read(ctx->regmap, MISTAT, &mistat) != 0) &&
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_write(ctx->regmap, MICMD, 0);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_read(ctx->regmap, MIRD, val);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_write(ctx->regmap, MIREGADR, reg);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ret = regmap_write(ctx->regmap, MIWR, val);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	while ((ret = regmap_read(ctx->regmap, MISTAT, &mistat) != 0) &&
drivers/net/ethernet/microchip/encx24j600-regmap.c:	mutex_init(&ctx->mutex);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ctx->regmap = devm_regmap_init(dev, &regmap_encx24j600, ctx, &regcfg);
drivers/net/ethernet/microchip/encx24j600-regmap.c:	ctx->phymap = devm_regmap_init(dev, &phymap_encx24j600, ctx, &phycfg);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		sds_ring = &adapter->recv_ctx->sds_rings[0];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	context_id = recv_ctx->context_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		sds = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		sds = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	cmd.req.arg[1] = recv_ctx->context_id | temp;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	recv_ctx->state = QLCNIC_HOST_CTX_STATE_FREED;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		sds = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	rds = &recv_ctx->rds_rings[0];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	rds = &recv_ctx->rds_rings[1];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	recv_ctx->context_id = mbx_out->ctx_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	recv_ctx->state = mbx_out->state;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	recv_ctx->virt_port = mbx_out->vport_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		 recv_ctx->context_id, recv_ctx->state);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	rds = &recv_ctx->rds_rings[0];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	rds = &recv_ctx->rds_rings[1];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		sds = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:		rds_ring = &adapter->recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			sds_ring = &adapter->recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			sds_ring = &adapter->recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	temp = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			*interface_id = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	if (adapter->recv_ctx->state == QLCNIC_HOST_CTX_STATE_FREED)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			*interface_id = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	if (adapter->recv_ctx->state == QLCNIC_HOST_CTX_STATE_FREED)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	temp = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	cmd.req.arg[1] = (adapter->recv_ctx->context_id);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:			*interface_id = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	if (adapter->recv_ctx->state == QLCNIC_HOST_CTX_STATE_FREED)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	temp = adapter->recv_ctx->context_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	if (adapter->recv_ctx->state == QLCNIC_HOST_CTX_STATE_FREED)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_83xx_hw.c:	cmd.req.arg[1] = adapter->recv_ctx->context_id << 16;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	if (recv_ctx->state != QLCNIC_HOST_CTX_STATE_ACTIVE)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	cmd.req.arg[1] = recv_ctx->context_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		rds_ring = &recv_ctx->rds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		sds_ring = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		rds_ring = &recv_ctx->rds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		sds_ring = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	recv_ctx->state = le32_to_cpu(prsp->host_ctx_state);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	recv_ctx->context_id = le16_to_cpu(prsp->context_id);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	recv_ctx->virt_port = prsp->virt_port;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		    recv_ctx->context_id, recv_ctx->state);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	cmd.req.arg[1] = recv_ctx->context_id;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:	recv_ctx->state = QLCNIC_HOST_CTX_STATE_FREED;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ctx.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:	recv_ctx->sds_rings = kzalloc(size, GFP_KERNEL);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:	return recv_ctx->sds_rings == NULL;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:	kfree(recv_ctx->sds_rings);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:	recv_ctx->sds_rings = NULL;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:				sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:				sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:		rds_ring = &adapter->recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:			sds_ring = &adapter->recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:		rds_ring = &adapter->recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:			sds_ring = &adapter->recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:		sds_ring = &(recv_ctx->sds_rings[ring]);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:	if (recv_ctx->rds_rings == NULL)
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:	kfree(recv_ctx->rds_rings);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:	recv_ctx->rds_rings = rds_ring;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_init.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		rds_ring = &adapter->recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		rds_ring = &adapter->recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ethtool.c:		rds_rings = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ethtool.c:		sds_ring = &(recv_ctx->sds_rings[ring]);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ethtool.c:	struct qlcnic_host_sds_ring *sds_ring = &recv_ctx->sds_rings[0];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_ethtool.c:	sds_ring = &adapter->recv_ctx->sds_rings[0];
drivers/net/ethernet/qlogic/qlge/qlge_main.c:			   ctx->intr_en_mask);
drivers/net/ethernet/qlogic/qlge/qlge_main.c:	if (atomic_dec_and_test(&ctx->irq_cnt)) {
drivers/net/ethernet/qlogic/qlge/qlge_main.c:			   ctx->intr_en_mask);
drivers/net/ethernet/qlogic/qlge/qlge_main.c:	if (!atomic_read(&ctx->irq_cnt)) {
drivers/net/ethernet/qlogic/qlge/qlge_main.c:		ctx->intr_dis_mask);
drivers/net/ethernet/qlogic/qlge/qlge_main.c:	atomic_inc(&ctx->irq_cnt);
drivers/net/ethernet/qlogic/qlge/qlge_main.c:		if ((ctx->irq_mask & (1 << trx_ring->cq_id)) &&
drivers/net/ethernet/qlogic/qlge/qlge_main.c:	int j, vect = ctx->intr;
drivers/net/ethernet/qlogic/qlge/qlge_main.c:		ctx->irq_mask = (1 << qdev->rx_ring[vect].cq_id);
drivers/net/ethernet/qlogic/qlge/qlge_main.c:			ctx->irq_mask |=
drivers/net/ethernet/qlogic/qlge/qlge_main.c:			ctx->irq_mask |= (1 << qdev->rx_ring[j].cq_id);
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:	if (recv_ctx->rds_rings == NULL)
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:	kfree(recv_ctx->rds_rings);
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:	recv_ctx->rds_rings = rds_ring;
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_init.c:	rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	cmd.req.arg1 = recv_ctx->context_id;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	if (recv_ctx->state == NX_HOST_CTX_STATE_ACTIVE)
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		rds_ring = &recv_ctx->rds_rings[i];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		sds_ring = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		rds_ring = &recv_ctx->rds_rings[i];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		sds_ring = &recv_ctx->sds_rings[i];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->state = le32_to_cpu(prsp->host_ctx_state);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->context_id = le16_to_cpu(prsp->context_id);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->virt_port = prsp->virt_port;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	cmd.req.arg1 = recv_ctx->context_id;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	offset = recv_ctx->phys_addr + sizeof(struct netxen_ring_ctx);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	hwctx = recv_ctx->hwctx;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	hwctx->cmd_ring_addr = cpu_to_le64(tx_ring->phys_addr);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	hwctx->cmd_ring_size = cpu_to_le32(tx_ring->num_desc);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		hwctx->rcv_rings[ring].addr =
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		hwctx->rcv_rings[ring].size =
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:			hwctx->sts_ring_addr = cpu_to_le64(sds_ring->phys_addr);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:			hwctx->sts_ring_size = cpu_to_le32(sds_ring->num_desc);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		hwctx->sts_rings[ring].addr = cpu_to_le64(sds_ring->phys_addr);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		hwctx->sts_rings[ring].size = cpu_to_le32(sds_ring->num_desc);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		hwctx->sts_rings[ring].msi_index = cpu_to_le16(ring);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	hwctx->sts_ring_count = cpu_to_le32(adapter->max_sds_rings);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:			lower32(recv_ctx->phys_addr));
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:			upper32(recv_ctx->phys_addr));
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:			&recv_ctx->phys_addr);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->hwctx = addr;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->hwctx->ctx_id = cpu_to_le32(port);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	recv_ctx->hwctx->cmd_consumer_offset =
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		cpu_to_le64(recv_ctx->phys_addr +
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:	if (recv_ctx->hwctx != NULL) {
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:				recv_ctx->hwctx,
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:				recv_ctx->phys_addr);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		recv_ctx->hwctx = NULL;
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		rds_ring = &recv_ctx->rds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ctx.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_ethtool.c:			 recv_ctx->rds_rings[0].crb_rcv_producer);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ethtool.c:			 recv_ctx->rds_rings[1].crb_rcv_producer);
drivers/net/ethernet/qlogic/netxen/netxen_nic_ethtool.c:		sds_ring = &(recv_ctx->sds_rings[ring]);
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:	recv_ctx->sds_rings = kzalloc(size, GFP_KERNEL);
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:	return recv_ctx->sds_rings == NULL;
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:	kfree(recv_ctx->sds_rings);
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:	recv_ctx->sds_rings = NULL;
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/qlogic/netxen/netxen_nic_main.c:		sds_ring = &recv_ctx->sds_rings[ring];
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	oct = lio_get_device(mdio_cmd_ctx->octeon_id);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:		WRITE_ONCE(mdio_cmd_ctx->cond, -1);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:		WRITE_ONCE(mdio_cmd_ctx->cond, 1);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	wake_up_interruptible(&mdio_cmd_ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	WRITE_ONCE(mdio_cmd_ctx->cond, 0);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	mdio_cmd_ctx->octeon_id = lio_get_device_id(oct_dev);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	init_waitqueue_head(&mdio_cmd_ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:		sleep_cond(&mdio_cmd_ctx->wc, &mdio_cmd_ctx->cond);
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:			if (READ_ONCE(mdio_cmd_ctx->cond) == 1) {
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	/*per_core_stats[cvmx_get_core_num()].link_stats[lro_ctx->ifidx].
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	/*per_core_stats[cvmx_get_core_num()].link_stats[lro_ctx->ifidx].
drivers/net/ethernet/cavium/liquidio/lio_ethtool.c:	/*per_core_stats[cvmx_get_core_num()].link_stats[lro_ctx->ifidx].
drivers/net/ethernet/cavium/liquidio/lio_main.c:	oct = lio_get_device(ctx->octeon_id);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	WRITE_ONCE(ctx->cond, 1);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	wake_up_interruptible(&ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	WRITE_ONCE(ctx->cond, 0);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	ctx->octeon_id = lio_get_device_id(oct);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	init_waitqueue_head(&ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		if (sleep_cond(&ctx->wc, &ctx->cond) == -EINTR)
drivers/net/ethernet/cavium/liquidio/lio_main.c:	oct = lio_get_device(ctx->octeon_id);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	WRITE_ONCE(ctx->cond, 1);
drivers/net/ethernet/cavium/liquidio/lio_main.c:	wake_up_interruptible(&ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		WRITE_ONCE(ctx->cond, 0);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		ctx->octeon_id = lio_get_device_id(octeon_dev);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		init_waitqueue_head(&ctx->wc);
drivers/net/ethernet/cavium/liquidio/lio_main.c:		if (sleep_cond(&ctx->wc, &ctx->cond) == -EINTR) {
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->uplink_seid = cpu_to_le16(vsi_ctx->uplink_seid);
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->connection_type = vsi_ctx->connection_type;
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->vf_id = vsi_ctx->vf_num;
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->vsi_flags = cpu_to_le16(vsi_ctx->flags);
drivers/net/ethernet/intel/i40e/i40e_common.c:	status = i40e_asq_send_command(hw, &desc, &vsi_ctx->info,
drivers/net/ethernet/intel/i40e/i40e_common.c:				    sizeof(vsi_ctx->info), cmd_details);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->seid = le16_to_cpu(resp->seid);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsi_number = le16_to_cpu(resp->vsi_number);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_allocated = le16_to_cpu(resp->vsi_used);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_unallocated = le16_to_cpu(resp->vsi_free);
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->uplink_seid = cpu_to_le16(vsi_ctx->seid);
drivers/net/ethernet/intel/i40e/i40e_common.c:	status = i40e_asq_send_command(hw, &desc, &vsi_ctx->info,
drivers/net/ethernet/intel/i40e/i40e_common.c:				    sizeof(vsi_ctx->info), NULL);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->seid = le16_to_cpu(resp->seid);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsi_number = le16_to_cpu(resp->vsi_number);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_allocated = le16_to_cpu(resp->vsi_used);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_unallocated = le16_to_cpu(resp->vsi_free);
drivers/net/ethernet/intel/i40e/i40e_common.c:	cmd->uplink_seid = cpu_to_le16(vsi_ctx->seid);
drivers/net/ethernet/intel/i40e/i40e_common.c:	status = i40e_asq_send_command(hw, &desc, &vsi_ctx->info,
drivers/net/ethernet/intel/i40e/i40e_common.c:				    sizeof(vsi_ctx->info), cmd_details);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_allocated = le16_to_cpu(resp->vsi_used);
drivers/net/ethernet/intel/i40e/i40e_common.c:	vsi_ctx->vsis_unallocated = le16_to_cpu(resp->vsi_free);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:		ctx->result = 0;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:		complete(&ctx->completion);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				ctx->result = 0;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				ctx->result = -ENOMEM;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				ctx->result = 0;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				ctx->tid = idx;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:				ctx->result = -EINVAL;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:			complete(&ctx->completion);
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:	u32			ts = (be32_to_cpu(qp_ctx->flags) >> 16) & 0xff;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:		port = (qp_ctx->pri_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:			qp_ctx->pri_path.mgid_index =
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:			qp_ctx->pri_path.mgid_index = slave | 0x80;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:			port = (qp_ctx->pri_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->pri_path.mgid_index +=
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->pri_path.mgid_index &= 0x7f;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->pri_path.mgid_index = slave & 0x7F;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:			port = (qp_ctx->alt_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->alt_path.mgid_index +=
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->alt_path.mgid_index &= 0x7f;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:				qp_ctx->alt_path.mgid_index = slave & 0x7F;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:	qp_type	= (be32_to_cpu(qp_ctx->flags) >> 16) & 0xff;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:		qp_ctx->params2 &= ~MLX4_QP_BIT_FPP;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:		if (qp_ctx->rate_limit_params)
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:					port = (qp_ctx->pri_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:					if (qp_ctx->pri_path.mgid_index >= num_gids)
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:					port = (qp_ctx->alt_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:					if (qp_ctx->alt_path.mgid_index >= num_gids)
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:		port = (qp_ctx->pri_path.sched_queue >> 6 & 1) + 1;
drivers/net/ethernet/mellanox/mlx4/eq.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx4/eq.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:		out_param[i].bw_share = be32_to_cpu(ctx->qos_p_up[i].bw_share);
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:			be32_to_cpu(ctx->qos_p_up[i].max_avg_bw);
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:			!!(be32_to_cpu(ctx->qos_p_up[i].enable) & 31);
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:		ctx->qos_p_up[i].bw_share = cpu_to_be32(in_param[i].bw_share);
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:		ctx->qos_p_up[i].max_avg_bw =
drivers/net/ethernet/mellanox/mlx4/fw_qos.c:		ctx->qos_p_up[i].enable =
drivers/net/ethernet/mellanox/mlx4/intf.c:	dev_ctx->intf    = intf;
drivers/net/ethernet/mellanox/mlx4/intf.c:	dev_ctx->context = intf->add(&priv->dev);
drivers/net/ethernet/mellanox/mlx4/intf.c:	if (dev_ctx->context) {
drivers/net/ethernet/mellanox/mlx4/intf.c:		list_add_tail(&dev_ctx->list, &priv->ctx_list);
drivers/net/ethernet/mellanox/mlx4/intf.c:			intf->activate(&priv->dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx4/intf.c:		if (dev_ctx->intf == intf) {
drivers/net/ethernet/mellanox/mlx4/intf.c:			list_del(&dev_ctx->list);
drivers/net/ethernet/mellanox/mlx4/intf.c:			intf->remove(&priv->dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx4/intf.c:		if (dev_ctx->intf->flags & MLX4_INTFF_BONDING) {
drivers/net/ethernet/mellanox/mlx4/intf.c:			list_add_tail(&dev_ctx->bond_list, &bond_list);
drivers/net/ethernet/mellanox/mlx4/intf.c:			list_del(&dev_ctx->list);
drivers/net/ethernet/mellanox/mlx4/intf.c:		dev_ctx->intf->remove(dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx4/intf.c:		dev_ctx->context =  dev_ctx->intf->add(dev);
drivers/net/ethernet/mellanox/mlx4/intf.c:		list_add_tail(&dev_ctx->list, &priv->ctx_list);
drivers/net/ethernet/mellanox/mlx4/intf.c:			 dev_ctx->intf->protocol, enable ?
drivers/net/ethernet/mellanox/mlx4/intf.c:		if (dev_ctx->intf->event)
drivers/net/ethernet/mellanox/mlx4/intf.c:			dev_ctx->intf->event(dev, dev_ctx->context, type, param);
drivers/net/ethernet/mellanox/mlx4/intf.c:		if (dev_ctx->intf->protocol == proto && dev_ctx->intf->get_dev) {
drivers/net/ethernet/mellanox/mlx4/intf.c:			result = dev_ctx->intf->get_dev(dev, dev_ctx->context, port);
drivers/net/ethernet/mellanox/mlx4/cq.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx4/cq.c:	list_splice_tail_init(&ctx->list, &ctx->process_list);
drivers/net/ethernet/mellanox/mlx4/cq.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx4/cq.c:	list_for_each_entry_safe(mcq, temp, &ctx->process_list, tasklet_ctx.list) {
drivers/net/ethernet/mellanox/mlx4/cq.c:	if (!list_empty(&ctx->process_list))
drivers/net/ethernet/mellanox/mlx4/cq.c:		tasklet_schedule(&ctx->task);
drivers/net/ethernet/mellanox/mlx4/cq.c:	spin_lock_irqsave(&tasklet_ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx4/cq.c:		list_add_tail(&cq->tasklet_ctx.list, &tasklet_ctx->list);
drivers/net/ethernet/mellanox/mlx4/cq.c:	spin_unlock_irqrestore(&tasklet_ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = (unsigned long)mlx5_qp_state_str(be32_to_cpu(ctx->flags) >> 28);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = (unsigned long)mlx5_qp_type_str((be32_to_cpu(ctx->flags) >> 16) & 0xff);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		switch (ctx->mtu_msgmax >> 5) {
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = 1 << ((ctx->rq_size_stride >> 3) & 0xf);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = 1 << ((ctx->rq_size_stride & 7) + 4);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		no_sq = be16_to_cpu(ctx->sq_crq_size) >> 15;
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:			param = 1 << (be16_to_cpu(ctx->sq_crq_size) >> 11);
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = (be32_to_cpu(ctx->log_pg_sz_remote_qpn) >> 24) & 0x1f;
drivers/net/ethernet/mellanox/mlx5/core/debugfs.c:		param = be32_to_cpu(ctx->log_pg_sz_remote_qpn) & 0xffffff;
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	dev_ctx->intf = intf;
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	dev_ctx->context = intf->add(dev);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	set_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		set_bit(MLX5_INTERFACE_ATTACHED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	if (dev_ctx->context) {
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		list_add_tail(&dev_ctx->list, &priv->ctx_list);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (dev_ctx->intf == intf)
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	list_del(&dev_ctx->list);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:	if (test_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state))
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		intf->remove(dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (test_bit(MLX5_INTERFACE_ATTACHED, &dev_ctx->state))
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		intf->attach(dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		set_bit(MLX5_INTERFACE_ATTACHED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (test_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state))
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		dev_ctx->context = intf->add(dev);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		set_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (!test_bit(MLX5_INTERFACE_ATTACHED, &dev_ctx->state))
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		intf->detach(dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		clear_bit(MLX5_INTERFACE_ATTACHED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (!test_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state))
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		intf->remove(dev, dev_ctx->context);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		clear_bit(MLX5_INTERFACE_ADDED, &dev_ctx->state);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if ((dev_ctx->intf->protocol == protocol) &&
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		    dev_ctx->intf->get_dev) {
drivers/net/ethernet/mellanox/mlx5/core/dev.c:			result = dev_ctx->intf->get_dev(dev_ctx->context);
drivers/net/ethernet/mellanox/mlx5/core/dev.c:		if (dev_ctx->intf->event)
drivers/net/ethernet/mellanox/mlx5/core/dev.c:			dev_ctx->intf->event(dev, dev_ctx->context, event, param);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	list_splice_tail_init(&ctx->list, &ctx->process_list);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	list_for_each_entry_safe(mcq, temp, &ctx->process_list,
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	if (!list_empty(&ctx->process_list))
drivers/net/ethernet/mellanox/mlx5/core/cq.c:		tasklet_schedule(&ctx->task);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	spin_lock_irqsave(&tasklet_ctx->lock, flags);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:		list_add_tail(&cq->tasklet_ctx.list, &tasklet_ctx->list);
drivers/net/ethernet/mellanox/mlx5/core/cq.c:	spin_unlock_irqrestore(&tasklet_ctx->lock, flags);
drivers/net/hyperv/netvsc.c:	struct hv_device *dev = net_device_ctx->device_ctx;
drivers/net/hyperv/netvsc.c:	struct netvsc_device *nv_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc.c:	struct netvsc_device *net_device = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc.c:	net_device_ctx->nvdev = NULL;
drivers/net/hyperv/netvsc.c:	    !net_device_ctx->start_remove &&
drivers/net/hyperv/netvsc.c:	net_device_ctx->vf_alloc = nvmsg->msg.v4_msg.vf_assoc.allocated;
drivers/net/hyperv/netvsc.c:	net_device_ctx->vf_serial = nvmsg->msg.v4_msg.vf_assoc.serial;
drivers/net/hyperv/netvsc.c:	net_device_ctx->nvdev = net_device;
drivers/net/hyperv/netvsc_drv.c:	struct hv_device *device_obj = ndevctx->device_ctx;
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvdev = ndevctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	schedule_work(&net_device_ctx->work);
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	cancel_work_sync(&net_device_ctx->work);
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvsc_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:		++net_device_ctx->eth_stats.tx_scattered;
drivers/net/hyperv/netvsc_drv.c:			++net_device_ctx->eth_stats.tx_too_big;
drivers/net/hyperv/netvsc_drv.c:	ret = netvsc_send(net_device_ctx->device_ctx, packet,
drivers/net/hyperv/netvsc_drv.c:		struct netvsc_stats *tx_stats = this_cpu_ptr(net_device_ctx->tx_stats);
drivers/net/hyperv/netvsc_drv.c:		++net_device_ctx->eth_stats.tx_busy;
drivers/net/hyperv/netvsc_drv.c:		++net_device_ctx->eth_stats.tx_no_space;
drivers/net/hyperv/netvsc_drv.c:	++net_device_ctx->eth_stats.tx_no_memory;
drivers/net/hyperv/netvsc_drv.c:		ndev_ctx->speed = speed;
drivers/net/hyperv/netvsc_drv.c:	spin_lock_irqsave(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:	list_add_tail(&event->list, &ndev_ctx->reconfig_events);
drivers/net/hyperv/netvsc_drv.c:	spin_unlock_irqrestore(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:	schedule_delayed_work(&ndev_ctx->dwork, 0);
drivers/net/hyperv/netvsc_drv.c:	vf_netdev = rcu_dereference(net_device_ctx->vf_netdev);
drivers/net/hyperv/netvsc_drv.c:	rx_stats = this_cpu_ptr(net_device_ctx->rx_stats);
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	struct hv_device *dev = net_device_ctx->device_ctx;
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	if (net_device_ctx->start_remove || !nvdev || nvdev->destroy)
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->start_remove = true;
drivers/net/hyperv/netvsc_drv.c:	nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->start_remove = false;
drivers/net/hyperv/netvsc_drv.c:	schedule_delayed_work(&net_device_ctx->dwork, 0);
drivers/net/hyperv/netvsc_drv.c:	struct netvsc_device *nvdev = ndevctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	struct hv_device *hdev = ndevctx->device_ctx;
drivers/net/hyperv/netvsc_drv.c:	if (ndevctx->start_remove || !nvdev || nvdev->destroy)
drivers/net/hyperv/netvsc_drv.c:	ndevctx->start_remove = true;
drivers/net/hyperv/netvsc_drv.c:	ndevctx->start_remove = false;
drivers/net/hyperv/netvsc_drv.c:	schedule_delayed_work(&ndevctx->dwork, 0);
drivers/net/hyperv/netvsc_drv.c:		struct netvsc_stats *tx_stats = per_cpu_ptr(ndev_ctx->tx_stats,
drivers/net/hyperv/netvsc_drv.c:		struct netvsc_stats *rx_stats = per_cpu_ptr(ndev_ctx->rx_stats,
drivers/net/hyperv/netvsc_drv.c:	struct hv_device *device_obj = ndev_ctx->device_ctx;
drivers/net/hyperv/netvsc_drv.c:		schedule_delayed_work(&ndev_ctx->dwork, LINKCHANGE_INT);
drivers/net/hyperv/netvsc_drv.c:	if (ndev_ctx->start_remove)
drivers/net/hyperv/netvsc_drv.c:	net_device = ndev_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	next_reconfig = ndev_ctx->last_reconfig + LINKCHANGE_INT;
drivers/net/hyperv/netvsc_drv.c:		schedule_delayed_work(&ndev_ctx->dwork, delay);
drivers/net/hyperv/netvsc_drv.c:	ndev_ctx->last_reconfig = jiffies;
drivers/net/hyperv/netvsc_drv.c:	spin_lock_irqsave(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:	if (!list_empty(&ndev_ctx->reconfig_events)) {
drivers/net/hyperv/netvsc_drv.c:		event = list_first_entry(&ndev_ctx->reconfig_events,
drivers/net/hyperv/netvsc_drv.c:		reschedule = !list_empty(&ndev_ctx->reconfig_events);
drivers/net/hyperv/netvsc_drv.c:	spin_unlock_irqrestore(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:			spin_lock_irqsave(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:			list_add(&event->list, &ndev_ctx->reconfig_events);
drivers/net/hyperv/netvsc_drv.c:			spin_unlock_irqrestore(&ndev_ctx->lock, flags);
drivers/net/hyperv/netvsc_drv.c:		schedule_delayed_work(&ndev_ctx->dwork, LINKCHANGE_INT);
drivers/net/hyperv/netvsc_drv.c:	free_percpu(net_device_ctx->tx_stats);
drivers/net/hyperv/netvsc_drv.c:	free_percpu(net_device_ctx->rx_stats);
drivers/net/hyperv/netvsc_drv.c:		if (net_device_ctx->nvdev == NULL)
drivers/net/hyperv/netvsc_drv.c:		if (rtnl_dereference(net_device_ctx->vf_netdev) == vf_netdev)
drivers/net/hyperv/netvsc_drv.c:	netvsc_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	if (!netvsc_dev || rtnl_dereference(net_device_ctx->vf_netdev))
drivers/net/hyperv/netvsc_drv.c:	rcu_assign_pointer(net_device_ctx->vf_netdev, vf_netdev);
drivers/net/hyperv/netvsc_drv.c:	netvsc_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	netvsc_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	netvsc_dev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	RCU_INIT_POINTER(net_device_ctx->vf_netdev, NULL);
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->device_ctx = dev;
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->msg_enable = netif_msg_init(debug, default_msg);
drivers/net/hyperv/netvsc_drv.c:			   net_device_ctx->msg_enable);
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->tx_stats = netdev_alloc_pcpu_stats(struct netvsc_stats);
drivers/net/hyperv/netvsc_drv.c:	if (!net_device_ctx->tx_stats) {
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->rx_stats = netdev_alloc_pcpu_stats(struct netvsc_stats);
drivers/net/hyperv/netvsc_drv.c:	if (!net_device_ctx->rx_stats) {
drivers/net/hyperv/netvsc_drv.c:		free_percpu(net_device_ctx->tx_stats);
drivers/net/hyperv/netvsc_drv.c:	net_device_ctx->start_remove = false;
drivers/net/hyperv/netvsc_drv.c:	INIT_DELAYED_WORK(&net_device_ctx->dwork, netvsc_link_change);
drivers/net/hyperv/netvsc_drv.c:	INIT_WORK(&net_device_ctx->work, do_set_multicast);
drivers/net/hyperv/netvsc_drv.c:	spin_lock_init(&net_device_ctx->lock);
drivers/net/hyperv/netvsc_drv.c:	INIT_LIST_HEAD(&net_device_ctx->reconfig_events);
drivers/net/hyperv/netvsc_drv.c:	nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	net_device = ndev_ctx->nvdev;
drivers/net/hyperv/netvsc_drv.c:	ndev_ctx->start_remove = true;
drivers/net/hyperv/netvsc_drv.c:	cancel_delayed_work_sync(&ndev_ctx->dwork);
drivers/net/hyperv/netvsc_drv.c:	cancel_work_sync(&ndev_ctx->work);
drivers/net/hyperv/rndis_filter.c:	ret = netvsc_send(net_device_ctx->device_ctx, packet, NULL, &pb, NULL);
drivers/net/hyperv/rndis_filter.c:	return netvsc_recv_callback(net_device_ctx->device_ctx, pkt, data,
drivers/net/hyperv/rndis_filter.c:	struct netvsc_device *net_dev = net_device_ctx->nvdev;
drivers/net/hyperv/rndis_filter.c:	struct netvsc_device *nvdev = net_device_ctx->nvdev;
drivers/net/hyperv/rndis_filter.c:	struct hv_device *hdev = net_device_ctx->device_ctx;
drivers/net/hyperv/rndis_filter.c:	net_device = net_device_ctx->nvdev;
drivers/net/vmxnet3/vmxnet3_drv.c:	BUG_ON(ctx->copy_size > skb_headlen(skb));
drivers/net/vmxnet3/vmxnet3_drv.c:	ctx->sop_txd = tq->tx_ring.base + tq->tx_ring.next2fill;
drivers/net/vmxnet3/vmxnet3_drv.c:	gdesc = ctx->sop_txd; /* both loops below can be skipped */
drivers/net/vmxnet3/vmxnet3_drv.c:	if (ctx->copy_size) {
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->sop_txd->txd.addr = cpu_to_le64(tq->data_ring.basePA +
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->sop_txd->dword[2] = cpu_to_le32(dw2 | ctx->copy_size);
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->sop_txd->dword[3] = 0;
drivers/net/vmxnet3/vmxnet3_drv.c:			le64_to_cpu(ctx->sop_txd->txd.addr),
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->sop_txd->dword[2], ctx->sop_txd->dword[3]);
drivers/net/vmxnet3/vmxnet3_drv.c:	len = skb_headlen(skb) - ctx->copy_size;
drivers/net/vmxnet3/vmxnet3_drv.c:	buf_offset = ctx->copy_size;
drivers/net/vmxnet3/vmxnet3_drv.c:	ctx->eop_txd = gdesc;
drivers/net/vmxnet3/vmxnet3_drv.c:	tbi->sop_idx = ctx->sop_txd - tq->tx_ring.base;
drivers/net/vmxnet3/vmxnet3_drv.c: *    2. ctx->copy_size is # of bytes copied
drivers/net/vmxnet3/vmxnet3_drv.c:	if (ctx->mss) {	/* TSO */
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->eth_ip_hdr_size = skb_transport_offset(skb);
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->l4_hdr_size = tcp_hdrlen(skb);
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->copy_size = ctx->eth_ip_hdr_size + ctx->l4_hdr_size;
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->eth_ip_hdr_size = skb_checksum_start_offset(skb);
drivers/net/vmxnet3/vmxnet3_drv.c:			if (ctx->ipv4) {
drivers/net/vmxnet3/vmxnet3_drv.c:			} else if (ctx->ipv6) {
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->l4_hdr_size = tcp_hdrlen(skb);
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->l4_hdr_size = sizeof(struct udphdr);
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->l4_hdr_size = 0;
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->copy_size = min(ctx->eth_ip_hdr_size +
drivers/net/vmxnet3/vmxnet3_drv.c:					 ctx->l4_hdr_size, skb->len);
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->eth_ip_hdr_size = 0;
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->l4_hdr_size = 0;
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->copy_size = min_t(unsigned int,
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->copy_size = skb->len;
drivers/net/vmxnet3/vmxnet3_drv.c:		if (unlikely(!pskb_may_pull(skb, ctx->copy_size)))
drivers/net/vmxnet3/vmxnet3_drv.c:	if (unlikely(ctx->copy_size > tq->txdata_desc_size)) {
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->copy_size = 0;
drivers/net/vmxnet3/vmxnet3_drv.c:	memcpy(tdd->data, skb->data, ctx->copy_size);
drivers/net/vmxnet3/vmxnet3_drv.c:		ctx->copy_size, tq->tx_ring.next2fill);
drivers/net/vmxnet3/vmxnet3_drv.c:	if (ctx->ipv4) {
drivers/net/vmxnet3/vmxnet3_drv.c:	} else if (ctx->ipv6) {
drivers/net/vmxnet3/vmxnet3_drv.c:	 * ctx->skb may be NULL if this is the first and the only one
drivers/net/vmxnet3/vmxnet3_drv.c:	if (ctx->skb)
drivers/net/vmxnet3/vmxnet3_drv.c:		dev_kfree_skb_irq(ctx->skb);
drivers/net/vmxnet3/vmxnet3_drv.c:	ctx->skb = NULL;
drivers/net/vmxnet3/vmxnet3_drv.c:			BUG_ON(ctx->skb != NULL || rbi->skb == NULL);
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->skb = rbi->skb;
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->skb = NULL;
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->skb = new_skb;
drivers/net/vmxnet3/vmxnet3_drv.c:				ctx->skb = rbi->skb;
drivers/net/vmxnet3/vmxnet3_drv.c:					ctx->skb = NULL;
drivers/net/vmxnet3/vmxnet3_drv.c:				skb_set_hash(ctx->skb,
drivers/net/vmxnet3/vmxnet3_drv.c:			skb_put(ctx->skb, rcd->len);
drivers/net/vmxnet3/vmxnet3_drv.c:			BUG_ON(ctx->skb == NULL && !skip_page_frags);
drivers/net/vmxnet3/vmxnet3_drv.c:					dev_kfree_skb(ctx->skb);
drivers/net/vmxnet3/vmxnet3_drv.c:					ctx->skb = NULL;
drivers/net/vmxnet3/vmxnet3_drv.c:					dev_kfree_skb(ctx->skb);
drivers/net/vmxnet3/vmxnet3_drv.c:					ctx->skb = NULL;
drivers/net/vmxnet3/vmxnet3_drv.c:				vmxnet3_append_frag(ctx->skb, rcd, rbi);
drivers/net/vmxnet3/vmxnet3_drv.c:		skb = ctx->skb;
drivers/net/vmxnet3/vmxnet3_drv.c:			ctx->skb = NULL;
drivers/net/wimax/i2400m/driver.c:		ctx->result = result;
drivers/net/wimax/i2400m/driver.c:		complete(&ctx->completion);
drivers/net/gtp.c:	return iph->saddr != pctx->ms_addr_ip4.s_addr;
drivers/net/gtp.c:	gtp0->seq	= htons((atomic_inc_return(&pctx->tx_seq) - 1) % 0xffff);
drivers/net/gtp.c:	gtp0->flow	= htons(pctx->u.v0.flow);
drivers/net/gtp.c:	gtp0->tid	= cpu_to_be64(pctx->u.v0.tid);
drivers/net/gtp.c:	gtp1->tid	= htonl(pctx->u.v1.o_tei);
drivers/net/gtp.c:	switch (pktinfo->pctx->gtp_version) {
drivers/net/gtp.c:	switch (pctx->gtp_version) {
drivers/net/gtp.c:				  pctx->sgsn_addr_ip4.s_addr);
drivers/net/gtp.c:			   &pctx->sgsn_addr_ip4.s_addr);
drivers/net/gtp.c:			   &pctx->sgsn_addr_ip4.s_addr);
drivers/net/gtp.c:		switch (pctx->gtp_version) {
drivers/net/gtp.c:			hlist_del_rcu(&pctx->hlist_tid);
drivers/net/gtp.c:			hlist_del_rcu(&pctx->hlist_addr);
drivers/net/gtp.c:	pctx->gtp_version = nla_get_u32(info->attrs[GTPA_VERSION]);
drivers/net/gtp.c:	pctx->af = AF_INET;
drivers/net/gtp.c:	pctx->sgsn_addr_ip4.s_addr =
drivers/net/gtp.c:	pctx->ms_addr_ip4.s_addr =
drivers/net/gtp.c:	switch (pctx->gtp_version) {
drivers/net/gtp.c:		pctx->u.v0.tid = nla_get_u64(info->attrs[GTPA_TID]);
drivers/net/gtp.c:		pctx->u.v0.flow = nla_get_u16(info->attrs[GTPA_FLOW]);
drivers/net/gtp.c:		pctx->u.v1.i_tei = nla_get_u32(info->attrs[GTPA_I_TEI]);
drivers/net/gtp.c:		pctx->u.v1.o_tei = nla_get_u32(info->attrs[GTPA_O_TEI]);
drivers/net/gtp.c:		if (pctx->ms_addr_ip4.s_addr == ms_addr) {
drivers/net/gtp.c:		if (pctx->gtp_version == GTP_V0)
drivers/net/gtp.c:				   pctx->u.v0.tid, pctx);
drivers/net/gtp.c:		else if (pctx->gtp_version == GTP_V1)
drivers/net/gtp.c:				   pctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);
drivers/net/gtp.c:	atomic_set(&pctx->tx_seq, 0);
drivers/net/gtp.c:	switch (pctx->gtp_version) {
drivers/net/gtp.c:		hash_tid = gtp0_hashfn(pctx->u.v0.tid) % gtp->hash_size;
drivers/net/gtp.c:		hash_tid = gtp1u_hashfn(pctx->u.v1.i_tei) % gtp->hash_size;
drivers/net/gtp.c:	hlist_add_head_rcu(&pctx->hlist_addr, &gtp->addr_hash[hash_ms]);
drivers/net/gtp.c:	hlist_add_head_rcu(&pctx->hlist_tid, &gtp->tid_hash[hash_tid]);
drivers/net/gtp.c:	switch (pctx->gtp_version) {
drivers/net/gtp.c:			   pctx->u.v0.tid, &pctx->sgsn_addr_ip4,
drivers/net/gtp.c:			   &pctx->ms_addr_ip4, pctx);
drivers/net/gtp.c:			   pctx->u.v1.i_tei, pctx->u.v1.o_tei,
drivers/net/gtp.c:			   &pctx->sgsn_addr_ip4, &pctx->ms_addr_ip4, pctx);
drivers/net/gtp.c:	if (pctx->gtp_version == GTP_V0)
drivers/net/gtp.c:			   pctx->u.v0.tid, pctx);
drivers/net/gtp.c:	else if (pctx->gtp_version == GTP_V1)
drivers/net/gtp.c:			   pctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);
drivers/net/gtp.c:	hlist_del_rcu(&pctx->hlist_tid);
drivers/net/gtp.c:	hlist_del_rcu(&pctx->hlist_addr);
drivers/net/gtp.c:	if (nla_put_u32(skb, GTPA_VERSION, pctx->gtp_version) ||
drivers/net/gtp.c:	    nla_put_be32(skb, GTPA_SGSN_ADDRESS, pctx->sgsn_addr_ip4.s_addr) ||
drivers/net/gtp.c:	    nla_put_be32(skb, GTPA_MS_ADDRESS, pctx->ms_addr_ip4.s_addr))
drivers/net/gtp.c:	switch (pctx->gtp_version) {
drivers/net/gtp.c:		if (nla_put_u64_64bit(skb, GTPA_TID, pctx->u.v0.tid, GTPA_PAD) ||
drivers/net/gtp.c:		    nla_put_u16(skb, GTPA_FLOW, pctx->u.v0.flow))
drivers/net/gtp.c:		if (nla_put_u32(skb, GTPA_I_TEI, pctx->u.v1.i_tei) ||
drivers/net/gtp.c:		    nla_put_u32(skb, GTPA_O_TEI, pctx->u.v1.o_tei))
drivers/net/gtp.c:				if (tid && tid != pctx->u.tid)
drivers/net/gtp.c:					cb->args[1] = pctx->u.tid;
drivers/net/team/team_mode_activebackup.c:		ctx->data.u32_val = active_port->dev->ifindex;
drivers/net/team/team_mode_activebackup.c:		ctx->data.u32_val = 0;
drivers/net/team/team_mode_activebackup.c:		if (port->dev->ifindex == ctx->data.u32_val) {
drivers/net/team/team_mode_loadbalance.c:		ctx->data.bin_val.len = 0;
drivers/net/team/team_mode_loadbalance.c:		ctx->data.bin_val.ptr = NULL;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.len = lb_priv->ex->orig_fprog->len *
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.ptr = lb_priv->ex->orig_fprog->filter;
drivers/net/team/team_mode_loadbalance.c:	if (ctx->data.bin_val.len) {
drivers/net/team/team_mode_loadbalance.c:		err = __fprog_create(&fprog, ctx->data.bin_val.len,
drivers/net/team/team_mode_loadbalance.c:				     ctx->data.bin_val.ptr);
drivers/net/team/team_mode_loadbalance.c:	ctx->data.str_val = name;
drivers/net/team/team_mode_loadbalance.c:	func = lb_select_tx_port_get_func(ctx->data.str_val);
drivers/net/team/team_mode_loadbalance.c:	unsigned char hash = ctx->info->array_index;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.u32_val = port ? port->dev->ifindex : 0;
drivers/net/team/team_mode_loadbalance.c:	unsigned char hash = ctx->info->array_index;
drivers/net/team/team_mode_loadbalance.c:		if (ctx->data.u32_val == port->dev->ifindex &&
drivers/net/team/team_mode_loadbalance.c:	unsigned char hash = ctx->info->array_index;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.ptr = &lb_priv->ex->stats.info[hash].stats;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.len = sizeof(struct lb_stats);
drivers/net/team/team_mode_loadbalance.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.ptr = &lb_port_priv->stats_info.stats;
drivers/net/team/team_mode_loadbalance.c:	ctx->data.bin_val.len = sizeof(struct lb_stats);
drivers/net/team/team_mode_loadbalance.c:	ctx->data.u32_val = lb_priv->ex->stats.refresh_interval;
drivers/net/team/team_mode_loadbalance.c:	interval = ctx->data.u32_val;
drivers/net/team/team.c:	ctx->data.str_val = team->mode->kind;
drivers/net/team/team.c:	return team_change_mode(team, ctx->data.str_val);
drivers/net/team/team.c:	ctx->data.u32_val = team->notify_peers.count;
drivers/net/team/team.c:	team->notify_peers.count = ctx->data.u32_val;
drivers/net/team/team.c:	ctx->data.u32_val = team->notify_peers.interval;
drivers/net/team/team.c:	team->notify_peers.interval = ctx->data.u32_val;
drivers/net/team/team.c:	ctx->data.u32_val = team->mcast_rejoin.count;
drivers/net/team/team.c:	team->mcast_rejoin.count = ctx->data.u32_val;
drivers/net/team/team.c:	ctx->data.u32_val = team->mcast_rejoin.interval;
drivers/net/team/team.c:	team->mcast_rejoin.interval = ctx->data.u32_val;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	ctx->data.bool_val = team_port_enabled(port);
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	if (ctx->data.bool_val)
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	ctx->data.bool_val = port->user.linkup;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	port->user.linkup = ctx->data.bool_val;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	ctx->data.bool_val = port->user.linkup_enabled;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	port->user.linkup_enabled = ctx->data.bool_val;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	ctx->data.s32_val = port->priority;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	s32 priority = ctx->data.s32_val;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	ctx->data.u32_val = port->queue_id;
drivers/net/team/team.c:	struct team_port *port = ctx->info->port;
drivers/net/team/team.c:	u16 new_queue_id = ctx->data.u32_val;
drivers/char/hw_random/xgene-rng.c:	disable_irq(ctx->irq);
drivers/char/hw_random/xgene-rng.c:	ctx->failure_cnt = 0;
drivers/char/hw_random/xgene-rng.c:	del_timer(&ctx->failure_timer);
drivers/char/hw_random/xgene-rng.c:	enable_irq(ctx->irq);
drivers/char/hw_random/xgene-rng.c:	ctx->failure_timer.data = (unsigned long) ctx;
drivers/char/hw_random/xgene-rng.c:	ctx->failure_timer.function = xgene_rng_expired_timer;
drivers/char/hw_random/xgene-rng.c:	ctx->failure_timer.expires = jiffies + 120 * HZ;
drivers/char/hw_random/xgene-rng.c:	add_timer(&ctx->failure_timer);
drivers/char/hw_random/xgene-rng.c:	writel(fro_val, ctx->csr_base + RNG_FRODETUNE);
drivers/char/hw_random/xgene-rng.c:	writel(0x00000000, ctx->csr_base + RNG_ALARMMASK);
drivers/char/hw_random/xgene-rng.c:	writel(0x00000000, ctx->csr_base + RNG_ALARMSTOP);
drivers/char/hw_random/xgene-rng.c:	writel(0xFFFFFFFF, ctx->csr_base + RNG_FROENABLE);
drivers/char/hw_random/xgene-rng.c:	val = readl(ctx->csr_base + RNG_INTR_STS_ACK);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "test monobit failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "test poker failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "test long run failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "test run failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "noise failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		dev_err(ctx->dev, "stuck out failure error 0x%08X\n", val);
drivers/char/hw_random/xgene-rng.c:		if (++ctx->failure_cnt == 1) {
drivers/char/hw_random/xgene-rng.c:			ctx->failure_ts = jiffies;
drivers/char/hw_random/xgene-rng.c:			frostopped = readl(ctx->csr_base + RNG_ALARMSTOP);
drivers/char/hw_random/xgene-rng.c:			if (time_after(ctx->failure_ts + 60 * HZ, jiffies)) {
drivers/char/hw_random/xgene-rng.c:				dev_err(ctx->dev,
drivers/char/hw_random/xgene-rng.c:				ctx->failure_ts = jiffies;
drivers/char/hw_random/xgene-rng.c:				ctx->failure_cnt = 1;
drivers/char/hw_random/xgene-rng.c:			frostopped = readl(ctx->csr_base + RNG_ALARMSTOP);
drivers/char/hw_random/xgene-rng.c:	writel(val, ctx->csr_base + RNG_INTR_STS_ACK);
drivers/char/hw_random/xgene-rng.c:		val = readl(ctx->csr_base + RNG_INTR_STS_ACK);
drivers/char/hw_random/xgene-rng.c:	for (i = 0; i < ctx->datum_size; i++)
drivers/char/hw_random/xgene-rng.c:		data[i] = readl(ctx->csr_base + RNG_INOUT_0 + i * 4);
drivers/char/hw_random/xgene-rng.c:	writel(READY_MASK, ctx->csr_base + RNG_INTR_STS_ACK);
drivers/char/hw_random/xgene-rng.c:	return ctx->datum_size << 2;
drivers/char/hw_random/xgene-rng.c:	writel(0x00000000, ctx->csr_base + RNG_CONTROL);
drivers/char/hw_random/xgene-rng.c:	writel(val, ctx->csr_base + RNG_CONFIG);
drivers/char/hw_random/xgene-rng.c:	writel(val, ctx->csr_base + RNG_ALARMCNT);
drivers/char/hw_random/xgene-rng.c:		READY_MASK, ctx->csr_base + RNG_INTR_STS_ACK);
drivers/char/hw_random/xgene-rng.c:	writel(val, ctx->csr_base + RNG_CONTROL);
drivers/char/hw_random/xgene-rng.c:	ctx->failure_cnt = 0;
drivers/char/hw_random/xgene-rng.c:	init_timer(&ctx->failure_timer);
drivers/char/hw_random/xgene-rng.c:	ctx->revision = readl(ctx->csr_base + RNG_EIP_REV);
drivers/char/hw_random/xgene-rng.c:	dev_dbg(ctx->dev, "Rev %d.%d.%d\n",
drivers/char/hw_random/xgene-rng.c:		MAJOR_HW_REV_RD(ctx->revision),
drivers/char/hw_random/xgene-rng.c:		MINOR_HW_REV_RD(ctx->revision),
drivers/char/hw_random/xgene-rng.c:		HW_PATCH_LEVEL_RD(ctx->revision));
drivers/char/hw_random/xgene-rng.c:	dev_dbg(ctx->dev, "Options 0x%08X",
drivers/char/hw_random/xgene-rng.c:		readl(ctx->csr_base + RNG_OPTIONS));
drivers/char/hw_random/xgene-rng.c:	ctx->datum_size = RNG_MAX_DATUM;
drivers/char/hw_random/xgene-rng.c:	ctx->dev = &pdev->dev;
drivers/char/hw_random/xgene-rng.c:	ctx->csr_base = devm_ioremap_resource(&pdev->dev, res);
drivers/char/hw_random/xgene-rng.c:	if (IS_ERR(ctx->csr_base))
drivers/char/hw_random/xgene-rng.c:		return PTR_ERR(ctx->csr_base);
drivers/char/hw_random/xgene-rng.c:	ctx->irq = rc;
drivers/char/hw_random/xgene-rng.c:		ctx->csr_base, ctx->irq);
drivers/char/hw_random/xgene-rng.c:	rc = devm_request_irq(&pdev->dev, ctx->irq, xgene_rng_irq_handler, 0,
drivers/char/hw_random/xgene-rng.c:	ctx->clk = devm_clk_get(&pdev->dev, NULL);
drivers/char/hw_random/xgene-rng.c:	if (IS_ERR(ctx->clk)) {
drivers/char/hw_random/xgene-rng.c:		rc = clk_prepare_enable(ctx->clk);
drivers/char/hw_random/xgene-rng.c:		if (!IS_ERR(ctx->clk))
drivers/char/hw_random/xgene-rng.c:			clk_disable_unprepare(ctx->clk);
drivers/char/hw_random/xgene-rng.c:		if (!IS_ERR(ctx->clk))
drivers/char/hw_random/xgene-rng.c:			clk_disable_unprepare(ctx->clk);
drivers/char/hw_random/xgene-rng.c:	if (!IS_ERR(ctx->clk))
drivers/char/hw_random/xgene-rng.c:		clk_disable_unprepare(ctx->clk);
drivers/char/adsprpc.c:		if (fl->sctx->smmu.cb)
drivers/char/adsprpc.c:			buf->phys &= ~((uint64_t)fl->sctx->smmu.cb << 32);
drivers/char/adsprpc.c:		dma_free_coherent(fl->sctx->smmu.dev, buf->size, buf->virt,
drivers/char/adsprpc.c:	buf->virt = dma_alloc_coherent(fl->sctx->smmu.dev, buf->size,
drivers/char/adsprpc.c:		buf->virt = dma_alloc_coherent(fl->sctx->smmu.dev, buf->size,
drivers/char/adsprpc.c:	if (fl->sctx->smmu.cb)
drivers/char/adsprpc.c:		buf->phys += ((uint64_t)fl->sctx->smmu.cb << 32);
drivers/char/adsprpc.c:		if (ictx->pid == current->pid) {
drivers/char/adsprpc.c:			if (invoke->sc != ictx->sc || ictx->fl != fl)
drivers/char/adsprpc.c:				hlist_del_init(&ctx->hn);
drivers/char/adsprpc.c:				hlist_add_head(&ctx->hn, &fl->clst.pending);
drivers/char/adsprpc.c:	remote_arg_t *lpra = ctx->lpra;
drivers/char/adsprpc.c:	int inbufs = REMOTE_SCALARS_INBUFS(ctx->sc);
drivers/char/adsprpc.c:	int outbufs = REMOTE_SCALARS_OUTBUFS(ctx->sc);
drivers/char/adsprpc.c:		ctx->overs[i].start = (uintptr_t)lpra[i].buf.pv;
drivers/char/adsprpc.c:		ctx->overs[i].end = ctx->overs[i].start + lpra[i].buf.len;
drivers/char/adsprpc.c:			VERIFY(err, ctx->overs[i].end > ctx->overs[i].start);
drivers/char/adsprpc.c:		ctx->overs[i].raix = i;
drivers/char/adsprpc.c:		ctx->overps[i] = &ctx->overs[i];
drivers/char/adsprpc.c:	sort(ctx->overps, nbufs, sizeof(*ctx->overps), overlap_ptr_cmp, NULL);
drivers/char/adsprpc.c:		if (ctx->overps[i]->start < max.end) {
drivers/char/adsprpc.c:			ctx->overps[i]->mstart = max.end;
drivers/char/adsprpc.c:			ctx->overps[i]->mend = ctx->overps[i]->end;
drivers/char/adsprpc.c:			ctx->overps[i]->offset = max.end -
drivers/char/adsprpc.c:				ctx->overps[i]->start;
drivers/char/adsprpc.c:			if (ctx->overps[i]->end > max.end) {
drivers/char/adsprpc.c:				max.end = ctx->overps[i]->end;
drivers/char/adsprpc.c:				ctx->overps[i]->mend = 0;
drivers/char/adsprpc.c:				ctx->overps[i]->mstart = 0;
drivers/char/adsprpc.c:			ctx->overps[i]->mend = ctx->overps[i]->end;
drivers/char/adsprpc.c:			ctx->overps[i]->mstart = ctx->overps[i]->start;
drivers/char/adsprpc.c:			ctx->overps[i]->offset = 0;
drivers/char/adsprpc.c:			max = *ctx->overps[i];
drivers/char/adsprpc.c:	size = bufs * sizeof(*ctx->lpra) + bufs * sizeof(*ctx->maps) +
drivers/char/adsprpc.c:		sizeof(*ctx->fds) * (bufs) +
drivers/char/adsprpc.c:		sizeof(*ctx->attrs) * (bufs) +
drivers/char/adsprpc.c:		sizeof(*ctx->overs) * (bufs) +
drivers/char/adsprpc.c:		sizeof(*ctx->overps) * (bufs);
drivers/char/adsprpc.c:	INIT_HLIST_NODE(&ctx->hn);
drivers/char/adsprpc.c:	hlist_add_fake(&ctx->hn);
drivers/char/adsprpc.c:	ctx->fl = fl;
drivers/char/adsprpc.c:	ctx->maps = (struct fastrpc_mmap **)(&ctx[1]);
drivers/char/adsprpc.c:	ctx->lpra = (remote_arg_t *)(&ctx->maps[bufs]);
drivers/char/adsprpc.c:	ctx->fds = (int *)(&ctx->lpra[bufs]);
drivers/char/adsprpc.c:	ctx->attrs = (unsigned int *)(&ctx->fds[bufs]);
drivers/char/adsprpc.c:	ctx->overs = (struct overlap *)(&ctx->attrs[bufs]);
drivers/char/adsprpc.c:	ctx->overps = (struct overlap **)(&ctx->overs[bufs]);
drivers/char/adsprpc.c:	K_COPY_FROM_USER(err, kernel, (void *)ctx->lpra, invoke->pra,
drivers/char/adsprpc.c:					bufs * sizeof(*ctx->lpra));
drivers/char/adsprpc.c:		K_COPY_FROM_USER(err, kernel, ctx->fds, invokefd->fds,
drivers/char/adsprpc.c:						bufs * sizeof(*ctx->fds));
drivers/char/adsprpc.c:		K_COPY_FROM_USER(err, kernel, ctx->attrs, invokefd->attrs,
drivers/char/adsprpc.c:						bufs * sizeof(*ctx->attrs));
drivers/char/adsprpc.c:	ctx->crc = (uint32_t *)invokefd->crc;
drivers/char/adsprpc.c:	ctx->sc = invoke->sc;
drivers/char/adsprpc.c:	ctx->retval = -1;
drivers/char/adsprpc.c:	ctx->pid = current->pid;
drivers/char/adsprpc.c:	ctx->tgid = fl->tgid;
drivers/char/adsprpc.c:	init_completion(&ctx->work);
drivers/char/adsprpc.c:	ctx->magic = FASTRPC_CTX_MAGIC;
drivers/char/adsprpc.c:	hlist_add_head(&ctx->hn, &clst->pending);
drivers/char/adsprpc.c:			ctx->ctxid = (ptr_to_uint64(ctx) & ~0xFFF)|(ii << 4);
drivers/char/adsprpc.c:	struct fastrpc_ctx_lst *clst = &ctx->fl->clst;
drivers/char/adsprpc.c:	spin_lock(&ctx->fl->hlock);
drivers/char/adsprpc.c:	hlist_del_init(&ctx->hn);
drivers/char/adsprpc.c:	hlist_add_head(&ctx->hn, &clst->interrupted);
drivers/char/adsprpc.c:	spin_unlock(&ctx->fl->hlock);
drivers/char/adsprpc.c:	fastrpc_buf_list_free(ctx->fl);
drivers/char/adsprpc.c:	int nbufs = REMOTE_SCALARS_INBUFS(ctx->sc) +
drivers/char/adsprpc.c:		    REMOTE_SCALARS_OUTBUFS(ctx->sc);
drivers/char/adsprpc.c:	spin_lock(&ctx->fl->hlock);
drivers/char/adsprpc.c:	hlist_del_init(&ctx->hn);
drivers/char/adsprpc.c:	spin_unlock(&ctx->fl->hlock);
drivers/char/adsprpc.c:	mutex_lock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:		fastrpc_mmap_free(ctx->maps[i], 0);
drivers/char/adsprpc.c:	mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:	fastrpc_buf_free(ctx->buf, 1);
drivers/char/adsprpc.c:	ctx->magic = 0;
drivers/char/adsprpc.c:	ctx->ctxid = 0;
drivers/char/adsprpc.c:	ctx->retval = retval;
drivers/char/adsprpc.c:	complete(&ctx->work);
drivers/char/adsprpc.c:		complete(&ictx->work);
drivers/char/adsprpc.c:		complete(&ictx->work);
drivers/char/adsprpc.c:			hlist_del_init(&ictx->hn);
drivers/char/adsprpc.c:			hlist_del_init(&ictx->hn);
drivers/char/adsprpc.c:	remote_arg_t *lpra = ctx->lpra;
drivers/char/adsprpc.c:	uint32_t sc = ctx->sc;
drivers/char/adsprpc.c:		mutex_lock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:		if (ctx->fds[i] && (ctx->fds[i] != -1))
drivers/char/adsprpc.c:			fastrpc_mmap_create(ctx->fl, ctx->fds[i],
drivers/char/adsprpc.c:					ctx->attrs[i], buf, len,
drivers/char/adsprpc.c:					mflags, &ctx->maps[i]);
drivers/char/adsprpc.c:		mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:	mutex_lock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:		VERIFY(err, !fastrpc_mmap_create(ctx->fl, ctx->fds[i],
drivers/char/adsprpc.c:				FASTRPC_ATTR_NOVA, 0, 0, 0, &ctx->maps[i]));
drivers/char/adsprpc.c:			mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:	mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:		int i = ctx->overps[oix]->raix;
drivers/char/adsprpc.c:		if (ctx->maps[i])
drivers/char/adsprpc.c:		if (ctx->overps[oix]->offset == 0)
drivers/char/adsprpc.c:		mstart = ctx->overps[oix]->mstart;
drivers/char/adsprpc.c:		mend = ctx->overps[oix]->mend;
drivers/char/adsprpc.c:	ctx->used = copylen;
drivers/char/adsprpc.c:		VERIFY(err, !fastrpc_buf_alloc(ctx->fl, copylen, &ctx->buf));
drivers/char/adsprpc.c:	if (ctx->buf->virt && metalen <= copylen)
drivers/char/adsprpc.c:		memset(ctx->buf->virt, 0, metalen);
drivers/char/adsprpc.c:	rpra = ctx->buf->virt;
drivers/char/adsprpc.c:	ctx->rpra = rpra;
drivers/char/adsprpc.c:	args = (uintptr_t)ctx->buf->virt + metalen;
drivers/char/adsprpc.c:	PERF(ctx->fl->profile, ctx->fl->perf.map,
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:	PERF(ctx->fl->profile, ctx->fl->perf.copy,
drivers/char/adsprpc.c:		int i = ctx->overps[oix]->raix;
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:		if (ctx->overps[oix]->offset == 0) {
drivers/char/adsprpc.c:		mlen = ctx->overps[oix]->mend - ctx->overps[oix]->mstart;
drivers/char/adsprpc.c:		rpra[i].buf.pv = (args - ctx->overps[oix]->offset);
drivers/char/adsprpc.c:		pages[list[i].pgidx].addr = ctx->buf->phys -
drivers/char/adsprpc.c:					    ctx->overps[oix]->offset +
drivers/char/adsprpc.c:	PERF(ctx->fl->profile, ctx->fl->perf.flush,
drivers/char/adsprpc.c:		int i = ctx->overps[oix]->raix;
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:		if (ctx->fl->sctx->smmu.coherent &&
drivers/char/adsprpc.c:		if (rpra[i].buf.len && ctx->overps[oix]->mstart)
drivers/char/adsprpc.c:		rpra[i].dma.fd = ctx->fds[i];
drivers/char/adsprpc.c:	if (!ctx->fl->sctx->smmu.coherent) {
drivers/char/adsprpc.c:		PERF(ctx->fl->profile, ctx->fl->perf.flush,
drivers/char/adsprpc.c:		dmac_flush_range((char *)rpra, (char *)rpra + ctx->used);
drivers/char/adsprpc.c:	uint32_t sc = ctx->sc;
drivers/char/adsprpc.c:	remote_arg64_t *rpra = ctx->rpra;
drivers/char/adsprpc.c:	list = smq_invoke_buf_start(ctx->rpra, sc);
drivers/char/adsprpc.c:		if (!ctx->maps[i]) {
drivers/char/adsprpc.c:				ctx->lpra[i].buf.pv,
drivers/char/adsprpc.c:			mutex_lock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:			fastrpc_mmap_free(ctx->maps[i], 0);
drivers/char/adsprpc.c:			mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:			ctx->maps[i] = NULL;
drivers/char/adsprpc.c:	mutex_lock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:			if (!fastrpc_mmap_find(ctx->fl, (int)fdlist[i], 0, 0,
drivers/char/adsprpc.c:	mutex_unlock(&ctx->fl->fl_map_mutex);
drivers/char/adsprpc.c:	if (ctx->crc && crclist && rpra)
drivers/char/adsprpc.c:		K_COPY_TO_USER(err, kernel, ctx->crc,
drivers/char/adsprpc.c:	uint32_t sc = ctx->sc;
drivers/char/adsprpc.c:	remote_arg64_t *rpra = ctx->rpra;
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:		if (ctx->fl->sctx->smmu.coherent &&
drivers/char/adsprpc.c:	uint32_t sc = ctx->sc;
drivers/char/adsprpc.c:	remote_arg64_t *rpra = ctx->rpra;
drivers/char/adsprpc.c:	int used = ctx->used;
drivers/char/adsprpc.c:		struct fastrpc_mmap *map = ctx->maps[i];
drivers/char/adsprpc.c:		if (ctx->fl->sctx->smmu.coherent &&
drivers/char/adsprpc.c:			msm_ion_do_cache_op(ctx->fl->apps->client, map->handle,
drivers/char/adsprpc.c:	struct smq_msg *msg = &ctx->msg;
drivers/char/adsprpc.c:	struct fastrpc_file *fl = ctx->fl;
drivers/char/adsprpc.c:	VERIFY(err, NULL != channel_ctx->chan);
drivers/char/adsprpc.c:	msg->invoke.header.ctx = ctx->ctxid | fl->pd;
drivers/char/adsprpc.c:	msg->invoke.header.sc = ctx->sc;
drivers/char/adsprpc.c:	msg->invoke.page.addr = ctx->buf ? ctx->buf->phys : 0;
drivers/char/adsprpc.c:	msg->invoke.page.size = buf_page_size(ctx->used);
drivers/char/adsprpc.c:	if (fl->ssrcount != channel_ctx->ssrcount) {
drivers/char/adsprpc.c:	VERIFY(err, channel_ctx->link.port_state ==
drivers/char/adsprpc.c:	err = glink_tx(channel_ctx->chan,
drivers/char/adsprpc.c:		if (fl->sctx->smmu.faults)
drivers/char/adsprpc.c:	if (REMOTE_SCALARS_LENGTH(ctx->sc)) {
drivers/char/adsprpc.c:	if (!fl->sctx->smmu.coherent)
drivers/char/adsprpc.c:		wait_for_completion(&ctx->work);
drivers/char/adsprpc.c:		interrupted = wait_for_completion_interruptible(&ctx->work);
drivers/char/adsprpc.c:	if (!fl->sctx->smmu.coherent)
drivers/char/adsprpc.c:	VERIFY(err, 0 == (err = ctx->retval));
drivers/char/adsprpc.c:	fastrpc_glink_close(ctx->chan, cid);
drivers/char/adsprpc.c:	ctx->chan = NULL;
drivers/char/adsprpc.c:	glink_unregister_link_state_cb(ctx->link.link_notify_handle);
drivers/char/adsprpc.c:	ctx->link.link_notify_handle = NULL;
drivers/char/adsprpc.c:						"sc:", ictx->sc,
drivers/char/adsprpc.c:						"tid:", ictx->pid,
drivers/char/adsprpc.c:						"handle", ictx->rpra->h);
drivers/char/adsprpc.c:					"sc:", ictx->sc,
drivers/char/adsprpc.c:					"tid:", ictx->pid,
drivers/char/adsprpc.c:					"handle", ictx->rpra->h);
drivers/char/adsprpc.c:	*info = (fl->sctx->smmu.enabled ? 1 : 0);
drivers/char/adsprpc.c:		ctx->ssrcount++;
drivers/char/adsprpc.c:		ctx->issubsystemup = 0;
drivers/char/adsprpc.c:		if (ctx->chan) {
drivers/char/adsprpc.c:			fastrpc_glink_close(ctx->chan, cid);
drivers/char/adsprpc.c:			ctx->chan = NULL;
drivers/char/adsprpc.c:		ctx->issubsystemup = 1;
drivers/bus/sunxi-rsb.c:	struct sunxi_rsb_device *rdev = ctx->rdev;
drivers/bus/sunxi-rsb.c:	return sunxi_rsb_read(rdev->rsb, rdev->rtaddr, reg, val, ctx->size);
drivers/bus/sunxi-rsb.c:	struct sunxi_rsb_device *rdev = ctx->rdev;
drivers/bus/sunxi-rsb.c:	return sunxi_rsb_write(rdev->rsb, rdev->rtaddr, reg, &val, ctx->size);
drivers/bus/sunxi-rsb.c:	ctx->rdev = rdev;
drivers/bus/sunxi-rsb.c:	ctx->size = config->val_bits / 8;
drivers/bluetooth/btintel.c:	bt_dev_dbg(ctx->hdev, "Register (0x%x) read", le32_to_cpu(cp.addr));
drivers/bluetooth/btintel.c:	skb = hci_cmd_sync(ctx->hdev, ctx->op_read, sizeof(cp), &cp,
drivers/bluetooth/btintel.c:		bt_dev_err(ctx->hdev, "regmap: Register (0x%x) read error (%d)",
drivers/bluetooth/btintel.c:		bt_dev_err(ctx->hdev, "regmap: Register (0x%x) read error, bad len",
drivers/bluetooth/btintel.c:		bt_dev_err(ctx->hdev, "regmap: Register (0x%x) read error, bad addr",
drivers/bluetooth/btintel.c:	bt_dev_dbg(ctx->hdev, "Register (0x%x) write", le32_to_cpu(cp->addr));
drivers/bluetooth/btintel.c:	skb = hci_cmd_sync(ctx->hdev, ctx->op_write, plen, cp, HCI_CMD_TIMEOUT);
drivers/bluetooth/btintel.c:		bt_dev_err(ctx->hdev, "regmap: Register (0x%x) write error (%d)",
drivers/bluetooth/btintel.c:	ctx->op_read = opcode_read;
drivers/bluetooth/btintel.c:	ctx->op_write = opcode_write;
drivers/bluetooth/btintel.c:	ctx->hdev = hdev;
drivers/crypto/hifn_795x.c:	switch (rctx->op) {
drivers/crypto/hifn_795x.c:	if (rctx->op == ACRYPTO_OP_ENCRYPT || rctx->op == ACRYPTO_OP_DECRYPT) {
drivers/crypto/hifn_795x.c:		if (ctx->keysize)
drivers/crypto/hifn_795x.c:		if (rctx->iv && rctx->mode != ACRYPTO_MODE_ECB)
drivers/crypto/hifn_795x.c:		switch (rctx->mode) {
drivers/crypto/hifn_795x.c:		switch (rctx->type) {
drivers/crypto/hifn_795x.c:			if (ctx->keysize != 16)
drivers/crypto/hifn_795x.c:			if (ctx->keysize != 24)
drivers/crypto/hifn_795x.c:			if (ctx->keysize != 32)
drivers/crypto/hifn_795x.c:			if (ctx->keysize != 24)
drivers/crypto/hifn_795x.c:			if (ctx->keysize != 8)
drivers/crypto/hifn_795x.c:				nbytes, nbytes, ctx->key, ctx->keysize,
drivers/crypto/hifn_795x.c:				rctx->iv, rctx->ivsize, md);
drivers/crypto/hifn_795x.c:	t = &rctx->walk.cache[0];
drivers/crypto/hifn_795x.c:		if (t->length && rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {
drivers/crypto/hifn_795x.c:	struct hifn_device *dev = ctx->dev;
drivers/crypto/hifn_795x.c:	if (rctx->iv && !rctx->ivsize && rctx->mode != ACRYPTO_MODE_ECB)
drivers/crypto/hifn_795x.c:	rctx->walk.flags = 0;
drivers/crypto/hifn_795x.c:			rctx->walk.flags |= ASYNC_FLAGS_MISALIGNED;
drivers/crypto/hifn_795x.c:	if (rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {
drivers/crypto/hifn_795x.c:		err = hifn_cipher_walk_init(&rctx->walk, idx, GFP_ATOMIC);
drivers/crypto/hifn_795x.c:	sg_num = hifn_cipher_walk(req, &rctx->walk);
drivers/crypto/hifn_795x.c:			 rctx->iv, rctx->ivsize,
drivers/crypto/hifn_795x.c:			 ctx->key, ctx->keysize,
drivers/crypto/hifn_795x.c:			 rctx->mode, rctx->op, rctx->type, err);
drivers/crypto/hifn_795x.c:	if (rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {
drivers/crypto/hifn_795x.c:			t = &rctx->walk.cache[idx];
drivers/crypto/hifn_795x.c:		hifn_cipher_walk_exit(&rctx->walk);
drivers/crypto/hifn_795x.c:	struct hifn_device *dev = ctx->dev;
drivers/crypto/hifn_795x.c:	memcpy(ctx->key, key, len);
drivers/crypto/hifn_795x.c:	ctx->keysize = len;
drivers/crypto/hifn_795x.c:	struct hifn_device *dev = ctx->dev;
drivers/crypto/hifn_795x.c:	if (ctx->keysize != 16 && type == ACRYPTO_TYPE_AES_128) {
drivers/crypto/hifn_795x.c:		if (ctx->keysize == 24)
drivers/crypto/hifn_795x.c:		else if (ctx->keysize == 32)
drivers/crypto/hifn_795x.c:	rctx->op = op;
drivers/crypto/hifn_795x.c:	rctx->mode = mode;
drivers/crypto/hifn_795x.c:	rctx->type = type;
drivers/crypto/hifn_795x.c:	rctx->iv = req->info;
drivers/crypto/hifn_795x.c:	rctx->ivsize = ivsize;
drivers/crypto/hifn_795x.c:	struct hifn_device *dev = ctx->dev;
drivers/crypto/hifn_795x.c:	ctx->dev = ha->dev;
drivers/crypto/padlock-sha.c:	dctx->fallback.tfm = ctx->fallback;
drivers/crypto/padlock-sha.c:	dctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/padlock-sha.c:	return crypto_shash_init(&dctx->fallback);
drivers/crypto/padlock-sha.c:	dctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/padlock-sha.c:	return crypto_shash_update(&dctx->fallback, data, length);
drivers/crypto/padlock-sha.c:	return crypto_shash_export(&dctx->fallback, out);
drivers/crypto/padlock-sha.c:	dctx->fallback.tfm = ctx->fallback;
drivers/crypto/padlock-sha.c:	dctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/padlock-sha.c:	return crypto_shash_import(&dctx->fallback, in);
drivers/crypto/padlock-sha.c:	dctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/padlock-sha.c:	err = crypto_shash_export(&dctx->fallback, &state);
drivers/crypto/padlock-sha.c:		return crypto_shash_finup(&dctx->fallback, in, count, out);
drivers/crypto/padlock-sha.c:			err = crypto_shash_update(&dctx->fallback, in, space) ?:
drivers/crypto/padlock-sha.c:			      crypto_shash_export(&dctx->fallback, &state);
drivers/crypto/padlock-sha.c:	dctx->fallback.flags = desc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/padlock-sha.c:	err = crypto_shash_export(&dctx->fallback, &state);
drivers/crypto/padlock-sha.c:		return crypto_shash_finup(&dctx->fallback, in, count, out);
drivers/crypto/padlock-sha.c:			err = crypto_shash_update(&dctx->fallback, in, space) ?:
drivers/crypto/padlock-sha.c:			      crypto_shash_export(&dctx->fallback, &state);
drivers/crypto/padlock-sha.c:	ctx->fallback = fallback_tfm;
drivers/crypto/padlock-sha.c:	crypto_free_shash(ctx->fallback);
drivers/crypto/padlock-sha.c:	partial = sctx->count & 0x3f;
drivers/crypto/padlock-sha.c:	sctx->count += len;
drivers/crypto/padlock-sha.c:	memcpy(dst, (u8 *)(sctx->state), SHA1_DIGEST_SIZE);
drivers/crypto/padlock-sha.c:			memcpy(sctx->buffer + partial, data,
drivers/crypto/padlock-sha.c:			src = sctx->buffer;
drivers/crypto/padlock-sha.c:	memcpy((u8 *)(sctx->state), dst, SHA1_DIGEST_SIZE);
drivers/crypto/padlock-sha.c:	memcpy(sctx->buffer + partial, src, len - done);
drivers/crypto/padlock-sha.c:	partial = sctx->count & 0x3f;
drivers/crypto/padlock-sha.c:	sctx->count += len;
drivers/crypto/padlock-sha.c:	memcpy(dst, (u8 *)(sctx->state), SHA256_DIGEST_SIZE);
drivers/crypto/padlock-sha.c:			memcpy(sctx->buf + partial, data,
drivers/crypto/padlock-sha.c:			src = sctx->buf;
drivers/crypto/padlock-sha.c:	memcpy((u8 *)(sctx->state), dst, SHA256_DIGEST_SIZE);
drivers/crypto/padlock-sha.c:	memcpy(sctx->buf + partial, src, len - done);
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = ctx->dd;
drivers/crypto/omap-sham.c:	u32 *hash = (u32 *)ctx->digest;
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = ctx->dd;
drivers/crypto/omap-sham.c:	if (ctx->flags & BIT(FLAGS_HMAC)) {
drivers/crypto/omap-sham.c:		struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:		u32 *opad = (u32 *)bctx->opad;
drivers/crypto/omap-sham.c:	u32 *in = (u32 *)ctx->digest;
drivers/crypto/omap-sham.c:	switch (ctx->flags & FLAGS_MODE_MASK) {
drivers/crypto/omap-sham.c:		if (test_bit(FLAGS_BE32_SHA1, &ctx->dd->flags))
drivers/crypto/omap-sham.c:	if (likely(ctx->digcnt))
drivers/crypto/omap-sham.c:		omap_sham_write(dd, SHA_REG_DIGCNT(dd), ctx->digcnt);
drivers/crypto/omap-sham.c:	if ((ctx->flags & FLAGS_MODE_MASK) == FLAGS_MODE_SHA1)
drivers/crypto/omap-sham.c:	if (!ctx->digcnt)
drivers/crypto/omap-sham.c:	switch (ctx->flags & FLAGS_MODE_MASK) {
drivers/crypto/omap-sham.c:	val = (ctx->flags & FLAGS_MODE_MASK) >> (FLAGS_MODE_SHIFT);
drivers/crypto/omap-sham.c:	if (!ctx->digcnt) {
drivers/crypto/omap-sham.c:		struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:		if (ctx->flags & BIT(FLAGS_HMAC)) {
drivers/crypto/omap-sham.c:					  (u32 *)bctx->ipad, nr_dr);
drivers/crypto/omap-sham.c:					  (u32 *)bctx->ipad + nr_dr, nr_dr);
drivers/crypto/omap-sham.c:			ctx->digcnt += bs;
drivers/crypto/omap-sham.c:		if (ctx->flags & BIT(FLAGS_HMAC))
drivers/crypto/omap-sham.c:	dev_dbg(dd->dev, "ctrl: %08x, flags: %08lx\n", val, ctx->flags);
drivers/crypto/omap-sham.c:						ctx->digcnt, length, final);
drivers/crypto/omap-sham.c:	ctx->digcnt += length;
drivers/crypto/omap-sham.c:	ctx->total -= length;
drivers/crypto/omap-sham.c:	sg_miter_start(&mi, ctx->sg, ctx->sg_len,
drivers/crypto/omap-sham.c:						ctx->digcnt, length, final);
drivers/crypto/omap-sham.c:	if (!dma_map_sg(dd->dev, ctx->sg, ctx->sg_len, DMA_TO_DEVICE)) {
drivers/crypto/omap-sham.c:	tx = dmaengine_prep_slave_sg(dd->dma_lch, ctx->sg, ctx->sg_len,
drivers/crypto/omap-sham.c:	ctx->digcnt += length;
drivers/crypto/omap-sham.c:	ctx->total -= length;
drivers/crypto/omap-sham.c:	int offset = ctx->offset;
drivers/crypto/omap-sham.c:	if (ctx->bufcnt)
drivers/crypto/omap-sham.c:	ctx->sg = kmalloc_array(n, sizeof(*sg), GFP_KERNEL);
drivers/crypto/omap-sham.c:	if (!ctx->sg)
drivers/crypto/omap-sham.c:	sg_init_table(ctx->sg, n);
drivers/crypto/omap-sham.c:	tmp = ctx->sg;
drivers/crypto/omap-sham.c:	ctx->sg_len = 0;
drivers/crypto/omap-sham.c:	if (ctx->bufcnt) {
drivers/crypto/omap-sham.c:		sg_set_buf(tmp, ctx->dd->xmit_buf, ctx->bufcnt);
drivers/crypto/omap-sham.c:		ctx->sg_len++;
drivers/crypto/omap-sham.c:			ctx->sg_len++;
drivers/crypto/omap-sham.c:	set_bit(FLAGS_SGS_ALLOCED, &ctx->dd->flags);
drivers/crypto/omap-sham.c:	ctx->bufcnt = 0;
drivers/crypto/omap-sham.c:	len = new_len + ctx->bufcnt;
drivers/crypto/omap-sham.c:	pages = get_order(ctx->total);
drivers/crypto/omap-sham.c:	if (ctx->bufcnt)
drivers/crypto/omap-sham.c:		memcpy(buf, ctx->dd->xmit_buf, ctx->bufcnt);
drivers/crypto/omap-sham.c:	scatterwalk_map_and_copy(buf + ctx->bufcnt, sg, ctx->offset,
drivers/crypto/omap-sham.c:				 ctx->total - ctx->bufcnt, 0);
drivers/crypto/omap-sham.c:	sg_init_table(ctx->sgl, 1);
drivers/crypto/omap-sham.c:	sg_set_buf(ctx->sgl, buf, len);
drivers/crypto/omap-sham.c:	ctx->sg = ctx->sgl;
drivers/crypto/omap-sham.c:	set_bit(FLAGS_SGS_COPIED, &ctx->dd->flags);
drivers/crypto/omap-sham.c:	ctx->sg_len = 1;
drivers/crypto/omap-sham.c:	ctx->bufcnt = 0;
drivers/crypto/omap-sham.c:	ctx->offset = 0;
drivers/crypto/omap-sham.c:	int offset = rctx->offset;
drivers/crypto/omap-sham.c:	rctx->sg_len = n;
drivers/crypto/omap-sham.c:	rctx->sg = sg;
drivers/crypto/omap-sham.c:	bool final = rctx->flags & BIT(FLAGS_FINUP);
drivers/crypto/omap-sham.c:	rctx->total = nbytes + rctx->bufcnt;
drivers/crypto/omap-sham.c:	if (!rctx->total)
drivers/crypto/omap-sham.c:	if (nbytes && (!IS_ALIGNED(rctx->bufcnt, bs))) {
drivers/crypto/omap-sham.c:		int len = bs - rctx->bufcnt % bs;
drivers/crypto/omap-sham.c:		scatterwalk_map_and_copy(rctx->buffer + rctx->bufcnt, req->src,
drivers/crypto/omap-sham.c:		rctx->bufcnt += len;
drivers/crypto/omap-sham.c:		rctx->offset = len;
drivers/crypto/omap-sham.c:	if (rctx->bufcnt)
drivers/crypto/omap-sham.c:		memcpy(rctx->dd->xmit_buf, rctx->buffer, rctx->bufcnt);
drivers/crypto/omap-sham.c:	xmit_len = rctx->total;
drivers/crypto/omap-sham.c:	hash_later = rctx->total - xmit_len;
drivers/crypto/omap-sham.c:	if (rctx->bufcnt && nbytes) {
drivers/crypto/omap-sham.c:		sg_init_table(rctx->sgl, 2);
drivers/crypto/omap-sham.c:		sg_set_buf(rctx->sgl, rctx->dd->xmit_buf, rctx->bufcnt);
drivers/crypto/omap-sham.c:		sg_chain(rctx->sgl, 2, req->src);
drivers/crypto/omap-sham.c:		rctx->sg = rctx->sgl;
drivers/crypto/omap-sham.c:		rctx->sg_len++;
drivers/crypto/omap-sham.c:	} else if (rctx->bufcnt) {
drivers/crypto/omap-sham.c:		sg_init_table(rctx->sgl, 1);
drivers/crypto/omap-sham.c:		sg_set_buf(rctx->sgl, rctx->dd->xmit_buf, xmit_len);
drivers/crypto/omap-sham.c:		rctx->sg = rctx->sgl;
drivers/crypto/omap-sham.c:		rctx->sg_len = 1;
drivers/crypto/omap-sham.c:			scatterwalk_map_and_copy(rctx->buffer, req->src,
drivers/crypto/omap-sham.c:			memcpy(rctx->buffer, rctx->buffer + xmit_len,
drivers/crypto/omap-sham.c:		rctx->bufcnt = hash_later;
drivers/crypto/omap-sham.c:		rctx->bufcnt = 0;
drivers/crypto/omap-sham.c:		rctx->total = xmit_len;
drivers/crypto/omap-sham.c:	dma_unmap_sg(dd->dev, ctx->sg, ctx->sg_len, DMA_TO_DEVICE);
drivers/crypto/omap-sham.c:	if (!tctx->dd) {
drivers/crypto/omap-sham.c:		tctx->dd = dd;
drivers/crypto/omap-sham.c:		dd = tctx->dd;
drivers/crypto/omap-sham.c:	ctx->dd = dd;
drivers/crypto/omap-sham.c:	ctx->flags = 0;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_MD5;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_SHA1;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_SHA224;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_SHA256;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_SHA384;
drivers/crypto/omap-sham.c:		ctx->flags |= FLAGS_MODE_SHA512;
drivers/crypto/omap-sham.c:	ctx->bufcnt = 0;
drivers/crypto/omap-sham.c:	ctx->digcnt = 0;
drivers/crypto/omap-sham.c:	ctx->total = 0;
drivers/crypto/omap-sham.c:	ctx->offset = 0;
drivers/crypto/omap-sham.c:	ctx->buflen = BUFLEN;
drivers/crypto/omap-sham.c:	if (tctx->flags & BIT(FLAGS_HMAC)) {
drivers/crypto/omap-sham.c:			struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:			memcpy(ctx->buffer, bctx->ipad, bs);
drivers/crypto/omap-sham.c:			ctx->bufcnt = bs;
drivers/crypto/omap-sham.c:		ctx->flags |= BIT(FLAGS_HMAC);
drivers/crypto/omap-sham.c:	bool final = ctx->flags & BIT(FLAGS_FINUP);
drivers/crypto/omap-sham.c:		 ctx->total, ctx->digcnt, (ctx->flags & BIT(FLAGS_FINUP)) != 0);
drivers/crypto/omap-sham.c:	if (ctx->total < get_block_size(ctx) ||
drivers/crypto/omap-sham.c:	    ctx->total < OMAP_SHA_DMA_THRESHOLD)
drivers/crypto/omap-sham.c:		ctx->flags |= BIT(FLAGS_CPU);
drivers/crypto/omap-sham.c:	if (ctx->flags & BIT(FLAGS_CPU))
drivers/crypto/omap-sham.c:		err = omap_sham_xmit_cpu(dd, ctx->total, final);
drivers/crypto/omap-sham.c:		err = omap_sham_xmit_dma(dd, ctx->total, final);
drivers/crypto/omap-sham.c:	dev_dbg(dd->dev, "update: err: %d, digcnt: %d\n", err, ctx->digcnt);
drivers/crypto/omap-sham.c:	if ((ctx->total <= get_block_size(ctx)) || dd->polling_mode)
drivers/crypto/omap-sham.c:		err = omap_sham_xmit_dma(dd, ctx->total, 1);
drivers/crypto/omap-sham.c:		err = omap_sham_xmit_cpu(dd, ctx->total, 1);
drivers/crypto/omap-sham.c:	ctx->bufcnt = 0;
drivers/crypto/omap-sham.c:	struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:	int bs = crypto_shash_blocksize(bctx->shash);
drivers/crypto/omap-sham.c:	int ds = crypto_shash_digestsize(bctx->shash);
drivers/crypto/omap-sham.c:	SHASH_DESC_ON_STACK(shash, bctx->shash);
drivers/crypto/omap-sham.c:	shash->tfm = bctx->shash;
drivers/crypto/omap-sham.c:	       crypto_shash_update(shash, bctx->opad, bs) ?:
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = ctx->dd;
drivers/crypto/omap-sham.c:	if (ctx->digcnt) {
drivers/crypto/omap-sham.c:		if ((ctx->flags & BIT(FLAGS_HMAC)) &&
drivers/crypto/omap-sham.c:	dev_dbg(dd->dev, "digcnt: %d, bufcnt: %d\n", ctx->digcnt, ctx->bufcnt);
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = ctx->dd;
drivers/crypto/omap-sham.c:		free_pages((unsigned long)sg_virt(ctx->sg),
drivers/crypto/omap-sham.c:			   get_order(ctx->sg->length));
drivers/crypto/omap-sham.c:		kfree(ctx->sg);
drivers/crypto/omap-sham.c:	ctx->sg = NULL;
drivers/crypto/omap-sham.c:		ctx->flags |= BIT(FLAGS_ERROR);
drivers/crypto/omap-sham.c:	err = omap_sham_prepare_request(req, ctx->op == OP_UPDATE);
drivers/crypto/omap-sham.c:						ctx->op, req->nbytes);
drivers/crypto/omap-sham.c:	if (ctx->digcnt)
drivers/crypto/omap-sham.c:	if (ctx->op == OP_UPDATE) {
drivers/crypto/omap-sham.c:		if (err != -EINPROGRESS && (ctx->flags & BIT(FLAGS_FINUP)))
drivers/crypto/omap-sham.c:	} else if (ctx->op == OP_FINAL) {
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = tctx->dd;
drivers/crypto/omap-sham.c:	ctx->op = op;
drivers/crypto/omap-sham.c:	struct omap_sham_dev *dd = ctx->dd;
drivers/crypto/omap-sham.c:	if (ctx->total + req->nbytes < ctx->buflen) {
drivers/crypto/omap-sham.c:		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, req->src,
drivers/crypto/omap-sham.c:		ctx->bufcnt += req->nbytes;
drivers/crypto/omap-sham.c:		ctx->total += req->nbytes;
drivers/crypto/omap-sham.c:		ctx->flags |= BIT(FLAGS_CPU);
drivers/crypto/omap-sham.c:	if (test_bit(FLAGS_HMAC, &ctx->flags) &&
drivers/crypto/omap-sham.c:	    !test_bit(FLAGS_AUTO_XOR, &ctx->dd->flags))
drivers/crypto/omap-sham.c:	return omap_sham_shash_digest(tctx->fallback, req->base.flags,
drivers/crypto/omap-sham.c:				      ctx->buffer + offset,
drivers/crypto/omap-sham.c:				      ctx->bufcnt - offset, req->result);
drivers/crypto/omap-sham.c:	ctx->flags |= BIT(FLAGS_FINUP);
drivers/crypto/omap-sham.c:	if (ctx->flags & BIT(FLAGS_ERROR))
drivers/crypto/omap-sham.c:	if (!ctx->digcnt && ctx->bufcnt < OMAP_SHA_DMA_THRESHOLD)
drivers/crypto/omap-sham.c:	else if (ctx->bufcnt)
drivers/crypto/omap-sham.c:	ctx->flags |= BIT(FLAGS_FINUP);
drivers/crypto/omap-sham.c:	struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:	int bs = crypto_shash_blocksize(bctx->shash);
drivers/crypto/omap-sham.c:	int ds = crypto_shash_digestsize(bctx->shash);
drivers/crypto/omap-sham.c:	if (!tctx->dd) {
drivers/crypto/omap-sham.c:		tctx->dd = dd;
drivers/crypto/omap-sham.c:		dd = tctx->dd;
drivers/crypto/omap-sham.c:	err = crypto_shash_setkey(tctx->fallback, key, keylen);
drivers/crypto/omap-sham.c:		err = omap_sham_shash_digest(bctx->shash,
drivers/crypto/omap-sham.c:				crypto_shash_get_flags(bctx->shash),
drivers/crypto/omap-sham.c:				key, keylen, bctx->ipad);
drivers/crypto/omap-sham.c:		memcpy(bctx->ipad, key, keylen);
drivers/crypto/omap-sham.c:	memset(bctx->ipad + keylen, 0, bs - keylen);
drivers/crypto/omap-sham.c:		memcpy(bctx->opad, bctx->ipad, bs);
drivers/crypto/omap-sham.c:			bctx->ipad[i] ^= 0x36;
drivers/crypto/omap-sham.c:			bctx->opad[i] ^= 0x5c;
drivers/crypto/omap-sham.c:	tctx->fallback = crypto_alloc_shash(alg_name, 0,
drivers/crypto/omap-sham.c:	if (IS_ERR(tctx->fallback)) {
drivers/crypto/omap-sham.c:		return PTR_ERR(tctx->fallback);
drivers/crypto/omap-sham.c:		struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:		tctx->flags |= BIT(FLAGS_HMAC);
drivers/crypto/omap-sham.c:		bctx->shash = crypto_alloc_shash(alg_base, 0,
drivers/crypto/omap-sham.c:		if (IS_ERR(bctx->shash)) {
drivers/crypto/omap-sham.c:			crypto_free_shash(tctx->fallback);
drivers/crypto/omap-sham.c:			return PTR_ERR(bctx->shash);
drivers/crypto/omap-sham.c:	crypto_free_shash(tctx->fallback);
drivers/crypto/omap-sham.c:	tctx->fallback = NULL;
drivers/crypto/omap-sham.c:	if (tctx->flags & BIT(FLAGS_HMAC)) {
drivers/crypto/omap-sham.c:		struct omap_sham_hmac_ctx *bctx = tctx->base;
drivers/crypto/omap-sham.c:		crypto_free_shash(bctx->shash);
drivers/crypto/omap-sham.c:	memcpy(out, rctx, sizeof(*rctx) + rctx->bufcnt);
drivers/crypto/atmel-sha.c:	while ((ctx->bufcnt < ctx->buflen) && ctx->total) {
drivers/crypto/atmel-sha.c:		count = min(ctx->sg->length - ctx->offset, ctx->total);
drivers/crypto/atmel-sha.c:		count = min(count, ctx->buflen - ctx->bufcnt);
drivers/crypto/atmel-sha.c:			if ((ctx->sg->length == 0) && !sg_is_last(ctx->sg)) {
drivers/crypto/atmel-sha.c:				ctx->sg = sg_next(ctx->sg);
drivers/crypto/atmel-sha.c:		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, ctx->sg,
drivers/crypto/atmel-sha.c:			ctx->offset, count, 0);
drivers/crypto/atmel-sha.c:		ctx->bufcnt += count;
drivers/crypto/atmel-sha.c:		ctx->offset += count;
drivers/crypto/atmel-sha.c:		ctx->total -= count;
drivers/crypto/atmel-sha.c:		if (ctx->offset == ctx->sg->length) {
drivers/crypto/atmel-sha.c:			ctx->sg = sg_next(ctx->sg);
drivers/crypto/atmel-sha.c:			if (ctx->sg)
drivers/crypto/atmel-sha.c:				ctx->offset = 0;
drivers/crypto/atmel-sha.c:				ctx->total = 0;
drivers/crypto/atmel-sha.c:	size[0] = ctx->digcnt[0];
drivers/crypto/atmel-sha.c:	size[1] = ctx->digcnt[1];
drivers/crypto/atmel-sha.c:	size[0] += ctx->bufcnt;
drivers/crypto/atmel-sha.c:	if (size[0] < ctx->bufcnt)
drivers/crypto/atmel-sha.c:	if (ctx->flags & (SHA_FLAGS_SHA384 | SHA_FLAGS_SHA512)) {
drivers/crypto/atmel-sha.c:		index = ctx->bufcnt & 0x7f;
drivers/crypto/atmel-sha.c:		*(ctx->buffer + ctx->bufcnt) = 0x80;
drivers/crypto/atmel-sha.c:		memset(ctx->buffer + ctx->bufcnt + 1, 0, padlen-1);
drivers/crypto/atmel-sha.c:		memcpy(ctx->buffer + ctx->bufcnt + padlen, bits, 16);
drivers/crypto/atmel-sha.c:		ctx->bufcnt += padlen + 16;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_PAD;
drivers/crypto/atmel-sha.c:		index = ctx->bufcnt & 0x3f;
drivers/crypto/atmel-sha.c:		*(ctx->buffer + ctx->bufcnt) = 0x80;
drivers/crypto/atmel-sha.c:		memset(ctx->buffer + ctx->bufcnt + 1, 0, padlen-1);
drivers/crypto/atmel-sha.c:		memcpy(ctx->buffer + ctx->bufcnt + padlen, &bits[1], 8);
drivers/crypto/atmel-sha.c:		ctx->bufcnt += padlen + 8;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_PAD;
drivers/crypto/atmel-sha.c:	if (!tctx->dd) {
drivers/crypto/atmel-sha.c:		tctx->dd = dd;
drivers/crypto/atmel-sha.c:		dd = tctx->dd;
drivers/crypto/atmel-sha.c:	ctx->dd = dd;
drivers/crypto/atmel-sha.c:	ctx->flags = 0;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_SHA1;
drivers/crypto/atmel-sha.c:		ctx->block_size = SHA1_BLOCK_SIZE;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_SHA224;
drivers/crypto/atmel-sha.c:		ctx->block_size = SHA224_BLOCK_SIZE;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_SHA256;
drivers/crypto/atmel-sha.c:		ctx->block_size = SHA256_BLOCK_SIZE;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_SHA384;
drivers/crypto/atmel-sha.c:		ctx->block_size = SHA384_BLOCK_SIZE;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_SHA512;
drivers/crypto/atmel-sha.c:		ctx->block_size = SHA512_BLOCK_SIZE;
drivers/crypto/atmel-sha.c:	ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:	ctx->digcnt[0] = 0;
drivers/crypto/atmel-sha.c:	ctx->digcnt[1] = 0;
drivers/crypto/atmel-sha.c:	ctx->buflen = SHA_BUFFER_LEN;
drivers/crypto/atmel-sha.c:	switch (ctx->flags & SHA_FLAGS_ALGO_MASK) {
drivers/crypto/atmel-sha.c:	if (!(ctx->digcnt[0] || ctx->digcnt[1])) {
drivers/crypto/atmel-sha.c:	} else if (dd->caps.has_uihv && (ctx->flags & SHA_FLAGS_RESTORE)) {
drivers/crypto/atmel-sha.c:		const u32 *hash = (const u32 *)ctx->digest;
drivers/crypto/atmel-sha.c:		ctx->flags &= ~SHA_FLAGS_RESTORE;
drivers/crypto/atmel-sha.c:		ctx->digcnt[1], ctx->digcnt[0], length, final);
drivers/crypto/atmel-sha.c:	ctx->digcnt[0] += length;
drivers/crypto/atmel-sha.c:	if (ctx->digcnt[0] < length)
drivers/crypto/atmel-sha.c:		ctx->digcnt[1]++;
drivers/crypto/atmel-sha.c:		ctx->digcnt[1], ctx->digcnt[0], length1, final);
drivers/crypto/atmel-sha.c:	ctx->digcnt[0] += length1;
drivers/crypto/atmel-sha.c:	if (ctx->digcnt[0] < length1)
drivers/crypto/atmel-sha.c:		ctx->digcnt[1]++;
drivers/crypto/atmel-sha.c:		ctx->digcnt[1], ctx->digcnt[0], length1, final);
drivers/crypto/atmel-sha.c:	ctx->digcnt[0] += length1;
drivers/crypto/atmel-sha.c:	if (ctx->digcnt[0] < length1)
drivers/crypto/atmel-sha.c:		ctx->digcnt[1]++;
drivers/crypto/atmel-sha.c:	bufcnt = ctx->bufcnt;
drivers/crypto/atmel-sha.c:	ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:	return atmel_sha_xmit_cpu(dd, ctx->buffer, bufcnt, 1);
drivers/crypto/atmel-sha.c:	ctx->dma_addr = dma_map_single(dd->dev, ctx->buffer,
drivers/crypto/atmel-sha.c:				ctx->buflen + ctx->block_size, DMA_TO_DEVICE);
drivers/crypto/atmel-sha.c:	if (dma_mapping_error(dd->dev, ctx->dma_addr)) {
drivers/crypto/atmel-sha.c:		dev_err(dd->dev, "dma %u bytes error\n", ctx->buflen +
drivers/crypto/atmel-sha.c:				ctx->block_size);
drivers/crypto/atmel-sha.c:	ctx->flags &= ~SHA_FLAGS_SG;
drivers/crypto/atmel-sha.c:	return atmel_sha_xmit_start(dd, ctx->dma_addr, length, 0, 0, final);
drivers/crypto/atmel-sha.c:	final = (ctx->flags & SHA_FLAGS_FINUP) && !ctx->total;
drivers/crypto/atmel-sha.c:		 ctx->bufcnt, ctx->digcnt[1], ctx->digcnt[0], final);
drivers/crypto/atmel-sha.c:	if (final || (ctx->bufcnt == ctx->buflen)) {
drivers/crypto/atmel-sha.c:		count = ctx->bufcnt;
drivers/crypto/atmel-sha.c:		ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:	if (!ctx->total)
drivers/crypto/atmel-sha.c:	if (ctx->bufcnt || ctx->offset)
drivers/crypto/atmel-sha.c:		ctx->digcnt[1], ctx->digcnt[0], ctx->bufcnt, ctx->total);
drivers/crypto/atmel-sha.c:	sg = ctx->sg;
drivers/crypto/atmel-sha.c:	if (!sg_is_last(sg) && !IS_ALIGNED(sg->length, ctx->block_size))
drivers/crypto/atmel-sha.c:		/* size is not ctx->block_size aligned */
drivers/crypto/atmel-sha.c:	length = min(ctx->total, sg->length);
drivers/crypto/atmel-sha.c:		if (!(ctx->flags & SHA_FLAGS_FINUP)) {
drivers/crypto/atmel-sha.c:			/* not last sg must be ctx->block_size aligned */
drivers/crypto/atmel-sha.c:			tail = length & (ctx->block_size - 1);
drivers/crypto/atmel-sha.c:	ctx->total -= length;
drivers/crypto/atmel-sha.c:	ctx->offset = length; /* offset where to start slow */
drivers/crypto/atmel-sha.c:	final = (ctx->flags & SHA_FLAGS_FINUP) && !ctx->total;
drivers/crypto/atmel-sha.c:		tail = length & (ctx->block_size - 1);
drivers/crypto/atmel-sha.c:		ctx->total += tail;
drivers/crypto/atmel-sha.c:		ctx->offset = length; /* offset where to start slow */
drivers/crypto/atmel-sha.c:		sg = ctx->sg;
drivers/crypto/atmel-sha.c:		ctx->dma_addr = dma_map_single(dd->dev, ctx->buffer,
drivers/crypto/atmel-sha.c:			ctx->buflen + ctx->block_size, DMA_TO_DEVICE);
drivers/crypto/atmel-sha.c:		if (dma_mapping_error(dd->dev, ctx->dma_addr)) {
drivers/crypto/atmel-sha.c:				ctx->buflen + ctx->block_size);
drivers/crypto/atmel-sha.c:			ctx->flags &= ~SHA_FLAGS_SG;
drivers/crypto/atmel-sha.c:			count = ctx->bufcnt;
drivers/crypto/atmel-sha.c:			ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:			return atmel_sha_xmit_start(dd, ctx->dma_addr, count, 0,
drivers/crypto/atmel-sha.c:			ctx->sg = sg;
drivers/crypto/atmel-sha.c:			if (!dma_map_sg(dd->dev, ctx->sg, 1,
drivers/crypto/atmel-sha.c:			ctx->flags |= SHA_FLAGS_SG;
drivers/crypto/atmel-sha.c:			count = ctx->bufcnt;
drivers/crypto/atmel-sha.c:			ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:			return atmel_sha_xmit_start(dd, sg_dma_address(ctx->sg),
drivers/crypto/atmel-sha.c:					length, ctx->dma_addr, count, final);
drivers/crypto/atmel-sha.c:	if (!dma_map_sg(dd->dev, ctx->sg, 1, DMA_TO_DEVICE)) {
drivers/crypto/atmel-sha.c:	ctx->flags |= SHA_FLAGS_SG;
drivers/crypto/atmel-sha.c:	return atmel_sha_xmit_start(dd, sg_dma_address(ctx->sg), length, 0,
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_SG) {
drivers/crypto/atmel-sha.c:		dma_unmap_sg(dd->dev, ctx->sg, 1, DMA_TO_DEVICE);
drivers/crypto/atmel-sha.c:		if (ctx->sg->length == ctx->offset) {
drivers/crypto/atmel-sha.c:			ctx->sg = sg_next(ctx->sg);
drivers/crypto/atmel-sha.c:			if (ctx->sg)
drivers/crypto/atmel-sha.c:				ctx->offset = 0;
drivers/crypto/atmel-sha.c:		if (ctx->flags & SHA_FLAGS_PAD) {
drivers/crypto/atmel-sha.c:			dma_unmap_single(dd->dev, ctx->dma_addr,
drivers/crypto/atmel-sha.c:				ctx->buflen + ctx->block_size, DMA_TO_DEVICE);
drivers/crypto/atmel-sha.c:		dma_unmap_single(dd->dev, ctx->dma_addr, ctx->buflen +
drivers/crypto/atmel-sha.c:						ctx->block_size, DMA_TO_DEVICE);
drivers/crypto/atmel-sha.c:		ctx->total, ctx->digcnt[1], ctx->digcnt[0]);
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_CPU)
drivers/crypto/atmel-sha.c:			err, ctx->digcnt[1], ctx->digcnt[0]);
drivers/crypto/atmel-sha.c:	if (ctx->bufcnt >= ATMEL_SHA_DMA_THRESHOLD) {
drivers/crypto/atmel-sha.c:		count = ctx->bufcnt;
drivers/crypto/atmel-sha.c:		ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:		count = ctx->bufcnt;
drivers/crypto/atmel-sha.c:		ctx->bufcnt = 0;
drivers/crypto/atmel-sha.c:		err = atmel_sha_xmit_cpu(dd, ctx->buffer, count, 1);
drivers/crypto/atmel-sha.c:	u32 *hash = (u32 *)ctx->digest;
drivers/crypto/atmel-sha.c:	switch (ctx->flags & SHA_FLAGS_ALGO_MASK) {
drivers/crypto/atmel-sha.c:		hash[i] = atmel_sha_read(ctx->dd, SHA_REG_DIGEST(i));
drivers/crypto/atmel-sha.c:	ctx->flags |= SHA_FLAGS_RESTORE;
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_SHA1)
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA1_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:	else if (ctx->flags & SHA_FLAGS_SHA224)
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA224_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:	else if (ctx->flags & SHA_FLAGS_SHA256)
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA256_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:	else if (ctx->flags & SHA_FLAGS_SHA384)
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA384_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA512_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:	struct atmel_sha_dev *dd = ctx->dd;
drivers/crypto/atmel-sha.c:	if (ctx->digcnt[0] || ctx->digcnt[1])
drivers/crypto/atmel-sha.c:	dev_dbg(dd->dev, "digcnt: 0x%llx 0x%llx, bufcnt: %d\n", ctx->digcnt[1],
drivers/crypto/atmel-sha.c:		ctx->digcnt[0], ctx->bufcnt);
drivers/crypto/atmel-sha.c:	struct atmel_sha_dev *dd = ctx->dd;
drivers/crypto/atmel-sha.c:		ctx->flags |= SHA_FLAGS_ERROR;
drivers/crypto/atmel-sha.c:						ctx->op, req->nbytes);
drivers/crypto/atmel-sha.c:	if (ctx->op == SHA_OP_UPDATE) {
drivers/crypto/atmel-sha.c:		if (err != -EINPROGRESS && (ctx->flags & SHA_FLAGS_FINUP))
drivers/crypto/atmel-sha.c:	} else if (ctx->op == SHA_OP_FINAL) {
drivers/crypto/atmel-sha.c:	struct atmel_sha_dev *dd = tctx->dd;
drivers/crypto/atmel-sha.c:	ctx->op = op;
drivers/crypto/atmel-sha.c:	ctx->total = req->nbytes;
drivers/crypto/atmel-sha.c:	ctx->sg = req->src;
drivers/crypto/atmel-sha.c:	ctx->offset = 0;
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_FINUP) {
drivers/crypto/atmel-sha.c:		if (ctx->bufcnt + ctx->total < ATMEL_SHA_DMA_THRESHOLD)
drivers/crypto/atmel-sha.c:			ctx->flags |= SHA_FLAGS_CPU;
drivers/crypto/atmel-sha.c:	} else if (ctx->bufcnt + ctx->total < ctx->buflen) {
drivers/crypto/atmel-sha.c:	ctx->flags |= SHA_FLAGS_FINUP;
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_ERROR)
drivers/crypto/atmel-sha.c:	if (ctx->flags & SHA_FLAGS_PAD)
drivers/crypto/atmel-sha.c:	ctx->flags |= SHA_FLAGS_FINUP;
drivers/crypto/ccp/ccp-crypto-main.c:	if (ctx->complete)
drivers/crypto/ccp/ccp-crypto-main.c:		ret = ctx->complete(req, ret);
drivers/crypto/ccp/ccp-crypto-main.c:		if (ctx->complete)
drivers/crypto/ccp/ccp-crypto-main.c:			ret = ctx->complete(held->req, ret);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	memcpy(req->info, rctx->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:		memcpy(ctx->u.aes.key, key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ctx->u.aes.key_len = key_len / 2;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	sg_init_one(&ctx->u.aes.key_sg, ctx->u.aes.key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	return crypto_skcipher_setkey(ctx->u.aes.tfm_skcipher, key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	if (!ctx->u.aes.key_len)
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	    (ctx->u.aes.key_len != AES_KEYSIZE_128)) {
drivers/crypto/ccp/ccp-crypto-aes-xts.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->u.aes.tfm_skcipher);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:		skcipher_request_set_tfm(subreq, ctx->u.aes.tfm_skcipher);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	memcpy(rctx->iv, req->info, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	sg_init_one(&rctx->iv_sg, rctx->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	memset(&rctx->cmd, 0, sizeof(rctx->cmd));
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	INIT_LIST_HEAD(&rctx->cmd.entry);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.engine = CCP_ENGINE_XTS_AES_128;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.type = CCP_AES_TYPE_128;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.action = (encrypt) ? CCP_AES_ACTION_ENCRYPT
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.unit_size = unit_size;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.key = &ctx->u.aes.key_sg;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.key_len = ctx->u.aes.key_len;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.iv = &rctx->iv_sg;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.iv_len = AES_BLOCK_SIZE;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.src = req->src;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.src_len = req->nbytes;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ctx->complete = ccp_aes_xts_complete;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ctx->u.aes.key_len = 0;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ctx->u.aes.tfm_skcipher = fallback_tfm;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	crypto_free_skcipher(ctx->u.aes.tfm_skcipher);
drivers/crypto/ccp/ccp-crypto-sha.c:	if (rctx->hash_rem) {
drivers/crypto/ccp/ccp-crypto-sha.c:		unsigned int offset = rctx->nbytes - rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-sha.c:		scatterwalk_map_and_copy(rctx->buf, rctx->src,
drivers/crypto/ccp/ccp-crypto-sha.c:					 offset, rctx->hash_rem, 0);
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->buf_count = rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->buf_count = 0;
drivers/crypto/ccp/ccp-crypto-sha.c:		memcpy(req->result, rctx->ctx, digest_size);
drivers/crypto/ccp/ccp-crypto-sha.c:	sg_free_table(&rctx->data_sg);
drivers/crypto/ccp/ccp-crypto-sha.c:	len = (u64)rctx->buf_count + (u64)nbytes;
drivers/crypto/ccp/ccp-crypto-sha.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->buf_count += nbytes;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->src = req->src;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->nbytes = nbytes;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->final = final;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->hash_rem = final ? 0 : len & (block_size - 1);
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->hash_cnt = len - rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-sha.c:	if (!final && !rctx->hash_rem) {
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->hash_cnt -= block_size;
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->hash_rem = block_size;
drivers/crypto/ccp/ccp-crypto-sha.c:	sg_init_one(&rctx->ctx_sg, rctx->ctx, sizeof(rctx->ctx));
drivers/crypto/ccp/ccp-crypto-sha.c:	if (rctx->buf_count && nbytes) {
drivers/crypto/ccp/ccp-crypto-sha.c:		ret = sg_alloc_table(&rctx->data_sg, sg_count, gfp);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->buf_sg);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = rctx->data_sg.sgl;
drivers/crypto/ccp/ccp-crypto-sha.c:	} else if (rctx->buf_count) {
drivers/crypto/ccp/ccp-crypto-sha.c:		sg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = &rctx->buf_sg;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->msg_bits += (rctx->hash_cnt << 3);	/* Total in bits */
drivers/crypto/ccp/ccp-crypto-sha.c:	memset(&rctx->cmd, 0, sizeof(rctx->cmd));
drivers/crypto/ccp/ccp-crypto-sha.c:	INIT_LIST_HEAD(&rctx->cmd.entry);
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.engine = CCP_ENGINE_SHA;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.type = rctx->type;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.ctx = &rctx->ctx_sg;
drivers/crypto/ccp/ccp-crypto-sha.c:	switch (rctx->type) {
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->cmd.u.sha.ctx_len = SHA1_DIGEST_SIZE;
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->cmd.u.sha.ctx_len = SHA224_DIGEST_SIZE;
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->cmd.u.sha.ctx_len = SHA256_DIGEST_SIZE;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.src = sg;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.src_len = rctx->hash_cnt;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.opad = ctx->u.sha.key_len ?
drivers/crypto/ccp/ccp-crypto-sha.c:		&ctx->u.sha.opad_sg : NULL;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.opad_len = ctx->u.sha.key_len ?
drivers/crypto/ccp/ccp-crypto-sha.c:		ctx->u.sha.opad_count : 0;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.first = rctx->first;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.final = rctx->final;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->cmd.u.sha.msg_bits = rctx->msg_bits;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->first = 0;
drivers/crypto/ccp/ccp-crypto-sha.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-sha.c:	sg_free_table(&rctx->data_sg);
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->type = alg->type;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->first = 1;
drivers/crypto/ccp/ccp-crypto-sha.c:	if (ctx->u.sha.key_len) {
drivers/crypto/ccp/ccp-crypto-sha.c:		memcpy(rctx->buf, ctx->u.sha.ipad, block_size);
drivers/crypto/ccp/ccp-crypto-sha.c:		rctx->buf_count = block_size;
drivers/crypto/ccp/ccp-crypto-sha.c:	state.type = rctx->type;
drivers/crypto/ccp/ccp-crypto-sha.c:	state.msg_bits = rctx->msg_bits;
drivers/crypto/ccp/ccp-crypto-sha.c:	state.first = rctx->first;
drivers/crypto/ccp/ccp-crypto-sha.c:	memcpy(state.ctx, rctx->ctx, sizeof(state.ctx));
drivers/crypto/ccp/ccp-crypto-sha.c:	state.buf_count = rctx->buf_count;
drivers/crypto/ccp/ccp-crypto-sha.c:	memcpy(state.buf, rctx->buf, sizeof(state.buf));
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->type = state.type;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->msg_bits = state.msg_bits;
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->first = state.first;
drivers/crypto/ccp/ccp-crypto-sha.c:	memcpy(rctx->ctx, state.ctx, sizeof(rctx->ctx));
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->buf_count = state.buf_count;
drivers/crypto/ccp/ccp-crypto-sha.c:	memcpy(rctx->buf, state.buf, sizeof(rctx->buf));
drivers/crypto/ccp/ccp-crypto-sha.c:	struct crypto_shash *shash = ctx->u.sha.hmac_tfm;
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->u.sha.key_len = 0;
drivers/crypto/ccp/ccp-crypto-sha.c:	memset(ctx->u.sha.key, 0, sizeof(ctx->u.sha.key));
drivers/crypto/ccp/ccp-crypto-sha.c:					  ctx->u.sha.key);
drivers/crypto/ccp/ccp-crypto-sha.c:		memcpy(ctx->u.sha.key, key, key_len);
drivers/crypto/ccp/ccp-crypto-sha.c:		ctx->u.sha.ipad[i] = ctx->u.sha.key[i] ^ 0x36;
drivers/crypto/ccp/ccp-crypto-sha.c:		ctx->u.sha.opad[i] = ctx->u.sha.key[i] ^ 0x5c;
drivers/crypto/ccp/ccp-crypto-sha.c:	sg_init_one(&ctx->u.sha.opad_sg, ctx->u.sha.opad, block_size);
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->u.sha.opad_count = block_size;
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->u.sha.key_len = key_len;
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->complete = ccp_sha_complete;
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->u.sha.key_len = 0;
drivers/crypto/ccp/ccp-crypto-sha.c:	ctx->u.sha.hmac_tfm = hmac_tfm;
drivers/crypto/ccp/ccp-crypto-sha.c:	if (ctx->u.sha.hmac_tfm)
drivers/crypto/ccp/ccp-crypto-sha.c:		crypto_free_shash(ctx->u.sha.hmac_tfm);
drivers/crypto/ccp/ccp-crypto-aes.c:	if (ctx->u.aes.mode != CCP_AES_MODE_ECB)
drivers/crypto/ccp/ccp-crypto-aes.c:		memcpy(req->info, rctx->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:		ctx->u.aes.type = CCP_AES_TYPE_128;
drivers/crypto/ccp/ccp-crypto-aes.c:		ctx->u.aes.type = CCP_AES_TYPE_192;
drivers/crypto/ccp/ccp-crypto-aes.c:		ctx->u.aes.type = CCP_AES_TYPE_256;
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->u.aes.mode = alg->mode;
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->u.aes.key_len = key_len;
drivers/crypto/ccp/ccp-crypto-aes.c:	memcpy(ctx->u.aes.key, key, key_len);
drivers/crypto/ccp/ccp-crypto-aes.c:	sg_init_one(&ctx->u.aes.key_sg, ctx->u.aes.key, key_len);
drivers/crypto/ccp/ccp-crypto-aes.c:	if (!ctx->u.aes.key_len)
drivers/crypto/ccp/ccp-crypto-aes.c:	if (((ctx->u.aes.mode == CCP_AES_MODE_ECB) ||
drivers/crypto/ccp/ccp-crypto-aes.c:	     (ctx->u.aes.mode == CCP_AES_MODE_CBC) ||
drivers/crypto/ccp/ccp-crypto-aes.c:	     (ctx->u.aes.mode == CCP_AES_MODE_CFB)) &&
drivers/crypto/ccp/ccp-crypto-aes.c:	if (ctx->u.aes.mode != CCP_AES_MODE_ECB) {
drivers/crypto/ccp/ccp-crypto-aes.c:		memcpy(rctx->iv, req->info, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:		iv_sg = &rctx->iv_sg;
drivers/crypto/ccp/ccp-crypto-aes.c:		sg_init_one(iv_sg, rctx->iv, iv_len);
drivers/crypto/ccp/ccp-crypto-aes.c:	memset(&rctx->cmd, 0, sizeof(rctx->cmd));
drivers/crypto/ccp/ccp-crypto-aes.c:	INIT_LIST_HEAD(&rctx->cmd.entry);
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.engine = CCP_ENGINE_AES;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.type = ctx->u.aes.type;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.mode = ctx->u.aes.mode;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.action =
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.key = &ctx->u.aes.key_sg;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.key_len = ctx->u.aes.key_len;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.iv = iv_sg;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.iv_len = iv_len;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.src = req->src;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.src_len = req->nbytes;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-aes.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->complete = ccp_aes_complete;
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->u.aes.key_len = 0;
drivers/crypto/ccp/ccp-crypto-aes.c:	req->info = rctx->rfc3686_info;
drivers/crypto/ccp/ccp-crypto-aes.c:	memcpy(ctx->u.aes.nonce, key + key_len, CTR_RFC3686_NONCE_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:	iv = rctx->rfc3686_iv;
drivers/crypto/ccp/ccp-crypto-aes.c:	memcpy(iv, ctx->u.aes.nonce, CTR_RFC3686_NONCE_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->rfc3686_info = req->info;
drivers/crypto/ccp/ccp-crypto-aes.c:	req->info = rctx->rfc3686_iv;
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->complete = ccp_aes_rfc3686_complete;
drivers/crypto/ccp/ccp-crypto-aes.c:	ctx->u.aes.key_len = 0;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (rctx->hash_rem) {
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		unsigned int offset = rctx->nbytes - rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		scatterwalk_map_and_copy(rctx->buf, rctx->src,
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:					 offset, rctx->hash_rem, 0);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->buf_count = rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->buf_count = 0;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		memcpy(req->result, rctx->iv, digest_size);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_free_table(&rctx->data_sg);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (!ctx->u.aes.key_len)
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->null_msg = 0;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	len = (u64)rctx->buf_count + (u64)nbytes;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->buf_count += nbytes;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->src = req->src;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->nbytes = nbytes;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->final = final;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->hash_rem = final ? 0 : len & (block_size - 1);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->hash_cnt = len - rctx->hash_rem;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (!final && !rctx->hash_rem) {
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->hash_cnt -= block_size;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->hash_rem = block_size;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (final && (rctx->null_msg || (len & (block_size - 1))))
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_init_one(&rctx->iv_sg, rctx->iv, sizeof(rctx->iv));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ret = sg_alloc_table(&rctx->data_sg, sg_count, gfp);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (rctx->buf_count) {
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->buf_sg);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->hash_cnt += pad_length;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		memset(rctx->pad, 0, sizeof(rctx->pad));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		rctx->pad[0] = 0x80;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg_init_one(&rctx->pad_sg, rctx->pad, pad_length);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->pad_sg);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg = rctx->data_sg.sgl;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		cmac_key_sg = (need_pad) ? &ctx->u.aes.k2_sg
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:					 : &ctx->u.aes.k1_sg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memset(&rctx->cmd, 0, sizeof(rctx->cmd));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	INIT_LIST_HEAD(&rctx->cmd.entry);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.engine = CCP_ENGINE_AES;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.type = ctx->u.aes.type;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.mode = ctx->u.aes.mode;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.action = CCP_AES_ACTION_ENCRYPT;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.key = &ctx->u.aes.key_sg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.key_len = ctx->u.aes.key_len;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.iv = &rctx->iv_sg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.iv_len = AES_BLOCK_SIZE;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.src = sg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.src_len = rctx->hash_cnt;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.dst = NULL;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.cmac_key = cmac_key_sg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.cmac_key_len = ctx->u.aes.kn_len;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->cmd.u.aes.cmac_final = final;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_free_table(&rctx->data_sg);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->null_msg = 1;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	state.null_msg = rctx->null_msg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memcpy(state.iv, rctx->iv, sizeof(state.iv));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	state.buf_count = rctx->buf_count;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memcpy(state.buf, rctx->buf, sizeof(state.buf));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->null_msg = state.null_msg;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memcpy(rctx->iv, state.iv, sizeof(rctx->iv));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->buf_count = state.buf_count;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memcpy(rctx->buf, state.buf, sizeof(rctx->buf));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		ctx->u.aes.type = CCP_AES_TYPE_128;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		ctx->u.aes.type = CCP_AES_TYPE_192;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		ctx->u.aes.type = CCP_AES_TYPE_256;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.mode = alg->mode;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.key_len = 0;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ret = crypto_cipher_setkey(ctx->u.aes.tfm_cipher, key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memset(ctx->u.aes.key, 0, sizeof(ctx->u.aes.key));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	crypto_cipher_encrypt_one(ctx->u.aes.tfm_cipher, ctx->u.aes.key,
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:				  ctx->u.aes.key);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	k0_hi = be64_to_cpu(*((__be64 *)ctx->u.aes.key));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	k0_lo = be64_to_cpu(*((__be64 *)ctx->u.aes.key + 1));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (ctx->u.aes.key[0] & 0x80) {
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	gk = (__be64 *)ctx->u.aes.k1;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (ctx->u.aes.k1[0] & 0x80) {
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	gk = (__be64 *)ctx->u.aes.k2;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.kn_len = sizeof(ctx->u.aes.k1);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_init_one(&ctx->u.aes.k1_sg, ctx->u.aes.k1, sizeof(ctx->u.aes.k1));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_init_one(&ctx->u.aes.k2_sg, ctx->u.aes.k2, sizeof(ctx->u.aes.k2));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memset(ctx->u.aes.key, 0, sizeof(ctx->u.aes.key));
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	memcpy(ctx->u.aes.key, key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.key_len = key_len;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_init_one(&ctx->u.aes.key_sg, ctx->u.aes.key, key_len);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->complete = ccp_aes_cmac_complete;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.key_len = 0;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.tfm_cipher = cipher_tfm;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (ctx->u.aes.tfm_cipher)
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		crypto_free_cipher(ctx->u.aes.tfm_cipher);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ctx->u.aes.tfm_cipher = NULL;
drivers/crypto/atmel-aes.c:	if (!ctx->dd) {
drivers/crypto/atmel-aes.c:		ctx->dd = aes_dd;
drivers/crypto/atmel-aes.c:		aes_dd = ctx->dd;
drivers/crypto/atmel-aes.c:	dd->flags = (dd->flags & AES_FLAGS_PERSISTENT) | rctx->mode;
drivers/crypto/atmel-aes.c:	if (dd->ctx->keylen == AES_KEYSIZE_128)
drivers/crypto/atmel-aes.c:	else if (dd->ctx->keylen == AES_KEYSIZE_192)
drivers/crypto/atmel-aes.c:	atmel_aes_write_n(dd, AES_KEYWR(0), dd->ctx->key,
drivers/crypto/atmel-aes.c:			  SIZE_IN_WORDS(dd->ctx->keylen));
drivers/crypto/atmel-aes.c:	if (!IS_ALIGNED(len, dd->ctx->block_size))
drivers/crypto/atmel-aes.c:			if (!IS_ALIGNED(len, dd->ctx->block_size))
drivers/crypto/atmel-aes.c:		if (!IS_ALIGNED(sg->length, dd->ctx->block_size))
drivers/crypto/atmel-aes.c:		padlen = atmel_aes_padlen(len, dd->ctx->block_size);
drivers/crypto/atmel-aes.c:	switch (dd->ctx->block_size) {
drivers/crypto/atmel-aes.c:	err = ctx->start(dd);
drivers/crypto/atmel-aes.c:			dd->ctx->block_size != AES_BLOCK_SIZE);
drivers/crypto/atmel-aes.c:	ctx->offset += dd->total;
drivers/crypto/atmel-aes.c:	if (ctx->offset >= req->nbytes)
drivers/crypto/atmel-aes.c:	datalen = req->nbytes - ctx->offset;
drivers/crypto/atmel-aes.c:	ctr = be32_to_cpu(ctx->iv[3]);
drivers/crypto/atmel-aes.c:	src = scatterwalk_ffwd(ctx->src, req->src, ctx->offset);
drivers/crypto/atmel-aes.c:	       scatterwalk_ffwd(ctx->dst, req->dst, ctx->offset));
drivers/crypto/atmel-aes.c:	atmel_aes_write_ctrl(dd, use_dma, ctx->iv);
drivers/crypto/atmel-aes.c:		ctx->iv[3] = cpu_to_be32(ctr);
drivers/crypto/atmel-aes.c:		crypto_inc((u8 *)ctx->iv, AES_BLOCK_SIZE);
drivers/crypto/atmel-aes.c:	memcpy(ctx->iv, req->info, AES_BLOCK_SIZE);
drivers/crypto/atmel-aes.c:	ctx->offset = 0;
drivers/crypto/atmel-aes.c:		ctx->block_size = CFB8_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:		ctx->block_size = CFB16_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:		ctx->block_size = CFB32_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:		ctx->block_size = CFB64_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:		ctx->block_size = AES_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:	rctx->mode = mode;
drivers/crypto/atmel-aes.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/atmel-aes.c:	ctx->keylen = keylen;
drivers/crypto/atmel-aes.c:	ctx->base.start = atmel_aes_start;
drivers/crypto/atmel-aes.c:	ctx->base.start = atmel_aes_ctr_start;
drivers/crypto/atmel-aes.c:	ctx->ghash_in = ghash_in;
drivers/crypto/atmel-aes.c:	ctx->ghash_out = ghash_out;
drivers/crypto/atmel-aes.c:	ctx->ghash_resume = resume;
drivers/crypto/atmel-aes.c:	if (ctx->ghash_in)
drivers/crypto/atmel-aes.c:		atmel_aes_write_block(dd, AES_GHASHR(0), ctx->ghash_in);
drivers/crypto/atmel-aes.c:	atmel_aes_read_block(dd, AES_GHASHR(0), ctx->ghash_out);
drivers/crypto/atmel-aes.c:	return ctx->ghash_resume(dd);
drivers/crypto/atmel-aes.c:		memcpy(ctx->j0, iv, ivsize);
drivers/crypto/atmel-aes.c:		ctx->j0[3] = cpu_to_be32(1);
drivers/crypto/atmel-aes.c:				   NULL, ctx->j0, atmel_aes_gcm_process);
drivers/crypto/atmel-aes.c:	ctx->textlen = req->cryptlen - (enc ? 0 : authsize);
drivers/crypto/atmel-aes.c:	if (likely(req->assoclen != 0 || ctx->textlen != 0))
drivers/crypto/atmel-aes.c:	u32 j0_lsw, *j0 = ctx->j0;
drivers/crypto/atmel-aes.c:	atmel_aes_write(dd, AES_CLENR, ctx->textlen);
drivers/crypto/atmel-aes.c:	bool use_dma = (ctx->textlen >= ATMEL_AES_DMA_THRESHOLD);
drivers/crypto/atmel-aes.c:	if (unlikely(ctx->textlen == 0))
drivers/crypto/atmel-aes.c:	src = scatterwalk_ffwd(ctx->src, req->src, req->assoclen);
drivers/crypto/atmel-aes.c:	       scatterwalk_ffwd(ctx->dst, req->dst, req->assoclen));
drivers/crypto/atmel-aes.c:		return atmel_aes_dma_start(dd, src, dst, ctx->textlen,
drivers/crypto/atmel-aes.c:	return atmel_aes_cpu_start(dd, src, dst, ctx->textlen,
drivers/crypto/atmel-aes.c:	atmel_aes_read_block(dd, AES_GHASHR(0), ctx->ghash);
drivers/crypto/atmel-aes.c:	data[1] = cpu_to_be64(ctx->textlen * 8);
drivers/crypto/atmel-aes.c:				   ctx->ghash, ctx->ghash, atmel_aes_gcm_tag);
drivers/crypto/atmel-aes.c:	atmel_aes_write_ctrl(dd, false, ctx->j0);
drivers/crypto/atmel-aes.c:	atmel_aes_write_block(dd, AES_IDATAR(0), ctx->ghash);
drivers/crypto/atmel-aes.c:	u32 offset, authsize, itag[4], *otag = ctx->tag;
drivers/crypto/atmel-aes.c:		atmel_aes_read_block(dd, AES_TAGR(0), ctx->tag);
drivers/crypto/atmel-aes.c:		atmel_aes_read_block(dd, AES_ODATAR(0), ctx->tag);
drivers/crypto/atmel-aes.c:	offset = req->assoclen + ctx->textlen;
drivers/crypto/atmel-aes.c:	ctx->block_size = AES_BLOCK_SIZE;
drivers/crypto/atmel-aes.c:	rctx->mode = AES_FLAGS_GCM | mode;
drivers/crypto/atmel-aes.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/atmel-aes.c:	ctx->keylen = keylen;
drivers/crypto/atmel-aes.c:	ctx->base.start = atmel_aes_gcm_start;
drivers/crypto/bfin_crc.c:	dev_dbg(ctx->crc->dev, "crc_init\n");
drivers/crypto/bfin_crc.c:		crc_ctx->crc = crc;
drivers/crypto/bfin_crc.c:		dev_dbg(ctx->crc->dev, "init: requested sg list is too big > %d\n",
drivers/crypto/bfin_crc.c:	ctx->crc = crc;
drivers/crypto/bfin_crc.c:	ctx->bufnext_len = 0;
drivers/crypto/bfin_crc.c:	ctx->buflast_len = 0;
drivers/crypto/bfin_crc.c:	ctx->sg_buflen = 0;
drivers/crypto/bfin_crc.c:	ctx->total = 0;
drivers/crypto/bfin_crc.c:	ctx->flag = 0;
drivers/crypto/bfin_crc.c:	put_unaligned_le32(crc_ctx->key, req->result);
drivers/crypto/bfin_crc.c:	dev_dbg(ctx->crc->dev, "init: digest size: %d\n",
drivers/crypto/bfin_crc.c:	return bfin_crypto_crc_init_hw(crc, crc_ctx->key);
drivers/crypto/bfin_crc.c:	dma_map_sg(crc->dev, ctx->sg, ctx->sg_nents, DMA_TO_DEVICE);
drivers/crypto/bfin_crc.c:	for_each_sg(ctx->sg, sg, ctx->sg_nents, j) {
drivers/crypto/bfin_crc.c:			dma_count = sg_dma_len(sg) - ctx->bufnext_len;
drivers/crypto/bfin_crc.c:	if (ctx->bufnext_len && (ctx->flag == CRC_CRYPTO_STATE_FINALUPDATE ||
drivers/crypto/bfin_crc.c:		ctx->flag == CRC_CRYPTO_STATE_FINISH)) {
drivers/crypto/bfin_crc.c:		crc->sg_cpu[i].start_addr = dma_map_single(crc->dev, ctx->bufnext,
drivers/crypto/bfin_crc.c:	ctx->sg = NULL;
drivers/crypto/bfin_crc.c:	ctx->sg_buflen = 0;
drivers/crypto/bfin_crc.c:	ctx->sg_nents = 0;
drivers/crypto/bfin_crc.c:						ctx->flag, req->nbytes);
drivers/crypto/bfin_crc.c:	if (ctx->flag == CRC_CRYPTO_STATE_FINISH) {
drivers/crypto/bfin_crc.c:		if (ctx->bufnext_len == 0) {
drivers/crypto/bfin_crc.c:		memset(ctx->bufnext + ctx->bufnext_len, 0,
drivers/crypto/bfin_crc.c:				CHKSUM_DIGEST_SIZE - ctx->bufnext_len);
drivers/crypto/bfin_crc.c:		if (ctx->bufnext_len + req->nbytes < CHKSUM_DIGEST_SIZE) {
drivers/crypto/bfin_crc.c:			memcpy(ctx->bufnext + ctx->bufnext_len,
drivers/crypto/bfin_crc.c:			ctx->bufnext_len += req->nbytes;
drivers/crypto/bfin_crc.c:			if (ctx->flag == CRC_CRYPTO_STATE_FINALUPDATE &&
drivers/crypto/bfin_crc.c:				ctx->bufnext_len) {
drivers/crypto/bfin_crc.c:		if (ctx->bufnext_len) {
drivers/crypto/bfin_crc.c:			ctx->buflast_len = ctx->bufnext_len;
drivers/crypto/bfin_crc.c:			memcpy(ctx->buflast, ctx->bufnext, ctx->buflast_len);
drivers/crypto/bfin_crc.c:			nsg = ctx->sg_buflen ? 2 : 1;
drivers/crypto/bfin_crc.c:			sg_init_table(ctx->bufsl, nsg);
drivers/crypto/bfin_crc.c:			sg_set_buf(ctx->bufsl, ctx->buflast, ctx->buflast_len);
drivers/crypto/bfin_crc.c:				sg_chain(ctx->bufsl, nsg, req->src);
drivers/crypto/bfin_crc.c:			ctx->sg = ctx->bufsl;
drivers/crypto/bfin_crc.c:			ctx->sg = req->src;
drivers/crypto/bfin_crc.c:		nsg = sg_nents(ctx->sg);
drivers/crypto/bfin_crc.c:		ctx->sg_nents = nsg;
drivers/crypto/bfin_crc.c:		ctx->sg_buflen = ctx->buflast_len + req->nbytes;
drivers/crypto/bfin_crc.c:		ctx->bufnext_len = ctx->sg_buflen % 4;
drivers/crypto/bfin_crc.c:		ctx->sg_buflen &= ~0x3;
drivers/crypto/bfin_crc.c:		if (ctx->bufnext_len) {
drivers/crypto/bfin_crc.c:			memset(ctx->bufnext, 0, CHKSUM_DIGEST_SIZE);
drivers/crypto/bfin_crc.c:			nextlen = ctx->bufnext_len;
drivers/crypto/bfin_crc.c:				sg = sg_get(ctx->sg, nsg, i);
drivers/crypto/bfin_crc.c:				memcpy(ctx->bufnext + nextlen - j,
drivers/crypto/bfin_crc.c:					ctx->sg_nents--;
drivers/crypto/bfin_crc.c:	if (ctx->bufnext_len && (ctx->flag == CRC_CRYPTO_STATE_FINALUPDATE ||
drivers/crypto/bfin_crc.c:		ctx->flag == CRC_CRYPTO_STATE_FINISH))
drivers/crypto/bfin_crc.c:		ctx->sg_buflen += CHKSUM_DIGEST_SIZE;
drivers/crypto/bfin_crc.c:	writel(ctx->sg_buflen >> 2, &crc->regs->datacnt);
drivers/crypto/bfin_crc.c:	dev_dbg(ctx->crc->dev, "crc_update\n");
drivers/crypto/bfin_crc.c:	ctx->total += req->nbytes;
drivers/crypto/bfin_crc.c:	ctx->flag = CRC_CRYPTO_STATE_UPDATE;
drivers/crypto/bfin_crc.c:	return bfin_crypto_crc_handle_queue(ctx->crc, req);
drivers/crypto/bfin_crc.c:	dev_dbg(ctx->crc->dev, "crc_final\n");
drivers/crypto/bfin_crc.c:	ctx->flag = CRC_CRYPTO_STATE_FINISH;
drivers/crypto/bfin_crc.c:	crc_ctx->key = 0;
drivers/crypto/bfin_crc.c:	return bfin_crypto_crc_handle_queue(ctx->crc, req);
drivers/crypto/bfin_crc.c:	dev_dbg(ctx->crc->dev, "crc_finishupdate\n");
drivers/crypto/bfin_crc.c:	ctx->total += req->nbytes;
drivers/crypto/bfin_crc.c:	ctx->flag = CRC_CRYPTO_STATE_FINALUPDATE;
drivers/crypto/bfin_crc.c:	crc_ctx->key = 0;
drivers/crypto/bfin_crc.c:	return bfin_crypto_crc_handle_queue(ctx->crc, req);
drivers/crypto/bfin_crc.c:	dev_dbg(crc_ctx->crc->dev, "crc_setkey\n");
drivers/crypto/bfin_crc.c:	crc_ctx->key = get_unaligned_le32(key);
drivers/crypto/bfin_crc.c:	crc_ctx->key = 0;
drivers/crypto/mxs-dcp.c:	const int chan = actx->chan;
drivers/crypto/mxs-dcp.c:	struct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];
drivers/crypto/mxs-dcp.c:	struct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];
drivers/crypto/mxs-dcp.c:	if (rctx->enc)
drivers/crypto/mxs-dcp.c:	if (rctx->ecb)
drivers/crypto/mxs-dcp.c:	desc->size = actx->fill;
drivers/crypto/mxs-dcp.c:	actx->fill = 0;
drivers/crypto/mxs-dcp.c:	memcpy(key, actx->key, actx->key_len);
drivers/crypto/mxs-dcp.c:	if (!rctx->ecb) {
drivers/crypto/mxs-dcp.c:			if (actx->fill + len > out_off)
drivers/crypto/mxs-dcp.c:				clen = out_off - actx->fill;
drivers/crypto/mxs-dcp.c:			memcpy(in_buf + actx->fill, src_buf, clen);
drivers/crypto/mxs-dcp.c:			actx->fill += clen;
drivers/crypto/mxs-dcp.c:			if (actx->fill == out_off || sg_is_last(src)) {
drivers/crypto/mxs-dcp.c:				while (dst && actx->fill) {
drivers/crypto/mxs-dcp.c:						  actx->fill);
drivers/crypto/mxs-dcp.c:					actx->fill -= rem;
drivers/crypto/mxs-dcp.c:	SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/mxs-dcp.c:	skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/mxs-dcp.c:	if (unlikely(actx->key_len != AES_KEYSIZE_128))
drivers/crypto/mxs-dcp.c:	rctx->enc = enc;
drivers/crypto/mxs-dcp.c:	rctx->ecb = ecb;
drivers/crypto/mxs-dcp.c:	actx->chan = DCP_CHAN_CRYPTO;
drivers/crypto/mxs-dcp.c:	mutex_lock(&sdcp->mutex[actx->chan]);
drivers/crypto/mxs-dcp.c:	ret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);
drivers/crypto/mxs-dcp.c:	mutex_unlock(&sdcp->mutex[actx->chan]);
drivers/crypto/mxs-dcp.c:	wake_up_process(sdcp->thread[actx->chan]);
drivers/crypto/mxs-dcp.c:	actx->key_len = len;
drivers/crypto/mxs-dcp.c:		memcpy(actx->key, key, len);
drivers/crypto/mxs-dcp.c:	crypto_skcipher_clear_flags(actx->fallback, CRYPTO_TFM_REQ_MASK);
drivers/crypto/mxs-dcp.c:	crypto_skcipher_set_flags(actx->fallback,
drivers/crypto/mxs-dcp.c:	ret = crypto_skcipher_setkey(actx->fallback, key, len);
drivers/crypto/mxs-dcp.c:	tfm->base.crt_flags |= crypto_skcipher_get_flags(actx->fallback) &
drivers/crypto/mxs-dcp.c:	actx->fallback = blk;
drivers/crypto/mxs-dcp.c:	crypto_free_skcipher(actx->fallback);
drivers/crypto/mxs-dcp.c:	struct dcp_dma_desc *desc = &sdcp->coh->desc[actx->chan];
drivers/crypto/mxs-dcp.c:	if (rctx->init)
drivers/crypto/mxs-dcp.c:	desc->control1 = actx->alg;
drivers/crypto/mxs-dcp.c:	desc->size = actx->fill;
drivers/crypto/mxs-dcp.c:	if (rctx->fini) {
drivers/crypto/mxs-dcp.c:	if (rctx->fini)
drivers/crypto/mxs-dcp.c:	int fin = rctx->fini;
drivers/crypto/mxs-dcp.c:		rctx->fini = 0;
drivers/crypto/mxs-dcp.c:			if (actx->fill + len > DCP_BUF_SZ)
drivers/crypto/mxs-dcp.c:				clen = DCP_BUF_SZ - actx->fill;
drivers/crypto/mxs-dcp.c:			memcpy(in_buf + actx->fill, src_buf, clen);
drivers/crypto/mxs-dcp.c:			actx->fill += clen;
drivers/crypto/mxs-dcp.c:			if (len && actx->fill == DCP_BUF_SZ) {
drivers/crypto/mxs-dcp.c:				actx->fill = 0;
drivers/crypto/mxs-dcp.c:				rctx->init = 0;
drivers/crypto/mxs-dcp.c:		rctx->fini = 1;
drivers/crypto/mxs-dcp.c:		actx->fill = 0;
drivers/crypto/mxs-dcp.c:			fini = rctx->fini;
drivers/crypto/mxs-dcp.c:		actx->alg = MXS_DCP_CONTROL1_HASH_SELECT_SHA1;
drivers/crypto/mxs-dcp.c:		actx->alg = MXS_DCP_CONTROL1_HASH_SELECT_SHA256;
drivers/crypto/mxs-dcp.c:	actx->fill = 0;
drivers/crypto/mxs-dcp.c:	actx->hot = 0;
drivers/crypto/mxs-dcp.c:	actx->chan = DCP_CHAN_HASH_SHA;
drivers/crypto/mxs-dcp.c:	mutex_init(&actx->mutex);
drivers/crypto/mxs-dcp.c:	mutex_lock(&actx->mutex);
drivers/crypto/mxs-dcp.c:	rctx->fini = fini;
drivers/crypto/mxs-dcp.c:	if (!actx->hot) {
drivers/crypto/mxs-dcp.c:		actx->hot = 1;
drivers/crypto/mxs-dcp.c:		rctx->init = 1;
drivers/crypto/mxs-dcp.c:	mutex_lock(&sdcp->mutex[actx->chan]);
drivers/crypto/mxs-dcp.c:	ret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);
drivers/crypto/mxs-dcp.c:	mutex_unlock(&sdcp->mutex[actx->chan]);
drivers/crypto/mxs-dcp.c:	wake_up_process(sdcp->thread[actx->chan]);
drivers/crypto/mxs-dcp.c:	mutex_unlock(&actx->mutex);
drivers/crypto/talitos.c:	memcpy(ctx->key, keys.authkey, keys.authkeylen);
drivers/crypto/talitos.c:	memcpy(&ctx->key[keys.authkeylen], keys.enckey, keys.enckeylen);
drivers/crypto/talitos.c:	ctx->keylen = keys.authkeylen + keys.enckeylen;
drivers/crypto/talitos.c:	ctx->enckeylen = keys.enckeylen;
drivers/crypto/talitos.c:	ctx->authkeylen = keys.authkeylen;
drivers/crypto/talitos.c:		sg_pcopy_to_buffer(areq->dst, dst_nents, ctx->iv, ivsize,
drivers/crypto/talitos.c:	struct device *dev = ctx->dev;
drivers/crypto/talitos.c:	map_single_talitos_ptr(dev, &desc->ptr[0], ctx->authkeylen, &ctx->key,
drivers/crypto/talitos.c:		map_single_talitos_ptr(dev, &desc->ptr[3], ctx->enckeylen,
drivers/crypto/talitos.c:				       (char *)&ctx->key + ctx->authkeylen,
drivers/crypto/talitos.c:		map_single_talitos_ptr(dev, &desc->ptr[2], ctx->enckeylen,
drivers/crypto/talitos.c:				       (char *)&ctx->key + ctx->authkeylen,
drivers/crypto/talitos.c:		map_single_talitos_ptr(dev, &desc->ptr[6], ivsize, ctx->iv,
drivers/crypto/talitos.c:	ret = talitos_submit(dev, ctx->ch, desc, callback, areq);
drivers/crypto/talitos.c:	return talitos_edesc_alloc(ctx->dev, areq->src, areq->dst,
drivers/crypto/talitos.c:	edesc->desc.hdr = ctx->desc_hdr_template | DESC_HDR_MODE0_ENCRYPT;
drivers/crypto/talitos.c:	struct talitos_private *priv = dev_get_drvdata(ctx->dev);
drivers/crypto/talitos.c:		edesc->desc.hdr = ctx->desc_hdr_template |
drivers/crypto/talitos.c:	edesc->desc.hdr = ctx->desc_hdr_template | DESC_HDR_DIR_INBOUND;
drivers/crypto/talitos.c:	memcpy(&ctx->key, key, keylen);
drivers/crypto/talitos.c:	ctx->keylen = keylen;
drivers/crypto/talitos.c:	struct device *dev = ctx->dev;
drivers/crypto/talitos.c:	map_single_talitos_ptr(dev, &desc->ptr[2], ctx->keylen,
drivers/crypto/talitos.c:			       (char *)&ctx->key, DMA_TO_DEVICE);
drivers/crypto/talitos.c:	map_single_talitos_ptr(dev, &desc->ptr[5], ivsize, ctx->iv,
drivers/crypto/talitos.c:	ret = talitos_submit(dev, ctx->ch, desc, callback, areq);
drivers/crypto/talitos.c:	return talitos_edesc_alloc(ctx->dev, areq->src, areq->dst,
drivers/crypto/talitos.c:	edesc->desc.hdr = ctx->desc_hdr_template | DESC_HDR_MODE0_ENCRYPT;
drivers/crypto/talitos.c:	edesc->desc.hdr = ctx->desc_hdr_template | DESC_HDR_DIR_INBOUND;
drivers/crypto/talitos.c:	talitos_sg_unmap(dev, edesc, req_ctx->psrc, NULL, 0, 0);
drivers/crypto/talitos.c:	/* When using hashctx-in, must unmap it. */
drivers/crypto/talitos.c:	if (!req_ctx->last && req_ctx->to_hash_later) {
drivers/crypto/talitos.c:		memcpy(req_ctx->buf, req_ctx->bufnext, req_ctx->to_hash_later);
drivers/crypto/talitos.c:		req_ctx->nbuf = req_ctx->to_hash_later;
drivers/crypto/talitos.c:	map_single_talitos_ptr(ctx->dev, ptr, sizeof(padded_hash),
drivers/crypto/talitos.c:	struct device *dev = ctx->dev;
drivers/crypto/talitos.c:	if (!req_ctx->first || req_ctx->swinit) {
drivers/crypto/talitos.c:				       req_ctx->hw_context_size,
drivers/crypto/talitos.c:				       (char *)req_ctx->hw_context,
drivers/crypto/talitos.c:		req_ctx->swinit = 0;
drivers/crypto/talitos.c:	req_ctx->first = 0;
drivers/crypto/talitos.c:	if (ctx->keylen)
drivers/crypto/talitos.c:		map_single_talitos_ptr(dev, &desc->ptr[2], ctx->keylen,
drivers/crypto/talitos.c:				       (char *)&ctx->key, DMA_TO_DEVICE);
drivers/crypto/talitos.c:		sg_copy_to_buffer(req_ctx->psrc, sg_count, edesc->buf, length);
drivers/crypto/talitos.c:		sg_count = dma_map_sg(dev, req_ctx->psrc, sg_count,
drivers/crypto/talitos.c:	sg_count = talitos_sg_map(dev, req_ctx->psrc, length, edesc,
drivers/crypto/talitos.c:	if (req_ctx->last)
drivers/crypto/talitos.c:				       req_ctx->hw_context_size,
drivers/crypto/talitos.c:				       req_ctx->hw_context, DMA_FROM_DEVICE);
drivers/crypto/talitos.c:	ret = talitos_submit(dev, ctx->ch, desc, callback, areq);
drivers/crypto/talitos.c:	return talitos_edesc_alloc(ctx->dev, req_ctx->psrc, NULL, NULL, 0,
drivers/crypto/talitos.c:	req_ctx->nbuf = 0;
drivers/crypto/talitos.c:	req_ctx->first = 1; /* first indicates h/w must init its context */
drivers/crypto/talitos.c:	req_ctx->swinit = 0; /* assume h/w init of context */
drivers/crypto/talitos.c:	req_ctx->hw_context_size =
drivers/crypto/talitos.c:	req_ctx->swinit = 1;/* prevent h/w initting context with sha256 values*/
drivers/crypto/talitos.c:	req_ctx->hw_context[0] = SHA224_H0;
drivers/crypto/talitos.c:	req_ctx->hw_context[1] = SHA224_H1;
drivers/crypto/talitos.c:	req_ctx->hw_context[2] = SHA224_H2;
drivers/crypto/talitos.c:	req_ctx->hw_context[3] = SHA224_H3;
drivers/crypto/talitos.c:	req_ctx->hw_context[4] = SHA224_H4;
drivers/crypto/talitos.c:	req_ctx->hw_context[5] = SHA224_H5;
drivers/crypto/talitos.c:	req_ctx->hw_context[6] = SHA224_H6;
drivers/crypto/talitos.c:	req_ctx->hw_context[7] = SHA224_H7;
drivers/crypto/talitos.c:	req_ctx->hw_context[8] = 0;
drivers/crypto/talitos.c:	req_ctx->hw_context[9] = 0;
drivers/crypto/talitos.c:	if (!req_ctx->last && (nbytes + req_ctx->nbuf <= blocksize)) {
drivers/crypto/talitos.c:			dev_err(ctx->dev, "Invalid number of src SG.\n");
drivers/crypto/talitos.c:				  req_ctx->buf + req_ctx->nbuf, nbytes);
drivers/crypto/talitos.c:		req_ctx->nbuf += nbytes;
drivers/crypto/talitos.c:	nbytes_to_hash = nbytes + req_ctx->nbuf;
drivers/crypto/talitos.c:	if (req_ctx->last)
drivers/crypto/talitos.c:	if (req_ctx->nbuf) {
drivers/crypto/talitos.c:		nsg = (req_ctx->nbuf < nbytes_to_hash) ? 2 : 1;
drivers/crypto/talitos.c:		sg_init_table(req_ctx->bufsl, nsg);
drivers/crypto/talitos.c:		sg_set_buf(req_ctx->bufsl, req_ctx->buf, req_ctx->nbuf);
drivers/crypto/talitos.c:			sg_chain(req_ctx->bufsl, 2, areq->src);
drivers/crypto/talitos.c:		req_ctx->psrc = req_ctx->bufsl;
drivers/crypto/talitos.c:		req_ctx->psrc = areq->src;
drivers/crypto/talitos.c:			dev_err(ctx->dev, "Invalid number of src SG.\n");
drivers/crypto/talitos.c:				      req_ctx->bufnext,
drivers/crypto/talitos.c:	req_ctx->to_hash_later = to_hash_later;
drivers/crypto/talitos.c:	edesc->desc.hdr = ctx->desc_hdr_template;
drivers/crypto/talitos.c:	if (req_ctx->last)
drivers/crypto/talitos.c:	if (req_ctx->first && !req_ctx->swinit)
drivers/crypto/talitos.c:	if (ctx->keylen && (req_ctx->first || req_ctx->last))
drivers/crypto/talitos.c:	req_ctx->last = 0;
drivers/crypto/talitos.c:	req_ctx->last = 1;
drivers/crypto/talitos.c:	req_ctx->last = 1;
drivers/crypto/talitos.c:	req_ctx->last = 1;
drivers/crypto/talitos.c:	memcpy(export->hw_context, req_ctx->hw_context,
drivers/crypto/talitos.c:	       req_ctx->hw_context_size);
drivers/crypto/talitos.c:	memcpy(export->buf, req_ctx->buf, req_ctx->nbuf);
drivers/crypto/talitos.c:	export->swinit = req_ctx->swinit;
drivers/crypto/talitos.c:	export->first = req_ctx->first;
drivers/crypto/talitos.c:	export->last = req_ctx->last;
drivers/crypto/talitos.c:	export->to_hash_later = req_ctx->to_hash_later;
drivers/crypto/talitos.c:	export->nbuf = req_ctx->nbuf;
drivers/crypto/talitos.c:	req_ctx->hw_context_size =
drivers/crypto/talitos.c:	memcpy(req_ctx->hw_context, export->hw_context,
drivers/crypto/talitos.c:	       req_ctx->hw_context_size);
drivers/crypto/talitos.c:	memcpy(req_ctx->buf, export->buf, export->nbuf);
drivers/crypto/talitos.c:	req_ctx->swinit = export->swinit;
drivers/crypto/talitos.c:	req_ctx->first = export->first;
drivers/crypto/talitos.c:	req_ctx->last = export->last;
drivers/crypto/talitos.c:	req_ctx->to_hash_later = export->to_hash_later;
drivers/crypto/talitos.c:	req_ctx->nbuf = export->nbuf;
drivers/crypto/talitos.c:	ctx->keylen = 0;
drivers/crypto/talitos.c:		memcpy(ctx->key, key, keysize);
drivers/crypto/talitos.c:		memcpy(ctx->key, hash, digestsize);
drivers/crypto/talitos.c:	ctx->keylen = keysize;
drivers/crypto/talitos.c:	ctx->dev = talitos_alg->dev;
drivers/crypto/talitos.c:	priv = dev_get_drvdata(ctx->dev);
drivers/crypto/talitos.c:	ctx->ch = atomic_inc_return(&priv->last_chan) &
drivers/crypto/talitos.c:	ctx->desc_hdr_template = talitos_alg->algt.desc_hdr_template;
drivers/crypto/talitos.c:	ctx->desc_hdr_template |= DESC_HDR_DONE_NOTIFY;
drivers/crypto/talitos.c:	ctx->keylen = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(!ctx->xa))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->p_size;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_hdr.cd_pars.func_id = qat_dh_fn_id(ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:						    !req->src && ctx->g2);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.dh.in.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.dh.in.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (ctx->g2) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in_g2.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in_g2.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.b = ctx->dma_g;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (sg_is_last(req->src) && req->src_len == ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:			int shift = ctx->p_size - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:								 ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_zalloc_coherent(dev, ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ret = adf_send_message(ctx->inst->pke_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->out.dh.r, ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_free_coherent(dev, ctx->p_size, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:						 ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p_size = params->p_size;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p = dma_zalloc_coherent(dev, ctx->p_size, &ctx->dma_p, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->p)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->p, params->p, ctx->p_size);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->g2 = true;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->g = dma_zalloc_coherent(dev, ctx->p_size, &ctx->dma_g, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->g) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, ctx->p, ctx->dma_p);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->p = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->g + (ctx->p_size - params->g_size), params->g,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->g) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, ctx->g, ctx->dma_g);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->g = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->xa) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, ctx->xa, ctx->dma_xa);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->xa = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->p) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, ctx->p, ctx->dma_p);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->p = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p_size = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->g2 = false;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->xa = dma_zalloc_coherent(dev, ctx->p_size, &ctx->dma_xa,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->xa) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->xa + (ctx->p_size - params.key_size), params.key,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	return ctx->p ? ctx->p_size : -EINVAL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p_size = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->g2 = false;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->inst = inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_crypto_put_instance(ctx->inst);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(!ctx->n || !ctx->e))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->key_sz;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_hdr.cd_pars.func_id = qat_rsa_enc_fn_id(ctx->key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.rsa.enc.e = ctx->dma_e;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.rsa.enc.n = ctx->dma_n;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->src) && req->src_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		int shift = ctx->key_sz - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = dma_zalloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_zalloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ret = adf_send_message(ctx->inst->pke_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 ctx->key_sz, DMA_FROM_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 ctx->key_sz, DMA_TO_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(!ctx->n || !ctx->d))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->key_sz;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_hdr.cd_pars.func_id = ctx->crt_mode ?
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_rsa_dec_fn_id_crt(ctx->key_sz) :
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_rsa_dec_fn_id(ctx->key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->crt_mode) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.q = ctx->dma_q;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.dp = ctx->dma_dp;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.dq = ctx->dma_dq;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.qinv = ctx->dma_qinv;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec.d = ctx->dma_d;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec.n = ctx->dma_n;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->src) && req->src_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		int shift = ctx->key_sz - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = dma_zalloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_zalloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->crt_mode)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->crt_mode)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ret = adf_send_message(ctx->inst->pke_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 ctx->key_sz, DMA_FROM_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 ctx->key_sz, DMA_TO_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->key_sz = vlen;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!qat_rsa_enc_fn_id(ctx->key_sz))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->n = dma_zalloc_coherent(dev, ctx->key_sz, &ctx->dma_n, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->n)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->n, ptr, ctx->key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->key_sz = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->n = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->key_sz || !vlen || vlen > ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		ctx->e = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->e = dma_zalloc_coherent(dev, ctx->key_sz, &ctx->dma_e, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->e)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->e + (ctx->key_sz - vlen), ptr, vlen);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->key_sz || !vlen || vlen > ctx->key_sz)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->d = dma_zalloc_coherent(dev, ctx->key_sz, &ctx->dma_d, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->d)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->d + (ctx->key_sz - vlen), ptr, vlen);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->d = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	unsigned int half_key_sz = ctx->key_sz / 2;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p = dma_zalloc_coherent(dev, half_key_sz, &ctx->dma_p, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->p)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->p + (half_key_sz - len), ptr, len);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->q = dma_zalloc_coherent(dev, half_key_sz, &ctx->dma_q, GFP_KERNEL);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->q)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->q + (half_key_sz - len), ptr, len);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dp = dma_zalloc_coherent(dev, half_key_sz, &ctx->dma_dp,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->dp)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->dp + (half_key_sz - len), ptr, len);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dq = dma_zalloc_coherent(dev, half_key_sz, &ctx->dma_dq,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->dq)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->dq + (half_key_sz - len), ptr, len);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->qinv = dma_zalloc_coherent(dev, half_key_sz, &ctx->dma_qinv,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->qinv)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memcpy(ctx->qinv + (half_key_sz - len), ptr, len);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->crt_mode = true;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memset(ctx->dq, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_free_coherent(dev, half_key_sz, ctx->dq, ctx->dma_dq);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dq = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memset(ctx->dp, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_free_coherent(dev, half_key_sz, ctx->dp, ctx->dma_dp);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dp = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memset(ctx->q, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_free_coherent(dev, half_key_sz, ctx->q, ctx->dma_q);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->q = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	memset(ctx->p, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_free_coherent(dev, half_key_sz, ctx->p, ctx->dma_p);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->crt_mode = false;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	unsigned int half_key_sz = ctx->key_sz / 2;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->n)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->n, ctx->dma_n);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->e)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->e, ctx->dma_e);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->d) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->d, '\0', ctx->key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->d, ctx->dma_d);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->p) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->p, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, half_key_sz, ctx->p, ctx->dma_p);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->q) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->q, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, half_key_sz, ctx->q, ctx->dma_q);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->dp) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->dp, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, half_key_sz, ctx->dp, ctx->dma_dp);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->dq) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->dq, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, half_key_sz, ctx->dq, ctx->dma_dq);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->qinv) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->qinv, '\0', half_key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, half_key_sz, ctx->qinv, ctx->dma_qinv);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->n = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->e = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->d = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->p = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->q = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dp = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->dq = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->qinv = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->crt_mode = false;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->key_sz = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!ctx->n || !ctx->e) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (private && !ctx->d) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:	return (ctx->n) ? ctx->key_sz : -EINVAL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->key_sz = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->inst = inst;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->n)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->n, ctx->dma_n);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->e)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->e, ctx->dma_e);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (ctx->d) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		memset(ctx->d, '\0', ctx->key_sz);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, ctx->d, ctx->dma_d);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_crypto_put_instance(ctx->inst);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->n = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->e = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	ctx->d = NULL;
drivers/crypto/qat/qat_common/qat_algs.c:	SHASH_DESC_ON_STACK(shash, ctx->hash_tfm);
drivers/crypto/qat/qat_common/qat_algs.c:	int block_size = crypto_shash_blocksize(ctx->hash_tfm);
drivers/crypto/qat/qat_common/qat_algs.c:	int digest_size = crypto_shash_digestsize(ctx->hash_tfm);
drivers/crypto/qat/qat_common/qat_algs.c:	shash->tfm = ctx->hash_tfm;
drivers/crypto/qat/qat_common/qat_algs.c:	switch (ctx->qat_hash_alg) {
drivers/crypto/qat/qat_common/qat_algs.c:	offset = round_up(qat_get_inter_state_size(ctx->qat_hash_alg), 8);
drivers/crypto/qat/qat_common/qat_algs.c:	switch (ctx->qat_hash_alg) {
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_enc *enc_ctx = &ctx->enc_cd->qat_enc_cd;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_hw_cipher_algo_blk *cipher = &enc_ctx->cipher;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_la_bulk_req *req_tmpl = &ctx->enc_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:					     ctx->qat_hash_alg, digestsize);
drivers/crypto/qat/qat_common/qat_algs.c:		cpu_to_be32(crypto_shash_blocksize(ctx->hash_tfm));
drivers/crypto/qat/qat_common/qat_algs.c:	cd_pars->u.s.content_desc_addr = ctx->enc_cd_paddr;
drivers/crypto/qat/qat_common/qat_algs.c:	switch (ctx->qat_hash_alg) {
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_dec *dec_ctx = &ctx->dec_cd->qat_dec_cd;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_hw_auth_algo_blk *hash = &dec_ctx->hash;
drivers/crypto/qat/qat_common/qat_algs.c:		roundup(crypto_shash_digestsize(ctx->hash_tfm), 8) * 2);
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_la_bulk_req *req_tmpl = &ctx->dec_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:					     ctx->qat_hash_alg,
drivers/crypto/qat/qat_common/qat_algs.c:		cpu_to_be32(crypto_shash_blocksize(ctx->hash_tfm));
drivers/crypto/qat/qat_common/qat_algs.c:	cd_pars->u.s.content_desc_addr = ctx->dec_cd_paddr;
drivers/crypto/qat/qat_common/qat_algs.c:		 roundup(crypto_shash_digestsize(ctx->hash_tfm), 8) * 2) >> 3;
drivers/crypto/qat/qat_common/qat_algs.c:	switch (ctx->qat_hash_alg) {
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_hw_cipher_algo_blk *enc_cd = ctx->enc_cd;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_la_bulk_req *req = &ctx->enc_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:	cd_pars->u.s.content_desc_addr = ctx->enc_cd_paddr;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_hw_cipher_algo_blk *dec_cd = ctx->dec_cd;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_la_bulk_req *req = &ctx->dec_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:	cd_pars->u.s.content_desc_addr = ctx->dec_cd_paddr;
drivers/crypto/qat/qat_common/qat_algs.c:	crypto_tfm_set_flags(ctx->tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->enc_cd, 0, sizeof(*ctx->enc_cd));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->dec_cd, 0, sizeof(*ctx->dec_cd));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(&ctx->enc_fw_req, 0, sizeof(ctx->enc_fw_req));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(&ctx->dec_fw_req, 0, sizeof(ctx->dec_fw_req));
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->inst = inst;
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->enc_cd = dma_zalloc_coherent(dev, sizeof(*ctx->enc_cd),
drivers/crypto/qat/qat_common/qat_algs.c:						  &ctx->enc_cd_paddr,
drivers/crypto/qat/qat_common/qat_algs.c:		if (!ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->dec_cd = dma_zalloc_coherent(dev, sizeof(*ctx->dec_cd),
drivers/crypto/qat/qat_common/qat_algs.c:						  &ctx->dec_cd_paddr,
drivers/crypto/qat/qat_common/qat_algs.c:		if (!ctx->dec_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:	memset(ctx->dec_cd, 0, sizeof(struct qat_alg_cd));
drivers/crypto/qat/qat_common/qat_algs.c:			  ctx->dec_cd, ctx->dec_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->dec_cd = NULL;
drivers/crypto/qat/qat_common/qat_algs.c:	memset(ctx->enc_cd, 0, sizeof(struct qat_alg_cd));
drivers/crypto/qat/qat_common/qat_algs.c:			  ctx->enc_cd, ctx->enc_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->enc_cd = NULL;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, areq->src, areq->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	*msg = ctx->dec_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:		ret = adf_send_message(ctx->inst->sym_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_algs.c:		qat_alg_free_bufl(ctx->inst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, areq->src, areq->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	*msg = ctx->enc_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:		ret = adf_send_message(ctx->inst->sym_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_algs.c:		qat_alg_free_bufl(ctx->inst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	spin_lock(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		dev = &GET_DEV(ctx->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->enc_cd, 0, sizeof(*ctx->enc_cd));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->dec_cd, 0, sizeof(*ctx->dec_cd));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(&ctx->enc_fw_req, 0, sizeof(ctx->enc_fw_req));
drivers/crypto/qat/qat_common/qat_algs.c:		memset(&ctx->dec_fw_req, 0, sizeof(ctx->dec_fw_req));
drivers/crypto/qat/qat_common/qat_algs.c:			spin_unlock(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->inst = inst;
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->enc_cd = dma_zalloc_coherent(dev, sizeof(*ctx->enc_cd),
drivers/crypto/qat/qat_common/qat_algs.c:						  &ctx->enc_cd_paddr,
drivers/crypto/qat/qat_common/qat_algs.c:		if (!ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:			spin_unlock(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:		ctx->dec_cd = dma_zalloc_coherent(dev, sizeof(*ctx->dec_cd),
drivers/crypto/qat/qat_common/qat_algs.c:						  &ctx->dec_cd_paddr,
drivers/crypto/qat/qat_common/qat_algs.c:		if (!ctx->dec_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:			spin_unlock(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:	spin_unlock(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:	memset(ctx->dec_cd, 0, sizeof(*ctx->dec_cd));
drivers/crypto/qat/qat_common/qat_algs.c:	dma_free_coherent(dev, sizeof(*ctx->dec_cd),
drivers/crypto/qat/qat_common/qat_algs.c:			  ctx->dec_cd, ctx->dec_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->dec_cd = NULL;
drivers/crypto/qat/qat_common/qat_algs.c:	memset(ctx->enc_cd, 0, sizeof(*ctx->enc_cd));
drivers/crypto/qat/qat_common/qat_algs.c:	dma_free_coherent(dev, sizeof(*ctx->enc_cd),
drivers/crypto/qat/qat_common/qat_algs.c:			  ctx->enc_cd, ctx->enc_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->enc_cd = NULL;
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, req->src, req->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	*msg = ctx->enc_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:		ret = adf_send_message(ctx->inst->sym_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_algs.c:		qat_alg_free_bufl(ctx->inst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, req->src, req->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	*msg = ctx->dec_fw_req;
drivers/crypto/qat/qat_common/qat_algs.c:		ret = adf_send_message(ctx->inst->sym_tx, (uint32_t *)msg);
drivers/crypto/qat/qat_common/qat_algs.c:		qat_alg_free_bufl(ctx->inst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->hash_tfm = crypto_alloc_shash(hash_name, 0, 0);
drivers/crypto/qat/qat_common/qat_algs.c:	if (IS_ERR(ctx->hash_tfm))
drivers/crypto/qat/qat_common/qat_algs.c:		return PTR_ERR(ctx->hash_tfm);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->qat_hash_alg = hash;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_algs.c:	crypto_free_shash(ctx->hash_tfm);
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->enc_cd, 0, sizeof(struct qat_alg_cd));
drivers/crypto/qat/qat_common/qat_algs.c:				  ctx->enc_cd, ctx->enc_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->dec_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->dec_cd, 0, sizeof(struct qat_alg_cd));
drivers/crypto/qat/qat_common/qat_algs.c:				  ctx->dec_cd, ctx->dec_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	spin_lock_init(&ctx->lock);
drivers/crypto/qat/qat_common/qat_algs.c:	ctx->tfm = tfm;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_crypto_instance *inst = ctx->inst;
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->enc_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->enc_cd, 0,
drivers/crypto/qat/qat_common/qat_algs.c:				  ctx->enc_cd, ctx->enc_cd_paddr);
drivers/crypto/qat/qat_common/qat_algs.c:	if (ctx->dec_cd) {
drivers/crypto/qat/qat_common/qat_algs.c:		memset(ctx->dec_cd, 0,
drivers/crypto/qat/qat_common/qat_algs.c:				  ctx->dec_cd, ctx->dec_cd_paddr);
drivers/crypto/s5p-sss.c:	if (dev->ctx->keylen == AES_KEYSIZE_192)
drivers/crypto/s5p-sss.c:	else if (dev->ctx->keylen == AES_KEYSIZE_256)
drivers/crypto/s5p-sss.c:	s5p_set_aes(dev, dev->ctx->aes_key, req->info, dev->ctx->keylen);
drivers/crypto/s5p-sss.c:	s5p_aes_crypt_start(dev, reqctx->mode);
drivers/crypto/s5p-sss.c:	struct s5p_aes_dev *dev = ctx->dev;
drivers/crypto/s5p-sss.c:	reqctx->mode = mode;
drivers/crypto/s5p-sss.c:	memcpy(ctx->aes_key, key, keylen);
drivers/crypto/s5p-sss.c:	ctx->keylen = keylen;
drivers/crypto/s5p-sss.c:	ctx->dev = s5p_dev;
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, &rctx->result_sg, 1, DMA_FROM_DEVICE);
drivers/crypto/qce/sha.c:	memcpy(rctx->digest, result->auth_iv, digestsize);
drivers/crypto/qce/sha.c:	rctx->byte_count[0] = cpu_to_be32(result->auth_byte_count[0]);
drivers/crypto/qce/sha.c:	rctx->byte_count[1] = cpu_to_be32(result->auth_byte_count[1]);
drivers/crypto/qce/sha.c:	req->src = rctx->src_orig;
drivers/crypto/qce/sha.c:	req->nbytes = rctx->nbytes_orig;
drivers/crypto/qce/sha.c:	rctx->last_blk = false;
drivers/crypto/qce/sha.c:	rctx->first_blk = false;
drivers/crypto/qce/sha.c:	unsigned long flags = rctx->flags;
drivers/crypto/qce/sha.c:		rctx->authkey = ctx->authkey;
drivers/crypto/qce/sha.c:		rctx->authklen = QCE_SHA_HMAC_KEY_SIZE;
drivers/crypto/qce/sha.c:		rctx->authkey = ctx->authkey;
drivers/crypto/qce/sha.c:		rctx->authklen = AES_KEYSIZE_128;
drivers/crypto/qce/sha.c:	rctx->src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/qce/sha.c:	if (rctx->src_nents < 0) {
drivers/crypto/qce/sha.c:		return rctx->src_nents;
drivers/crypto/qce/sha.c:	ret = dma_map_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	sg_init_one(&rctx->result_sg, qce->dma.result_buf, QCE_RESULT_BUF_SZ);
drivers/crypto/qce/sha.c:	ret = dma_map_sg(qce->dev, &rctx->result_sg, 1, DMA_FROM_DEVICE);
drivers/crypto/qce/sha.c:	ret = qce_dma_prep_sgs(&qce->dma, req->src, rctx->src_nents,
drivers/crypto/qce/sha.c:			       &rctx->result_sg, 1, qce_ahash_done, async_req);
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, &rctx->result_sg, 1, DMA_FROM_DEVICE);
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	rctx->first_blk = true;
drivers/crypto/qce/sha.c:	rctx->last_blk = false;
drivers/crypto/qce/sha.c:	rctx->flags = tmpl->alg_flags;
drivers/crypto/qce/sha.c:	memcpy(rctx->digest, std_iv, sizeof(rctx->digest));
drivers/crypto/qce/sha.c:	unsigned long flags = rctx->flags;
drivers/crypto/qce/sha.c:		out_state->count = rctx->count;
drivers/crypto/qce/sha.c:				       rctx->digest, digestsize);
drivers/crypto/qce/sha.c:		memcpy(out_state->buffer, rctx->buf, blocksize);
drivers/crypto/qce/sha.c:		out_state->count = rctx->count;
drivers/crypto/qce/sha.c:				       rctx->digest, digestsize);
drivers/crypto/qce/sha.c:		memcpy(out_state->buf, rctx->buf, blocksize);
drivers/crypto/qce/sha.c:	rctx->count = in_count;
drivers/crypto/qce/sha.c:	memcpy(rctx->buf, buffer, blocksize);
drivers/crypto/qce/sha.c:		rctx->first_blk = 1;
drivers/crypto/qce/sha.c:		rctx->first_blk = 0;
drivers/crypto/qce/sha.c:	rctx->byte_count[0] = (__force __be32)(count & ~SHA_PADDING_MASK);
drivers/crypto/qce/sha.c:	rctx->byte_count[1] = (__force __be32)(count >> 32);
drivers/crypto/qce/sha.c:	qce_cpu_to_be32p_array((__be32 *)rctx->digest, (const u8 *)state,
drivers/crypto/qce/sha.c:	rctx->buflen = (unsigned int)(in_count & (blocksize - 1));
drivers/crypto/qce/sha.c:	unsigned long flags = rctx->flags;
drivers/crypto/qce/sha.c:	rctx->count += req->nbytes;
drivers/crypto/qce/sha.c:	total = req->nbytes + rctx->buflen;
drivers/crypto/qce/sha.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buflen, req->src,
drivers/crypto/qce/sha.c:		rctx->buflen += req->nbytes;
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:	if (rctx->buflen)
drivers/crypto/qce/sha.c:		memcpy(rctx->tmpbuf, rctx->buf, rctx->buflen);
drivers/crypto/qce/sha.c:		scatterwalk_map_and_copy(rctx->buf, req->src, src_offset,
drivers/crypto/qce/sha.c:	len = rctx->buflen;
drivers/crypto/qce/sha.c:	if (rctx->buflen) {
drivers/crypto/qce/sha.c:		sg_init_table(rctx->sg, 2);
drivers/crypto/qce/sha.c:		sg_set_buf(rctx->sg, rctx->tmpbuf, rctx->buflen);
drivers/crypto/qce/sha.c:		sg_chain(rctx->sg, 2, req->src);
drivers/crypto/qce/sha.c:		req->src = rctx->sg;
drivers/crypto/qce/sha.c:	rctx->buflen = hash_later;
drivers/crypto/qce/sha.c:	if (!rctx->buflen)
drivers/crypto/qce/sha.c:	rctx->last_blk = true;
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:	memcpy(rctx->tmpbuf, rctx->buf, rctx->buflen);
drivers/crypto/qce/sha.c:	sg_init_one(rctx->sg, rctx->tmpbuf, rctx->buflen);
drivers/crypto/qce/sha.c:	req->src = rctx->sg;
drivers/crypto/qce/sha.c:	req->nbytes = rctx->buflen;
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:	rctx->first_blk = true;
drivers/crypto/qce/sha.c:	rctx->last_blk = true;
drivers/crypto/qce/sha.c:	memset(ctx->authkey, 0, sizeof(ctx->authkey));
drivers/crypto/qce/sha.c:		memcpy(ctx->authkey, key, keylen);
drivers/crypto/qce/sha.c:	ahash_request_set_crypt(req, &sg, ctx->authkey, keylen);
drivers/crypto/qce/common.c:	if (!rctx->last_blk && req->nbytes % blocksize)
drivers/crypto/qce/common.c:	if (IS_CMAC(rctx->flags)) {
drivers/crypto/qce/common.c:		auth_cfg = qce_auth_cfg(rctx->flags, rctx->authklen);
drivers/crypto/qce/common.c:	if (IS_SHA_HMAC(rctx->flags) || IS_CMAC(rctx->flags)) {
drivers/crypto/qce/common.c:		u32 authkey_words = rctx->authklen / sizeof(u32);
drivers/crypto/qce/common.c:		qce_cpu_to_be32p_array(mackey, rctx->authkey, rctx->authklen);
drivers/crypto/qce/common.c:	if (IS_CMAC(rctx->flags))
drivers/crypto/qce/common.c:	if (rctx->first_blk)
drivers/crypto/qce/common.c:		memcpy(auth, rctx->digest, digestsize);
drivers/crypto/qce/common.c:		qce_cpu_to_be32p_array(auth, rctx->digest, digestsize);
drivers/crypto/qce/common.c:	iv_words = (IS_SHA1(rctx->flags) || IS_SHA1_HMAC(rctx->flags)) ? 5 : 8;
drivers/crypto/qce/common.c:	if (rctx->first_blk)
drivers/crypto/qce/common.c:				(u32 *)rctx->byte_count, 2);
drivers/crypto/qce/common.c:	auth_cfg = qce_auth_cfg(rctx->flags, 0);
drivers/crypto/qce/common.c:	if (rctx->last_blk)
drivers/crypto/qce/common.c:	if (rctx->first_blk)
drivers/crypto/qce/common.c:	unsigned int ivsize = rctx->ivsize;
drivers/crypto/qce/common.c:	unsigned long flags = rctx->flags;
drivers/crypto/qce/common.c:		keylen = ctx->enc_keylen / 2;
drivers/crypto/qce/common.c:		keylen = ctx->enc_keylen;
drivers/crypto/qce/common.c:	qce_cpu_to_be32p_array(enckey, ctx->enc_key, keylen);
drivers/crypto/qce/common.c:			qce_xtskey(qce, ctx->enc_key, ctx->enc_keylen,
drivers/crypto/qce/common.c:				   rctx->cryptlen);
drivers/crypto/qce/common.c:			qce_xts_swapiv(enciv, rctx->iv, ivsize);
drivers/crypto/qce/common.c:			qce_cpu_to_be32p_array(enciv, rctx->iv, ivsize);
drivers/crypto/qce/common.c:	qce_write(qce, REG_ENCR_SEG_SIZE, rctx->cryptlen);
drivers/crypto/qce/ablkcipher.c:		dma_unmap_sg(qce->dev, rctx->src_sg, rctx->src_nents, dir_src);
drivers/crypto/qce/ablkcipher.c:	dma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);
drivers/crypto/qce/ablkcipher.c:	sg_free_table(&rctx->dst_tbl);
drivers/crypto/qce/ablkcipher.c:	rctx->iv = req->info;
drivers/crypto/qce/ablkcipher.c:	rctx->ivsize = crypto_ablkcipher_ivsize(ablkcipher);
drivers/crypto/qce/ablkcipher.c:	rctx->cryptlen = req->nbytes;
drivers/crypto/qce/ablkcipher.c:	rctx->src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/qce/ablkcipher.c:		rctx->dst_nents = sg_nents_for_len(req->dst, req->nbytes);
drivers/crypto/qce/ablkcipher.c:		rctx->dst_nents = rctx->src_nents;
drivers/crypto/qce/ablkcipher.c:	if (rctx->src_nents < 0) {
drivers/crypto/qce/ablkcipher.c:		return rctx->src_nents;
drivers/crypto/qce/ablkcipher.c:	if (rctx->dst_nents < 0) {
drivers/crypto/qce/ablkcipher.c:		return -rctx->dst_nents;
drivers/crypto/qce/ablkcipher.c:	rctx->dst_nents += 1;
drivers/crypto/qce/ablkcipher.c:	ret = sg_alloc_table(&rctx->dst_tbl, rctx->dst_nents, gfp);
drivers/crypto/qce/ablkcipher.c:	sg_init_one(&rctx->result_sg, qce->dma.result_buf, QCE_RESULT_BUF_SZ);
drivers/crypto/qce/ablkcipher.c:	sg = qce_sgtable_add(&rctx->dst_tbl, req->dst);
drivers/crypto/qce/ablkcipher.c:	sg = qce_sgtable_add(&rctx->dst_tbl, &rctx->result_sg);
drivers/crypto/qce/ablkcipher.c:	rctx->dst_sg = rctx->dst_tbl.sgl;
drivers/crypto/qce/ablkcipher.c:	ret = dma_map_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);
drivers/crypto/qce/ablkcipher.c:		ret = dma_map_sg(qce->dev, req->src, rctx->src_nents, dir_src);
drivers/crypto/qce/ablkcipher.c:		rctx->src_sg = req->src;
drivers/crypto/qce/ablkcipher.c:		rctx->src_sg = rctx->dst_sg;
drivers/crypto/qce/ablkcipher.c:	ret = qce_dma_prep_sgs(&qce->dma, rctx->src_sg, rctx->src_nents,
drivers/crypto/qce/ablkcipher.c:			       rctx->dst_sg, rctx->dst_nents,
drivers/crypto/qce/ablkcipher.c:		dma_unmap_sg(qce->dev, req->src, rctx->src_nents, dir_src);
drivers/crypto/qce/ablkcipher.c:	dma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);
drivers/crypto/qce/ablkcipher.c:	sg_free_table(&rctx->dst_tbl);
drivers/crypto/qce/ablkcipher.c:	ctx->enc_keylen = keylen;
drivers/crypto/qce/ablkcipher.c:	memcpy(ctx->enc_key, key, keylen);
drivers/crypto/qce/ablkcipher.c:	ret = crypto_skcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/qce/ablkcipher.c:		ctx->enc_keylen = keylen;
drivers/crypto/qce/ablkcipher.c:	rctx->flags = tmpl->alg_flags;
drivers/crypto/qce/ablkcipher.c:	rctx->flags |= encrypt ? QCE_ENCRYPT : QCE_DECRYPT;
drivers/crypto/qce/ablkcipher.c:	if (IS_AES(rctx->flags) && ctx->enc_keylen != AES_KEYSIZE_128 &&
drivers/crypto/qce/ablkcipher.c:	    ctx->enc_keylen != AES_KEYSIZE_256) {
drivers/crypto/qce/ablkcipher.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/qce/ablkcipher.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/qce/ablkcipher.c:	ctx->fallback = crypto_alloc_skcipher(crypto_tfm_alg_name(tfm), 0,
drivers/crypto/qce/ablkcipher.c:	if (IS_ERR(ctx->fallback))
drivers/crypto/qce/ablkcipher.c:		return PTR_ERR(ctx->fallback);
drivers/crypto/qce/ablkcipher.c:	crypto_free_skcipher(ctx->fallback);
drivers/crypto/picoxcell_crypto.c:	return is_cipher_ctx ? ctx->engine->cipher_ctx_base +
drivers/crypto/picoxcell_crypto.c:			(indx * ctx->engine->cipher_pg_sz) :
drivers/crypto/picoxcell_crypto.c:		ctx->engine->hash_key_base + (indx * ctx->engine->hash_pg_sz);
drivers/crypto/picoxcell_crypto.c:	void __iomem *key_ptr = page_addr + ctx->key_offs;
drivers/crypto/picoxcell_crypto.c:	void __iomem *iv_ptr = page_addr + ctx->iv_offs;
drivers/crypto/picoxcell_crypto.c:	unsigned indx = ctx->engine->next_ctx++;
drivers/crypto/picoxcell_crypto.c:	ctx->engine->next_ctx &= ctx->engine->fifo_sz - 1;
drivers/crypto/picoxcell_crypto.c:	       ctx->engine->regs + SPA_KEY_SZ_REG_OFFSET);
drivers/crypto/picoxcell_crypto.c:		       ctx->engine->regs + SPA_KEY_SZ_REG_OFFSET);
drivers/crypto/picoxcell_crypto.c:	struct spacc_engine *engine = aead_ctx->generic.engine;
drivers/crypto/picoxcell_crypto.c:	crypto_aead_clear_flags(ctx->sw_cipher, CRYPTO_TFM_REQ_MASK);
drivers/crypto/picoxcell_crypto.c:	crypto_aead_set_flags(ctx->sw_cipher, crypto_aead_get_flags(tfm) &
drivers/crypto/picoxcell_crypto.c:	err = crypto_aead_setkey(ctx->sw_cipher, key, keylen);
drivers/crypto/picoxcell_crypto.c:	crypto_aead_set_flags(tfm, crypto_aead_get_flags(ctx->sw_cipher) &
drivers/crypto/picoxcell_crypto.c:	if (keys.authkeylen > sizeof(ctx->hash_ctx))
drivers/crypto/picoxcell_crypto.c:	memcpy(ctx->cipher_key, keys.enckey, keys.enckeylen);
drivers/crypto/picoxcell_crypto.c:	ctx->cipher_key_len = keys.enckeylen;
drivers/crypto/picoxcell_crypto.c:	memcpy(ctx->hash_ctx, keys.authkey, keys.authkeylen);
drivers/crypto/picoxcell_crypto.c:	ctx->hash_key_len = keys.authkeylen;
drivers/crypto/picoxcell_crypto.c:	return crypto_aead_setauthsize(ctx->sw_cipher, authsize);
drivers/crypto/picoxcell_crypto.c:	    ctx->cipher_key_len != AES_KEYSIZE_128 &&
drivers/crypto/picoxcell_crypto.c:	    ctx->cipher_key_len != AES_KEYSIZE_256)
drivers/crypto/picoxcell_crypto.c:	aead_request_set_tfm(subreq, ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	struct spacc_engine *engine = ctx->generic.engine;
drivers/crypto/picoxcell_crypto.c:	req->ctx_id = spacc_load_ctx(&ctx->generic, ctx->cipher_key,
drivers/crypto/picoxcell_crypto.c:		ctx->cipher_key_len, aead_req->iv, crypto_aead_ivsize(aead),
drivers/crypto/picoxcell_crypto.c:		ctx->hash_ctx, ctx->hash_key_len);
drivers/crypto/picoxcell_crypto.c:	ctx->generic.flags = spacc_alg->type;
drivers/crypto/picoxcell_crypto.c:	ctx->generic.engine = engine;
drivers/crypto/picoxcell_crypto.c:	ctx->sw_cipher = crypto_alloc_aead(alg->base.cra_name, 0,
drivers/crypto/picoxcell_crypto.c:	if (IS_ERR(ctx->sw_cipher))
drivers/crypto/picoxcell_crypto.c:		return PTR_ERR(ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	ctx->generic.key_offs = spacc_alg->key_offs;
drivers/crypto/picoxcell_crypto.c:	ctx->generic.iv_offs = spacc_alg->iv_offs;
drivers/crypto/picoxcell_crypto.c:		    crypto_aead_reqsize(ctx->sw_cipher)));
drivers/crypto/picoxcell_crypto.c:	crypto_free_aead(ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	memcpy(ctx->key, key, len);
drivers/crypto/picoxcell_crypto.c:	ctx->key_len = len;
drivers/crypto/picoxcell_crypto.c:		if (!ctx->sw_cipher)
drivers/crypto/picoxcell_crypto.c:		crypto_skcipher_clear_flags(ctx->sw_cipher,
drivers/crypto/picoxcell_crypto.c:		crypto_skcipher_set_flags(ctx->sw_cipher,
drivers/crypto/picoxcell_crypto.c:		err = crypto_skcipher_setkey(ctx->sw_cipher, key, len);
drivers/crypto/picoxcell_crypto.c:			crypto_skcipher_get_flags(ctx->sw_cipher) &
drivers/crypto/picoxcell_crypto.c:	memcpy(ctx->key, key, len);
drivers/crypto/picoxcell_crypto.c:	ctx->key_len = len;
drivers/crypto/picoxcell_crypto.c:	memcpy(ctx->key, key, len);
drivers/crypto/picoxcell_crypto.c:	ctx->key_len = len;
drivers/crypto/picoxcell_crypto.c:			ctx->key_len != AES_KEYSIZE_128 &&
drivers/crypto/picoxcell_crypto.c:			ctx->key_len != AES_KEYSIZE_256;
drivers/crypto/picoxcell_crypto.c:	struct spacc_engine *engine = ctx->generic.engine;
drivers/crypto/picoxcell_crypto.c:	req->ctx_id = spacc_load_ctx(&ctx->generic, ctx->key,
drivers/crypto/picoxcell_crypto.c:		ctx->key_len, ablk_req->info, alg->cra_ablkcipher.ivsize,
drivers/crypto/picoxcell_crypto.c:	SKCIPHER_REQUEST_ON_STACK(subreq, ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	skcipher_request_set_tfm(subreq, ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	ctx->generic.flags = spacc_alg->type;
drivers/crypto/picoxcell_crypto.c:	ctx->generic.engine = engine;
drivers/crypto/picoxcell_crypto.c:		ctx->sw_cipher = crypto_alloc_skcipher(
drivers/crypto/picoxcell_crypto.c:		if (IS_ERR(ctx->sw_cipher)) {
drivers/crypto/picoxcell_crypto.c:			return PTR_ERR(ctx->sw_cipher);
drivers/crypto/picoxcell_crypto.c:	ctx->generic.key_offs = spacc_alg->key_offs;
drivers/crypto/picoxcell_crypto.c:	ctx->generic.iv_offs = spacc_alg->iv_offs;
drivers/crypto/picoxcell_crypto.c:	crypto_free_skcipher(ctx->sw_cipher);
drivers/crypto/sahara.c:	if (ctx->flags & FLAGS_NEW_KEY) {
drivers/crypto/sahara.c:		memcpy(dev->key_base, ctx->key, ctx->keylen);
drivers/crypto/sahara.c:		ctx->flags &= ~FLAGS_NEW_KEY;
drivers/crypto/sahara.c:		dev->hw_desc[idx]->len2 = ctx->keylen;
drivers/crypto/sahara.c:	rctx->mode &= FLAGS_MODE_MASK;
drivers/crypto/sahara.c:	dev->flags = (dev->flags & ~FLAGS_MODE_MASK) | rctx->mode;
drivers/crypto/sahara.c:	ctx->keylen = keylen;
drivers/crypto/sahara.c:		memcpy(ctx->key, key, keylen);
drivers/crypto/sahara.c:		ctx->flags |= FLAGS_NEW_KEY;
drivers/crypto/sahara.c:	crypto_skcipher_clear_flags(ctx->fallback, CRYPTO_TFM_REQ_MASK);
drivers/crypto/sahara.c:	crypto_skcipher_set_flags(ctx->fallback, tfm->base.crt_flags &
drivers/crypto/sahara.c:	ret = crypto_skcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/sahara.c:	tfm->base.crt_flags |= crypto_skcipher_get_flags(ctx->fallback) &
drivers/crypto/sahara.c:	rctx->mode = mode;
drivers/crypto/sahara.c:	if (unlikely(ctx->keylen != AES_KEYSIZE_128)) {
drivers/crypto/sahara.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/sahara.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/sahara.c:	if (unlikely(ctx->keylen != AES_KEYSIZE_128)) {
drivers/crypto/sahara.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/sahara.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/sahara.c:	if (unlikely(ctx->keylen != AES_KEYSIZE_128)) {
drivers/crypto/sahara.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/sahara.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/sahara.c:	if (unlikely(ctx->keylen != AES_KEYSIZE_128)) {
drivers/crypto/sahara.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/sahara.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/sahara.c:	ctx->fallback = crypto_alloc_skcipher(name, 0,
drivers/crypto/sahara.c:	if (IS_ERR(ctx->fallback)) {
drivers/crypto/sahara.c:		return PTR_ERR(ctx->fallback);
drivers/crypto/sahara.c:	crypto_free_skcipher(ctx->fallback);
drivers/crypto/sahara.c:	hdr = rctx->mode;
drivers/crypto/sahara.c:	if (rctx->first) {
drivers/crypto/sahara.c:	if (rctx->last)
drivers/crypto/sahara.c:	dev->in_sg = rctx->in_sg;
drivers/crypto/sahara.c:	dev->nb_in_sg = sg_nents_for_len(dev->in_sg, rctx->total);
drivers/crypto/sahara.c:	if (rctx->first)
drivers/crypto/sahara.c:	dev->hw_desc[index]->len1 = rctx->total;
drivers/crypto/sahara.c:		rctx->sg_in_idx = 0;
drivers/crypto/sahara.c:		rctx->sg_in_idx = index;
drivers/crypto/sahara.c:	result_len = rctx->context_size;
drivers/crypto/sahara.c:	dev->hw_desc[index]->len1 = rctx->context_size;
drivers/crypto/sahara.c:	dev->hw_link[index]->len = rctx->context_size;
drivers/crypto/sahara.c:	len = rctx->buf_cnt + req->nbytes;
drivers/crypto/sahara.c:	if (!rctx->last && (len < block_size)) {
drivers/crypto/sahara.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_cnt, req->src,
drivers/crypto/sahara.c:		rctx->buf_cnt += req->nbytes;
drivers/crypto/sahara.c:	if (rctx->buf_cnt)
drivers/crypto/sahara.c:		memcpy(rctx->rembuf, rctx->buf, rctx->buf_cnt);
drivers/crypto/sahara.c:	hash_later = rctx->last ? 0 : len & (block_size - 1);
drivers/crypto/sahara.c:		scatterwalk_map_and_copy(rctx->buf, req->src, offset,
drivers/crypto/sahara.c:	if (rctx->buf_cnt && req->nbytes) {
drivers/crypto/sahara.c:		sg_init_table(rctx->in_sg_chain, 2);
drivers/crypto/sahara.c:		sg_set_buf(rctx->in_sg_chain, rctx->rembuf, rctx->buf_cnt);
drivers/crypto/sahara.c:		sg_chain(rctx->in_sg_chain, 2, req->src);
drivers/crypto/sahara.c:		rctx->total = req->nbytes + rctx->buf_cnt;
drivers/crypto/sahara.c:		rctx->in_sg = rctx->in_sg_chain;
drivers/crypto/sahara.c:		req->src = rctx->in_sg_chain;
drivers/crypto/sahara.c:	} else if (rctx->buf_cnt) {
drivers/crypto/sahara.c:			rctx->in_sg = req->src;
drivers/crypto/sahara.c:			rctx->in_sg = rctx->in_sg_chain;
drivers/crypto/sahara.c:		sg_init_one(rctx->in_sg, rctx->rembuf, rctx->buf_cnt);
drivers/crypto/sahara.c:		rctx->total = rctx->buf_cnt;
drivers/crypto/sahara.c:		rctx->in_sg = req->src;
drivers/crypto/sahara.c:		rctx->total = req->nbytes;
drivers/crypto/sahara.c:		req->src = rctx->in_sg;
drivers/crypto/sahara.c:	rctx->buf_cnt = hash_later;
drivers/crypto/sahara.c:	if (rctx->first) {
drivers/crypto/sahara.c:		rctx->first = 0;
drivers/crypto/sahara.c:		memcpy(dev->context_base, rctx->context, rctx->context_size);
drivers/crypto/sahara.c:	if (rctx->sg_in_idx)
drivers/crypto/sahara.c:	memcpy(rctx->context, dev->context_base, rctx->context_size);
drivers/crypto/sahara.c:		memcpy(req->result, rctx->context, rctx->digest_size);
drivers/crypto/sahara.c:	rctx->last = last;
drivers/crypto/sahara.c:	if (!rctx->active) {
drivers/crypto/sahara.c:		rctx->active = 1;
drivers/crypto/sahara.c:		rctx->first = 1;
drivers/crypto/sahara.c:		rctx->mode |= SAHARA_HDR_MDHA_ALG_SHA1;
drivers/crypto/sahara.c:		rctx->digest_size = SHA1_DIGEST_SIZE;
drivers/crypto/sahara.c:		rctx->mode |= SAHARA_HDR_MDHA_ALG_SHA256;
drivers/crypto/sahara.c:		rctx->digest_size = SHA256_DIGEST_SIZE;
drivers/crypto/sahara.c:	rctx->context_size = rctx->digest_size + 4;
drivers/crypto/sahara.c:	rctx->active = 0;
drivers/crypto/mxc-scc.c:	struct mxc_scc *scc = ctx->scc;
drivers/crypto/mxc-scc.c:	if (ctx->ctrl & SCC_SCM_CTRL_DECRYPT_MODE)
drivers/crypto/mxc-scc.c:		ctx->dst_nents * 8);
drivers/crypto/mxc-scc.c:	len = sg_pcopy_from_buffer(ablkreq->dst, ctx->dst_nents,
drivers/crypto/mxc-scc.c:				   from, ctx->size, ctx->offset);
drivers/crypto/mxc-scc.c:		       scc->red_memory, ctx->size, 1);
drivers/crypto/mxc-scc.c:		       scc->black_memory, ctx->size, 1);
drivers/crypto/mxc-scc.c:	ctx->offset += len;
drivers/crypto/mxc-scc.c:	if (ctx->offset < ablkreq->nbytes)
drivers/crypto/mxc-scc.c:	struct mxc_scc *scc = ctx->scc;
drivers/crypto/mxc-scc.c:	ctx->src_nents = nents;
drivers/crypto/mxc-scc.c:	ctx->dst_nents = nents;
drivers/crypto/mxc-scc.c:	ctx->size = 0;
drivers/crypto/mxc-scc.c:	ctx->offset = 0;
drivers/crypto/mxc-scc.c:	struct mxc_scc *scc = ctx->scc;
drivers/crypto/mxc-scc.c:	if (ctx->ctrl & SCC_SCM_CTRL_CBC_MODE)
drivers/crypto/mxc-scc.c:	size_t len = min_t(size_t, req->nbytes - ctx->offset,
drivers/crypto/mxc-scc.c:			   ctx->scc->bytes_remaining);
drivers/crypto/mxc-scc.c:	struct mxc_scc *scc = ctx->scc;
drivers/crypto/mxc-scc.c:	if (ctx->ctrl & SCC_SCM_CTRL_DECRYPT_MODE)
drivers/crypto/mxc-scc.c:	if (ctx->ctrl & SCC_SCM_CTRL_CBC_MODE && req->info)
drivers/crypto/mxc-scc.c:	len = sg_pcopy_to_buffer(req->src, ctx->src_nents,
drivers/crypto/mxc-scc.c:				 to, len, ctx->offset);
drivers/crypto/mxc-scc.c:	ctx->size = len;
drivers/crypto/mxc-scc.c:		       scc->red_memory, ctx->size, 1);
drivers/crypto/mxc-scc.c:		       scc->black_memory, ctx->size, 1);
drivers/crypto/mxc-scc.c:		ctx->size += padding_byte_count;
drivers/crypto/mxc-scc.c:		       to, ctx->size, 1);
drivers/crypto/mxc-scc.c:	struct mxc_scc *scc = ctx->scc;
drivers/crypto/mxc-scc.c:	writel((ctx->size / ctx->scc->block_size_bytes) - 1,
drivers/crypto/mxc-scc.c:		ctx->size / ctx->scc->block_size_bytes,
drivers/crypto/mxc-scc.c:		(ctx->ctrl & SCC_SCM_CTRL_DECRYPT_MODE) ? scc->black_memory :
drivers/crypto/mxc-scc.c:	writel(ctx->ctrl, scc->base + SCC_SCM_CTRL);
drivers/crypto/mxc-scc.c:	ctx->scc = algt->scc;
drivers/crypto/mxc-scc.c:	if (ctx->scc->hw_busy)
drivers/crypto/mxc-scc.c:	spin_lock_bh(&ctx->scc->lock);
drivers/crypto/mxc-scc.c:	backlog = crypto_get_backlog(&ctx->scc->queue);
drivers/crypto/mxc-scc.c:	req = crypto_dequeue_request(&ctx->scc->queue);
drivers/crypto/mxc-scc.c:	ctx->scc->req = req;
drivers/crypto/mxc-scc.c:	ctx->scc->hw_busy = true;
drivers/crypto/mxc-scc.c:	spin_unlock_bh(&ctx->scc->lock);
drivers/crypto/mxc-scc.c:	spin_lock_bh(&ctx->scc->lock);
drivers/crypto/mxc-scc.c:	ret = crypto_enqueue_request(&ctx->scc->queue, req);
drivers/crypto/mxc-scc.c:	spin_unlock_bh(&ctx->scc->lock);
drivers/crypto/mxc-scc.c:	ctx->ctrl = SCC_SCM_CTRL_START_CIPHER;
drivers/crypto/mxc-scc.c:	ctx->ctrl = SCC_SCM_CTRL_START_CIPHER;
drivers/crypto/mxc-scc.c:	ctx->ctrl |= SCC_SCM_CTRL_DECRYPT_MODE;
drivers/crypto/mxc-scc.c:	ctx->ctrl = SCC_SCM_CTRL_START_CIPHER;
drivers/crypto/mxc-scc.c:	ctx->ctrl |= SCC_SCM_CTRL_CBC_MODE;
drivers/crypto/mxc-scc.c:	ctx->ctrl = SCC_SCM_CTRL_START_CIPHER;
drivers/crypto/mxc-scc.c:	ctx->ctrl |= SCC_SCM_CTRL_CBC_MODE;
drivers/crypto/mxc-scc.c:	ctx->ctrl |= SCC_SCM_CTRL_DECRYPT_MODE;
drivers/crypto/omap-des.c:	key32 = dd->ctx->keylen / sizeof(u32);
drivers/crypto/omap-des.c:			       __le32_to_cpu(dd->ctx->key[i]));
drivers/crypto/omap-des.c:	if (!ctx->dd) {
drivers/crypto/omap-des.c:		ctx->dd = dd;
drivers/crypto/omap-des.c:		dd = ctx->dd;
drivers/crypto/omap-des.c:	struct omap_des_dev *dd = ctx->dd;
drivers/crypto/omap-des.c:	rctx->mode &= FLAGS_MODE_MASK;
drivers/crypto/omap-des.c:	dd->flags = (dd->flags & ~FLAGS_MODE_MASK) | rctx->mode;
drivers/crypto/omap-des.c:	ctx->dd = dd;
drivers/crypto/omap-des.c:	rctx->mode = mode;
drivers/crypto/omap-des.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/omap-des.c:	ctx->keylen = keylen;
drivers/crypto/ux500/hash/hash_core.c:	device_data->current_ctx->device = NULL;
drivers/crypto/ux500/hash/hash_core.c:	complete(&ctx->device->dma.complete);
drivers/crypto/ux500/hash/hash_core.c:		dev_err(ctx->device->dev, "%s: Invalid DMA direction\n",
drivers/crypto/ux500/hash/hash_core.c:	channel = ctx->device->dma.chan_mem2hash;
drivers/crypto/ux500/hash/hash_core.c:	ctx->device->dma.sg = sg;
drivers/crypto/ux500/hash/hash_core.c:	ctx->device->dma.sg_len = dma_map_sg(channel->device->dev,
drivers/crypto/ux500/hash/hash_core.c:			ctx->device->dma.sg, ctx->device->dma.nents,
drivers/crypto/ux500/hash/hash_core.c:	if (!ctx->device->dma.sg_len) {
drivers/crypto/ux500/hash/hash_core.c:		dev_err(ctx->device->dev, "%s: Could not map the sg list (TO_DEVICE)\n",
drivers/crypto/ux500/hash/hash_core.c:	dev_dbg(ctx->device->dev, "%s: Setting up DMA for buffer (TO_DEVICE)\n",
drivers/crypto/ux500/hash/hash_core.c:			ctx->device->dma.sg, ctx->device->dma.sg_len,
drivers/crypto/ux500/hash/hash_core.c:		dev_err(ctx->device->dev,
drivers/crypto/ux500/hash/hash_core.c:	chan = ctx->device->dma.chan_mem2hash;
drivers/crypto/ux500/hash/hash_core.c:	dma_unmap_sg(chan->device->dev, ctx->device->dma.sg,
drivers/crypto/ux500/hash/hash_core.c:		     ctx->device->dma.sg_len, DMA_TO_DEVICE);
drivers/crypto/ux500/hash/hash_core.c:		dev_dbg(ctx->device->dev,
drivers/crypto/ux500/hash/hash_core.c:	if (HASH_OPER_MODE_HASH == ctx->config.oper_mode) {
drivers/crypto/ux500/hash/hash_core.c:		if (HASH_ALGO_SHA1 == ctx->config.algorithm) {
drivers/crypto/ux500/hash/hash_core.c:				ctx->config.algorithm) {
drivers/crypto/ux500/hash/hash_core.c:	} else if (HASH_OPER_MODE_HMAC == ctx->config.oper_mode) {
drivers/crypto/ux500/hash/hash_core.c:		if (!ctx->keylen) {
drivers/crypto/ux500/hash/hash_core.c:			if (HASH_ALGO_SHA1 == ctx->config.algorithm) {
drivers/crypto/ux500/hash/hash_core.c:			} else if (HASH_ALGO_SHA256 == ctx->config.algorithm) {
drivers/crypto/ux500/hash/hash_core.c:			ctx->device = local_device_data;
drivers/crypto/ux500/hash/hash_core.c:	ret = hash_setconfiguration(device_data, &ctx->config);
drivers/crypto/ux500/hash/hash_core.c:	if (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)
drivers/crypto/ux500/hash/hash_core.c:		hash_hw_write_key(device_data, ctx->key, ctx->keylen);
drivers/crypto/ux500/hash/hash_core.c:	if (!ctx->key)
drivers/crypto/ux500/hash/hash_core.c:		ctx->keylen = 0;
drivers/crypto/ux500/hash/hash_core.c:	memset(&req_ctx->state, 0, sizeof(struct hash_state));
drivers/crypto/ux500/hash/hash_core.c:	req_ctx->updated = 0;
drivers/crypto/ux500/hash/hash_core.c:			req_ctx->dma_mode = false; /* Don't use DMA */
drivers/crypto/ux500/hash/hash_core.c:				req_ctx->dma_mode = true;
drivers/crypto/ux500/hash/hash_core.c:				req_ctx->dma_mode = false;
drivers/crypto/ux500/hash/hash_core.c:	ctx->state.length.low_word += incr;
drivers/crypto/ux500/hash/hash_core.c:	if (ctx->state.length.low_word < incr)
drivers/crypto/ux500/hash/hash_core.c:		ctx->state.length.high_word++;
drivers/crypto/ux500/hash/hash_core.c:		if (device_data->current_ctx->keylen > HASH_BLOCK_SIZE) {
drivers/crypto/ux500/hash/hash_core.c:			if (req_ctx->updated) {
drivers/crypto/ux500/hash/hash_core.c:				memmove(req_ctx->state.buffer,
drivers/crypto/ux500/hash/hash_core.c:				req_ctx->updated = 1;
drivers/crypto/ux500/hash/hash_core.c:				req_ctx->state.buffer,
drivers/crypto/ux500/hash/hash_core.c:	if (req_ctx->updated) {
drivers/crypto/ux500/hash/hash_core.c:	if (!req_ctx->updated) {
drivers/crypto/ux500/hash/hash_core.c:		ret = hash_setconfiguration(device_data, &ctx->config);
drivers/crypto/ux500/hash/hash_core.c:		if (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode) {
drivers/crypto/ux500/hash/hash_core.c:		if (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)
drivers/crypto/ux500/hash/hash_core.c:			hash_hw_write_key(device_data, ctx->key, ctx->keylen);
drivers/crypto/ux500/hash/hash_core.c:		req_ctx->updated = 1;
drivers/crypto/ux500/hash/hash_core.c:	ctx->device->dma.nents = hash_get_nents(req->src, req->nbytes, NULL);
drivers/crypto/ux500/hash/hash_core.c:	if (!ctx->device->dma.nents) {
drivers/crypto/ux500/hash/hash_core.c:		dev_err(device_data->dev, "%s: ctx->device->dma.nents = 0\n",
drivers/crypto/ux500/hash/hash_core.c:		ret = ctx->device->dma.nents;
drivers/crypto/ux500/hash/hash_core.c:	wait_for_completion(&ctx->device->dma.complete);
drivers/crypto/ux500/hash/hash_core.c:	if (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {
drivers/crypto/ux500/hash/hash_core.c:		unsigned int keylen = ctx->keylen;
drivers/crypto/ux500/hash/hash_core.c:		u8 *key = ctx->key;
drivers/crypto/ux500/hash/hash_core.c:			__func__, ctx->keylen);
drivers/crypto/ux500/hash/hash_core.c:	hash_get_digest(device_data, digest, ctx->config.algorithm);
drivers/crypto/ux500/hash/hash_core.c:	memcpy(req->result, digest, ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:	kfree(ctx->key);
drivers/crypto/ux500/hash/hash_core.c:	if (req_ctx->updated) {
drivers/crypto/ux500/hash/hash_core.c:	} else if (req->nbytes == 0 && ctx->keylen == 0) {
drivers/crypto/ux500/hash/hash_core.c:		if (!ret && likely(zero_hash_size == ctx->digestsize) &&
drivers/crypto/ux500/hash/hash_core.c:			memcpy(req->result, &zero_hash[0], ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:				zero_hash_size == ctx->digestsize ?
drivers/crypto/ux500/hash/hash_core.c:	} else if (req->nbytes == 0 && ctx->keylen > 0) {
drivers/crypto/ux500/hash/hash_core.c:	if (!req_ctx->updated) {
drivers/crypto/ux500/hash/hash_core.c:	if (req_ctx->state.index) {
drivers/crypto/ux500/hash/hash_core.c:		hash_messagepad(device_data, req_ctx->state.buffer,
drivers/crypto/ux500/hash/hash_core.c:				req_ctx->state.index);
drivers/crypto/ux500/hash/hash_core.c:	if (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {
drivers/crypto/ux500/hash/hash_core.c:		unsigned int keylen = ctx->keylen;
drivers/crypto/ux500/hash/hash_core.c:		u8 *key = ctx->key;
drivers/crypto/ux500/hash/hash_core.c:			__func__, ctx->keylen);
drivers/crypto/ux500/hash/hash_core.c:	hash_get_digest(device_data, digest, ctx->config.algorithm);
drivers/crypto/ux500/hash/hash_core.c:	memcpy(req->result, digest, ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:	kfree(ctx->key);
drivers/crypto/ux500/hash/hash_core.c:	index = req_ctx->state.index;
drivers/crypto/ux500/hash/hash_core.c:	buffer = (u8 *)req_ctx->state.buffer;
drivers/crypto/ux500/hash/hash_core.c:	/* Check if ctx->state.length + msg_length
drivers/crypto/ux500/hash/hash_core.c:	if (msg_length > (req_ctx->state.length.low_word + msg_length) &&
drivers/crypto/ux500/hash/hash_core.c:	    HASH_HIGH_WORD_MAX_VAL == req_ctx->state.length.high_word) {
drivers/crypto/ux500/hash/hash_core.c:	req_ctx->state.index = index;
drivers/crypto/ux500/hash/hash_core.c:		__func__, req_ctx->state.index, req_ctx->state.bit_index);
drivers/crypto/ux500/hash/hash_core.c:	if (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode)
drivers/crypto/ux500/hash/hash_core.c:	if ((hash_mode == HASH_MODE_DMA) && req_ctx->dma_mode)
drivers/crypto/ux500/hash/hash_core.c:	ctx->key = kmemdup(key, keylen, GFP_KERNEL);
drivers/crypto/ux500/hash/hash_core.c:	if (!ctx->key) {
drivers/crypto/ux500/hash/hash_core.c:		pr_err("%s: Failed to allocate ctx->key for %d\n",
drivers/crypto/ux500/hash/hash_core.c:	ctx->keylen = keylen;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.data_format = HASH_DATA_8_BITS;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.algorithm = HASH_ALGO_SHA1;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.oper_mode = HASH_OPER_MODE_HASH;
drivers/crypto/ux500/hash/hash_core.c:	ctx->digestsize = SHA1_DIGEST_SIZE;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.data_format = HASH_DATA_8_BITS;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.algorithm = HASH_ALGO_SHA256;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.oper_mode = HASH_OPER_MODE_HASH;
drivers/crypto/ux500/hash/hash_core.c:	ctx->digestsize = SHA256_DIGEST_SIZE;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.data_format	= HASH_DATA_8_BITS;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.algorithm	= HASH_ALGO_SHA1;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.oper_mode	= HASH_OPER_MODE_HMAC;
drivers/crypto/ux500/hash/hash_core.c:	ctx->digestsize		= SHA1_DIGEST_SIZE;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.data_format	= HASH_DATA_8_BITS;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.algorithm	= HASH_ALGO_SHA256;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.oper_mode	= HASH_OPER_MODE_HMAC;
drivers/crypto/ux500/hash/hash_core.c:	ctx->digestsize		= SHA256_DIGEST_SIZE;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.data_format = HASH_DATA_8_BITS;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.algorithm = hash_alg->conf.algorithm;
drivers/crypto/ux500/hash/hash_core.c:	ctx->config.oper_mode = hash_alg->conf.oper_mode;
drivers/crypto/ux500/hash/hash_core.c:	ctx->digestsize = hash_alg->hash.halg.digestsize;
drivers/crypto/ux500/cryp/cryp.c:		ctx->din = readl_relaxed(&src_reg->din);
drivers/crypto/ux500/cryp/cryp.c:	ctx->cr = readl_relaxed(&src_reg->cr) & CRYP_CR_CONTEXT_SAVE_MASK;
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_4_l = readl_relaxed(&src_reg->key_4_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_4_r = readl_relaxed(&src_reg->key_4_r);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_3_l = readl_relaxed(&src_reg->key_3_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_3_r = readl_relaxed(&src_reg->key_3_r);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_2_l = readl_relaxed(&src_reg->key_2_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_2_r = readl_relaxed(&src_reg->key_2_r);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_1_l = readl_relaxed(&src_reg->key_1_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->key_1_r = readl_relaxed(&src_reg->key_1_r);
drivers/crypto/ux500/cryp/cryp.c:	algomode = ((ctx->cr & CRYP_CR_ALGOMODE_MASK) >> CRYP_CR_ALGOMODE_POS);
drivers/crypto/ux500/cryp/cryp.c:		ctx->init_vect_0_l = readl_relaxed(&src_reg->init_vect_0_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->init_vect_0_r = readl_relaxed(&src_reg->init_vect_0_r);
drivers/crypto/ux500/cryp/cryp.c:		ctx->init_vect_1_l = readl_relaxed(&src_reg->init_vect_1_l);
drivers/crypto/ux500/cryp/cryp.c:		ctx->init_vect_1_r = readl_relaxed(&src_reg->init_vect_1_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_4_l, &reg->key_4_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_4_r, &reg->key_4_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_3_l, &reg->key_3_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_3_r, &reg->key_3_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_2_l, &reg->key_2_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_2_r, &reg->key_2_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_1_l, &reg->key_1_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->key_1_r, &reg->key_1_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->init_vect_0_l, &reg->init_vect_0_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->init_vect_0_r, &reg->init_vect_0_r);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->init_vect_1_l, &reg->init_vect_1_l);
drivers/crypto/ux500/cryp/cryp.c:		writel_relaxed(ctx->init_vect_1_r, &reg->init_vect_1_r);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->session_id = atomic_read(&session_id);
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s] (len: %d) %s, ", __func__, ctx->outlen,
drivers/crypto/ux500/cryp/cryp_core.c:		if (ctx->outlen / ctx->blocksize > 0) {
drivers/crypto/ux500/cryp/cryp_core.c:			count = ctx->blocksize / 4;
drivers/crypto/ux500/cryp/cryp_core.c:			readsl(&device_data->base->dout, ctx->outdata, count);
drivers/crypto/ux500/cryp/cryp_core.c:			ctx->outdata += count;
drivers/crypto/ux500/cryp/cryp_core.c:			ctx->outlen -= count;
drivers/crypto/ux500/cryp/cryp_core.c:			if (ctx->outlen == 0) {
drivers/crypto/ux500/cryp/cryp_core.c:		if (ctx->datalen / ctx->blocksize > 0) {
drivers/crypto/ux500/cryp/cryp_core.c:			count = ctx->blocksize / 4;
drivers/crypto/ux500/cryp/cryp_core.c:			writesl(&device_data->base->din, ctx->indata, count);
drivers/crypto/ux500/cryp/cryp_core.c:			ctx->indata += count;
drivers/crypto/ux500/cryp/cryp_core.c:			ctx->datalen -= count;
drivers/crypto/ux500/cryp/cryp_core.c:			if (ctx->datalen == 0)
drivers/crypto/ux500/cryp/cryp_core.c:			if (ctx->config.algomode == CRYP_ALGO_AES_XTS) {
drivers/crypto/ux500/cryp/cryp_core.c:	int num_of_regs = ctx->blocksize / 8;
drivers/crypto/ux500/cryp/cryp_core.c:			__func__, ctx->blocksize);
drivers/crypto/ux500/cryp/cryp_core.c:	for (i = 0; i < ctx->blocksize / 4; i++)
drivers/crypto/ux500/cryp/cryp_core.c:		iv[i] = uint8p_to_uint32_be(ctx->iv + i*4);
drivers/crypto/ux500/cryp/cryp_core.c:	int num_of_regs = ctx->keylen / 8;
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s]", __func__);
drivers/crypto/ux500/cryp/cryp_core.c:	if (mode_is_aes(ctx->config.algomode)) {
drivers/crypto/ux500/cryp/cryp_core.c:		swap_words_in_key_and_bits_in_byte((u8 *)ctx->key,
drivers/crypto/ux500/cryp/cryp_core.c:						   ctx->keylen);
drivers/crypto/ux500/cryp/cryp_core.c:		for (i = 0; i < ctx->keylen / 4; i++)
drivers/crypto/ux500/cryp/cryp_core.c:			swapped_key[i] = uint8p_to_uint32_be(ctx->key + i*4);
drivers/crypto/ux500/cryp/cryp_core.c:		cryp_error = set_key(ctx->device,
drivers/crypto/ux500/cryp/cryp_core.c:			dev_err(ctx->device->dev, "[%s]: set_key() failed!",
drivers/crypto/ux500/cryp/cryp_core.c:	if (ctx->updated == 0) {
drivers/crypto/ux500/cryp/cryp_core.c:			dev_err(ctx->device->dev, "[%s]: cfg_keys failed!",
drivers/crypto/ux500/cryp/cryp_core.c:		if (ctx->iv &&
drivers/crypto/ux500/cryp/cryp_core.c:		    CRYP_ALGO_AES_ECB != ctx->config.algomode &&
drivers/crypto/ux500/cryp/cryp_core.c:		    CRYP_ALGO_DES_ECB != ctx->config.algomode &&
drivers/crypto/ux500/cryp/cryp_core.c:		    CRYP_ALGO_TDES_ECB != ctx->config.algomode) {
drivers/crypto/ux500/cryp/cryp_core.c:		cryp_set_configuration(device_data, &ctx->config,
drivers/crypto/ux500/cryp/cryp_core.c:	} else if (ctx->updated == 1 &&
drivers/crypto/ux500/cryp/cryp_core.c:		   ctx->session_id != atomic_read(&session_id)) {
drivers/crypto/ux500/cryp/cryp_core.c:		cryp_restore_device_context(device_data, &ctx->dev_ctx);
drivers/crypto/ux500/cryp/cryp_core.c:		control_register = ctx->dev_ctx.cr;
drivers/crypto/ux500/cryp/cryp_core.c:		control_register = ctx->dev_ctx.cr;
drivers/crypto/ux500/cryp/cryp_core.c:			ctx->device = local_device_data;
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s]: ", __func__);
drivers/crypto/ux500/cryp/cryp_core.c:	complete(&ctx->device->dma.cryp_dma_complete);
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s]: ", __func__);
drivers/crypto/ux500/cryp/cryp_core.c:		dev_err(ctx->device->dev, "[%s]: Data in sg list isn't "
drivers/crypto/ux500/cryp/cryp_core.c:		channel = ctx->device->dma.chan_mem2cryp;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->device->dma.sg_src = sg;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->device->dma.sg_src_len = dma_map_sg(channel->device->dev,
drivers/crypto/ux500/cryp/cryp_core.c:						 ctx->device->dma.sg_src,
drivers/crypto/ux500/cryp/cryp_core.c:						 ctx->device->dma.nents_src,
drivers/crypto/ux500/cryp/cryp_core.c:		if (!ctx->device->dma.sg_src_len) {
drivers/crypto/ux500/cryp/cryp_core.c:			dev_dbg(ctx->device->dev,
drivers/crypto/ux500/cryp/cryp_core.c:		dev_dbg(ctx->device->dev, "[%s]: Setting up DMA for buffer "
drivers/crypto/ux500/cryp/cryp_core.c:				ctx->device->dma.sg_src,
drivers/crypto/ux500/cryp/cryp_core.c:				ctx->device->dma.sg_src_len,
drivers/crypto/ux500/cryp/cryp_core.c:		channel = ctx->device->dma.chan_cryp2mem;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->device->dma.sg_dst = sg;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->device->dma.sg_dst_len = dma_map_sg(channel->device->dev,
drivers/crypto/ux500/cryp/cryp_core.c:						 ctx->device->dma.sg_dst,
drivers/crypto/ux500/cryp/cryp_core.c:						 ctx->device->dma.nents_dst,
drivers/crypto/ux500/cryp/cryp_core.c:		if (!ctx->device->dma.sg_dst_len) {
drivers/crypto/ux500/cryp/cryp_core.c:			dev_dbg(ctx->device->dev,
drivers/crypto/ux500/cryp/cryp_core.c:		dev_dbg(ctx->device->dev, "[%s]: Setting up DMA for buffer "
drivers/crypto/ux500/cryp/cryp_core.c:				ctx->device->dma.sg_dst,
drivers/crypto/ux500/cryp/cryp_core.c:				ctx->device->dma.sg_dst_len,
drivers/crypto/ux500/cryp/cryp_core.c:		dev_dbg(ctx->device->dev, "[%s]: Invalid DMA direction",
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s]: ", __func__);
drivers/crypto/ux500/cryp/cryp_core.c:	chan = ctx->device->dma.chan_mem2cryp;
drivers/crypto/ux500/cryp/cryp_core.c:	dma_unmap_sg(chan->device->dev, ctx->device->dma.sg_src,
drivers/crypto/ux500/cryp/cryp_core.c:		     ctx->device->dma.sg_src_len, DMA_TO_DEVICE);
drivers/crypto/ux500/cryp/cryp_core.c:	chan = ctx->device->dma.chan_cryp2mem;
drivers/crypto/ux500/cryp/cryp_core.c:	dma_unmap_sg(chan->device->dev, ctx->device->dma.sg_dst,
drivers/crypto/ux500/cryp/cryp_core.c:		     ctx->device->dma.sg_dst_len, DMA_FROM_DEVICE);
drivers/crypto/ux500/cryp/cryp_core.c:	dev_dbg(ctx->device->dev, "[%s]: ", __func__);
drivers/crypto/ux500/cryp/cryp_core.c:		dev_dbg(ctx->device->dev, "[%s]: cryp_set_dma_transfer() "
drivers/crypto/ux500/cryp/cryp_core.c:		dev_dbg(ctx->device->dev, "[%s]: cryp_set_dma_transfer() "
drivers/crypto/ux500/cryp/cryp_core.c:	int len = ctx->blocksize / BYTES_PER_WORD;
drivers/crypto/ux500/cryp/cryp_core.c:	int remaining_length = ctx->datalen;
drivers/crypto/ux500/cryp/cryp_core.c:	u32 *indata = (u32 *)ctx->indata;
drivers/crypto/ux500/cryp/cryp_core.c:	u32 *outdata = (u32 *)ctx->outdata;
drivers/crypto/ux500/cryp/cryp_core.c:				&device_data->current_ctx->dev_ctx,
drivers/crypto/ux500/cryp/cryp_core.c:					&device_data->current_ctx->dev_ctx);
drivers/crypto/ux500/cryp/cryp_core.c:	const u8 *indata = ctx->indata;
drivers/crypto/ux500/cryp/cryp_core.c:	u8 *outdata = ctx->outdata;
drivers/crypto/ux500/cryp/cryp_core.c:	u32 datalen = ctx->datalen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->outlen = ctx->datalen;
drivers/crypto/ux500/cryp/cryp_core.c:		 * ctx->outlen is decremented in the cryp_interrupt_handler
drivers/crypto/ux500/cryp/cryp_core.c:		while (ctx->outlen > 0)
drivers/crypto/ux500/cryp/cryp_core.c:		dev_err(ctx->device->dev, "[%s]: Invalid operation mode!",
drivers/crypto/ux500/cryp/cryp_core.c:	cryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->updated = 1;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->indata = indata;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->outdata = outdata;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->datalen = datalen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->outlen = outlen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->datalen = areq->nbytes;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->outlen = areq->nbytes;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device->dma.nents_src = get_nents(areq->src, ctx->datalen);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device->dma.nents_dst = get_nents(areq->dst, ctx->outlen);
drivers/crypto/ux500/cryp/cryp_core.c:	bytes_written = cryp_dma_write(ctx, areq->src, ctx->datalen);
drivers/crypto/ux500/cryp/cryp_core.c:	wait_for_completion(&ctx->device->dma.cryp_dma_complete);
drivers/crypto/ux500/cryp/cryp_core.c:	cryp_save_device_context(device_data, &ctx->dev_ctx, cryp_mode);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->updated = 1;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device = NULL;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->iv = walk.iv;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->indata = phys_to_virt(src_paddr);
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->outdata = phys_to_virt(dst_paddr);
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->datalen = nbytes - (nbytes % ctx->blocksize);
drivers/crypto/ux500/cryp/cryp_core.c:		nbytes -= ctx->datalen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device = NULL;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->config.keysize = CRYP_KEY_SIZE_128;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->config.keysize = CRYP_KEY_SIZE_192;
drivers/crypto/ux500/cryp/cryp_core.c:		ctx->config.keysize = CRYP_KEY_SIZE_256;
drivers/crypto/ux500/cryp/cryp_core.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->keylen = keylen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->updated = 0;
drivers/crypto/ux500/cryp/cryp_core.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->keylen = keylen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->updated = 0;
drivers/crypto/ux500/cryp/cryp_core.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->keylen = keylen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->updated = 0;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->config.algodir = CRYP_ALGORITHM_ENCRYPT;
drivers/crypto/ux500/cryp/cryp_core.c:	if (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->config.algodir = CRYP_ALGORITHM_DECRYPT;
drivers/crypto/ux500/cryp/cryp_core.c:	if (cryp_mode == CRYP_MODE_DMA && mode_is_aes(ctx->config.algomode))
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->config.algomode = cryp_alg->algomode;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->blocksize = crypto_tfm_alg_blocksize(tfm);
drivers/crypto/vmx/ghash.c:	ctx->fallback = fallback;
drivers/crypto/vmx/ghash.c:	if (ctx->fallback) {
drivers/crypto/vmx/ghash.c:		crypto_free_shash(ctx->fallback);
drivers/crypto/vmx/ghash.c:		ctx->fallback = NULL;
drivers/crypto/vmx/ghash.c:	dctx->bytes = 0;
drivers/crypto/vmx/ghash.c:	memset(dctx->shash, 0, GHASH_DIGEST_SIZE);
drivers/crypto/vmx/ghash.c:	dctx->fallback_desc.tfm = ctx->fallback;
drivers/crypto/vmx/ghash.c:	dctx->fallback_desc.flags = desc->flags;
drivers/crypto/vmx/ghash.c:	return crypto_shash_init(&dctx->fallback_desc);
drivers/crypto/vmx/ghash.c:	gcm_init_p8(ctx->htable, (const u64 *) key);
drivers/crypto/vmx/ghash.c:	return crypto_shash_setkey(ctx->fallback, key, keylen);
drivers/crypto/vmx/ghash.c:		return crypto_shash_update(&dctx->fallback_desc, src,
drivers/crypto/vmx/ghash.c:		if (dctx->bytes) {
drivers/crypto/vmx/ghash.c:			if (dctx->bytes + srclen < GHASH_DIGEST_SIZE) {
drivers/crypto/vmx/ghash.c:				memcpy(dctx->buffer + dctx->bytes, src,
drivers/crypto/vmx/ghash.c:				dctx->bytes += srclen;
drivers/crypto/vmx/ghash.c:			memcpy(dctx->buffer + dctx->bytes, src,
drivers/crypto/vmx/ghash.c:			       GHASH_DIGEST_SIZE - dctx->bytes);
drivers/crypto/vmx/ghash.c:			gcm_ghash_p8(dctx->shash, ctx->htable,
drivers/crypto/vmx/ghash.c:				     dctx->buffer, GHASH_DIGEST_SIZE);
drivers/crypto/vmx/ghash.c:			src += GHASH_DIGEST_SIZE - dctx->bytes;
drivers/crypto/vmx/ghash.c:			srclen -= GHASH_DIGEST_SIZE - dctx->bytes;
drivers/crypto/vmx/ghash.c:			dctx->bytes = 0;
drivers/crypto/vmx/ghash.c:			gcm_ghash_p8(dctx->shash, ctx->htable, src, len);
drivers/crypto/vmx/ghash.c:			memcpy(dctx->buffer, src, srclen);
drivers/crypto/vmx/ghash.c:			dctx->bytes = srclen;
drivers/crypto/vmx/ghash.c:		return crypto_shash_final(&dctx->fallback_desc, out);
drivers/crypto/vmx/ghash.c:		if (dctx->bytes) {
drivers/crypto/vmx/ghash.c:			for (i = dctx->bytes; i < GHASH_DIGEST_SIZE; i++)
drivers/crypto/vmx/ghash.c:				dctx->buffer[i] = 0;
drivers/crypto/vmx/ghash.c:			gcm_ghash_p8(dctx->shash, ctx->htable,
drivers/crypto/vmx/ghash.c:				     dctx->buffer, GHASH_DIGEST_SIZE);
drivers/crypto/vmx/ghash.c:			dctx->bytes = 0;
drivers/crypto/vmx/ghash.c:		memcpy(out, dctx->shash, GHASH_DIGEST_SIZE);
drivers/crypto/vmx/aes.c:	ctx->fallback = fallback;
drivers/crypto/vmx/aes.c:	if (ctx->fallback) {
drivers/crypto/vmx/aes.c:		crypto_free_cipher(ctx->fallback);
drivers/crypto/vmx/aes.c:		ctx->fallback = NULL;
drivers/crypto/vmx/aes.c:	ret = aes_p8_set_encrypt_key(key, keylen * 8, &ctx->enc_key);
drivers/crypto/vmx/aes.c:	ret += aes_p8_set_decrypt_key(key, keylen * 8, &ctx->dec_key);
drivers/crypto/vmx/aes.c:	ret += crypto_cipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/vmx/aes.c:		crypto_cipher_encrypt_one(ctx->fallback, dst, src);
drivers/crypto/vmx/aes.c:		aes_p8_encrypt(src, dst, &ctx->enc_key);
drivers/crypto/vmx/aes.c:		crypto_cipher_decrypt_one(ctx->fallback, dst, src);
drivers/crypto/vmx/aes.c:		aes_p8_decrypt(src, dst, &ctx->dec_key);
drivers/crypto/vmx/aes_ctr.c:	ctx->fallback = fallback;
drivers/crypto/vmx/aes_ctr.c:	if (ctx->fallback) {
drivers/crypto/vmx/aes_ctr.c:		crypto_free_blkcipher(ctx->fallback);
drivers/crypto/vmx/aes_ctr.c:		ctx->fallback = NULL;
drivers/crypto/vmx/aes_ctr.c:	ret = aes_p8_set_encrypt_key(key, keylen * 8, &ctx->enc_key);
drivers/crypto/vmx/aes_ctr.c:	ret += crypto_blkcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/vmx/aes_ctr.c:	aes_p8_encrypt(ctrblk, keystream, &ctx->enc_key);
drivers/crypto/vmx/aes_ctr.c:		.tfm = ctx->fallback,
drivers/crypto/vmx/aes_ctr.c:						    &ctx->enc_key,
drivers/crypto/vmx/aes_xts.c:	ctx->fallback = fallback;
drivers/crypto/vmx/aes_xts.c:	if (ctx->fallback) {
drivers/crypto/vmx/aes_xts.c:		crypto_free_blkcipher(ctx->fallback);
drivers/crypto/vmx/aes_xts.c:		ctx->fallback = NULL;
drivers/crypto/vmx/aes_xts.c:	ret = aes_p8_set_encrypt_key(key + keylen/2, (keylen/2) * 8, &ctx->tweak_key);
drivers/crypto/vmx/aes_xts.c:	ret += aes_p8_set_encrypt_key(key, (keylen/2) * 8, &ctx->enc_key);
drivers/crypto/vmx/aes_xts.c:	ret += aes_p8_set_decrypt_key(key, (keylen/2) * 8, &ctx->dec_key);
drivers/crypto/vmx/aes_xts.c:	ret += crypto_blkcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/vmx/aes_xts.c:		.tfm = ctx->fallback,
drivers/crypto/vmx/aes_xts.c:		aes_p8_encrypt(iv, tweak, &ctx->tweak_key);
drivers/crypto/vmx/aes_xts.c:						nbytes & AES_BLOCK_MASK, &ctx->enc_key, NULL, tweak);
drivers/crypto/vmx/aes_xts.c:						nbytes & AES_BLOCK_MASK, &ctx->dec_key, NULL, tweak);
drivers/crypto/vmx/aes_cbc.c:	ctx->fallback = fallback;
drivers/crypto/vmx/aes_cbc.c:	if (ctx->fallback) {
drivers/crypto/vmx/aes_cbc.c:		crypto_free_blkcipher(ctx->fallback);
drivers/crypto/vmx/aes_cbc.c:		ctx->fallback = NULL;
drivers/crypto/vmx/aes_cbc.c:	ret = aes_p8_set_encrypt_key(key, keylen * 8, &ctx->enc_key);
drivers/crypto/vmx/aes_cbc.c:	ret += aes_p8_set_decrypt_key(key, keylen * 8, &ctx->dec_key);
drivers/crypto/vmx/aes_cbc.c:	ret += crypto_blkcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/vmx/aes_cbc.c:		.tfm = ctx->fallback,
drivers/crypto/vmx/aes_cbc.c:					   &ctx->enc_key, walk.iv, 1);
drivers/crypto/vmx/aes_cbc.c:		.tfm = ctx->fallback,
drivers/crypto/vmx/aes_cbc.c:					   &ctx->dec_key, walk.iv, 0);
drivers/crypto/mv_cesa.c:	if (!ctx->need_calc_aes_dkey)
drivers/crypto/mv_cesa.c:	crypto_aes_expand_key(&gen_aes_key, ctx->aes_enc_key, ctx->key_len);
drivers/crypto/mv_cesa.c:	key_pos = ctx->key_len + 24;
drivers/crypto/mv_cesa.c:	memcpy(ctx->aes_dec_key, &gen_aes_key.key_enc[key_pos], 4 * 4);
drivers/crypto/mv_cesa.c:	switch (ctx->key_len) {
drivers/crypto/mv_cesa.c:		memcpy(&ctx->aes_dec_key[4], &gen_aes_key.key_enc[key_pos],
drivers/crypto/mv_cesa.c:	ctx->need_calc_aes_dkey = 0;
drivers/crypto/mv_cesa.c:	ctx->key_len = len;
drivers/crypto/mv_cesa.c:	ctx->need_calc_aes_dkey = 1;
drivers/crypto/mv_cesa.c:	memcpy(ctx->aes_enc_key, key, AES_KEY_LEN);
drivers/crypto/mv_cesa.c:	switch (req_ctx->op) {
drivers/crypto/mv_cesa.c:	if (req_ctx->decrypt) {
drivers/crypto/mv_cesa.c:		memcpy(cpg->sram + SRAM_DATA_KEY_P, ctx->aes_dec_key,
drivers/crypto/mv_cesa.c:		memcpy(cpg->sram + SRAM_DATA_KEY_P, ctx->aes_enc_key,
drivers/crypto/mv_cesa.c:	switch (ctx->key_len) {
drivers/crypto/mv_cesa.c:	if (req_ctx->op != COP_AES_CBC)
drivers/crypto/mv_cesa.c:	switch (req_ctx->op) {
drivers/crypto/mv_cesa.c:				tfm_ctx->ivs, sizeof(tfm_ctx->ivs));
drivers/crypto/mv_cesa.c:		req_ctx->
drivers/crypto/mv_cesa.c:	is_last = req_ctx->last_chunk
drivers/crypto/mv_cesa.c:		&& (req_ctx->count <= MAX_HW_HASH_SIZE);
drivers/crypto/mv_cesa.c:	if (req_ctx->first_hash) {
drivers/crypto/mv_cesa.c:		req_ctx->first_hash = 0;
drivers/crypto/mv_cesa.c:			writel(req_ctx->state[0], cpg->reg + DIGEST_INITIAL_VAL_A);
drivers/crypto/mv_cesa.c:			writel(req_ctx->state[1], cpg->reg + DIGEST_INITIAL_VAL_B);
drivers/crypto/mv_cesa.c:			writel(req_ctx->state[2], cpg->reg + DIGEST_INITIAL_VAL_C);
drivers/crypto/mv_cesa.c:			writel(req_ctx->state[3], cpg->reg + DIGEST_INITIAL_VAL_D);
drivers/crypto/mv_cesa.c:			writel(req_ctx->state[4], cpg->reg + DIGEST_INITIAL_VAL_E);
drivers/crypto/mv_cesa.c:	shash_state.count = ctx->count + ctx->count_add;
drivers/crypto/mv_cesa.c:		shash_state.state[i] = ctx->state[i];
drivers/crypto/mv_cesa.c:	memcpy(shash_state.buffer, ctx->buffer, sizeof(shash_state.buffer));
drivers/crypto/mv_cesa.c:	SHASH_DESC_ON_STACK(shash, tfm_ctx->fallback);
drivers/crypto/mv_cesa.c:	shash->tfm = tfm_ctx->fallback;
drivers/crypto/mv_cesa.c:	if (unlikely(req_ctx->first_hash)) {
drivers/crypto/mv_cesa.c:		crypto_shash_update(shash, req_ctx->buffer,
drivers/crypto/mv_cesa.c:				    req_ctx->extra_bytes);
drivers/crypto/mv_cesa.c:	ctx->state[0] = readl(cpg->reg + DIGEST_INITIAL_VAL_A);
drivers/crypto/mv_cesa.c:	ctx->state[1] = readl(cpg->reg + DIGEST_INITIAL_VAL_B);
drivers/crypto/mv_cesa.c:	ctx->state[2] = readl(cpg->reg + DIGEST_INITIAL_VAL_C);
drivers/crypto/mv_cesa.c:	ctx->state[3] = readl(cpg->reg + DIGEST_INITIAL_VAL_D);
drivers/crypto/mv_cesa.c:	ctx->state[4] = readl(cpg->reg + DIGEST_INITIAL_VAL_E);
drivers/crypto/mv_cesa.c:	if (ctx->extra_bytes)
drivers/crypto/mv_cesa.c:		copy_src_to_buf(&cpg->p, ctx->buffer, ctx->extra_bytes);
drivers/crypto/mv_cesa.c:	if (likely(ctx->last_chunk)) {
drivers/crypto/mv_cesa.c:		if (likely(ctx->count <= MAX_HW_HASH_SIZE)) {
drivers/crypto/mv_cesa.c:	hw_bytes = req->nbytes + ctx->extra_bytes;
drivers/crypto/mv_cesa.c:	old_extra_bytes = ctx->extra_bytes;
drivers/crypto/mv_cesa.c:	ctx->extra_bytes = hw_bytes % SHA1_BLOCK_SIZE;
drivers/crypto/mv_cesa.c:	if (ctx->extra_bytes != 0
drivers/crypto/mv_cesa.c:	    && (!ctx->last_chunk || ctx->count > MAX_HW_HASH_SIZE))
drivers/crypto/mv_cesa.c:		hw_bytes -= ctx->extra_bytes;
drivers/crypto/mv_cesa.c:		ctx->extra_bytes = 0;
drivers/crypto/mv_cesa.c:			memcpy(cpg->sram + SRAM_DATA_IN_START, ctx->buffer,
drivers/crypto/mv_cesa.c:		copy_src_to_buf(p, ctx->buffer + old_extra_bytes,
drivers/crypto/mv_cesa.c:				ctx->extra_bytes - old_extra_bytes);
drivers/crypto/mv_cesa.c:		if (ctx->last_chunk)
drivers/crypto/mv_cesa.c:	req_ctx->op = COP_AES_ECB;
drivers/crypto/mv_cesa.c:	req_ctx->decrypt = 0;
drivers/crypto/mv_cesa.c:	req_ctx->op = COP_AES_ECB;
drivers/crypto/mv_cesa.c:	req_ctx->decrypt = 1;
drivers/crypto/mv_cesa.c:	req_ctx->op = COP_AES_CBC;
drivers/crypto/mv_cesa.c:	req_ctx->decrypt = 0;
drivers/crypto/mv_cesa.c:	req_ctx->op = COP_AES_CBC;
drivers/crypto/mv_cesa.c:	req_ctx->decrypt = 1;
drivers/crypto/mv_cesa.c:	ctx->op = op;
drivers/crypto/mv_cesa.c:	ctx->count = req_len;
drivers/crypto/mv_cesa.c:	ctx->first_hash = 1;
drivers/crypto/mv_cesa.c:	ctx->last_chunk = is_last;
drivers/crypto/mv_cesa.c:	ctx->count_add = count_add;
drivers/crypto/mv_cesa.c:	ctx->last_chunk = is_last;
drivers/crypto/mv_cesa.c:	ctx->count += req_len;
drivers/crypto/mv_cesa.c:	mv_init_hash_req_ctx(ahash_request_ctx(req), tfm_ctx->op, 0, 0,
drivers/crypto/mv_cesa.c:			     tfm_ctx->count_add);
drivers/crypto/mv_cesa.c:	mv_init_hash_req_ctx(ahash_request_ctx(req), tfm_ctx->op, 1,
drivers/crypto/mv_cesa.c:			     req->nbytes, tfm_ctx->count_add);
drivers/crypto/mv_cesa.c:		ctx->ivs[i] = cpu_to_be32(isha1_state->state[i]);
drivers/crypto/mv_cesa.c:		ctx->ivs[i + 5] = cpu_to_be32(osha1_state->state[i]);
drivers/crypto/mv_cesa.c:	if (!ctx->base_hash)
drivers/crypto/mv_cesa.c:	rc = crypto_shash_setkey(ctx->fallback, key, keylen);
drivers/crypto/mv_cesa.c:	bs = crypto_shash_blocksize(ctx->base_hash);
drivers/crypto/mv_cesa.c:	ds = crypto_shash_digestsize(ctx->base_hash);
drivers/crypto/mv_cesa.c:	ss = crypto_shash_statesize(ctx->base_hash);
drivers/crypto/mv_cesa.c:		SHASH_DESC_ON_STACK(shash, ctx->base_hash);
drivers/crypto/mv_cesa.c:		shash->tfm = ctx->base_hash;
drivers/crypto/mv_cesa.c:		shash->flags = crypto_shash_get_flags(ctx->base_hash) &
drivers/crypto/mv_cesa.c:	ctx->op = op;
drivers/crypto/mv_cesa.c:	ctx->count_add = count_add;
drivers/crypto/mv_cesa.c:	ctx->fallback = fallback_tfm;
drivers/crypto/mv_cesa.c:	ctx->base_hash = base_hash;
drivers/crypto/mv_cesa.c:				 crypto_shash_descsize(ctx->fallback));
drivers/crypto/mv_cesa.c:	crypto_free_shash(ctx->fallback);
drivers/crypto/mv_cesa.c:	if (ctx->base_hash)
drivers/crypto/mv_cesa.c:		crypto_free_shash(ctx->base_hash);
drivers/crypto/padlock-aes.c:	ctx->D = ctx->E;
drivers/crypto/padlock-aes.c:	ctx->E[0] = le32_to_cpu(key[0]);
drivers/crypto/padlock-aes.c:	ctx->E[1] = le32_to_cpu(key[1]);
drivers/crypto/padlock-aes.c:	ctx->E[2] = le32_to_cpu(key[2]);
drivers/crypto/padlock-aes.c:	ctx->E[3] = le32_to_cpu(key[3]);
drivers/crypto/padlock-aes.c:	memset(&ctx->cword, 0, sizeof(ctx->cword));
drivers/crypto/padlock-aes.c:	ctx->cword.decrypt.encdec = 1;
drivers/crypto/padlock-aes.c:	ctx->cword.encrypt.rounds = 10 + (key_len - 16) / 4;
drivers/crypto/padlock-aes.c:	ctx->cword.decrypt.rounds = ctx->cword.encrypt.rounds;
drivers/crypto/padlock-aes.c:	ctx->cword.encrypt.ksize = (key_len - 16) / 8;
drivers/crypto/padlock-aes.c:	ctx->cword.decrypt.ksize = ctx->cword.encrypt.ksize;
drivers/crypto/padlock-aes.c:	ctx->D = ctx->d_data;
drivers/crypto/padlock-aes.c:	ctx->cword.encrypt.keygen = 1;
drivers/crypto/padlock-aes.c:	ctx->cword.decrypt.keygen = 1;
drivers/crypto/padlock-aes.c:	memcpy(ctx->E, gen_aes.key_enc, AES_MAX_KEYLENGTH);
drivers/crypto/padlock-aes.c:	memcpy(ctx->D, gen_aes.key_dec, AES_MAX_KEYLENGTH);
drivers/crypto/padlock-aes.c:		if (&ctx->cword.encrypt == per_cpu(paes_last_cword, cpu) ||
drivers/crypto/padlock-aes.c:		    &ctx->cword.decrypt == per_cpu(paes_last_cword, cpu))
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	ecb_crypt(in, out, ctx->E, &ctx->cword.encrypt, 1);
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	ecb_crypt(in, out, ctx->D, &ctx->cword.decrypt, 1);
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:				   ctx->E, &ctx->cword.encrypt,
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.decrypt);
drivers/crypto/padlock-aes.c:				   ctx->D, &ctx->cword.decrypt,
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:					    walk.dst.virt.addr, ctx->E,
drivers/crypto/padlock-aes.c:					    walk.iv, &ctx->cword.encrypt,
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.decrypt);
drivers/crypto/padlock-aes.c:	padlock_reset_key(&ctx->cword.encrypt);
drivers/crypto/padlock-aes.c:				   ctx->D, walk.iv, &ctx->cword.decrypt,
drivers/crypto/padlock-aes.c:	padlock_store_cword(&ctx->cword.encrypt);
drivers/crypto/ixp4xx_crypto.c:	if (req_ctx->encrypt) {
drivers/crypto/ixp4xx_crypto.c:		scatterwalk_map_and_copy(req_ctx->hmac_virt,
drivers/crypto/ixp4xx_crypto.c:	dma_pool_free(buffer_pool, req_ctx->hmac_virt, crypt->icv_rev_aes);
drivers/crypto/ixp4xx_crypto.c:		free_buf_chain(dev, req_ctx->src, crypt->src_buf);
drivers/crypto/ixp4xx_crypto.c:		free_buf_chain(dev, req_ctx->dst, crypt->dst_buf);
drivers/crypto/ixp4xx_crypto.c:		if (req_ctx->hmac_virt) {
drivers/crypto/ixp4xx_crypto.c:		if (req_ctx->dst) {
drivers/crypto/ixp4xx_crypto.c:			free_buf_chain(dev, req_ctx->dst, crypt->dst_buf);
drivers/crypto/ixp4xx_crypto.c:		free_buf_chain(dev, req_ctx->src, crypt->src_buf);
drivers/crypto/ixp4xx_crypto.c:		if (atomic_dec_and_test(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:			complete(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:		*(u32*)ctx->decrypt.npe_ctx &= cpu_to_be32(~CIPH_ENCR);
drivers/crypto/ixp4xx_crypto.c:		if (atomic_dec_and_test(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:			complete(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:	atomic_set(&ctx->configuring, 0);
drivers/crypto/ixp4xx_crypto.c:	ret = init_sa_dir(&ctx->encrypt);
drivers/crypto/ixp4xx_crypto.c:	ret = init_sa_dir(&ctx->decrypt);
drivers/crypto/ixp4xx_crypto.c:		free_sa_dir(&ctx->encrypt);
drivers/crypto/ixp4xx_crypto.c:	free_sa_dir(&ctx->encrypt);
drivers/crypto/ixp4xx_crypto.c:	free_sa_dir(&ctx->decrypt);
drivers/crypto/ixp4xx_crypto.c:	atomic_inc(&ctx->configuring);
drivers/crypto/ixp4xx_crypto.c:	dir = encrypt ? &ctx->encrypt : &ctx->decrypt;
drivers/crypto/ixp4xx_crypto.c:	struct ix_sa_dir *dir = &ctx->decrypt;
drivers/crypto/ixp4xx_crypto.c:	atomic_inc(&ctx->configuring);
drivers/crypto/ixp4xx_crypto.c:	dir = encrypt ? &ctx->encrypt : &ctx->decrypt;
drivers/crypto/ixp4xx_crypto.c:	init_completion(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:	atomic_inc(&ctx->configuring);
drivers/crypto/ixp4xx_crypto.c:	reset_sa_dir(&ctx->encrypt);
drivers/crypto/ixp4xx_crypto.c:	reset_sa_dir(&ctx->decrypt);
drivers/crypto/ixp4xx_crypto.c:	ctx->encrypt.npe_mode = NPE_OP_HMAC_DISABLE;
drivers/crypto/ixp4xx_crypto.c:	ctx->decrypt.npe_mode = NPE_OP_HMAC_DISABLE;
drivers/crypto/ixp4xx_crypto.c:	if (!atomic_dec_and_test(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:		wait_for_completion(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:	memcpy(ctx->nonce, key + (key_len - CTR_RFC3686_NONCE_SIZE),
drivers/crypto/ixp4xx_crypto.c:	if (atomic_read(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:	dir = encrypt ? &ctx->encrypt : &ctx->decrypt;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->dst = NULL;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->dst = dst_hook.next;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->dst = NULL;
drivers/crypto/ixp4xx_crypto.c:	req_ctx->src = NULL;
drivers/crypto/ixp4xx_crypto.c:	req_ctx->src = src_hook.next;
drivers/crypto/ixp4xx_crypto.c:	free_buf_chain(dev, req_ctx->src, crypt->src_buf);
drivers/crypto/ixp4xx_crypto.c:		free_buf_chain(dev, req_ctx->dst, crypt->dst_buf);
drivers/crypto/ixp4xx_crypto.c:        memcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);
drivers/crypto/ixp4xx_crypto.c:	if (atomic_read(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:		dir = &ctx->encrypt;
drivers/crypto/ixp4xx_crypto.c:		dir = &ctx->decrypt;
drivers/crypto/ixp4xx_crypto.c:	req_ctx->src = src_hook.next;
drivers/crypto/ixp4xx_crypto.c:	req_ctx->dst = NULL;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->dst = dst_hook.next;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->hmac_virt = dma_pool_alloc(buffer_pool, flags,
drivers/crypto/ixp4xx_crypto.c:		if (unlikely(!req_ctx->hmac_virt))
drivers/crypto/ixp4xx_crypto.c:			scatterwalk_map_and_copy(req_ctx->hmac_virt,
drivers/crypto/ixp4xx_crypto.c:		req_ctx->encrypt = encrypt;
drivers/crypto/ixp4xx_crypto.c:		req_ctx->hmac_virt = NULL;
drivers/crypto/ixp4xx_crypto.c:	free_buf_chain(dev, req_ctx->dst, crypt->dst_buf);
drivers/crypto/ixp4xx_crypto.c:	free_buf_chain(dev, req_ctx->src, crypt->src_buf);
drivers/crypto/ixp4xx_crypto.c:	if (!ctx->enckey_len && !ctx->authkey_len)
drivers/crypto/ixp4xx_crypto.c:	init_completion(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:	atomic_inc(&ctx->configuring);
drivers/crypto/ixp4xx_crypto.c:	reset_sa_dir(&ctx->encrypt);
drivers/crypto/ixp4xx_crypto.c:	reset_sa_dir(&ctx->decrypt);
drivers/crypto/ixp4xx_crypto.c:	ret = setup_cipher(&tfm->base, 0, ctx->enckey, ctx->enckey_len);
drivers/crypto/ixp4xx_crypto.c:	ret = setup_cipher(&tfm->base, 1, ctx->enckey, ctx->enckey_len);
drivers/crypto/ixp4xx_crypto.c:	ret = setup_auth(&tfm->base, 0, authsize, ctx->authkey,
drivers/crypto/ixp4xx_crypto.c:			ctx->authkey_len, digest_len);
drivers/crypto/ixp4xx_crypto.c:	ret = setup_auth(&tfm->base, 1, authsize,  ctx->authkey,
drivers/crypto/ixp4xx_crypto.c:			ctx->authkey_len, digest_len);
drivers/crypto/ixp4xx_crypto.c:	if (!atomic_dec_and_test(&ctx->configuring))
drivers/crypto/ixp4xx_crypto.c:		wait_for_completion(&ctx->completion);
drivers/crypto/ixp4xx_crypto.c:	if (keys.authkeylen > sizeof(ctx->authkey))
drivers/crypto/ixp4xx_crypto.c:	if (keys.enckeylen > sizeof(ctx->enckey))
drivers/crypto/ixp4xx_crypto.c:	memcpy(ctx->authkey, keys.authkey, keys.authkeylen);
drivers/crypto/ixp4xx_crypto.c:	memcpy(ctx->enckey, keys.enckey, keys.enckeylen);
drivers/crypto/ixp4xx_crypto.c:	ctx->authkey_len = keys.authkeylen;
drivers/crypto/ixp4xx_crypto.c:	ctx->enckey_len = keys.enckeylen;
drivers/crypto/omap-aes.c:	key32 = dd->ctx->keylen / sizeof(u32);
drivers/crypto/omap-aes.c:			__le32_to_cpu(dd->ctx->key[i]));
drivers/crypto/omap-aes.c:	val = FLD_VAL(((dd->ctx->keylen >> 3) - 1), 4, 3);
drivers/crypto/omap-aes.c:	ctx->dd = dd;
drivers/crypto/omap-aes.c:	struct omap_aes_dev *dd = ctx->dd;
drivers/crypto/omap-aes.c:	struct omap_aes_dev *dd = ctx->dd;
drivers/crypto/omap-aes.c:	rctx->mode &= FLAGS_MODE_MASK;
drivers/crypto/omap-aes.c:	dd->flags = (dd->flags & ~FLAGS_MODE_MASK) | rctx->mode;
drivers/crypto/omap-aes.c:	ctx->dd = dd;
drivers/crypto/omap-aes.c:	struct omap_aes_dev *dd = ctx->dd;
drivers/crypto/omap-aes.c:		SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);
drivers/crypto/omap-aes.c:		skcipher_request_set_tfm(subreq, ctx->fallback);
drivers/crypto/omap-aes.c:	rctx->mode = mode;
drivers/crypto/omap-aes.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/omap-aes.c:	ctx->keylen = keylen;
drivers/crypto/omap-aes.c:	crypto_skcipher_clear_flags(ctx->fallback, CRYPTO_TFM_REQ_MASK);
drivers/crypto/omap-aes.c:	crypto_skcipher_set_flags(ctx->fallback, tfm->base.crt_flags &
drivers/crypto/omap-aes.c:	ret = crypto_skcipher_setkey(ctx->fallback, key, keylen);
drivers/crypto/omap-aes.c:	ctx->fallback = blk;
drivers/crypto/omap-aes.c:	if (ctx->fallback)
drivers/crypto/omap-aes.c:		crypto_free_skcipher(ctx->fallback);
drivers/crypto/omap-aes.c:	ctx->fallback = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->flags = 0;
drivers/crypto/msm/qcrypto.c:	ctx->cp = q_alg->cp;
drivers/crypto/msm/qcrypto.c:	get_random_bytes(ctx->iv, QCRYPTO_MAX_IV_LENGTH);
drivers/crypto/msm/qcrypto.c:		ctx->pengine = _qcrypto_static_assign_engine(ctx->cp);
drivers/crypto/msm/qcrypto.c:		if (ctx->pengine == NULL)
drivers/crypto/msm/qcrypto.c:		ctx->pengine = NULL;
drivers/crypto/msm/qcrypto.c:	INIT_LIST_HEAD(&ctx->rsp_queue);
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg = QCE_HASH_LAST;
drivers/crypto/msm/qcrypto.c:	sha_ctx->cp = q_alg->cp;
drivers/crypto/msm/qcrypto.c:	sha_ctx->flags = 0;
drivers/crypto/msm/qcrypto.c:	sha_ctx->ahash_req = NULL;
drivers/crypto/msm/qcrypto.c:		sha_ctx->pengine = _qcrypto_static_assign_engine(sha_ctx->cp);
drivers/crypto/msm/qcrypto.c:		if (sha_ctx->pengine == NULL)
drivers/crypto/msm/qcrypto.c:		sha_ctx->pengine = NULL;
drivers/crypto/msm/qcrypto.c:	INIT_LIST_HEAD(&sha_ctx->rsp_queue);
drivers/crypto/msm/qcrypto.c:	if (!list_empty(&sha_ctx->rsp_queue))
drivers/crypto/msm/qcrypto.c:	if (sha_ctx->ahash_req != NULL) {
drivers/crypto/msm/qcrypto.c:		ahash_request_free(sha_ctx->ahash_req);
drivers/crypto/msm/qcrypto.c:		sha_ctx->ahash_req = NULL;
drivers/crypto/msm/qcrypto.c:	sha_ctx->ahash_req = ahash_request_alloc(ahash, GFP_KERNEL);
drivers/crypto/msm/qcrypto.c:	if (sha_ctx->ahash_req == NULL) {
drivers/crypto/msm/qcrypto.c:	init_completion(&sha_ctx->ahash_req_complete);
drivers/crypto/msm/qcrypto.c:	ahash_request_set_callback(sha_ctx->ahash_req,
drivers/crypto/msm/qcrypto.c:				&sha_ctx->ahash_req_complete);
drivers/crypto/msm/qcrypto.c:		ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb = crypto_alloc_skcipher(name, 0,
drivers/crypto/msm/qcrypto.c:	if (IS_ERR(ctx->cipher_aes192_fb)) {
drivers/crypto/msm/qcrypto.c:		ret = PTR_ERR(ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:		ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg = QCE_HASH_SHA1_HMAC;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg = QCE_HASH_SHA256_HMAC;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg =  QCE_HASH_AES_CMAC;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg =  QCE_HASH_AES_CMAC;
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->ahash_aead_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:		ctx->cipher_aes192_fb = crypto_alloc_skcipher(
drivers/crypto/msm/qcrypto.c:		if (IS_ERR(ctx->cipher_aes192_fb)) {
drivers/crypto/msm/qcrypto.c:			ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:			ctx->ahash_aead_aes192_fb = crypto_alloc_ahash(
drivers/crypto/msm/qcrypto.c:			if (IS_ERR(ctx->ahash_aead_aes192_fb)) {
drivers/crypto/msm/qcrypto.c:				ctx->ahash_aead_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:				crypto_free_skcipher(ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg = QCE_HASH_SHA1_HMAC;
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->ahash_aead_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:		ctx->cipher_aes192_fb = crypto_alloc_skcipher(
drivers/crypto/msm/qcrypto.c:		if (IS_ERR(ctx->cipher_aes192_fb)) {
drivers/crypto/msm/qcrypto.c:			ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:			ctx->ahash_aead_aes192_fb = crypto_alloc_ahash(
drivers/crypto/msm/qcrypto.c:			if (IS_ERR(ctx->ahash_aead_aes192_fb)) {
drivers/crypto/msm/qcrypto.c:				ctx->ahash_aead_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:				crypto_free_skcipher(ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->auth_alg = QCE_HASH_SHA256_HMAC;
drivers/crypto/msm/qcrypto.c:	if (!list_empty(&ctx->rsp_queue))
drivers/crypto/msm/qcrypto.c:	if (ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:		crypto_free_skcipher(ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	if (!list_empty(&ctx->rsp_queue))
drivers/crypto/msm/qcrypto.c:	if (!list_empty(&ctx->rsp_queue))
drivers/crypto/msm/qcrypto.c:	if (ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:		crypto_free_skcipher(ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	if (ctx->ahash_aead_aes192_fb)
drivers/crypto/msm/qcrypto.c:		crypto_free_ahash(ctx->ahash_aead_aes192_fb);
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->ahash_aead_aes192_fb = NULL;
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = AES_KEYSIZE_192;
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;
drivers/crypto/msm/qcrypto.c:	ctx->cipher_aes192_fb->base.crt_flags |=
drivers/crypto/msm/qcrypto.c:	ret = crypto_skcipher_setkey(ctx->cipher_aes192_fb, key,
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if ((ctx->flags & QCRYPTO_CTX_USE_HW_KEY) == QCRYPTO_CTX_USE_HW_KEY)
drivers/crypto/msm/qcrypto.c:					&& ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = len;
drivers/crypto/msm/qcrypto.c:	if (!(ctx->flags & QCRYPTO_CTX_USE_PIPE_KEY))  {
drivers/crypto/msm/qcrypto.c:			memcpy(ctx->enc_key, key, len);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if ((ctx->flags & QCRYPTO_CTX_USE_HW_KEY) == QCRYPTO_CTX_USE_HW_KEY)
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = len;
drivers/crypto/msm/qcrypto.c:	if (!(ctx->flags & QCRYPTO_CTX_USE_PIPE_KEY))  {
drivers/crypto/msm/qcrypto.c:			memcpy(ctx->enc_key, key, len);
drivers/crypto/msm/qcrypto.c:	if ((ctx->flags & QCRYPTO_CTX_USE_HW_KEY) == QCRYPTO_CTX_USE_HW_KEY) {
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = len;
drivers/crypto/msm/qcrypto.c:	if (!(ctx->flags & QCRYPTO_CTX_USE_PIPE_KEY))
drivers/crypto/msm/qcrypto.c:		memcpy(ctx->enc_key, key, len);
drivers/crypto/msm/qcrypto.c:	if ((ctx->flags & QCRYPTO_CTX_USE_HW_KEY) == QCRYPTO_CTX_USE_HW_KEY) {
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = len;
drivers/crypto/msm/qcrypto.c:	if (!(ctx->flags & QCRYPTO_CTX_USE_PIPE_KEY)) {
drivers/crypto/msm/qcrypto.c:			memcpy(ctx->enc_key, key, len);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	pengine = rctx->pengine;
drivers/crypto/msm/qcrypto.c:		memcpy(rctx->digest, digest, diglen);
drivers/crypto/msm/qcrypto.c:		if (rctx->last_blk)
drivers/crypto/msm/qcrypto.c:		rctx->byte_count[0] = auth32[0];
drivers/crypto/msm/qcrypto.c:		rctx->byte_count[1] = auth32[1];
drivers/crypto/msm/qcrypto.c:		rctx->byte_count[2] = auth32[2];
drivers/crypto/msm/qcrypto.c:		rctx->byte_count[3] = auth32[3];
drivers/crypto/msm/qcrypto.c:	areq->src = rctx->src;
drivers/crypto/msm/qcrypto.c:	areq->nbytes = rctx->nbytes;
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 0;
drivers/crypto/msm/qcrypto.c:	rctx->first_blk = 0;
drivers/crypto/msm/qcrypto.c:		areq->src = rctx->orig_src;
drivers/crypto/msm/qcrypto.c:		kfree(rctx->data);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	pengine = rctx->pengine;
drivers/crypto/msm/qcrypto.c:		memcpy(ctx->iv, iv, crypto_ablkcipher_ivsize(ablk));
drivers/crypto/msm/qcrypto.c:		areq->src = rctx->orig_src;
drivers/crypto/msm/qcrypto.c:		areq->dst = rctx->orig_dst;
drivers/crypto/msm/qcrypto.c:			rctx->data, areq->nbytes);
drivers/crypto/msm/qcrypto.c:		kzfree(rctx->data);
drivers/crypto/msm/qcrypto.c:	pengine = rctx->pengine;
drivers/crypto/msm/qcrypto.c:	if (rctx->mode == QCE_MODE_CCM) {
drivers/crypto/msm/qcrypto.c:		kzfree(rctx->adata);
drivers/crypto/msm/qcrypto.c:			if (rctx->dir  == QCE_ENCRYPT) {
drivers/crypto/msm/qcrypto.c:						ctx->authsize, 1);
drivers/crypto/msm/qcrypto.c:					areq->cryptlen - ctx->authsize,
drivers/crypto/msm/qcrypto.c:					ctx->authsize, 0);
drivers/crypto/msm/qcrypto.c:				ret = memcmp(icv, tmp, ctx->authsize);
drivers/crypto/msm/qcrypto.c:			memcpy(ctx->iv, iv, ivsize);
drivers/crypto/msm/qcrypto.c:	rctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:		rctx->orig_src = req->src;
drivers/crypto/msm/qcrypto.c:		rctx->orig_dst = req->dst;
drivers/crypto/msm/qcrypto.c:		rctx->data = kzalloc((req->nbytes + 64), GFP_ATOMIC);
drivers/crypto/msm/qcrypto.c:		if (rctx->data == NULL)
drivers/crypto/msm/qcrypto.c:		bytes = qcrypto_sg_copy_to_buffer(req->src, num_sg, rctx->data,
drivers/crypto/msm/qcrypto.c:		sg_set_buf(&rctx->dsg, rctx->data, req->nbytes);
drivers/crypto/msm/qcrypto.c:		sg_mark_end(&rctx->dsg);
drivers/crypto/msm/qcrypto.c:		rctx->iv = req->info;
drivers/crypto/msm/qcrypto.c:		req->src = &rctx->dsg;
drivers/crypto/msm/qcrypto.c:		req->dst = &rctx->dsg;
drivers/crypto/msm/qcrypto.c:	qreq.alg = rctx->alg;
drivers/crypto/msm/qcrypto.c:	qreq.dir = rctx->dir;
drivers/crypto/msm/qcrypto.c:	qreq.mode = rctx->mode;
drivers/crypto/msm/qcrypto.c:	qreq.enckey = cipher_ctx->enc_key;
drivers/crypto/msm/qcrypto.c:	qreq.encklen = cipher_ctx->enc_key_len;
drivers/crypto/msm/qcrypto.c:	qreq.flags = cipher_ctx->flags;
drivers/crypto/msm/qcrypto.c:	if ((cipher_ctx->enc_key_len == 0) &&
drivers/crypto/msm/qcrypto.c:	rctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	sreq.digest =  &rctx->digest[0];
drivers/crypto/msm/qcrypto.c:	sreq.auth_data[0] = rctx->byte_count[0];
drivers/crypto/msm/qcrypto.c:	sreq.auth_data[1] = rctx->byte_count[1];
drivers/crypto/msm/qcrypto.c:	sreq.auth_data[2] = rctx->byte_count[2];
drivers/crypto/msm/qcrypto.c:	sreq.auth_data[3] = rctx->byte_count[3];
drivers/crypto/msm/qcrypto.c:	sreq.first_blk = rctx->first_blk;
drivers/crypto/msm/qcrypto.c:	sreq.last_blk = rctx->last_blk;
drivers/crypto/msm/qcrypto.c:	sreq.flags = sha_ctx->flags;
drivers/crypto/msm/qcrypto.c:	switch (sha_ctx->alg) {
drivers/crypto/msm/qcrypto.c:		sreq.authkey = &sha_ctx->authkey[0];
drivers/crypto/msm/qcrypto.c:		sreq.authkey = &sha_ctx->authkey[0];
drivers/crypto/msm/qcrypto.c:		pr_err("Algorithm %d not supported, exiting", sha_ctx->alg);
drivers/crypto/msm/qcrypto.c:	rctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	qreq.alg = rctx->alg;
drivers/crypto/msm/qcrypto.c:	qreq.dir = rctx->dir;
drivers/crypto/msm/qcrypto.c:	qreq.mode = rctx->mode;
drivers/crypto/msm/qcrypto.c:	qreq.iv = rctx->iv;
drivers/crypto/msm/qcrypto.c:	qreq.enckey = cipher_ctx->enc_key;
drivers/crypto/msm/qcrypto.c:	qreq.encklen = cipher_ctx->enc_key_len;
drivers/crypto/msm/qcrypto.c:	qreq.authkey = cipher_ctx->auth_key;
drivers/crypto/msm/qcrypto.c:	qreq.authklen = cipher_ctx->auth_key_len;
drivers/crypto/msm/qcrypto.c:	qreq.auth_alg = cipher_ctx->auth_alg;
drivers/crypto/msm/qcrypto.c:	qreq.flags = cipher_ctx->flags;
drivers/crypto/msm/qcrypto.c:		if (rctx->ccmtype)
drivers/crypto/msm/qcrypto.c:			rctx->adata = kzalloc((assoclen + 0x64),
drivers/crypto/msm/qcrypto.c:			if (!rctx->adata)
drivers/crypto/msm/qcrypto.c:						rctx->adata);
drivers/crypto/msm/qcrypto.c:			rctx->adata = NULL;
drivers/crypto/msm/qcrypto.c:			kzfree(rctx->adata);
drivers/crypto/msm/qcrypto.c:		qreq.asg = &rctx->asg;
drivers/crypto/msm/qcrypto.c:		if (rctx->adata)
drivers/crypto/msm/qcrypto.c:			sg_set_buf(qreq.asg, rctx->adata,
drivers/crypto/msm/qcrypto.c:		arsp = &ahash_rctx->rsp_entry;
drivers/crypto/msm/qcrypto.c:		arsp = &cipher_rctx->rsp_entry;
drivers/crypto/msm/qcrypto.c:		arsp = &cipher_rctx->rsp_entry;
drivers/crypto/msm/qcrypto.c:	SKCIPHER_REQUEST_ON_STACK(subreq, ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	skcipher_request_set_tfm(subreq, ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	SKCIPHER_REQUEST_ON_STACK(subreq, ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	skcipher_request_set_tfm(subreq, ctx->cipher_aes192_fb);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_enc_aes_ecb: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_enc_aes_cbc: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_enc_aes_ctr: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CTR;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_XTS;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if ((ctx->authsize > 16) || (ctx->authsize < 4) || (ctx->authsize & 1))
drivers/crypto/msm/qcrypto.c:	if ((ctx->auth_key_len != AES_KEYSIZE_128) &&
drivers/crypto/msm/qcrypto.c:		(ctx->auth_key_len != AES_KEYSIZE_256))
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CCM;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	rctx->ccmtype = 0;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CCM;
drivers/crypto/msm/qcrypto.c:	memset(rctx->rfc4309_iv, 0, sizeof(rctx->rfc4309_iv));
drivers/crypto/msm/qcrypto.c:	rctx->rfc4309_iv[0] = 3; /* L -1 */
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->rfc4309_iv[1], ctx->ccm4309_nonce, 3);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->rfc4309_iv[4], req->iv, 8);
drivers/crypto/msm/qcrypto.c:	rctx->ccmtype = 1;
drivers/crypto/msm/qcrypto.c:	rctx->iv = rctx->rfc4309_iv;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_dec_aes_ecb: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_dec_aes_cbc: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev, "_qcrypto_dec_aes_ctr: %pK\n", req);
drivers/crypto/msm/qcrypto.c:	if ((ctx->enc_key_len == AES_KEYSIZE_192) &&
drivers/crypto/msm/qcrypto.c:				ctx->cipher_aes192_fb)
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CTR;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_ECB;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 0;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_XTS;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if ((ctx->authsize > 16) || (ctx->authsize < 4) || (ctx->authsize & 1))
drivers/crypto/msm/qcrypto.c:	if ((ctx->auth_key_len != AES_KEYSIZE_128) &&
drivers/crypto/msm/qcrypto.c:		(ctx->auth_key_len != AES_KEYSIZE_256))
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CCM;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	rctx->ccmtype = 0;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CCM;
drivers/crypto/msm/qcrypto.c:	memset(rctx->rfc4309_iv, 0, sizeof(rctx->rfc4309_iv));
drivers/crypto/msm/qcrypto.c:	rctx->rfc4309_iv[0] = 3; /* L -1 */
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->rfc4309_iv[1], ctx->ccm4309_nonce, 3);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->rfc4309_iv[4], req->iv, 8);
drivers/crypto/msm/qcrypto.c:	rctx->ccmtype = 1;
drivers/crypto/msm/qcrypto.c:	rctx->iv = rctx->rfc4309_iv;
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	ctx->authsize = authsize;
drivers/crypto/msm/qcrypto.c:	ctx->authsize = authsize;
drivers/crypto/msm/qcrypto.c:	ctx->authsize = authsize;
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = be32_to_cpu(param->enckeylen);
drivers/crypto/msm/qcrypto.c:	if (keylen < ctx->enc_key_len)
drivers/crypto/msm/qcrypto.c:	ctx->auth_key_len = keylen - ctx->enc_key_len;
drivers/crypto/msm/qcrypto.c:	if (ctx->enc_key_len >= QCRYPTO_MAX_KEY_SIZE ||
drivers/crypto/msm/qcrypto.c:				ctx->auth_key_len >= QCRYPTO_MAX_KEY_SIZE)
drivers/crypto/msm/qcrypto.c:	memset(ctx->auth_key, 0, QCRYPTO_MAX_KEY_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->enc_key, key + ctx->auth_key_len, ctx->enc_key_len);
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->auth_key, key, ctx->auth_key_len);
drivers/crypto/msm/qcrypto.c:	if (ctx->enc_key_len == AES_KEYSIZE_192 &&  ctx->cipher_aes192_fb &&
drivers/crypto/msm/qcrypto.c:			ctx->ahash_aead_aes192_fb) {
drivers/crypto/msm/qcrypto.c:		crypto_ahash_clear_flags(ctx->ahash_aead_aes192_fb, ~0);
drivers/crypto/msm/qcrypto.c:		ret = crypto_ahash_setkey(ctx->ahash_aead_aes192_fb,
drivers/crypto/msm/qcrypto.c:					ctx->auth_key, ctx->auth_key_len);
drivers/crypto/msm/qcrypto.c:		crypto_skcipher_clear_flags(ctx->cipher_aes192_fb, ~0);
drivers/crypto/msm/qcrypto.c:		ret = crypto_skcipher_setkey(ctx->cipher_aes192_fb,
drivers/crypto/msm/qcrypto.c:					ctx->enc_key, ctx->enc_key_len);
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = 0;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:		ctx->enc_key_len = 0;
drivers/crypto/msm/qcrypto.c:	ctx->enc_key_len = keylen;
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->enc_key, key, keylen);
drivers/crypto/msm/qcrypto.c:	ctx->auth_key_len = keylen;
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->auth_key, key, keylen);
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->ccm4309_nonce, key + key_len,  QCRYPTO_CCM4309_NONCE_LEN);
drivers/crypto/msm/qcrypto.c:	req = rctx->aead_req;
drivers/crypto/msm/qcrypto.c:	if (rctx->fb_aes_req)
drivers/crypto/msm/qcrypto.c:		skcipher_request_free(rctx->fb_aes_req);
drivers/crypto/msm/qcrypto.c:	if (rctx->fb_hash_req)
drivers/crypto/msm/qcrypto.c:		ahash_request_free(rctx->fb_hash_req);
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_req = NULL;
drivers/crypto/msm/qcrypto.c:	rctx->fb_hash_req = NULL;
drivers/crypto/msm/qcrypto.c:	kfree(rctx->fb_aes_iv);
drivers/crypto/msm/qcrypto.c:	req = rctx->aead_req;
drivers/crypto/msm/qcrypto.c:		scatterwalk_map_and_copy(rctx->fb_ahash_digest,
drivers/crypto/msm/qcrypto.c:					rctx->fb_aes_dst,
drivers/crypto/msm/qcrypto.c:					ctx->authsize, 1);
drivers/crypto/msm/qcrypto.c:	ahash_req = rctx->fb_hash_req;
drivers/crypto/msm/qcrypto.c:	aes_req = rctx->fb_aes_req;
drivers/crypto/msm/qcrypto.c:	req = rctx->aead_req;
drivers/crypto/msm/qcrypto.c:		unsigned char tmp[ctx->authsize];
drivers/crypto/msm/qcrypto.c:		scatterwalk_map_and_copy(tmp, rctx->fb_aes_src,
drivers/crypto/msm/qcrypto.c:			req->cryptlen - ctx->authsize, ctx->authsize, 0);
drivers/crypto/msm/qcrypto.c:		if (memcmp(rctx->fb_ahash_digest, tmp, ctx->authsize) != 0)
drivers/crypto/msm/qcrypto.c:	req = rctx->aead_req;
drivers/crypto/msm/qcrypto.c:	memcpy(ctx->iv, rctx->fb_aes_iv, rctx->ivsize);
drivers/crypto/msm/qcrypto.c:		scatterwalk_map_and_copy(rctx->fb_ahash_digest,
drivers/crypto/msm/qcrypto.c:					rctx->fb_aes_dst,
drivers/crypto/msm/qcrypto.c:					ctx->authsize, 1);
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_iv = NULL;
drivers/crypto/msm/qcrypto.c:	aes_req = skcipher_request_alloc(ctx->cipher_aes192_fb, GFP_KERNEL);
drivers/crypto/msm/qcrypto.c:	ahash_req = ahash_request_alloc(ctx->ahash_aead_aes192_fb, GFP_KERNEL);
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_req = aes_req;
drivers/crypto/msm/qcrypto.c:	rctx->fb_hash_req = ahash_req;
drivers/crypto/msm/qcrypto.c:	rctx->aead_req = req;
drivers/crypto/msm/qcrypto.c:	src = scatterwalk_ffwd(rctx->fb_ablkcipher_src_sg, req->src,
drivers/crypto/msm/qcrypto.c:	dst = scatterwalk_ffwd(rctx->fb_ablkcipher_dst_sg, req->dst,
drivers/crypto/msm/qcrypto.c:		nbytes -=  ctx->authsize;
drivers/crypto/msm/qcrypto.c:	rctx->fb_ahash_length = nbytes +  req->assoclen;
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_src = src;
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_dst = dst;
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_cryptlen = nbytes;
drivers/crypto/msm/qcrypto.c:	rctx->ivsize = crypto_aead_ivsize(aead_tfm);
drivers/crypto/msm/qcrypto.c:	rctx->fb_aes_iv = kzalloc(rctx->ivsize, GFP_ATOMIC);
drivers/crypto/msm/qcrypto.c:	if (!rctx->fb_aes_iv)
drivers/crypto/msm/qcrypto.c:	memcpy(rctx->fb_aes_iv, req->iv, rctx->ivsize);
drivers/crypto/msm/qcrypto.c:	skcipher_request_set_crypt(aes_req, rctx->fb_aes_src,
drivers/crypto/msm/qcrypto.c:					rctx->fb_aes_dst,
drivers/crypto/msm/qcrypto.c:					rctx->fb_aes_cryptlen, rctx->fb_aes_iv);
drivers/crypto/msm/qcrypto.c:					rctx->fb_ahash_digest,
drivers/crypto/msm/qcrypto.c:					rctx->fb_ahash_length);
drivers/crypto/msm/qcrypto.c:					rctx->fb_ahash_digest,
drivers/crypto/msm/qcrypto.c:					rctx->fb_ahash_length);
drivers/crypto/msm/qcrypto.c:			memcpy(ctx->iv, rctx->fb_aes_iv, rctx->ivsize);
drivers/crypto/msm/qcrypto.c:				scatterwalk_map_and_copy(rctx->fb_ahash_digest,
drivers/crypto/msm/qcrypto.c:					ctx->authsize, 1);
drivers/crypto/msm/qcrypto.c:			unsigned char tmp[ctx->authsize];
drivers/crypto/msm/qcrypto.c:				src, req->cryptlen - ctx->authsize,
drivers/crypto/msm/qcrypto.c:				ctx->authsize, 0);
drivers/crypto/msm/qcrypto.c:			if (memcmp(rctx->fb_ahash_digest, tmp,
drivers/crypto/msm/qcrypto.c:							ctx->authsize) != 0)
drivers/crypto/msm/qcrypto.c:	kfree(rctx->fb_aes_iv);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev,
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	rctx->aead_req = req;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	if (ctx->enc_key_len == AES_KEYSIZE_192 &&  ctx->cipher_aes192_fb &&
drivers/crypto/msm/qcrypto.c:						ctx->ahash_aead_aes192_fb)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	dev_info(&ctx->pengine->pdev->dev,
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_AES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	rctx->aead_req = req;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	if (ctx->enc_key_len == AES_KEYSIZE_192 &&  ctx->cipher_aes192_fb &&
drivers/crypto/msm/qcrypto.c:						ctx->ahash_aead_aes192_fb)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_ENCRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->aead = 1;
drivers/crypto/msm/qcrypto.c:	rctx->alg = CIPHER_ALG_3DES;
drivers/crypto/msm/qcrypto.c:	rctx->dir = QCE_DECRYPT;
drivers/crypto/msm/qcrypto.c:	rctx->mode = QCE_MODE_CBC;
drivers/crypto/msm/qcrypto.c:	rctx->iv = req->iv;
drivers/crypto/msm/qcrypto.c:	if (ctx->auth_alg == QCE_HASH_SHA1_HMAC)
drivers/crypto/msm/qcrypto.c:	return _qcrypto_queue_req(cp, ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	rctx->first_blk = 1;
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[0] = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[1] = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[2] = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[3] = 0;
drivers/crypto/msm/qcrypto.c:	rctx->trailing_buf_len = 0;
drivers/crypto/msm/qcrypto.c:	rctx->count = 0;
drivers/crypto/msm/qcrypto.c:	sha_ctx->alg = QCE_HASH_SHA1;
drivers/crypto/msm/qcrypto.c:	memset(&rctx->trailing_buf[0], 0x00, SHA1_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha1_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA1_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:	sha_ctx->alg = QCE_HASH_SHA256;
drivers/crypto/msm/qcrypto.c:	memset(&rctx->trailing_buf[0], 0x00, SHA256_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha256_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA256_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:	out_ctx->count = rctx->count;
drivers/crypto/msm/qcrypto.c:	_byte_stream_to_words(out_ctx->state, rctx->digest, SHA1_DIGEST_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(out_ctx->buffer, rctx->trailing_buf, SHA1_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	u64 hw_count = in_ctx->count;
drivers/crypto/msm/qcrypto.c:	rctx->count = in_ctx->count;
drivers/crypto/msm/qcrypto.c:	memcpy(rctx->trailing_buf, in_ctx->buffer, SHA1_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	if (in_ctx->count <= SHA1_BLOCK_SIZE) {
drivers/crypto/msm/qcrypto.c:		rctx->first_blk = 1;
drivers/crypto/msm/qcrypto.c:		rctx->first_blk = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[0] =  (uint32_t)(hw_count & 0xFFFFFFC0);
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[1] =  (uint32_t)(hw_count >> 32);
drivers/crypto/msm/qcrypto.c:	_words_to_byte_stream(in_ctx->state, rctx->digest, sha_ctx->diglen);
drivers/crypto/msm/qcrypto.c:	rctx->trailing_buf_len = (uint32_t)(in_ctx->count &
drivers/crypto/msm/qcrypto.c:	out_ctx->count = rctx->count;
drivers/crypto/msm/qcrypto.c:	_byte_stream_to_words(out_ctx->state, rctx->digest, SHA256_DIGEST_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(out_ctx->buf, rctx->trailing_buf, SHA256_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	u64 hw_count = in_ctx->count;
drivers/crypto/msm/qcrypto.c:	rctx->count = in_ctx->count;
drivers/crypto/msm/qcrypto.c:	memcpy(rctx->trailing_buf, in_ctx->buf, SHA256_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	if (in_ctx->count <= SHA256_BLOCK_SIZE) {
drivers/crypto/msm/qcrypto.c:		rctx->first_blk = 1;
drivers/crypto/msm/qcrypto.c:		rctx->first_blk = 0;
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[0] =  (uint32_t)(hw_count & 0xFFFFFFC0);
drivers/crypto/msm/qcrypto.c:	rctx->byte_count[1] =  (uint32_t)(hw_count >> 32);
drivers/crypto/msm/qcrypto.c:	_words_to_byte_stream(in_ctx->state, rctx->digest, sha_ctx->diglen);
drivers/crypto/msm/qcrypto.c:	rctx->trailing_buf_len = (uint32_t)(in_ctx->count &
drivers/crypto/msm/qcrypto.c:	srctx->orig_src = req->src;
drivers/crypto/msm/qcrypto.c:	srctx->data = kzalloc((req->nbytes + 64), GFP_ATOMIC);
drivers/crypto/msm/qcrypto.c:	if (srctx->data == NULL) {
drivers/crypto/msm/qcrypto.c:		pr_err("Mem Alloc fail rctx->data, err %ld for 0x%x\n",
drivers/crypto/msm/qcrypto.c:				PTR_ERR(srctx->data), (req->nbytes + 64));
drivers/crypto/msm/qcrypto.c:	bytes = qcrypto_sg_copy_to_buffer(req->src, num_sg, srctx->data,
drivers/crypto/msm/qcrypto.c:	sg_set_buf(&srctx->dsg, srctx->data,
drivers/crypto/msm/qcrypto.c:	sg_mark_end(&srctx->dsg);
drivers/crypto/msm/qcrypto.c:	req->src = &srctx->dsg;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	total = req->nbytes + rctx->trailing_buf_len;
drivers/crypto/msm/qcrypto.c:		k_src = &rctx->trailing_buf[rctx->trailing_buf_len];
drivers/crypto/msm/qcrypto.c:		rctx->trailing_buf_len = total;
drivers/crypto/msm/qcrypto.c:	rctx->src = req->src;
drivers/crypto/msm/qcrypto.c:	rctx->nbytes = req->nbytes;
drivers/crypto/msm/qcrypto.c:	staging = (uint8_t *)ALIGN(((uintptr_t)rctx->staging_dmabuf),
drivers/crypto/msm/qcrypto.c:	memcpy(staging, rctx->trailing_buf, rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	k_src = &rctx->trailing_buf[0];
drivers/crypto/msm/qcrypto.c:	len = rctx->trailing_buf_len;
drivers/crypto/msm/qcrypto.c:	if (rctx->trailing_buf_len) {
drivers/crypto/msm/qcrypto.c:			rctx->data2 = kzalloc((req->nbytes + 64), GFP_ATOMIC);
drivers/crypto/msm/qcrypto.c:			if (rctx->data2 == NULL) {
drivers/crypto/msm/qcrypto.c:				pr_err("Mem Alloc fail srctx->data2, err %ld\n",
drivers/crypto/msm/qcrypto.c:							PTR_ERR(rctx->data2));
drivers/crypto/msm/qcrypto.c:			memcpy(rctx->data2, staging,
drivers/crypto/msm/qcrypto.c:						rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:			memcpy((rctx->data2 + rctx->trailing_buf_len),
drivers/crypto/msm/qcrypto.c:					rctx->data, req->src->length);
drivers/crypto/msm/qcrypto.c:			kzfree(rctx->data);
drivers/crypto/msm/qcrypto.c:			rctx->data = rctx->data2;
drivers/crypto/msm/qcrypto.c:			sg_set_buf(&rctx->sg[0], rctx->data,
drivers/crypto/msm/qcrypto.c:					(rctx->trailing_buf_len +
drivers/crypto/msm/qcrypto.c:			req->src = rctx->sg;
drivers/crypto/msm/qcrypto.c:			sg_mark_end(&rctx->sg[0]);
drivers/crypto/msm/qcrypto.c:			memset(rctx->sg, 0, sizeof(rctx->sg));
drivers/crypto/msm/qcrypto.c:			sg_set_buf(&rctx->sg[0], staging,
drivers/crypto/msm/qcrypto.c:						rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:			sg_mark_end(&rctx->sg[1]);
drivers/crypto/msm/qcrypto.c:			sg_chain(rctx->sg, 2, req->src);
drivers/crypto/msm/qcrypto.c:			req->src = rctx->sg;
drivers/crypto/msm/qcrypto.c:	rctx->trailing_buf_len = trailing_buf_len;
drivers/crypto/msm/qcrypto.c:	ret =  _qcrypto_queue_req(cp, sha_ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->count += req->nbytes;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->count += req->nbytes;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 1;
drivers/crypto/msm/qcrypto.c:	rctx->src = req->src;
drivers/crypto/msm/qcrypto.c:	rctx->nbytes = req->nbytes;
drivers/crypto/msm/qcrypto.c:	staging = (uint8_t *)ALIGN(((uintptr_t)rctx->staging_dmabuf),
drivers/crypto/msm/qcrypto.c:	memcpy(staging, rctx->trailing_buf, rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	sg_set_buf(&rctx->sg[0], staging, rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	sg_mark_end(&rctx->sg[0]);
drivers/crypto/msm/qcrypto.c:	req->src = &rctx->sg[0];
drivers/crypto/msm/qcrypto.c:	req->nbytes = rctx->trailing_buf_len;
drivers/crypto/msm/qcrypto.c:	ret =  _qcrypto_queue_req(cp, sha_ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	rctx->src = req->src;
drivers/crypto/msm/qcrypto.c:	rctx->nbytes = req->nbytes;
drivers/crypto/msm/qcrypto.c:	rctx->first_blk = 1;
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 1;
drivers/crypto/msm/qcrypto.c:	ret =  _qcrypto_queue_req(cp, sha_ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:				&sha_ctx->authkey[0], len);
drivers/crypto/msm/qcrypto.c:	if (sha_ctx->alg == QCE_HASH_SHA1)
drivers/crypto/msm/qcrypto.c:		reinit_completion(&sha_ctx->ahash_req_complete);
drivers/crypto/msm/qcrypto.c:	memset(&sha_ctx->authkey[0], 0, SHA1_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:		memcpy(&sha_ctx->authkey[0], key, len);
drivers/crypto/msm/qcrypto.c:		sha_ctx->authkey_in_len = len;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA1;
drivers/crypto/msm/qcrypto.c:		sha_ctx->diglen = SHA1_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:		sha_ctx->authkey_in_len = SHA1_BLOCK_SIZE;
drivers/crypto/msm/qcrypto.c:	memset(&sha_ctx->authkey[0], 0, SHA256_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:		memcpy(&sha_ctx->authkey[0], key, len);
drivers/crypto/msm/qcrypto.c:		sha_ctx->authkey_in_len = len;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA256;
drivers/crypto/msm/qcrypto.c:		sha_ctx->diglen = SHA256_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:		sha_ctx->authkey_in_len = SHA256_BLOCK_SIZE;
drivers/crypto/msm/qcrypto.c:		rctx->trailing_buf[i] = sha_ctx->authkey[i] ^ 0x36;
drivers/crypto/msm/qcrypto.c:	rctx->trailing_buf_len = sha_block_size;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	memset(&rctx->trailing_buf[0], 0x00, SHA1_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha1_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA1_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA1_HMAC;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA1;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	memset(&rctx->trailing_buf[0], 0x00, SHA256_BLOCK_SIZE);
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha256_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA256_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA256_HMAC;
drivers/crypto/msm/qcrypto.c:		sha_ctx->alg = QCE_HASH_SHA256;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	staging = (uint8_t *)ALIGN(((uintptr_t)rctx->staging_dmabuf),
drivers/crypto/msm/qcrypto.c:		*p++ = sha_ctx->authkey[i] ^ 0x5c;
drivers/crypto/msm/qcrypto.c:	memcpy(p, &rctx->digest[0], sha_digest_size);
drivers/crypto/msm/qcrypto.c:	sg_set_buf(&rctx->sg[0], staging, sha_block_size +
drivers/crypto/msm/qcrypto.c:	sg_mark_end(&rctx->sg[0]);
drivers/crypto/msm/qcrypto.c:	rctx->src = req->src;
drivers/crypto/msm/qcrypto.c:	rctx->nbytes = req->nbytes;
drivers/crypto/msm/qcrypto.c:	req->src = &rctx->sg[0];
drivers/crypto/msm/qcrypto.c:	if (sha_ctx->alg == QCE_HASH_SHA1) {
drivers/crypto/msm/qcrypto.c:		memcpy(&rctx->digest[0], &_std_init_vector_sha1_uint8[0],
drivers/crypto/msm/qcrypto.c:		sha_ctx->diglen = SHA1_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:		memcpy(&rctx->digest[0], &_std_init_vector_sha256_uint8[0],
drivers/crypto/msm/qcrypto.c:		sha_ctx->diglen = SHA256_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 1;
drivers/crypto/msm/qcrypto.c:	return  _qcrypto_queue_req(cp, sha_ctx->pengine, &req->base);
drivers/crypto/msm/qcrypto.c:	struct ahash_request *areq = sha_ctx->ahash_req;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	staging = (uint8_t *)ALIGN(((uintptr_t)rctx->staging_dmabuf),
drivers/crypto/msm/qcrypto.c:	memcpy(staging, rctx->trailing_buf, rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	sg_set_buf(&rctx->sg[0], staging, rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	sg_mark_end(&rctx->sg[0]);
drivers/crypto/msm/qcrypto.c:	ahash_request_set_crypt(areq, &rctx->sg[0], &rctx->digest[0],
drivers/crypto/msm/qcrypto.c:						rctx->trailing_buf_len);
drivers/crypto/msm/qcrypto.c:	rctx->last_blk = 1;
drivers/crypto/msm/qcrypto.c:	ret =  _qcrypto_queue_req(cp, sha_ctx->pengine, &areq->base);
drivers/crypto/msm/qcrypto.c:		wait_for_completion_interruptible(&sha_ctx->ahash_req_complete);
drivers/crypto/msm/qcrypto.c:		reinit_completion(&sha_ctx->ahash_req_complete);
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = sha_ctx->cp;
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha1_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA1_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:	sha_ctx->alg = QCE_HASH_SHA1_HMAC;
drivers/crypto/msm/qcrypto.c:	memcpy(&rctx->digest[0], &_std_init_vector_sha256_uint8[0],
drivers/crypto/msm/qcrypto.c:	sha_ctx->diglen = SHA256_DIGEST_SIZE;
drivers/crypto/msm/qcrypto.c:	sha_ctx->alg = QCE_HASH_SHA256_HMAC;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	ctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	ctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	ctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	ctx->pengine = pengine;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if (((flags | ctx->flags) & QCRYPTO_CTX_KEY_MASK) ==
drivers/crypto/msm/qcrypto.c:	ctx->flags |= flags;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if (((flags | ctx->flags) & QCRYPTO_CTX_KEY_MASK) ==
drivers/crypto/msm/qcrypto.c:	ctx->flags |= flags;
drivers/crypto/msm/qcrypto.c:	struct crypto_priv *cp = ctx->cp;
drivers/crypto/msm/qcrypto.c:	if (((flags | ctx->flags) & QCRYPTO_CTX_KEY_MASK) ==
drivers/crypto/msm/qcrypto.c:	ctx->flags |= flags;
drivers/crypto/msm/qcrypto.c:	ctx->flags &= ~flags;
drivers/crypto/msm/qcrypto.c:	ctx->flags &= ~flags;
drivers/crypto/msm/qcrypto.c:	ctx->flags &= ~flags;
drivers/crypto/nx/nx-aes-ctr.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ctr.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-ctr.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_192];
drivers/crypto/nx/nx-aes-ctr.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_256];
drivers/crypto/nx/nx-aes-ctr.c:	memcpy(nx_ctx->priv.ctr.nonce,
drivers/crypto/nx/nx-aes-ctr.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ctr.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ctr.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-aes-ctr.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-ctr.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ctr.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-ctr.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ctr.c:	memcpy(iv, nx_ctx->priv.ctr.nonce, CTR_RFC3686_IV_SIZE);
drivers/crypto/nx/nx-aes-ecb.c:	struct nx_csbcpb *csbcpb = (struct nx_csbcpb *)nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ecb.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-ecb.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_192];
drivers/crypto/nx/nx-aes-ecb.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_256];
drivers/crypto/nx/nx-aes-ecb.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ecb.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ecb.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-aes-ecb.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-ecb.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ecb.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-ecb.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_csbcpb *csbcpb_aead = nx_ctx->csbcpb_aead;
drivers/crypto/nx/nx-aes-ccm.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-ccm.c:	memcpy(nx_ctx->priv.ccm.nonce, in_key + key_len, 3);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_sg *nx_insg = nx_ctx->in_sg;
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_sg *nx_outsg = nx_ctx->out_sg;
drivers/crypto/nx/nx-aes-ccm.c:		b0 = nx_ctx->csbcpb->cpb.aes_ccm.in_pat_or_b0;
drivers/crypto/nx/nx-aes-ccm.c:		b0 = nx_ctx->csbcpb->cpb.aes_ccm.in_pat_or_b0;
drivers/crypto/nx/nx-aes-ccm.c:		b1 = nx_ctx->priv.ccm.iauth_tag;
drivers/crypto/nx/nx-aes-ccm.c:		b0 = nx_ctx->csbcpb_aead->cpb.aes_cca.b0;
drivers/crypto/nx/nx-aes-ccm.c:		b1 = nx_ctx->csbcpb_aead->cpb.aes_cca.b1;
drivers/crypto/nx/nx-aes-ccm.c:		b0 = nx_ctx->csbcpb_aead->cpb.aes_cca.b0;
drivers/crypto/nx/nx-aes-ccm.c:		b1 = nx_ctx->csbcpb_aead->cpb.aes_cca.b1;
drivers/crypto/nx/nx-aes-ccm.c:		nx_insg = nx_build_sg_list(nx_insg, b1, &len, nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-ccm.c:					    nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-ccm.c:		nx_ctx->op.inlen = (nx_ctx->in_sg - nx_insg) *
drivers/crypto/nx/nx-aes-ccm.c:		nx_ctx->op.outlen = (nx_ctx->out_sg - nx_outsg) *
drivers/crypto/nx/nx-aes-ccm.c:		NX_CPB_FDM(nx_ctx->csbcpb) |= NX_FDM_ENDE_ENCRYPT;
drivers/crypto/nx/nx-aes-ccm.c:		NX_CPB_FDM(nx_ctx->csbcpb) |= NX_FDM_INTERMEDIATE;
drivers/crypto/nx/nx-aes-ccm.c:		result = nx_ctx->csbcpb->cpb.aes_ccm.out_pat_or_mac;
drivers/crypto/nx/nx-aes-ccm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-ccm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ccm.c:		atomic64_add(assoclen, &nx_ctx->stats->aes_bytes);
drivers/crypto/nx/nx-aes-ccm.c:		max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx-aes-ccm.c:				nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-aes-ccm.c:					   nx_ctx->ap->databytelen);
drivers/crypto/nx/nx-aes-ccm.c:			nx_insg = nx_walk_and_build(nx_ctx->in_sg,
drivers/crypto/nx/nx-aes-ccm.c:						    nx_ctx->ap->sglen,
drivers/crypto/nx/nx-aes-ccm.c:				NX_CPB_FDM(nx_ctx->csbcpb_aead) |=
drivers/crypto/nx/nx-aes-ccm.c:				NX_CPB_FDM(nx_ctx->csbcpb_aead) &=
drivers/crypto/nx/nx-aes-ccm.c:			nx_ctx->op_aead.inlen = (nx_ctx->in_sg - nx_insg) *
drivers/crypto/nx/nx-aes-ccm.c:			result = nx_ctx->csbcpb_aead->cpb.aes_cca.out_pat_or_b0;
drivers/crypto/nx/nx-aes-ccm.c:			rc = nx_hcall_sync(nx_ctx, &nx_ctx->op_aead,
drivers/crypto/nx/nx-aes-ccm.c:			memcpy(nx_ctx->csbcpb_aead->cpb.aes_cca.b0,
drivers/crypto/nx/nx-aes-ccm.c:				nx_ctx->csbcpb_aead->cpb.aes_cca.out_pat_or_b0,
drivers/crypto/nx/nx-aes-ccm.c:			NX_CPB_FDM(nx_ctx->csbcpb_aead) |= NX_FDM_CONTINUATION;
drivers/crypto/nx/nx-aes-ccm.c:			atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ccm.c:			atomic64_add(assoclen, &nx_ctx->stats->aes_bytes);
drivers/crypto/nx/nx-aes-ccm.c:		result = nx_ctx->csbcpb_aead->cpb.aes_cca.out_pat_or_b0;
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_ccm_priv *priv = &nx_ctx->priv.ccm;
drivers/crypto/nx/nx-aes-ccm.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ccm.c:		NX_CPB_FDM(nx_ctx->csbcpb) &= ~NX_FDM_ENDE_ENCRYPT;
drivers/crypto/nx/nx-aes-ccm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-ccm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ccm.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-ccm.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-ccm.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ccm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-ccm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-ccm.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-ccm.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-ccm.c:	u8 *iv = rctx->iv;
drivers/crypto/nx/nx-aes-ccm.c:	memcpy(iv + 1, nx_ctx->priv.ccm.nonce, 3);
drivers/crypto/nx/nx-aes-ccm.c:	u8 *iv = rctx->iv;
drivers/crypto/nx/nx-aes-ccm.c:	memcpy(iv + 1, nx_ctx->priv.ccm.nonce, 3);
drivers/crypto/nx/nx-aes-cbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-cbc.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-cbc.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_192];
drivers/crypto/nx/nx-aes-cbc.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_256];
drivers/crypto/nx/nx-aes-cbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-cbc.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-cbc.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-aes-cbc.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-cbc.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-cbc.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-cbc.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha256.c:	nx_ctx->ap = &nx_ctx->props[NX_PROPS_SHA256];
drivers/crypto/nx/nx-sha256.c:	NX_CPB_SET_DIGEST_SIZE(nx_ctx->csbcpb, NX_DS_SHA256);
drivers/crypto/nx/nx-sha256.c:	sctx->state[0] = __cpu_to_be32(SHA256_H0);
drivers/crypto/nx/nx-sha256.c:	sctx->state[1] = __cpu_to_be32(SHA256_H1);
drivers/crypto/nx/nx-sha256.c:	sctx->state[2] = __cpu_to_be32(SHA256_H2);
drivers/crypto/nx/nx-sha256.c:	sctx->state[3] = __cpu_to_be32(SHA256_H3);
drivers/crypto/nx/nx-sha256.c:	sctx->state[4] = __cpu_to_be32(SHA256_H4);
drivers/crypto/nx/nx-sha256.c:	sctx->state[5] = __cpu_to_be32(SHA256_H5);
drivers/crypto/nx/nx-sha256.c:	sctx->state[6] = __cpu_to_be32(SHA256_H6);
drivers/crypto/nx/nx-sha256.c:	sctx->state[7] = __cpu_to_be32(SHA256_H7);
drivers/crypto/nx/nx-sha256.c:	sctx->count = 0;
drivers/crypto/nx/nx-sha256.c:	struct nx_csbcpb *csbcpb = (struct nx_csbcpb *)nx_ctx->csbcpb;
drivers/crypto/nx/nx-sha256.c:	u64 buf_len = (sctx->count % SHA256_BLOCK_SIZE);
drivers/crypto/nx/nx-sha256.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha256.c:	total = (sctx->count % SHA256_BLOCK_SIZE) + len;
drivers/crypto/nx/nx-sha256.c:		memcpy(sctx->buf + buf_len, data, len);
drivers/crypto/nx/nx-sha256.c:		sctx->count += len;
drivers/crypto/nx/nx-sha256.c:	memcpy(csbcpb->cpb.sha256.message_digest, sctx->state, SHA256_DIGEST_SIZE);
drivers/crypto/nx/nx-sha256.c:	max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx-sha256.c:			nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-sha256.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, (u8 *)sctx->state,
drivers/crypto/nx/nx-sha256.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha256.c:		struct nx_sg *in_sg = nx_ctx->in_sg;
drivers/crypto/nx/nx-sha256.c:						 (u8 *) sctx->buf,
drivers/crypto/nx/nx-sha256.c:			used_sgs = in_sg - nx_ctx->in_sg;
drivers/crypto/nx/nx-sha256.c:		nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha256.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-sha256.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-sha256.c:		atomic_inc(&(nx_ctx->stats->sha256_ops));
drivers/crypto/nx/nx-sha256.c:		memcpy(sctx->buf, data, leftover);
drivers/crypto/nx/nx-sha256.c:	sctx->count += len;
drivers/crypto/nx/nx-sha256.c:	memcpy(sctx->state, csbcpb->cpb.sha256.message_digest, SHA256_DIGEST_SIZE);
drivers/crypto/nx/nx-sha256.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha256.c:	struct nx_csbcpb *csbcpb = (struct nx_csbcpb *)nx_ctx->csbcpb;
drivers/crypto/nx/nx-sha256.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha256.c:	max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx-sha256.c:			nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-sha256.c:	if (sctx->count >= SHA256_BLOCK_SIZE) {
drivers/crypto/nx/nx-sha256.c:		memcpy(csbcpb->cpb.sha256.input_partial_digest, sctx->state, SHA256_DIGEST_SIZE);
drivers/crypto/nx/nx-sha256.c:	csbcpb->cpb.sha256.message_bit_length = (u64) (sctx->count * 8);
drivers/crypto/nx/nx-sha256.c:	len = sctx->count & (SHA256_BLOCK_SIZE - 1);
drivers/crypto/nx/nx-sha256.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, (u8 *) sctx->buf,
drivers/crypto/nx/nx-sha256.c:	if (len != (sctx->count & (SHA256_BLOCK_SIZE - 1))) {
drivers/crypto/nx/nx-sha256.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, out, &len, max_sg_len);
drivers/crypto/nx/nx-sha256.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha256.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha256.c:	if (!nx_ctx->op.outlen) {
drivers/crypto/nx/nx-sha256.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-sha256.c:	atomic_inc(&(nx_ctx->stats->sha256_ops));
drivers/crypto/nx/nx-sha256.c:	atomic64_add(sctx->count, &(nx_ctx->stats->sha256_bytes));
drivers/crypto/nx/nx-sha256.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-xcbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-xcbc.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-xcbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-xcbc.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, (u8 *) keys, &len,
drivers/crypto/nx/nx-aes-xcbc.c:				 nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, (u8 *) keys, &len,
drivers/crypto/nx/nx-aes-xcbc.c:				  nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-xcbc.c:	atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-xcbc.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, (u8 *) keys[1], &len,
drivers/crypto/nx/nx-aes-xcbc.c:				 nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, out, &len,
drivers/crypto/nx/nx-aes-xcbc.c:				  nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-xcbc.c:	atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-xcbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-xcbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-xcbc.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-xcbc.c:	total = sctx->count + len;
drivers/crypto/nx/nx-aes-xcbc.c:		memcpy(sctx->buffer + sctx->count, data, len);
drivers/crypto/nx/nx-aes-xcbc.c:		sctx->count += len;
drivers/crypto/nx/nx-aes-xcbc.c:	in_sg = nx_ctx->in_sg;
drivers/crypto/nx/nx-aes-xcbc.c:				nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:				nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-aes-xcbc.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, (u8 *)sctx->state,
drivers/crypto/nx/nx-aes-xcbc.c:				  &len, nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:		if (sctx->count) {
drivers/crypto/nx/nx-aes-xcbc.c:			data_len = sctx->count;
drivers/crypto/nx/nx-aes-xcbc.c:			in_sg = nx_build_sg_list(nx_ctx->in_sg,
drivers/crypto/nx/nx-aes-xcbc.c:						(u8 *) sctx->buffer,
drivers/crypto/nx/nx-aes-xcbc.c:			if (data_len != sctx->count) {
drivers/crypto/nx/nx-aes-xcbc.c:		data_len = to_process - sctx->count;
drivers/crypto/nx/nx-aes-xcbc.c:		if (data_len != to_process - sctx->count) {
drivers/crypto/nx/nx-aes-xcbc.c:		nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) *
drivers/crypto/nx/nx-aes-xcbc.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-aes-xcbc.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-xcbc.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-xcbc.c:		data += to_process - sctx->count;
drivers/crypto/nx/nx-aes-xcbc.c:		sctx->count = 0;
drivers/crypto/nx/nx-aes-xcbc.c:		in_sg = nx_ctx->in_sg;
drivers/crypto/nx/nx-aes-xcbc.c:	memcpy(sctx->buffer, data, leftover);
drivers/crypto/nx/nx-aes-xcbc.c:	sctx->count = leftover;
drivers/crypto/nx/nx-aes-xcbc.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-xcbc.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-xcbc.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-xcbc.c:	} else if (sctx->count == 0) {
drivers/crypto/nx/nx-aes-xcbc.c:	len = sctx->count;
drivers/crypto/nx/nx-aes-xcbc.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, (u8 *)sctx->buffer,
drivers/crypto/nx/nx-aes-xcbc.c:				 &len, nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	if (len != sctx->count) {
drivers/crypto/nx/nx-aes-xcbc.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, out, &len,
drivers/crypto/nx/nx-aes-xcbc.c:				  nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-xcbc.c:	if (!nx_ctx->op.outlen) {
drivers/crypto/nx/nx-aes-xcbc.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-xcbc.c:	atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-xcbc.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha512.c:	nx_ctx->ap = &nx_ctx->props[NX_PROPS_SHA512];
drivers/crypto/nx/nx-sha512.c:	NX_CPB_SET_DIGEST_SIZE(nx_ctx->csbcpb, NX_DS_SHA512);
drivers/crypto/nx/nx-sha512.c:	sctx->state[0] = __cpu_to_be64(SHA512_H0);
drivers/crypto/nx/nx-sha512.c:	sctx->state[1] = __cpu_to_be64(SHA512_H1);
drivers/crypto/nx/nx-sha512.c:	sctx->state[2] = __cpu_to_be64(SHA512_H2);
drivers/crypto/nx/nx-sha512.c:	sctx->state[3] = __cpu_to_be64(SHA512_H3);
drivers/crypto/nx/nx-sha512.c:	sctx->state[4] = __cpu_to_be64(SHA512_H4);
drivers/crypto/nx/nx-sha512.c:	sctx->state[5] = __cpu_to_be64(SHA512_H5);
drivers/crypto/nx/nx-sha512.c:	sctx->state[6] = __cpu_to_be64(SHA512_H6);
drivers/crypto/nx/nx-sha512.c:	sctx->state[7] = __cpu_to_be64(SHA512_H7);
drivers/crypto/nx/nx-sha512.c:	sctx->count[0] = 0;
drivers/crypto/nx/nx-sha512.c:	struct nx_csbcpb *csbcpb = (struct nx_csbcpb *)nx_ctx->csbcpb;
drivers/crypto/nx/nx-sha512.c:	u64 buf_len = (sctx->count[0] % SHA512_BLOCK_SIZE);
drivers/crypto/nx/nx-sha512.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha512.c:	total = (sctx->count[0] % SHA512_BLOCK_SIZE) + len;
drivers/crypto/nx/nx-sha512.c:		memcpy(sctx->buf + buf_len, data, len);
drivers/crypto/nx/nx-sha512.c:		sctx->count[0] += len;
drivers/crypto/nx/nx-sha512.c:	memcpy(csbcpb->cpb.sha512.message_digest, sctx->state, SHA512_DIGEST_SIZE);
drivers/crypto/nx/nx-sha512.c:	max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx-sha512.c:			nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-sha512.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, (u8 *)sctx->state,
drivers/crypto/nx/nx-sha512.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha512.c:		struct nx_sg *in_sg = nx_ctx->in_sg;
drivers/crypto/nx/nx-sha512.c:						 (u8 *) sctx->buf,
drivers/crypto/nx/nx-sha512.c:			used_sgs = in_sg - nx_ctx->in_sg;
drivers/crypto/nx/nx-sha512.c:		nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha512.c:		if (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {
drivers/crypto/nx/nx-sha512.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-sha512.c:		atomic_inc(&(nx_ctx->stats->sha512_ops));
drivers/crypto/nx/nx-sha512.c:		memcpy(sctx->buf, data, leftover);
drivers/crypto/nx/nx-sha512.c:	sctx->count[0] += len;
drivers/crypto/nx/nx-sha512.c:	memcpy(sctx->state, csbcpb->cpb.sha512.message_digest, SHA512_DIGEST_SIZE);
drivers/crypto/nx/nx-sha512.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha512.c:	struct nx_csbcpb *csbcpb = (struct nx_csbcpb *)nx_ctx->csbcpb;
drivers/crypto/nx/nx-sha512.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-sha512.c:	max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx-sha512.c:			nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-sha512.c:	if (sctx->count[0] >= SHA512_BLOCK_SIZE) {
drivers/crypto/nx/nx-sha512.c:		memcpy(csbcpb->cpb.sha512.input_partial_digest, sctx->state,
drivers/crypto/nx/nx-sha512.c:	count0 = sctx->count[0] * 8;
drivers/crypto/nx/nx-sha512.c:	len = sctx->count[0] & (SHA512_BLOCK_SIZE - 1);
drivers/crypto/nx/nx-sha512.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, sctx->buf, &len,
drivers/crypto/nx/nx-sha512.c:	if (len != (sctx->count[0] & (SHA512_BLOCK_SIZE - 1))) {
drivers/crypto/nx/nx-sha512.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, out, &len,
drivers/crypto/nx/nx-sha512.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha512.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-sha512.c:	if (!nx_ctx->op.outlen) {
drivers/crypto/nx/nx-sha512.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-sha512.c:	atomic_inc(&(nx_ctx->stats->sha512_ops));
drivers/crypto/nx/nx-sha512.c:	atomic64_add(sctx->count[0], &(nx_ctx->stats->sha512_bytes));
drivers/crypto/nx/nx-sha512.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb_aead = nx_ctx->csbcpb_aead;
drivers/crypto/nx/nx-aes-gcm.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];
drivers/crypto/nx/nx-aes-gcm.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_192];
drivers/crypto/nx/nx-aes-gcm.c:		nx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_256];
drivers/crypto/nx/nx-aes-gcm.c:	char *nonce = nx_ctx->priv.gcm.nonce;
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb_aead = nx_ctx->csbcpb_aead;
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_sg *nx_sg = nx_ctx->in_sg;
drivers/crypto/nx/nx-aes-gcm.c:			   nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-gcm.c:			   nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-aes-gcm.c:				   nx_ctx->ap->databytelen);
drivers/crypto/nx/nx-aes-gcm.c:		nx_sg = nx_walk_and_build(nx_ctx->in_sg, max_sg_len,
drivers/crypto/nx/nx-aes-gcm.c:		nx_ctx->op_aead.inlen = (nx_ctx->in_sg - nx_sg)
drivers/crypto/nx/nx-aes-gcm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op_aead,
drivers/crypto/nx/nx-aes-gcm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-gcm.c:		atomic64_add(assoclen, &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-gcm.c:			   nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-gcm.c:			   nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx-aes-gcm.c:				   nx_ctx->ap->databytelen);
drivers/crypto/nx/nx-aes-gcm.c:		nx_sg = nx_walk_and_build(nx_ctx->in_sg, max_sg_len,
drivers/crypto/nx/nx-aes-gcm.c:		nx_ctx->op.inlen = (nx_ctx->in_sg - nx_sg)
drivers/crypto/nx/nx-aes-gcm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-gcm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-gcm.c:		atomic64_add(assoclen, &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-gcm.c:	in_sg = nx_build_sg_list(nx_ctx->in_sg, (u8 *) desc->info,
drivers/crypto/nx/nx-aes-gcm.c:				 &len, nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-gcm.c:	out_sg = nx_build_sg_list(nx_ctx->out_sg, (u8 *) out, &len,
drivers/crypto/nx/nx-aes-gcm.c:				  nx_ctx->ap->sglen);
drivers/crypto/nx/nx-aes-gcm.c:	nx_ctx->op.inlen = (nx_ctx->in_sg - in_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-gcm.c:	nx_ctx->op.outlen = (nx_ctx->out_sg - out_sg) * sizeof(struct nx_sg);
drivers/crypto/nx/nx-aes-gcm.c:	rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-gcm.c:	atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-gcm.c:	struct nx_csbcpb *csbcpb = nx_ctx->csbcpb;
drivers/crypto/nx/nx-aes-gcm.c:	spin_lock_irqsave(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-gcm.c:	desc.info = rctx->iv;
drivers/crypto/nx/nx-aes-gcm.c:		rc = nx_hcall_sync(nx_ctx, &nx_ctx->op,
drivers/crypto/nx/nx-aes-gcm.c:		atomic_inc(&(nx_ctx->stats->aes_ops));
drivers/crypto/nx/nx-aes-gcm.c:			     &(nx_ctx->stats->aes_bytes));
drivers/crypto/nx/nx-aes-gcm.c:		u8 *itag = nx_ctx->priv.gcm.iauth_tag;
drivers/crypto/nx/nx-aes-gcm.c:	spin_unlock_irqrestore(&nx_ctx->lock, irq_flags);
drivers/crypto/nx/nx-aes-gcm.c:	char *iv = rctx->iv;
drivers/crypto/nx/nx-aes-gcm.c:	char *iv = rctx->iv;
drivers/crypto/nx/nx-aes-gcm.c:	char *iv = rctx->iv;
drivers/crypto/nx/nx-aes-gcm.c:	char *nonce = nx_ctx->priv.gcm.nonce;
drivers/crypto/nx/nx-aes-gcm.c:	char *iv = rctx->iv;
drivers/crypto/nx/nx-aes-gcm.c:	char *nonce = nx_ctx->priv.gcm.nonce;
drivers/crypto/nx/nx-842.c:	spin_lock_init(&ctx->lock);
drivers/crypto/nx/nx-842.c:	ctx->driver = driver;
drivers/crypto/nx/nx-842.c:	ctx->wmem = kmalloc(driver->workmem_size, GFP_KERNEL);
drivers/crypto/nx/nx-842.c:	ctx->sbounce = (u8 *)__get_free_pages(GFP_KERNEL, BOUNCE_BUFFER_ORDER);
drivers/crypto/nx/nx-842.c:	ctx->dbounce = (u8 *)__get_free_pages(GFP_KERNEL, BOUNCE_BUFFER_ORDER);
drivers/crypto/nx/nx-842.c:	if (!ctx->wmem || !ctx->sbounce || !ctx->dbounce) {
drivers/crypto/nx/nx-842.c:		kfree(ctx->wmem);
drivers/crypto/nx/nx-842.c:		free_page((unsigned long)ctx->sbounce);
drivers/crypto/nx/nx-842.c:		free_page((unsigned long)ctx->dbounce);
drivers/crypto/nx/nx-842.c:	kfree(ctx->wmem);
drivers/crypto/nx/nx-842.c:	free_page((unsigned long)ctx->sbounce);
drivers/crypto/nx/nx-842.c:	free_page((unsigned long)ctx->dbounce);
drivers/crypto/nx/nx-842.c:			memset(ctx->sbounce + slen, 0, adj_slen - slen);
drivers/crypto/nx/nx-842.c:		memcpy(ctx->sbounce, src, slen);
drivers/crypto/nx/nx-842.c:		src = ctx->sbounce;
drivers/crypto/nx/nx-842.c:		dst = ctx->dbounce;
drivers/crypto/nx/nx-842.c:		ret = ctx->driver->compress(src, slen, dst, &dlen, ctx->wmem);
drivers/crypto/nx/nx-842.c:		if (ret == -ENOSPC && dst != ctx->dbounce)
drivers/crypto/nx/nx-842.c:	if (dst == ctx->dbounce)
drivers/crypto/nx/nx-842.c:	struct nx842_crypto_header *hdr = &ctx->header;
drivers/crypto/nx/nx-842.c:	struct nx842_constraints c = *ctx->driver->constraints;
drivers/crypto/nx/nx-842.c:	spin_lock_bh(&ctx->lock);
drivers/crypto/nx/nx-842.c:	spin_unlock_bh(&ctx->lock);
drivers/crypto/nx/nx-842.c:			memset(ctx->sbounce + slen, 0, adj_slen - slen);
drivers/crypto/nx/nx-842.c:		memcpy(ctx->sbounce, src, slen);
drivers/crypto/nx/nx-842.c:		src = ctx->sbounce;
drivers/crypto/nx/nx-842.c:		dst = ctx->dbounce;
drivers/crypto/nx/nx-842.c:		ret = ctx->driver->decompress(src, slen, dst, &dlen, ctx->wmem);
drivers/crypto/nx/nx-842.c:			dst = ctx->dbounce;
drivers/crypto/nx/nx-842.c:	if (dst == ctx->dbounce)
drivers/crypto/nx/nx-842.c:	struct nx842_constraints c = *ctx->driver->constraints;
drivers/crypto/nx/nx-842.c:	spin_lock_bh(&ctx->lock);
drivers/crypto/nx/nx-842.c:	memcpy(&ctx->header, src, hdr_len);
drivers/crypto/nx/nx-842.c:	hdr = &ctx->header;
drivers/crypto/nx/nx-842.c:	spin_unlock_bh(&ctx->lock);
drivers/crypto/nx/nx.c:	atomic_inc(&(nx_ctx->stats->sync_ops));
drivers/crypto/nx/nx.c:		atomic_inc(&(nx_ctx->stats->errors));
drivers/crypto/nx/nx.c:		atomic_set(&(nx_ctx->stats->last_error), op->hcall_err);
drivers/crypto/nx/nx.c:		atomic_set(&(nx_ctx->stats->last_error_pid), current->pid);
drivers/crypto/nx/nx.c:	struct nx_sg *nx_insg = nx_ctx->in_sg;
drivers/crypto/nx/nx.c:	struct nx_sg *nx_outsg = nx_ctx->out_sg;
drivers/crypto/nx/nx.c:	max_sg_len = min_t(u64, nx_ctx->ap->sglen,
drivers/crypto/nx/nx.c:			nx_ctx->ap->databytelen/NX_PAGE_SIZE);
drivers/crypto/nx/nx.c:	*nbytes = min_t(u64, *nbytes, nx_ctx->ap->databytelen);
drivers/crypto/nx/nx.c:	nx_ctx->op.inlen = trim_sg_list(nx_ctx->in_sg, nx_insg, delta, nbytes);
drivers/crypto/nx/nx.c:	nx_ctx->op.outlen = trim_sg_list(nx_ctx->out_sg, nx_outsg, delta, nbytes);
drivers/crypto/nx/nx.c:	spin_lock_init(&nx_ctx->lock);
drivers/crypto/nx/nx.c:	memset(nx_ctx->kmem, 0, nx_ctx->kmem_len);
drivers/crypto/nx/nx.c:	nx_ctx->csbcpb->csb.valid |= NX_CSB_VALID_BIT;
drivers/crypto/nx/nx.c:	nx_ctx->op.flags = function;
drivers/crypto/nx/nx.c:	nx_ctx->op.csbcpb = __pa(nx_ctx->csbcpb);
drivers/crypto/nx/nx.c:	nx_ctx->op.in = __pa(nx_ctx->in_sg);
drivers/crypto/nx/nx.c:	nx_ctx->op.out = __pa(nx_ctx->out_sg);
drivers/crypto/nx/nx.c:	if (nx_ctx->csbcpb_aead) {
drivers/crypto/nx/nx.c:		nx_ctx->csbcpb_aead->csb.valid |= NX_CSB_VALID_BIT;
drivers/crypto/nx/nx.c:		nx_ctx->op_aead.flags = function;
drivers/crypto/nx/nx.c:		nx_ctx->op_aead.csbcpb = __pa(nx_ctx->csbcpb_aead);
drivers/crypto/nx/nx.c:		nx_ctx->op_aead.in = __pa(nx_ctx->in_sg);
drivers/crypto/nx/nx.c:		nx_ctx->op_aead.out = __pa(nx_ctx->out_sg);
drivers/crypto/nx/nx.c:		nx_ctx->kmem_len = (5 * NX_PAGE_SIZE) +
drivers/crypto/nx/nx.c:		nx_ctx->kmem_len = (4 * NX_PAGE_SIZE) +
drivers/crypto/nx/nx.c:	nx_ctx->kmem = kmalloc(nx_ctx->kmem_len, GFP_KERNEL);
drivers/crypto/nx/nx.c:	if (!nx_ctx->kmem)
drivers/crypto/nx/nx.c:	nx_ctx->csbcpb = (struct nx_csbcpb *)(round_up((u64)nx_ctx->kmem,
drivers/crypto/nx/nx.c:	nx_ctx->in_sg = (struct nx_sg *)((u8 *)nx_ctx->csbcpb + NX_PAGE_SIZE);
drivers/crypto/nx/nx.c:	nx_ctx->out_sg = (struct nx_sg *)((u8 *)nx_ctx->in_sg + NX_PAGE_SIZE);
drivers/crypto/nx/nx.c:		nx_ctx->csbcpb_aead =
drivers/crypto/nx/nx.c:			(struct nx_csbcpb *)((u8 *)nx_ctx->out_sg +
drivers/crypto/nx/nx.c:	nx_ctx->stats = &nx_driver.stats;
drivers/crypto/nx/nx.c:	memcpy(nx_ctx->props, nx_driver.of.ap[fc][mode],
drivers/crypto/nx/nx.c:	kzfree(nx_ctx->kmem);
drivers/crypto/nx/nx.c:	nx_ctx->csbcpb = NULL;
drivers/crypto/nx/nx.c:	nx_ctx->csbcpb_aead = NULL;
drivers/crypto/nx/nx.c:	nx_ctx->in_sg = NULL;
drivers/crypto/nx/nx.c:	nx_ctx->out_sg = NULL;
drivers/crypto/nx/nx.c:	kzfree(nx_ctx->kmem);
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	octx->byte_count = op->byte_count + op->len;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	memcpy(octx->block, op->buf, op->len);
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:			octx->hash[i] = op->hash[i];
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->hash[0] = SHA1_H0;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->hash[1] = SHA1_H1;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->hash[2] = SHA1_H2;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->hash[3] = SHA1_H3;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	op->byte_count = ictx->byte_count & ~0x3F;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	op->len = ictx->byte_count & 0x3F;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	memcpy(op->buf, ictx->block, op->len);
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		op->hash[i] = ictx->hash[i];
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	octx->count = op->byte_count + op->len;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	memcpy(octx->buffer, op->buf, op->len);
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:			octx->state[i] = op->hash[i];
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->state[0] = SHA1_H0;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->state[1] = SHA1_H1;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->state[2] = SHA1_H2;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->state[3] = SHA1_H3;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		octx->state[4] = SHA1_H4;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	op->byte_count = ictx->count & ~0x3F;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	op->len = ictx->count & 0x3F;
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	memcpy(op->buf, ictx->buffer, op->len);
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:		op->hash[i] = ictx->state[i];
drivers/crypto/sunxi-ss/sun4i-ss-hash.c:	struct sun4i_ss_ctx *ss = tfmctx->ss;
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	u32 mode = ctx->mode;
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	u32 mode = ctx->mode;
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_AES | SS_CBC | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_AES | SS_CBC | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_AES | SS_ECB | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_AES | SS_ECB | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_DES | SS_CBC | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_DES | SS_CBC | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_DES | SS_ECB | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_DES | SS_ECB | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_3DES | SS_CBC | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_3DES | SS_CBC | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_3DES | SS_ECB | SS_ENABLED | SS_ENCRYPTION |
drivers/crypto/sunxi-ss/sun4i-ss-cipher.c:	rctx->mode = SS_OP_3DES | SS_ECB | SS_ENABLED | SS_DECRYPTION |
drivers/crypto/amcc/crypto4xx_core.h:	void *sa_va;		/* shadow sa, when using cp from ctx->sa */
drivers/crypto/amcc/crypto4xx_reg_def.h:	u32 sa;                 /* get from ctx->sa_dma_addr */
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_OUTBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->pd_ctl = 0x1;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->pd_ctl = 1;
drivers/crypto/amcc/crypto4xx_alg.c:	if (ctx->sa_in_dma_addr || ctx->sa_out_dma_addr)
drivers/crypto/amcc/crypto4xx_alg.c:	if (ctx->state_record_dma_addr == 0) {
drivers/crypto/amcc/crypto4xx_alg.c:	sa = (struct dynamic_sa_ctl *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	crypto4xx_memcpy_le(ctx->sa_in + get_dynamic_sa_offset_key_field(ctx),
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	memcpy(ctx->sa_in + get_dynamic_sa_offset_state_ptr_field(ctx),
drivers/crypto/amcc/crypto4xx_alg.c:			(void *)&ctx->state_record_dma_addr, 4);
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->offset_to_sr_ptr = get_dynamic_sa_offset_state_ptr_field(ctx);
drivers/crypto/amcc/crypto4xx_alg.c:	memcpy(ctx->sa_out, ctx->sa_in, ctx->sa_len * 4);
drivers/crypto/amcc/crypto4xx_alg.c:	sa = (struct dynamic_sa_ctl *) ctx->sa_out;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->dev   = my_alg->dev;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 1;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	if (ctx->sa_in_dma_addr || ctx->sa_out_dma_addr)
drivers/crypto/amcc/crypto4xx_alg.c:	if (ctx->state_record_dma_addr == 0) {
drivers/crypto/amcc/crypto4xx_alg.c:		if (!ctx->state_record_dma_addr) {
drivers/crypto/amcc/crypto4xx_alg.c:	sa = (struct dynamic_sa_ctl *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	sa_in = (struct dynamic_sa_hash160 *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_alg.c:	sa_in->state_ptr = ctx->state_record_dma_addr;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->offset_to_sr_ptr = get_dynamic_sa_offset_state_ptr_field(ctx);
drivers/crypto/amcc/crypto4xx_alg.c:	sa = (struct dynamic_sa_ctl *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 1;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->is_hash = 1;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 0;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->pd_ctl = 0x11;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->hash_final = 1;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->pd_ctl = 0x11;
drivers/crypto/amcc/crypto4xx_alg.c:	ctx->direction = DIR_INBOUND;
drivers/crypto/amcc/crypto4xx_sa.c:	if (ctx->direction == DIR_INBOUND)
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_in)->sa_contents;
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_out)->sa_contents;
drivers/crypto/amcc/crypto4xx_sa.c:	if (ctx->direction == DIR_INBOUND)
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_in)->sa_contents;
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_out)->sa_contents;
drivers/crypto/amcc/crypto4xx_sa.c:	if (ctx->direction == DIR_INBOUND)
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_in)->sa_contents;
drivers/crypto/amcc/crypto4xx_sa.c:		cts.w = ((struct dynamic_sa_ctl *) ctx->sa_out)->sa_contents;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_in = dma_alloc_coherent(ctx->dev->core_dev->device, size * 4,
drivers/crypto/amcc/crypto4xx_core.c:					&ctx->sa_in_dma_addr, GFP_ATOMIC);
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->sa_in == NULL)
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_out = dma_alloc_coherent(ctx->dev->core_dev->device, size * 4,
drivers/crypto/amcc/crypto4xx_core.c:					 &ctx->sa_out_dma_addr, GFP_ATOMIC);
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->sa_out == NULL) {
drivers/crypto/amcc/crypto4xx_core.c:		dma_free_coherent(ctx->dev->core_dev->device,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->sa_len * 4,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->sa_in, ctx->sa_in_dma_addr);
drivers/crypto/amcc/crypto4xx_core.c:	memset(ctx->sa_in, 0, size * 4);
drivers/crypto/amcc/crypto4xx_core.c:	memset(ctx->sa_out, 0, size * 4);
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_len = size;
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->sa_in != NULL)
drivers/crypto/amcc/crypto4xx_core.c:		dma_free_coherent(ctx->dev->core_dev->device, ctx->sa_len * 4,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->sa_in, ctx->sa_in_dma_addr);
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->sa_out != NULL)
drivers/crypto/amcc/crypto4xx_core.c:		dma_free_coherent(ctx->dev->core_dev->device, ctx->sa_len * 4,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->sa_out, ctx->sa_out_dma_addr);
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_in_dma_addr = 0;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_out_dma_addr = 0;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_len = 0;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->state_record = dma_alloc_coherent(ctx->dev->core_dev->device,
drivers/crypto/amcc/crypto4xx_core.c:				&ctx->state_record_dma_addr, GFP_ATOMIC);
drivers/crypto/amcc/crypto4xx_core.c:	if (!ctx->state_record_dma_addr)
drivers/crypto/amcc/crypto4xx_core.c:	memset(ctx->state_record, 0, sizeof(struct sa_state_record));
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->state_record != NULL)
drivers/crypto/amcc/crypto4xx_core.c:		dma_free_coherent(ctx->dev->core_dev->device,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->state_record,
drivers/crypto/amcc/crypto4xx_core.c:				  ctx->state_record_dma_addr);
drivers/crypto/amcc/crypto4xx_core.c:	ctx->state_record_dma_addr = 0;
drivers/crypto/amcc/crypto4xx_core.c:	struct dynamic_sa_ctl *sa = (struct dynamic_sa_ctl *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_core.c:	struct crypto4xx_device *dev = ctx->dev;
drivers/crypto/amcc/crypto4xx_core.c:	if (sg_is_last(dst) || ctx->is_hash) {
drivers/crypto/amcc/crypto4xx_core.c:	if (iv_len || ctx->is_hash) {
drivers/crypto/amcc/crypto4xx_core.c:		if (ctx->direction == DIR_INBOUND)
drivers/crypto/amcc/crypto4xx_core.c:			memcpy(sa, ctx->sa_in, ctx->sa_len * 4);
drivers/crypto/amcc/crypto4xx_core.c:			memcpy(sa, ctx->sa_out, ctx->sa_len * 4);
drivers/crypto/amcc/crypto4xx_core.c:		memcpy((void *) sa + ctx->offset_to_sr_ptr,
drivers/crypto/amcc/crypto4xx_core.c:		if (ctx->direction == DIR_INBOUND) {
drivers/crypto/amcc/crypto4xx_core.c:			pd->sa = ctx->sa_in_dma_addr;
drivers/crypto/amcc/crypto4xx_core.c:			sa = (struct dynamic_sa_ctl *) ctx->sa_in;
drivers/crypto/amcc/crypto4xx_core.c:			pd->sa = ctx->sa_out_dma_addr;
drivers/crypto/amcc/crypto4xx_core.c:			sa = (struct dynamic_sa_ctl *) ctx->sa_out;
drivers/crypto/amcc/crypto4xx_core.c:	pd->sa_len = ctx->sa_len;
drivers/crypto/amcc/crypto4xx_core.c:	if (ctx->is_hash || sg_is_last(dst)) {
drivers/crypto/amcc/crypto4xx_core.c:		if (ctx->is_hash)
drivers/crypto/amcc/crypto4xx_core.c:	pd->pd_ctl.w = ctx->pd_ctl;
drivers/crypto/amcc/crypto4xx_core.c:	pd->pd_ctl_len.w = 0x00400000 | (ctx->bypass << 24) | datalen;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->dev = amcc_alg->dev;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_in = NULL;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_out = NULL;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_in_dma_addr = 0;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_out_dma_addr = 0;
drivers/crypto/amcc/crypto4xx_core.c:	ctx->sa_len = 0;
drivers/crypto/marvell/tdma.c:			res = ctx->ops->process(req, current_status);
drivers/crypto/marvell/tdma.c:			ctx->ops->complete(req);
drivers/crypto/marvell/hash.c:	ctx->base.ops = &mv_cesa_ahash_req_ops;
drivers/crypto/marvell/hash.c:	ctx->base.ops = &mv_cesa_ahash_req_ops;
drivers/crypto/marvell/hash.c:	memcpy(tmpl.ctx.hash.iv, ctx->iv, sizeof(ctx->iv));
drivers/crypto/marvell/hash.c:		ctx->iv[i] = be32_to_cpu(istate.hash[i]);
drivers/crypto/marvell/hash.c:		ctx->iv[i + 8] = be32_to_cpu(ostate.hash[i]);
drivers/crypto/marvell/hash.c:	memcpy(tmpl.ctx.hash.iv, ctx->iv, sizeof(ctx->iv));
drivers/crypto/marvell/hash.c:		ctx->iv[i] = be32_to_cpu(istate.state[i]);
drivers/crypto/marvell/hash.c:		ctx->iv[i + 8] = be32_to_cpu(ostate.state[i]);
drivers/crypto/marvell/hash.c:		ctx->iv[i] = be32_to_cpu(istate.state[i]);
drivers/crypto/marvell/hash.c:		ctx->iv[i + 8] = be32_to_cpu(ostate.state[i]);
drivers/crypto/marvell/hash.c:	memcpy(tmpl.ctx.hash.iv, ctx->iv, sizeof(ctx->iv));
drivers/crypto/marvell/cipher.c:	ctx->base.ops = &mv_cesa_ablkcipher_req_ops;
drivers/crypto/marvell/cipher.c:	ret = crypto_aes_expand_key(&ctx->aes, key, len);
drivers/crypto/marvell/cipher.c:	remaining = (ctx->aes.key_length - 16) / 4;
drivers/crypto/marvell/cipher.c:	offset = ctx->aes.key_length + 24 - remaining;
drivers/crypto/marvell/cipher.c:		ctx->aes.key_dec[4 + i] =
drivers/crypto/marvell/cipher.c:			cpu_to_le32(ctx->aes.key_enc[offset + i]);
drivers/crypto/marvell/cipher.c:	memcpy(ctx->key, key, DES_KEY_SIZE);
drivers/crypto/marvell/cipher.c:	memcpy(ctx->key, key, DES3_EDE_KEY_SIZE);
drivers/crypto/marvell/cipher.c:	memcpy(tmpl->ctx.blkcipher.key, ctx->key, DES_KEY_SIZE);
drivers/crypto/marvell/cipher.c:	memcpy(tmpl->ctx.blkcipher.key, ctx->key, DES3_EDE_KEY_SIZE);
drivers/crypto/marvell/cipher.c:		key = ctx->aes.key_dec;
drivers/crypto/marvell/cipher.c:		key = ctx->aes.key_enc;
drivers/crypto/marvell/cipher.c:	for (i = 0; i < ctx->aes.key_length / sizeof(u32); i++)
drivers/crypto/marvell/cipher.c:	if (ctx->aes.key_length == 24)
drivers/crypto/marvell/cipher.c:	else if (ctx->aes.key_length == 32)
drivers/crypto/marvell/cesa.c:	ctx->ops->step(req);
drivers/crypto/marvell/cesa.c:	res = ctx->ops->process(req, status);
drivers/crypto/marvell/cesa.c:		ctx->ops->complete(req);
drivers/crypto/marvell/cesa.c:		ctx->ops->step(req);
drivers/crypto/marvell/cesa.c:	ctx->ops->cleanup(req);
drivers/crypto/n2_core.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	return crypto_ahash_init(&rctx->fallback_req);
drivers/crypto/n2_core.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:	rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:	return crypto_ahash_update(&rctx->fallback_req);
drivers/crypto/n2_core.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:	return crypto_ahash_final(&rctx->fallback_req);
drivers/crypto/n2_core.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:	rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:	rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:	return crypto_ahash_finup(&rctx->fallback_req);
drivers/crypto/n2_core.c:	ctx->fallback_tfm = fallback_tfm;
drivers/crypto/n2_core.c:	crypto_free_ahash(ctx->fallback_tfm);
drivers/crypto/n2_core.c:	ctx->child_shash = child_shash;
drivers/crypto/n2_core.c:	ctx->base.fallback_tfm = fallback_tfm;
drivers/crypto/n2_core.c:	crypto_free_ahash(ctx->base.fallback_tfm);
drivers/crypto/n2_core.c:	crypto_free_shash(ctx->child_shash);
drivers/crypto/n2_core.c:	struct crypto_shash *child_shash = ctx->child_shash;
drivers/crypto/n2_core.c:	fallback_tfm = ctx->base.fallback_tfm;
drivers/crypto/n2_core.c:					  ctx->hash_key);
drivers/crypto/n2_core.c:		memcpy(ctx->hash_key, key, keylen);
drivers/crypto/n2_core.c:	ctx->hash_key_len = keylen;
drivers/crypto/n2_core.c:		ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:		rctx->fallback_req.base.flags =
drivers/crypto/n2_core.c:		rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:		rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:		rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:		return crypto_ahash_digest(&rctx->fallback_req);
drivers/crypto/n2_core.c:	memcpy(&rctx->u, n2alg->hash_init, n2alg->hw_op_hashsz);
drivers/crypto/n2_core.c:				  &rctx->u, 0UL, 0);
drivers/crypto/n2_core.c:	    unlikely(ctx->hash_key_len > N2_HASH_KEY_MAX)) {
drivers/crypto/n2_core.c:		ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/n2_core.c:		rctx->fallback_req.base.flags =
drivers/crypto/n2_core.c:		rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:		rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:		rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:		return crypto_ahash_digest(&rctx->fallback_req);
drivers/crypto/n2_core.c:	memcpy(&rctx->u, n2alg->derived.hash_init,
drivers/crypto/n2_core.c:				  &rctx->u,
drivers/crypto/n2_core.c:				  __pa(&ctx->hash_key),
drivers/crypto/n2_core.c:				  ctx->hash_key_len);
drivers/crypto/n2_core.c:	ctx->enc_type = (n2alg->enc_type & ENC_TYPE_CHAINING_MASK);
drivers/crypto/n2_core.c:		ctx->enc_type |= ENC_TYPE_ALG_AES128;
drivers/crypto/n2_core.c:		ctx->enc_type |= ENC_TYPE_ALG_AES192;
drivers/crypto/n2_core.c:		ctx->enc_type |= ENC_TYPE_ALG_AES256;
drivers/crypto/n2_core.c:	ctx->key_len = keylen;
drivers/crypto/n2_core.c:	memcpy(ctx->key.aes, key, keylen);
drivers/crypto/n2_core.c:	ctx->enc_type = n2alg->enc_type;
drivers/crypto/n2_core.c:	ctx->key_len = keylen;
drivers/crypto/n2_core.c:	memcpy(ctx->key.des, key, keylen);
drivers/crypto/n2_core.c:	ctx->enc_type = n2alg->enc_type;
drivers/crypto/n2_core.c:	ctx->key_len = keylen;
drivers/crypto/n2_core.c:	memcpy(ctx->key.des3, key, keylen);
drivers/crypto/n2_core.c:	u8 *s = ctx->key.arc4;
drivers/crypto/n2_core.c:	ctx->enc_type = n2alg->enc_type;
drivers/crypto/n2_core.c:					 0, ctx->enc_type, 0, 0,
drivers/crypto/n2_core.c:	ent->enc_key_addr = __pa(&ctx->key);
drivers/crypto/n2_core.c:	struct ablkcipher_walk *walk = &rctx->walk;
drivers/crypto/n2_core.c:	INIT_LIST_HEAD(&rctx->chunk_list);
drivers/crypto/n2_core.c:	chunk = &rctx->chunk;
drivers/crypto/n2_core.c:					      &rctx->chunk_list);
drivers/crypto/n2_core.c:		list_add_tail(&chunk->entry, &rctx->chunk_list);
drivers/crypto/n2_core.c:		memcpy(rctx->walk.iv, final_iv, rctx->walk.blocksize);
drivers/crypto/n2_core.c:	ablkcipher_walk_complete(&rctx->walk);
drivers/crypto/n2_core.c:	list_for_each_entry_safe(c, tmp, &rctx->chunk_list, entry) {
drivers/crypto/n2_core.c:		if (unlikely(c != &rctx->chunk))
drivers/crypto/n2_core.c:	list_for_each_entry_safe(c, tmp, &rctx->chunk_list, entry) {
drivers/crypto/n2_core.c:		if (unlikely(c != &rctx->chunk))
drivers/crypto/n2_core.c:		iv_paddr = __pa(rctx->walk.iv);
drivers/crypto/n2_core.c:		list_for_each_entry_safe(c, tmp, &rctx->chunk_list,
drivers/crypto/n2_core.c:			iv_paddr = c->dest_final - rctx->walk.blocksize;
drivers/crypto/n2_core.c:			if (unlikely(c != &rctx->chunk))
drivers/crypto/n2_core.c:		list_for_each_entry_safe_reverse(c, tmp, &rctx->chunk_list,
drivers/crypto/n2_core.c:			if (c == &rctx->chunk) {
drivers/crypto/n2_core.c:				iv_paddr = __pa(rctx->walk.iv);
drivers/crypto/n2_core.c:					    rctx->walk.blocksize);
drivers/crypto/n2_core.c:				      rctx->walk.blocksize);
drivers/crypto/n2_core.c:				final_iv_addr = rctx->temp_iv;
drivers/crypto/n2_core.c:				memcpy(rctx->temp_iv, __va(pa),
drivers/crypto/n2_core.c:				       rctx->walk.blocksize);
drivers/crypto/n2_core.c:			if (unlikely(c != &rctx->chunk))
drivers/crypto/chelsio/chcr_algo.c:	return ctx->crypto_ctx->ablkctx;
drivers/crypto/chelsio/chcr_algo.c:	return ctx->crypto_ctx->hmacctx;
drivers/crypto/chelsio/chcr_algo.c:	return ctx->dev->u_ctx;
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(&u_ctx->lldi.pdev->dev, ctx_req.req.ablk_req->dst,
drivers/crypto/chelsio/chcr_algo.c:		if (ctx_req.ctx.ablk_ctx->skb) {
drivers/crypto/chelsio/chcr_algo.c:			kfree_skb(ctx_req.ctx.ablk_ctx->skb);
drivers/crypto/chelsio/chcr_algo.c:			ctx_req.ctx.ablk_ctx->skb = NULL;
drivers/crypto/chelsio/chcr_algo.c:		if (ctx_req.ctx.ahash_ctx->skb)
drivers/crypto/chelsio/chcr_algo.c:			ctx_req.ctx.ahash_ctx->skb = NULL;
drivers/crypto/chelsio/chcr_algo.c:		if (ctx_req.ctx.ahash_ctx->result == 1) {
drivers/crypto/chelsio/chcr_algo.c:			ctx_req.ctx.ahash_ctx->result = 0;
drivers/crypto/chelsio/chcr_algo.c:			memcpy(ctx_req.ctx.ahash_ctx->partial_hash, input +
drivers/crypto/chelsio/chcr_algo.c:		kfree(ctx_req.ctx.ahash_ctx->dummy_payload_ptr);
drivers/crypto/chelsio/chcr_algo.c:		ctx_req.ctx.ahash_ctx->dummy_payload_ptr = NULL;
drivers/crypto/chelsio/chcr_algo.c:	if (ablkctx->ciph_mode == CHCR_SCMD_CIPHER_MODE_AES_CBC) {
drivers/crypto/chelsio/chcr_algo.c:		get_aes_decrypt_key(key_ctx->key, ablkctx->key,
drivers/crypto/chelsio/chcr_algo.c:				    ablkctx->enckey_len << 3);
drivers/crypto/chelsio/chcr_algo.c:		memset(key_ctx->key + ablkctx->enckey_len, 0,
drivers/crypto/chelsio/chcr_algo.c:		       CHCR_AES_MAX_KEY_LEN - ablkctx->enckey_len);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(key_ctx->key,
drivers/crypto/chelsio/chcr_algo.c:		       ablkctx->key + (ablkctx->enckey_len >> 1),
drivers/crypto/chelsio/chcr_algo.c:		       ablkctx->enckey_len >> 1);
drivers/crypto/chelsio/chcr_algo.c:		get_aes_decrypt_key(key_ctx->key + (ablkctx->enckey_len >> 1),
drivers/crypto/chelsio/chcr_algo.c:				    ablkctx->key, ablkctx->enckey_len << 2);
drivers/crypto/chelsio/chcr_algo.c:	int qid = u_ctx->lldi.rxq_ids[ctx->tx_channel_id];
drivers/crypto/chelsio/chcr_algo.c:		FILL_WR_RX_Q_ID(ctx->dev->tx_channel_id, qid,
drivers/crypto/chelsio/chcr_algo.c:	ulptx->cmd_dest = FILL_ULPTX_CMD_DEST(ctx->dev->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->dst_nents = ch_nents(req->dst, &dst_bufsize);
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->enc = op_type;
drivers/crypto/chelsio/chcr_algo.c:	if ((ablkctx->enckey_len == 0) || (ivsize > AES_BLOCK_SIZE) ||
drivers/crypto/chelsio/chcr_algo.c:	phys_dsgl = get_space_for_phys_dsgl(ablkctx->dst_nents);
drivers/crypto/chelsio/chcr_algo.c:		(DIV_ROUND_UP(ablkctx->enckey_len, 16) * 16);
drivers/crypto/chelsio/chcr_algo.c:		FILL_SEC_CPL_OP_IVINSR(ctx->dev->tx_channel_id, 2, 1, 1);
drivers/crypto/chelsio/chcr_algo.c:							 ablkctx->ciph_mode,
drivers/crypto/chelsio/chcr_algo.c:	key_ctx->ctx_hdr = ablkctx->key_ctx_hdr;
drivers/crypto/chelsio/chcr_algo.c:		if (ablkctx->ciph_mode == CHCR_SCMD_CIPHER_MODE_AES_CBC) {
drivers/crypto/chelsio/chcr_algo.c:			memcpy(key_ctx->key, ablkctx->key, ablkctx->enckey_len);
drivers/crypto/chelsio/chcr_algo.c:			memcpy(key_ctx->key, ablkctx->key +
drivers/crypto/chelsio/chcr_algo.c:			       (ablkctx->enckey_len >> 1),
drivers/crypto/chelsio/chcr_algo.c:			       ablkctx->enckey_len >> 1);
drivers/crypto/chelsio/chcr_algo.c:			memcpy(key_ctx->key +
drivers/crypto/chelsio/chcr_algo.c:			       (ablkctx->enckey_len >> 1),
drivers/crypto/chelsio/chcr_algo.c:			       ablkctx->key,
drivers/crypto/chelsio/chcr_algo.c:			       ablkctx->enckey_len >> 1);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(ablkctx->iv, req->info, ivsize);
drivers/crypto/chelsio/chcr_algo.c:	sg_init_table(&ablkctx->iv_sg, 1);
drivers/crypto/chelsio/chcr_algo.c:	sg_set_buf(&ablkctx->iv_sg, ablkctx->iv, ivsize);
drivers/crypto/chelsio/chcr_algo.c:	sg_param.nents = ablkctx->dst_nents;
drivers/crypto/chelsio/chcr_algo.c:	if (map_writesg_phys_cpl(&u_ctx->lldi.pdev->dev, phys_cpl, req->dst,
drivers/crypto/chelsio/chcr_algo.c:	write_sg_data_page_desc(skb, &frags, &ablkctx->iv_sg, ivsize);
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->skb = skb;
drivers/crypto/chelsio/chcr_algo.c:	memcpy(ablkctx->key, key, keylen);
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->enckey_len = keylen;
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->key_ctx_hdr = FILL_KEY_CTX_HDR(ck_size, CHCR_KEYCTX_NO_KEY,
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->ciph_mode = CHCR_SCMD_CIPHER_MODE_AES_CBC;
drivers/crypto/chelsio/chcr_algo.c:	ablkctx->enckey_len = 0;
drivers/crypto/chelsio/chcr_algo.c:	if (unlikely(cxgb4_is_crypto_q_full(u_ctx->lldi.ports[0],
drivers/crypto/chelsio/chcr_algo.c:					    ctx->tx_channel_id))) {
drivers/crypto/chelsio/chcr_algo.c:			       u_ctx->lldi.rxq_ids[ctx->tx_channel_id],
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	if (unlikely(cxgb4_is_crypto_q_full(u_ctx->lldi.ports[0],
drivers/crypto/chelsio/chcr_algo.c:					    ctx->tx_channel_id))) {
drivers/crypto/chelsio/chcr_algo.c:	skb = create_cipher_wr(req_base, ctx, u_ctx->lldi.rxq_ids[0],
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	if (!ctx->dev) {
drivers/crypto/chelsio/chcr_algo.c:		err = assign_chcr_device(&ctx->dev);
drivers/crypto/chelsio/chcr_algo.c:		rxq_perchan = u_ctx->lldi.nrxq / u_ctx->lldi.nchan;
drivers/crypto/chelsio/chcr_algo.c:		ctx->dev->tx_channel_id = 0;
drivers/crypto/chelsio/chcr_algo.c:		rxq_idx = ctx->dev->tx_channel_id * rxq_perchan;
drivers/crypto/chelsio/chcr_algo.c:		spin_lock(&ctx->dev->lock_chcr_dev);
drivers/crypto/chelsio/chcr_algo.c:		ctx->tx_channel_id = rxq_idx;
drivers/crypto/chelsio/chcr_algo.c:		spin_unlock(&ctx->dev->lock_chcr_dev);
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->dummy_payload_ptr = page_ptr;
drivers/crypto/chelsio/chcr_algo.c:	if (req_ctx->result)
drivers/crypto/chelsio/chcr_algo.c:		FILL_SEC_CPL_OP_IVINSR(ctx->dev->tx_channel_id, 2, 0, 0);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(key_ctx->key, req_ctx->partial_hash, param->alg_prm.result_size);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(key_ctx->key + ((param->alg_prm.result_size <= 32) ? 32 :
drivers/crypto/chelsio/chcr_algo.c:		       hmacctx->opad, param->alg_prm.result_size);
drivers/crypto/chelsio/chcr_algo.c:	key_ctx->ctx_hdr = FILL_KEY_CTX_HDR(CHCR_KEYCTX_NO_KEY,
drivers/crypto/chelsio/chcr_algo.c:		write_buffer_data_page_desc(req_ctx, skb, &frags, req_ctx->bfr,
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->skb = skb;
drivers/crypto/chelsio/chcr_algo.c:	if (unlikely(cxgb4_is_crypto_q_full(u_ctx->lldi.ports[0],
drivers/crypto/chelsio/chcr_algo.c:					    ctx->tx_channel_id))) {
drivers/crypto/chelsio/chcr_algo.c:	if (nbytes + req_ctx->bfr_len >= bs) {
drivers/crypto/chelsio/chcr_algo.c:		remainder = (nbytes + req_ctx->bfr_len) % bs;
drivers/crypto/chelsio/chcr_algo.c:		nbytes = nbytes + req_ctx->bfr_len - remainder;
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src), req_ctx->bfr +
drivers/crypto/chelsio/chcr_algo.c:				   req_ctx->bfr_len, nbytes, 0);
drivers/crypto/chelsio/chcr_algo.c:		req_ctx->bfr_len += nbytes;
drivers/crypto/chelsio/chcr_algo.c:	params.sg_len = nbytes - req_ctx->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	params.bfr_len = req_ctx->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->result = 0;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len += params.sg_len + params.bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->bfr_len = remainder;
drivers/crypto/chelsio/chcr_algo.c:				   req_ctx->bfr, remainder, req->nbytes -
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->result = 1;
drivers/crypto/chelsio/chcr_algo.c:	params.bfr_len = req_ctx->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len += params.bfr_len + params.sg_len;
drivers/crypto/chelsio/chcr_algo.c:	if (req_ctx->bfr && (req_ctx->bfr_len == 0)) {
drivers/crypto/chelsio/chcr_algo.c:		create_last_hash_block(req_ctx->bfr, bs, req_ctx->data_len);
drivers/crypto/chelsio/chcr_algo.c:		params.scmd1 = req_ctx->data_len;
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	if (unlikely(cxgb4_is_crypto_q_full(u_ctx->lldi.ports[0],
drivers/crypto/chelsio/chcr_algo.c:					    ctx->tx_channel_id))) {
drivers/crypto/chelsio/chcr_algo.c:	params.bfr_len = req_ctx->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len += params.bfr_len + params.sg_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->result = 1;
drivers/crypto/chelsio/chcr_algo.c:	if (req_ctx->bfr && (req_ctx->bfr_len + req->nbytes) == 0) {
drivers/crypto/chelsio/chcr_algo.c:		create_last_hash_block(req_ctx->bfr, bs, req_ctx->data_len);
drivers/crypto/chelsio/chcr_algo.c:		params.scmd1 = req_ctx->data_len;
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	if (unlikely(cxgb4_is_crypto_q_full(u_ctx->lldi.ports[0],
drivers/crypto/chelsio/chcr_algo.c:					    ctx->tx_channel_id))) {
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->result = 1;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len += params.bfr_len + params.sg_len;
drivers/crypto/chelsio/chcr_algo.c:	if (req_ctx->bfr && req->nbytes == 0) {
drivers/crypto/chelsio/chcr_algo.c:		create_last_hash_block(req_ctx->bfr, bs, 0);
drivers/crypto/chelsio/chcr_algo.c:	skb->dev = u_ctx->lldi.ports[0];
drivers/crypto/chelsio/chcr_algo.c:	set_wr_txq(skb, CPL_PRIORITY_DATA, ctx->tx_channel_id);
drivers/crypto/chelsio/chcr_algo.c:	state->bfr_len = req_ctx->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	state->data_len = req_ctx->data_len;
drivers/crypto/chelsio/chcr_algo.c:	memcpy(state->bfr, req_ctx->bfr, CHCR_HASH_MAX_BLOCK_SIZE_128);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(state->partial_hash, req_ctx->partial_hash,
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->bfr_len = state->bfr_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len = state->data_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->dummy_payload_ptr = NULL;
drivers/crypto/chelsio/chcr_algo.c:	memcpy(req_ctx->bfr, state->bfr, CHCR_HASH_MAX_BLOCK_SIZE_128);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(req_ctx->partial_hash, state->partial_hash,
drivers/crypto/chelsio/chcr_algo.c:	 * ipad in hmacctx->ipad and opad in hmacctx->opad location
drivers/crypto/chelsio/chcr_algo.c:	if (!hmacctx->desc)
drivers/crypto/chelsio/chcr_algo.c:		err = crypto_shash_digest(hmacctx->desc, key, keylen,
drivers/crypto/chelsio/chcr_algo.c:					  hmacctx->ipad);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(hmacctx->ipad, key, keylen);
drivers/crypto/chelsio/chcr_algo.c:	memset(hmacctx->ipad + keylen, 0, bs - keylen);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(hmacctx->opad, hmacctx->ipad, bs);
drivers/crypto/chelsio/chcr_algo.c:		*((unsigned int *)(&hmacctx->ipad) + i) ^= IPAD_DATA;
drivers/crypto/chelsio/chcr_algo.c:		*((unsigned int *)(&hmacctx->opad) + i) ^= OPAD_DATA;
drivers/crypto/chelsio/chcr_algo.c:	err = chcr_compute_partial_hash(hmacctx->desc, hmacctx->ipad,
drivers/crypto/chelsio/chcr_algo.c:					hmacctx->ipad, digestsize);
drivers/crypto/chelsio/chcr_algo.c:	chcr_change_order(hmacctx->ipad, updated_digestsize);
drivers/crypto/chelsio/chcr_algo.c:	err = chcr_compute_partial_hash(hmacctx->desc, hmacctx->opad,
drivers/crypto/chelsio/chcr_algo.c:					hmacctx->opad, digestsize);
drivers/crypto/chelsio/chcr_algo.c:	chcr_change_order(hmacctx->opad, updated_digestsize);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ablkctx->key, key, key_len);
drivers/crypto/chelsio/chcr_algo.c:		ablkctx->enckey_len = key_len;
drivers/crypto/chelsio/chcr_algo.c:		ablkctx->key_ctx_hdr =
drivers/crypto/chelsio/chcr_algo.c:		ablkctx->ciph_mode = CHCR_SCMD_CIPHER_MODE_AES_XTS;
drivers/crypto/chelsio/chcr_algo.c:		ablkctx->enckey_len = 0;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len = 0;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->dummy_payload_ptr = NULL;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->bfr_len = 0;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->skb = NULL;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->result = 0;
drivers/crypto/chelsio/chcr_algo.c:	copy_hash_init_values(req_ctx->partial_hash, digestsize);
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->data_len = bs;
drivers/crypto/chelsio/chcr_algo.c:			memcpy(req_ctx->partial_hash, hmacctx->ipad,
drivers/crypto/chelsio/chcr_algo.c:			memcpy(req_ctx->partial_hash, hmacctx->ipad,
drivers/crypto/chelsio/chcr_algo.c:			memcpy(req_ctx->partial_hash, hmacctx->ipad,
drivers/crypto/chelsio/chcr_algo.c:	hmacctx->desc = chcr_alloc_shash(digestsize);
drivers/crypto/chelsio/chcr_algo.c:	if (IS_ERR(hmacctx->desc))
drivers/crypto/chelsio/chcr_algo.c:		return PTR_ERR(hmacctx->desc);
drivers/crypto/chelsio/chcr_algo.c:	if (hmacctx->desc) {
drivers/crypto/chelsio/chcr_algo.c:		chcr_free_shash(hmacctx->desc);
drivers/crypto/chelsio/chcr_algo.c:		hmacctx->desc = NULL;
drivers/crypto/chelsio/chcr_core.c:		if (u_ctx && u_ctx->dev) {
drivers/crypto/chelsio/chcr_core.c:			*dev = u_ctx->dev;
drivers/crypto/chelsio/chcr_core.c:	u_ctx->dev = dev;
drivers/crypto/chelsio/chcr_core.c:	kfree(u_ctx->dev);
drivers/crypto/chelsio/chcr_core.c:	u_ctx->dev = NULL;
drivers/crypto/chelsio/chcr_core.c:	u_ctx->lldi = *lld;
drivers/crypto/chelsio/chcr_core.c:	list_add_tail(&u_ctx->entry, &uld_ctx_list);
drivers/crypto/chelsio/chcr_core.c:	struct chcr_dev *dev = u_ctx->dev;
drivers/crypto/chelsio/chcr_core.c:		if (!u_ctx->dev) {
drivers/crypto/chelsio/chcr_core.c:		if (u_ctx->dev) {
drivers/crypto/chelsio/chcr_core.c:		if (u_ctx->dev)
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_init(&rctx->fallback_req);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_update(&rctx->fallback_req);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_final(&rctx->fallback_req);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_finup(&rctx->fallback_req);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_import(&rctx->fallback_req, in);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return crypto_ahash_export(&rctx->fallback_req, out);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev = tctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->dev = algt->dev;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->dev->addr_vir = (void *)__get_free_page(GFP_KERNEL);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	if (!tctx->dev->addr_vir) {
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		dev_err(tctx->dev->dev, "failed to kmalloc for addr_vir\n");
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->dev->start = rk_ahash_start;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->dev->update = rk_ahash_crypto_rx;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->dev->complete = rk_ahash_crypto_complete;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	tctx->fallback_tfm = crypto_alloc_ahash(alg_name, 0,
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	if (IS_ERR(tctx->fallback_tfm)) {
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		dev_err(tctx->dev->dev, "Could not load fallback driver.\n");
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		return PTR_ERR(tctx->fallback_tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:				 crypto_ahash_reqsize(tctx->fallback_tfm));
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return tctx->dev->enable_clk(tctx->dev);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	free_page((unsigned long)tctx->dev->addr_vir);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	return tctx->dev->disable_clk(tctx->dev);
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->keylen = keylen;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	memcpy_toio(ctx->dev->reg + RK_CRYPTO_AES_KEY_0, key, keylen);
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->keylen = keylen;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	memcpy_toio(ctx->dev->reg + RK_CRYPTO_TDES_KEY1_0, key, keylen);
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	struct rk_crypto_info *dev = ctx->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:		if (ctx->keylen == AES_KEYSIZE_192)
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:		else if (ctx->keylen == AES_KEYSIZE_256)
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev = algt->dev;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->align_size = crypto_tfm_alg_alignmask(tfm) + 1;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->start = rk_ablk_start;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->update = rk_ablk_rx;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->complete = rk_crypto_complete;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->addr_vir = (char *)__get_free_page(GFP_KERNEL);
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	return ctx->dev->addr_vir ? ctx->dev->enable_clk(ctx->dev) : -ENOMEM;
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	free_page((unsigned long)ctx->dev->addr_vir);
drivers/crypto/rockchip/rk3288_crypto_ablkcipher.c:	ctx->dev->disable_clk(ctx->dev);
drivers/crypto/img-hash.c:	if (ctx->flags & DRIVER_FLAGS_MD5)
drivers/crypto/img-hash.c:	else if (ctx->flags & DRIVER_FLAGS_SHA1)
drivers/crypto/img-hash.c:	else if (ctx->flags & DRIVER_FLAGS_SHA224)
drivers/crypto/img-hash.c:	else if (ctx->flags & DRIVER_FLAGS_SHA256)
drivers/crypto/img-hash.c:	if (ctx->bufcnt) {
drivers/crypto/img-hash.c:		img_hash_xmit_cpu(hdev, ctx->buffer, ctx->bufcnt, 0);
drivers/crypto/img-hash.c:		ctx->bufcnt = 0;
drivers/crypto/img-hash.c:	if (ctx->sg)
drivers/crypto/img-hash.c:	ctx->dma_ct = dma_map_sg(hdev->dev, sg, 1, DMA_MEM_TO_DEV);
drivers/crypto/img-hash.c:	if (ctx->dma_ct == 0) {
drivers/crypto/img-hash.c:				       ctx->dma_ct,
drivers/crypto/img-hash.c:	ctx->bufcnt = sg_copy_to_buffer(hdev->req->src, sg_nents(ctx->sg),
drivers/crypto/img-hash.c:					ctx->buffer, hdev->req->nbytes);
drivers/crypto/img-hash.c:	ctx->total = hdev->req->nbytes;
drivers/crypto/img-hash.c:	ctx->bufcnt = 0;
drivers/crypto/img-hash.c:	return img_hash_xmit_cpu(hdev, ctx->buffer, ctx->total, 1);
drivers/crypto/img-hash.c:	memcpy(req->result, ctx->digest, ctx->digsize);
drivers/crypto/img-hash.c:	u32 *hash = (u32 *)ctx->digest;
drivers/crypto/img-hash.c:	for (i = (ctx->digsize / sizeof(u32)) - 1; i >= 0; i--)
drivers/crypto/img-hash.c:		hash[i] = img_hash_read_result_queue(ctx->hdev);
drivers/crypto/img-hash.c:	struct img_hash_dev *hdev =  ctx->hdev;
drivers/crypto/img-hash.c:		ctx->flags |= DRIVER_FLAGS_ERROR;
drivers/crypto/img-hash.c:	dev_dbg(hdev->dev, "xmit dma size: %d\n", ctx->total);
drivers/crypto/img-hash.c:	if (!ctx->total)
drivers/crypto/img-hash.c:	if (!hdev->req || !ctx->sg)
drivers/crypto/img-hash.c:	addr = sg_virt(ctx->sg);
drivers/crypto/img-hash.c:	nbytes = ctx->sg->length - ctx->offset;
drivers/crypto/img-hash.c:		sg_init_one(&tsg, addr + ctx->offset, wsend * 4);
drivers/crypto/img-hash.c:			ctx->flags |= DRIVER_FLAGS_CPU;
drivers/crypto/img-hash.c:			img_hash_xmit_cpu(hdev, addr + ctx->offset,
drivers/crypto/img-hash.c:			ctx->sent += wsend * 4;
drivers/crypto/img-hash.c:			ctx->sent += wsend * 4;
drivers/crypto/img-hash.c:		ctx->bufcnt = sg_pcopy_to_buffer(ctx->sgfirst, ctx->nents,
drivers/crypto/img-hash.c:						 ctx->buffer, bleft, ctx->sent);
drivers/crypto/img-hash.c:		ctx->sg = sg_next(ctx->sg);
drivers/crypto/img-hash.c:		while (ctx->sg && (ctx->bufcnt < 4)) {
drivers/crypto/img-hash.c:			len = ctx->sg->length;
drivers/crypto/img-hash.c:			if (likely(len > (4 - ctx->bufcnt)))
drivers/crypto/img-hash.c:				len = 4 - ctx->bufcnt;
drivers/crypto/img-hash.c:			tbc = sg_pcopy_to_buffer(ctx->sgfirst, ctx->nents,
drivers/crypto/img-hash.c:						 ctx->buffer + ctx->bufcnt, len,
drivers/crypto/img-hash.c:					ctx->sent + ctx->bufcnt);
drivers/crypto/img-hash.c:			ctx->bufcnt += tbc;
drivers/crypto/img-hash.c:			if (tbc >= ctx->sg->length) {
drivers/crypto/img-hash.c:				ctx->sg = sg_next(ctx->sg);
drivers/crypto/img-hash.c:		ctx->sent += ctx->bufcnt;
drivers/crypto/img-hash.c:		ctx->offset = tbc;
drivers/crypto/img-hash.c:		ctx->offset = 0;
drivers/crypto/img-hash.c:		ctx->sg = sg_next(ctx->sg);
drivers/crypto/img-hash.c:	if (ctx->flags & DRIVER_FLAGS_SG)
drivers/crypto/img-hash.c:		dma_unmap_sg(hdev->dev, ctx->sg, ctx->dma_ct, DMA_TO_DEVICE);
drivers/crypto/img-hash.c:	ctx->bufcnt = 0;
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags =	req->base.flags
drivers/crypto/img-hash.c:	return crypto_ahash_init(&rctx->fallback_req);
drivers/crypto/img-hash.c:		 ctx->op, req->nbytes);
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/img-hash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/img-hash.c:	return crypto_ahash_update(&rctx->fallback_req);
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/img-hash.c:	return crypto_ahash_final(&rctx->fallback_req);
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/img-hash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/img-hash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/img-hash.c:	return crypto_ahash_finup(&rctx->fallback_req);
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	return crypto_ahash_import(&rctx->fallback_req, in);
drivers/crypto/img-hash.c:	ahash_request_set_tfm(&rctx->fallback_req, ctx->fallback);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	return crypto_ahash_export(&rctx->fallback_req, out);
drivers/crypto/img-hash.c:	if (!tctx->hdev) {
drivers/crypto/img-hash.c:		tctx->hdev = hdev;
drivers/crypto/img-hash.c:		hdev = tctx->hdev;
drivers/crypto/img-hash.c:	ctx->hdev = hdev;
drivers/crypto/img-hash.c:	ctx->flags = 0;
drivers/crypto/img-hash.c:	ctx->digsize = crypto_ahash_digestsize(tfm);
drivers/crypto/img-hash.c:	switch (ctx->digsize) {
drivers/crypto/img-hash.c:		ctx->flags |= DRIVER_FLAGS_SHA1;
drivers/crypto/img-hash.c:		ctx->flags |= DRIVER_FLAGS_SHA256;
drivers/crypto/img-hash.c:		ctx->flags |= DRIVER_FLAGS_SHA224;
drivers/crypto/img-hash.c:		ctx->flags |= DRIVER_FLAGS_MD5;
drivers/crypto/img-hash.c:	ctx->bufcnt = 0;
drivers/crypto/img-hash.c:	ctx->offset = 0;
drivers/crypto/img-hash.c:	ctx->sent = 0;
drivers/crypto/img-hash.c:	ctx->total = req->nbytes;
drivers/crypto/img-hash.c:	ctx->sg = req->src;
drivers/crypto/img-hash.c:	ctx->sgfirst = req->src;
drivers/crypto/img-hash.c:	ctx->nents = sg_nents(ctx->sg);
drivers/crypto/img-hash.c:	err = img_hash_handle_queue(tctx->hdev, req);
drivers/crypto/img-hash.c:	ctx->fallback = crypto_alloc_ahash(alg_name, 0,
drivers/crypto/img-hash.c:	if (IS_ERR(ctx->fallback)) {
drivers/crypto/img-hash.c:		err = PTR_ERR(ctx->fallback);
drivers/crypto/img-hash.c:				 crypto_ahash_reqsize(ctx->fallback) +
drivers/crypto/img-hash.c:	crypto_free_ahash(tctx->fallback);
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct device *dev = ctx->dev;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct device *dev = ctx->dev;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct device *dev = ctx->dev;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct device *jrdev = ctx->dev;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct device *jrdev = ctx->dev;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *rsa_key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *rsa_key = &ctx->key;
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	ctx->dev = caam_jr_alloc();
drivers/crypto/caam/caampkc.c:	if (IS_ERR(ctx->dev)) {
drivers/crypto/caam/caampkc.c:		return PTR_ERR(ctx->dev);
drivers/crypto/caam/caampkc.c:	struct caam_rsa_key *key = &ctx->key;
drivers/crypto/caam/caampkc.c:	caam_jr_free(ctx->dev);
drivers/crypto/caam/caamrng.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamrng.c:	if (ctx->sh_desc_dma)
drivers/crypto/caam/caamrng.c:		dma_unmap_single(jrdev, ctx->sh_desc_dma,
drivers/crypto/caam/caamrng.c:				 desc_bytes(ctx->sh_desc), DMA_TO_DEVICE);
drivers/crypto/caam/caamrng.c:	rng_unmap_buf(jrdev, &ctx->bufs[0]);
drivers/crypto/caam/caamrng.c:	rng_unmap_buf(jrdev, &ctx->bufs[1]);
drivers/crypto/caam/caamrng.c:	struct buf_data *bd = &ctx->bufs[!(to_current ^ ctx->current_buf)];
drivers/crypto/caam/caamrng.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamrng.c:	dev_dbg(jrdev, "submitting job %d\n", !(to_current ^ ctx->current_buf));
drivers/crypto/caam/caamrng.c:	struct buf_data *bd = &ctx->bufs[ctx->current_buf];
drivers/crypto/caam/caamrng.c:	next_buf_idx = ctx->cur_buf_idx + max;
drivers/crypto/caam/caamrng.c:	dev_dbg(ctx->jrdev, "%s: start reading at buffer %d, idx %d\n",
drivers/crypto/caam/caamrng.c:		 __func__, ctx->current_buf, ctx->cur_buf_idx);
drivers/crypto/caam/caamrng.c:		memcpy(data, bd->buf + ctx->cur_buf_idx, max);
drivers/crypto/caam/caamrng.c:		ctx->cur_buf_idx = next_buf_idx;
drivers/crypto/caam/caamrng.c:	copied_idx = RN_BUF_SIZE - ctx->cur_buf_idx;
drivers/crypto/caam/caamrng.c:	memcpy(data, bd->buf + ctx->cur_buf_idx, copied_idx);
drivers/crypto/caam/caamrng.c:	ctx->cur_buf_idx = 0;
drivers/crypto/caam/caamrng.c:	ctx->current_buf = !ctx->current_buf;
drivers/crypto/caam/caamrng.c:	dev_dbg(ctx->jrdev, "switched to buffer %d\n", ctx->current_buf);
drivers/crypto/caam/caamrng.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamrng.c:	u32 *desc = ctx->sh_desc;
drivers/crypto/caam/caamrng.c:	ctx->sh_desc_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamrng.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dma)) {
drivers/crypto/caam/caamrng.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamrng.c:	struct buf_data *bd = &ctx->bufs[buf_id];
drivers/crypto/caam/caamrng.c:	int sh_len = desc_len(ctx->sh_desc);
drivers/crypto/caam/caamrng.c:	init_job_desc_shared(desc, ctx->sh_desc_dma, sh_len, HDR_SHARE_DEFER |
drivers/crypto/caam/caamrng.c:		bd = &rng_ctx->bufs[i];
drivers/crypto/caam/caamrng.c:	struct buf_data *bd = &ctx->bufs[buf_id];
drivers/crypto/caam/caamrng.c:	submit_job(ctx, buf_id == ctx->current_buf);
drivers/crypto/caam/caamrng.c:	ctx->jrdev = jrdev;
drivers/crypto/caam/caamrng.c:	ctx->current_buf = 0;
drivers/crypto/caam/caamrng.c:	ctx->cur_buf_idx = 0;
drivers/crypto/caam/caamrng.c:	caam_jr_free(rng_ctx->jrdev);
drivers/crypto/caam/caamalg.c:	unsigned int enckeylen = ctx->enckeylen;
drivers/crypto/caam/caamalg.c:	 *	| ctx->key = {AUTH_KEY, ENC_KEY, NONCE}
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, ctx->key, ctx->split_key_pad_len,
drivers/crypto/caam/caamalg.c:				  ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key +
drivers/crypto/caam/caamalg.c:				  ctx->split_key_pad_len, enckeylen,
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma + ctx->split_key_pad_len,
drivers/crypto/caam/caamalg.c:		nonce = (u32 *)((void *)ctx->key + ctx->split_key_pad_len +
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	    ctx->split_key_pad_len <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, ctx->key, ctx->split_key_pad_len,
drivers/crypto/caam/caamalg.c:				  ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class2_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_2_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->split_key_pad_len <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, ctx->key, ctx->split_key_pad_len,
drivers/crypto/caam/caamalg.c:				  ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class2_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS2 |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	const bool ctr_mode = ((ctx->class1_alg_type & OP_ALG_AAI_MASK) ==
drivers/crypto/caam/caamalg.c:	if (!ctx->authsize)
drivers/crypto/caam/caamalg.c:	if (!ctx->enckeylen)
drivers/crypto/caam/caamalg.c:	    ctx->split_key_pad_len + ctx->enckeylen +
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class2_alg_type |
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_2_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->split_key_pad_len + ctx->enckeylen +
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class2_alg_type |
drivers/crypto/caam/caamalg.c:		append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:		append_dec_op1(desc, ctx->class1_alg_type);
drivers/crypto/caam/caamalg.c:	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS2 |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->split_key_pad_len + ctx->enckeylen +
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class2_alg_type |
drivers/crypto/caam/caamalg.c:	append_math_sub_imm_u32(desc, REG3, SEQOUTLEN, IMM, ctx->authsize);
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_2_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->authsize = authsize;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	if (!ctx->enckeylen || !ctx->authsize)
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_1_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS1 |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->authsize = authsize;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	if (!ctx->enckeylen || !ctx->authsize)
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_1_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS1 |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->authsize = authsize;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	if (!ctx->enckeylen || !ctx->authsize)
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_store(desc, ctx->authsize, LDST_CLASS_1_CCB |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	    ctx->enckeylen <= CAAM_DESC_BYTES_MAX)
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:		append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:				  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:		append_key(desc, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	append_seq_fifo_load(desc, ctx->authsize, FIFOLD_CLASS_CLASS1 |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->authsize = authsize;
drivers/crypto/caam/caamalg.c:	return gen_split_key(ctx->jrdev, ctx->key, ctx->split_key_len,
drivers/crypto/caam/caamalg.c:			       ctx->split_key_pad_len, key_in, authkeylen,
drivers/crypto/caam/caamalg.c:			       ctx->alg_op);
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	ctx->split_key_len = mdpadlen[(ctx->alg_op & OP_ALG_ALGSEL_SUBMASK) >>
drivers/crypto/caam/caamalg.c:	ctx->split_key_pad_len = ALIGN(ctx->split_key_len, 16);
drivers/crypto/caam/caamalg.c:	if (ctx->split_key_pad_len + keys.enckeylen > CAAM_MAX_KEY_SIZE)
drivers/crypto/caam/caamalg.c:	       ctx->split_key_len, ctx->split_key_pad_len);
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key + ctx->split_key_pad_len, keys.enckey, keys.enckeylen);
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, ctx->split_key_pad_len +
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:		       DUMP_PREFIX_ADDRESS, 16, 4, ctx->key,
drivers/crypto/caam/caamalg.c:		       ctx->split_key_pad_len + keys.enckeylen, 1);
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keys.enckeylen;
drivers/crypto/caam/caamalg.c:		dma_unmap_single(jrdev, ctx->key_dma, ctx->split_key_pad_len +
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, keylen,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keylen;
drivers/crypto/caam/caamalg.c:		dma_unmap_single(jrdev, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keylen - 4;
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:		dma_unmap_single(jrdev, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keylen - 4;
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:		dma_unmap_single(jrdev, ctx->key_dma, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	const bool ctr_mode = ((ctx->class1_alg_type & OP_ALG_AAI_MASK) ==
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, keylen,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keylen;
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:	append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:			  ctx->enckeylen, CLASS_1 |
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:	append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:			  ctx->enckeylen, CLASS_1 |
drivers/crypto/caam/caamalg.c:		append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:		append_dec_op1(desc, ctx->class1_alg_type);
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_givenc;
drivers/crypto/caam/caamalg.c:	append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:			  ctx->enckeylen, CLASS_1 |
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_givenc_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_givenc_dma)) {
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/caam/caamalg.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, keylen, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamalg.c:	ctx->enckeylen = keylen;
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_enc;
drivers/crypto/caam/caamalg.c:	append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:			  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:	append_operation(desc, ctx->class1_alg_type | OP_ALG_AS_INITFINAL |
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_enc_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_enc_dma)) {
drivers/crypto/caam/caamalg.c:	desc = ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:	append_key_as_imm(desc, (void *)ctx->key, ctx->enckeylen,
drivers/crypto/caam/caamalg.c:			  ctx->enckeylen, CLASS_1 | KEY_DEST_CLASS_REG);
drivers/crypto/caam/caamalg.c:	append_dec_op1(desc, ctx->class1_alg_type);
drivers/crypto/caam/caamalg.c:	ctx->sh_desc_dec_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamalg.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_dec_dma)) {
drivers/crypto/caam/caamalg.c:		dma_unmap_single(jrdev, ctx->sh_desc_enc_dma,
drivers/crypto/caam/caamalg.c:				 desc_bytes(ctx->sh_desc_enc), DMA_TO_DEVICE);
drivers/crypto/caam/caamalg.c:	int authsize = ctx->authsize;
drivers/crypto/caam/caamalg.c:	sh_desc = encrypt ? ctx->sh_desc_enc : ctx->sh_desc_dec;
drivers/crypto/caam/caamalg.c:	ptr = encrypt ? ctx->sh_desc_enc_dma : ctx->sh_desc_dec_dma;
drivers/crypto/caam/caamalg.c:		append_data(desc, ctx->key + ctx->enckeylen, 4);
drivers/crypto/caam/caamalg.c:	const bool ctr_mode = ((ctx->class1_alg_type & OP_ALG_AAI_MASK) ==
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	unsigned int authsize = ctx->authsize;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	init_ablkcipher_job(ctx->sh_desc_enc,
drivers/crypto/caam/caamalg.c:		ctx->sh_desc_enc_dma, edesc, req, iv_contig);
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	init_ablkcipher_job(ctx->sh_desc_dec,
drivers/crypto/caam/caamalg.c:		ctx->sh_desc_dec_dma, edesc, req, iv_contig);
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamalg.c:	init_ablkcipher_giv_job(ctx->sh_desc_givenc, ctx->sh_desc_givenc_dma,
drivers/crypto/caam/caamalg.c:	ctx->jrdev = caam_jr_alloc();
drivers/crypto/caam/caamalg.c:	if (IS_ERR(ctx->jrdev)) {
drivers/crypto/caam/caamalg.c:		return PTR_ERR(ctx->jrdev);
drivers/crypto/caam/caamalg.c:	ctx->class1_alg_type = OP_TYPE_CLASS1_ALG | caam->class1_alg_type;
drivers/crypto/caam/caamalg.c:	ctx->class2_alg_type = OP_TYPE_CLASS2_ALG | caam->class2_alg_type;
drivers/crypto/caam/caamalg.c:	ctx->alg_op = OP_TYPE_CLASS2_ALG | caam->alg_op;
drivers/crypto/caam/caamalg.c:	if (ctx->sh_desc_enc_dma &&
drivers/crypto/caam/caamalg.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_enc_dma))
drivers/crypto/caam/caamalg.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_enc_dma,
drivers/crypto/caam/caamalg.c:				 desc_bytes(ctx->sh_desc_enc), DMA_TO_DEVICE);
drivers/crypto/caam/caamalg.c:	if (ctx->sh_desc_dec_dma &&
drivers/crypto/caam/caamalg.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_dec_dma))
drivers/crypto/caam/caamalg.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_dec_dma,
drivers/crypto/caam/caamalg.c:				 desc_bytes(ctx->sh_desc_dec), DMA_TO_DEVICE);
drivers/crypto/caam/caamalg.c:	if (ctx->sh_desc_givenc_dma &&
drivers/crypto/caam/caamalg.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_givenc_dma))
drivers/crypto/caam/caamalg.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_givenc_dma,
drivers/crypto/caam/caamalg.c:				 desc_bytes(ctx->sh_desc_givenc),
drivers/crypto/caam/caamalg.c:	if (ctx->key_dma &&
drivers/crypto/caam/caamalg.c:	    !dma_mapping_error(ctx->jrdev, ctx->key_dma))
drivers/crypto/caam/caamalg.c:		dma_unmap_single(ctx->jrdev, ctx->key_dma,
drivers/crypto/caam/caamalg.c:				 ctx->enckeylen + ctx->split_key_pad_len,
drivers/crypto/caam/caamalg.c:	caam_jr_free(ctx->jrdev);
drivers/crypto/caam/caamhash.c:	append_key_as_imm(desc, ctx->key, ctx->split_key_pad_len,
drivers/crypto/caam/caamhash.c:			  ctx->split_key_len, CLASS_2 |
drivers/crypto/caam/caamhash.c:	if (ctx->split_key_len) {
drivers/crypto/caam/caamhash.c:		   LDST_CLASS_2_CCB | ctx->ctx_len);
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:	if (ctx->split_key_len)
drivers/crypto/caam/caamhash.c:	desc = ctx->sh_desc_update;
drivers/crypto/caam/caamhash.c:		   LDST_CLASS_2_CCB | ctx->ctx_len);
drivers/crypto/caam/caamhash.c:	append_operation(desc, ctx->alg_type | OP_ALG_AS_UPDATE |
drivers/crypto/caam/caamhash.c:	ahash_append_load_str(desc, ctx->ctx_len);
drivers/crypto/caam/caamhash.c:	ctx->sh_desc_update_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_update_dma)) {
drivers/crypto/caam/caamhash.c:	desc = ctx->sh_desc_update_first;
drivers/crypto/caam/caamhash.c:	ahash_data_to_out(desc, have_key | ctx->alg_type, OP_ALG_AS_INIT,
drivers/crypto/caam/caamhash.c:			  ctx->ctx_len, ctx);
drivers/crypto/caam/caamhash.c:	ctx->sh_desc_update_first_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_update_first_dma)) {
drivers/crypto/caam/caamhash.c:	desc = ctx->sh_desc_fin;
drivers/crypto/caam/caamhash.c:	ahash_ctx_data_to_out(desc, have_key | ctx->alg_type,
drivers/crypto/caam/caamhash.c:	ctx->sh_desc_fin_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_fin_dma)) {
drivers/crypto/caam/caamhash.c:	desc = ctx->sh_desc_finup;
drivers/crypto/caam/caamhash.c:	ahash_ctx_data_to_out(desc, have_key | ctx->alg_type,
drivers/crypto/caam/caamhash.c:	ctx->sh_desc_finup_dma = dma_map_single(jrdev, desc, desc_bytes(desc),
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_finup_dma)) {
drivers/crypto/caam/caamhash.c:	desc = ctx->sh_desc_digest;
drivers/crypto/caam/caamhash.c:	ahash_data_to_out(desc, have_key | ctx->alg_type, OP_ALG_AS_INITFINAL,
drivers/crypto/caam/caamhash.c:	ctx->sh_desc_digest_dma = dma_map_single(jrdev, desc,
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->sh_desc_digest_dma)) {
drivers/crypto/caam/caamhash.c:	return gen_split_key(ctx->jrdev, ctx->key, ctx->split_key_len,
drivers/crypto/caam/caamhash.c:			       ctx->split_key_pad_len, key_in, keylen,
drivers/crypto/caam/caamhash.c:			       ctx->alg_op);
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:	append_operation(desc, ctx->alg_type | OP_ALG_ENCRYPT |
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:	ctx->split_key_len = mdpadlen[(ctx->alg_op & OP_ALG_ALGSEL_SUBMASK) >>
drivers/crypto/caam/caamhash.c:	ctx->split_key_pad_len = ALIGN(ctx->split_key_len, 16);
drivers/crypto/caam/caamhash.c:	       ctx->split_key_len, ctx->split_key_pad_len);
drivers/crypto/caam/caamhash.c:	ctx->key_dma = dma_map_single(jrdev, ctx->key, ctx->split_key_pad_len,
drivers/crypto/caam/caamhash.c:	if (dma_mapping_error(jrdev, ctx->key_dma)) {
drivers/crypto/caam/caamhash.c:		       DUMP_PREFIX_ADDRESS, 16, 4, ctx->key,
drivers/crypto/caam/caamhash.c:		       ctx->split_key_pad_len, 1);
drivers/crypto/caam/caamhash.c:		dma_unmap_single(jrdev, ctx->key_dma, ctx->split_key_pad_len,
drivers/crypto/caam/caamhash.c:		dma_unmap_single(dev, state->ctx_dma, ctx->ctx_len, flag);
drivers/crypto/caam/caamhash.c:		       ctx->ctx_len, 1);
drivers/crypto/caam/caamhash.c:	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_BIDIRECTIONAL);
drivers/crypto/caam/caamhash.c:		       ctx->ctx_len, 1);
drivers/crypto/caam/caamhash.c:		       ctx->ctx_len, 1);
drivers/crypto/caam/caamhash.c:	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_FROM_DEVICE);
drivers/crypto/caam/caamhash.c:		       ctx->ctx_len, 1);
drivers/crypto/caam/caamhash.c:		dev_err(ctx->jrdev, "could not allocate extended descriptor\n");
drivers/crypto/caam/caamhash.c:		src_dma = dma_map_single(ctx->jrdev, sg, sgsize, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:		if (dma_mapping_error(ctx->jrdev, src_dma)) {
drivers/crypto/caam/caamhash.c:			dev_err(ctx->jrdev, "unable to map S/G table\n");
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update,
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update_dma, flags);
drivers/crypto/caam/caamhash.c:		ret = ctx_map_to_sec4_sg(desc, jrdev, state, ctx->ctx_len,
drivers/crypto/caam/caamhash.c:		append_seq_in_ptr(desc, edesc->sec4_sg_dma, ctx->ctx_len +
drivers/crypto/caam/caamhash.c:		append_seq_out_ptr(desc, state->ctx_dma, ctx->ctx_len, 0);
drivers/crypto/caam/caamhash.c:	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_BIDIRECTIONAL);
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:				  ctx->sh_desc_fin, ctx->sh_desc_fin_dma,
drivers/crypto/caam/caamhash.c:	ret = ctx_map_to_sec4_sg(desc, jrdev, state, ctx->ctx_len,
drivers/crypto/caam/caamhash.c:	append_seq_in_ptr(desc, edesc->sec4_sg_dma, ctx->ctx_len + buflen,
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:				  ctx->sh_desc_finup, ctx->sh_desc_finup_dma,
drivers/crypto/caam/caamhash.c:	ret = ctx_map_to_sec4_sg(desc, jrdev, state, ctx->ctx_len,
drivers/crypto/caam/caamhash.c:				  sec4_sg_src_index, ctx->ctx_len + buflen,
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:				  ctx->sh_desc_digest, ctx->sh_desc_digest_dma,
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:	edesc = ahash_edesc_alloc(ctx, 0, ctx->sh_desc_digest,
drivers/crypto/caam/caamhash.c:				  ctx->sh_desc_digest_dma, flags);
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update_first,
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update_first_dma,
drivers/crypto/caam/caamhash.c:		ret = map_seq_out_ptr_ctx(desc, jrdev, state, ctx->ctx_len);
drivers/crypto/caam/caamhash.c:	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:				  ctx->sh_desc_digest, ctx->sh_desc_digest_dma,
drivers/crypto/caam/caamhash.c:	struct device *jrdev = ctx->jrdev;
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update_first,
drivers/crypto/caam/caamhash.c:					  ctx->sh_desc_update_first_dma,
drivers/crypto/caam/caamhash.c:		ret = map_seq_out_ptr_ctx(desc, jrdev, state, ctx->ctx_len);
drivers/crypto/caam/caamhash.c:	ahash_unmap_ctx(jrdev, edesc, req, ctx->ctx_len, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:	ctx->jrdev = caam_jr_alloc();
drivers/crypto/caam/caamhash.c:	if (IS_ERR(ctx->jrdev)) {
drivers/crypto/caam/caamhash.c:		return PTR_ERR(ctx->jrdev);
drivers/crypto/caam/caamhash.c:	ctx->alg_type = OP_TYPE_CLASS2_ALG | caam_hash->alg_type;
drivers/crypto/caam/caamhash.c:	ctx->alg_op = OP_TYPE_CLASS2_ALG | caam_hash->alg_op;
drivers/crypto/caam/caamhash.c:	ctx->ctx_len = runninglen[(ctx->alg_op & OP_ALG_ALGSEL_SUBMASK) >>
drivers/crypto/caam/caamhash.c:	if (ctx->sh_desc_update_dma &&
drivers/crypto/caam/caamhash.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_update_dma))
drivers/crypto/caam/caamhash.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_update_dma,
drivers/crypto/caam/caamhash.c:				 desc_bytes(ctx->sh_desc_update),
drivers/crypto/caam/caamhash.c:	if (ctx->sh_desc_update_first_dma &&
drivers/crypto/caam/caamhash.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_update_first_dma))
drivers/crypto/caam/caamhash.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_update_first_dma,
drivers/crypto/caam/caamhash.c:				 desc_bytes(ctx->sh_desc_update_first),
drivers/crypto/caam/caamhash.c:	if (ctx->sh_desc_fin_dma &&
drivers/crypto/caam/caamhash.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_fin_dma))
drivers/crypto/caam/caamhash.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_fin_dma,
drivers/crypto/caam/caamhash.c:				 desc_bytes(ctx->sh_desc_fin), DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:	if (ctx->sh_desc_digest_dma &&
drivers/crypto/caam/caamhash.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_digest_dma))
drivers/crypto/caam/caamhash.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_digest_dma,
drivers/crypto/caam/caamhash.c:				 desc_bytes(ctx->sh_desc_digest),
drivers/crypto/caam/caamhash.c:	if (ctx->sh_desc_finup_dma &&
drivers/crypto/caam/caamhash.c:	    !dma_mapping_error(ctx->jrdev, ctx->sh_desc_finup_dma))
drivers/crypto/caam/caamhash.c:		dma_unmap_single(ctx->jrdev, ctx->sh_desc_finup_dma,
drivers/crypto/caam/caamhash.c:				 desc_bytes(ctx->sh_desc_finup), DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:	caam_jr_free(ctx->jrdev);
drivers/crypto/atmel-tdes.c:	if (!ctx->dd) {
drivers/crypto/atmel-tdes.c:		ctx->dd = tdes_dd;
drivers/crypto/atmel-tdes.c:		tdes_dd = ctx->dd;
drivers/crypto/atmel-tdes.c:	if (dd->ctx->keylen > (DES_KEY_SIZE << 1)) {
drivers/crypto/atmel-tdes.c:	} else if (dd->ctx->keylen > DES_KEY_SIZE) {
drivers/crypto/atmel-tdes.c:	atmel_tdes_write_n(dd, TDES_KEY1W1R, dd->ctx->key,
drivers/crypto/atmel-tdes.c:						dd->ctx->keylen >> 2);
drivers/crypto/atmel-tdes.c:	struct atmel_tdes_dev *dd = ctx->dd;
drivers/crypto/atmel-tdes.c:	struct atmel_tdes_dev *dd = ctx->dd;
drivers/crypto/atmel-tdes.c:			IS_ALIGNED(dd->in_sg->length, dd->ctx->block_size);
drivers/crypto/atmel-tdes.c:			IS_ALIGNED(dd->out_sg->length, dd->ctx->block_size);
drivers/crypto/atmel-tdes.c:	rctx->mode &= TDES_FLAGS_MODE_MASK;
drivers/crypto/atmel-tdes.c:	dd->flags = (dd->flags & ~TDES_FLAGS_MODE_MASK) | rctx->mode;
drivers/crypto/atmel-tdes.c:	ctx->dd = dd;
drivers/crypto/atmel-tdes.c:		ctx->block_size = CFB8_BLOCK_SIZE;
drivers/crypto/atmel-tdes.c:		ctx->block_size = CFB16_BLOCK_SIZE;
drivers/crypto/atmel-tdes.c:		ctx->block_size = CFB32_BLOCK_SIZE;
drivers/crypto/atmel-tdes.c:		ctx->block_size = DES_BLOCK_SIZE;
drivers/crypto/atmel-tdes.c:	rctx->mode = mode;
drivers/crypto/atmel-tdes.c:	return atmel_tdes_handle_queue(ctx->dd, req);
drivers/crypto/atmel-tdes.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/atmel-tdes.c:	ctx->keylen = keylen;
drivers/crypto/atmel-tdes.c:	if (!ctx->dd->caps.has_cfb_3keys && strstr(alg_name, "cfb")
drivers/crypto/atmel-tdes.c:	memcpy(ctx->key, key, keylen);
drivers/crypto/atmel-tdes.c:	ctx->keylen = keylen;
drivers/nvme/host/rdma.c:	hctx->driver_data = queue;
drivers/nvme/host/rdma.c:	hctx->driver_data = queue;
drivers/nvme/host/rdma.c:	struct nvme_ns *ns = hctx->queue->queuedata;
drivers/nvme/host/rdma.c:	struct nvme_rdma_queue *queue = hctx->driver_data;
drivers/nvme/host/rdma.c:	struct nvme_rdma_queue *queue = hctx->driver_data;
drivers/nvme/host/pci.c:	WARN_ON(dev->admin_tagset.tags[0] != hctx->tags);
drivers/nvme/host/pci.c:	hctx->driver_data = nvmeq;
drivers/nvme/host/pci.c:	struct nvme_queue *nvmeq = hctx->driver_data;
drivers/nvme/host/pci.c:	WARN_ON(dev->tagset.tags[hctx_idx] != hctx->tags);
drivers/nvme/host/pci.c:	hctx->driver_data = nvmeq;
drivers/nvme/host/pci.c:	struct nvme_ns *ns = hctx->queue->queuedata;
drivers/nvme/host/pci.c:	struct nvme_queue *nvmeq = hctx->driver_data;
drivers/nvme/host/pci.c:	struct nvme_queue *nvmeq = hctx->driver_data;
drivers/nvme/target/loop.c:	struct nvme_ns *ns = hctx->queue->queuedata;
drivers/nvme/target/loop.c:	struct nvme_loop_queue *queue = hctx->driver_data;
drivers/nvme/target/loop.c:	hctx->driver_data = queue;
drivers/nvme/target/loop.c:	hctx->driver_data = queue;
drivers/vfio/platform/vfio_platform_irq.c:	spin_lock_irqsave(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:	if (!irq_ctx->masked) {
drivers/vfio/platform/vfio_platform_irq.c:		disable_irq_nosync(irq_ctx->hwirq);
drivers/vfio/platform/vfio_platform_irq.c:		irq_ctx->masked = true;
drivers/vfio/platform/vfio_platform_irq.c:	spin_unlock_irqrestore(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:	spin_lock_irqsave(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:	if (irq_ctx->masked) {
drivers/vfio/platform/vfio_platform_irq.c:		enable_irq(irq_ctx->hwirq);
drivers/vfio/platform/vfio_platform_irq.c:		irq_ctx->masked = false;
drivers/vfio/platform/vfio_platform_irq.c:	spin_unlock_irqrestore(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:	spin_lock_irqsave(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:	if (!irq_ctx->masked) {
drivers/vfio/platform/vfio_platform_irq.c:		disable_irq_nosync(irq_ctx->hwirq);
drivers/vfio/platform/vfio_platform_irq.c:		irq_ctx->masked = true;
drivers/vfio/platform/vfio_platform_irq.c:	spin_unlock_irqrestore(&irq_ctx->lock, flags);
drivers/vfio/platform/vfio_platform_irq.c:		eventfd_signal(irq_ctx->trigger, 1);
drivers/vfio/platform/vfio_platform_irq.c:	eventfd_signal(irq_ctx->trigger, 1);
drivers/mmc/core/slot-gpio.c:		ctx->ro_label = ctx->cd_label + len;
drivers/mmc/core/slot-gpio.c:		snprintf(ctx->cd_label, len, "%s cd", dev_name(host->parent));
drivers/mmc/core/slot-gpio.c:		snprintf(ctx->ro_label, len, "%s ro", dev_name(host->parent));
drivers/mmc/core/slot-gpio.c:	if (!ctx || !ctx->ro_gpio)
drivers/mmc/core/slot-gpio.c:	if (ctx->override_ro_active_level)
drivers/mmc/core/slot-gpio.c:		return !gpiod_get_raw_value_cansleep(ctx->ro_gpio) ^
drivers/mmc/core/slot-gpio.c:	return gpiod_get_value_cansleep(ctx->ro_gpio);
drivers/mmc/core/slot-gpio.c:	if (!ctx || !ctx->cd_gpio)
drivers/mmc/core/slot-gpio.c:	if (ctx->override_cd_active_level)
drivers/mmc/core/slot-gpio.c:		return !gpiod_get_raw_value_cansleep(ctx->cd_gpio) ^
drivers/mmc/core/slot-gpio.c:	return gpiod_get_value_cansleep(ctx->cd_gpio);
drivers/mmc/core/slot-gpio.c:				    ctx->ro_label);
drivers/mmc/core/slot-gpio.c:	ctx->override_ro_active_level = true;
drivers/mmc/core/slot-gpio.c:	ctx->ro_gpio = gpio_to_desc(gpio);
drivers/mmc/core/slot-gpio.c:	if (host->slot.cd_irq >= 0 || !ctx || !ctx->cd_gpio)
drivers/mmc/core/slot-gpio.c:	irq = gpiod_to_irq(ctx->cd_gpio);
drivers/mmc/core/slot-gpio.c:		if (!ctx->cd_gpio_isr)
drivers/mmc/core/slot-gpio.c:			ctx->cd_gpio_isr = mmc_gpio_cd_irqt;
drivers/mmc/core/slot-gpio.c:			NULL, ctx->cd_gpio_isr,
drivers/mmc/core/slot-gpio.c:			ctx->cd_label, host);
drivers/mmc/core/slot-gpio.c:	WARN_ON(ctx->cd_gpio_isr);
drivers/mmc/core/slot-gpio.c:	ctx->cd_gpio_isr = isr;
drivers/mmc/core/slot-gpio.c:				    ctx->cd_label);
drivers/mmc/core/slot-gpio.c:	ctx->override_cd_active_level = true;
drivers/mmc/core/slot-gpio.c:	ctx->cd_gpio = gpio_to_desc(gpio);
drivers/mmc/core/slot-gpio.c:		con_id = ctx->cd_label;
drivers/mmc/core/slot-gpio.c:	ctx->override_cd_active_level = override_active_level;
drivers/mmc/core/slot-gpio.c:	ctx->cd_gpio = desc;
drivers/mmc/core/slot-gpio.c:		con_id = ctx->ro_label;
drivers/mmc/core/slot-gpio.c:	ctx->override_ro_active_level = override_active_level;
drivers/mmc/core/slot-gpio.c:	ctx->ro_gpio = desc;
drivers/mmc/card/block.c:		if (!test_bit(CMDQ_STATE_HALT, &ctx->curr_state)) {
drivers/mmc/card/block.c:		wait_event_interruptible(ctx->queue_empty_wq,
drivers/mmc/card/block.c:					(!ctx->active_reqs));
drivers/mmc/card/block.c:	if (!test_bit(CMDQ_STATE_HALT, &ctx->curr_state)) {
drivers/mmc/card/block.c:		    ctx->active_small_sector_read_reqs) {
drivers/mmc/card/block.c:			ret = wait_event_interruptible(ctx->queue_empty_wq,
drivers/mmc/card/block.c:						      !ctx->active_reqs);
drivers/mmc/card/block.c:			ctx->active_small_sector_read_reqs = 0;
drivers/mmc/card/queue.c:	wait_event(ctx->wait, kthread_should_stop()
drivers/mmc/card/queue.c:		  && test_bit(CMDQ_STATE_DCMD_ACTIVE, &ctx->curr_state))
drivers/mmc/card/queue.c:		&& !test_bit(CMDQ_STATE_ERR, &ctx->curr_state)
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (ctx->resp_msg)
drivers/i2c/busses/i2c-xgene-slimpro.c:		*ctx->resp_msg = ((u32 *)mssg)[1];
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (ctx->mbox_client.tx_block)
drivers/i2c/busses/i2c-xgene-slimpro.c:		complete(&ctx->rd_complete);
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (ctx->mbox_client.tx_block) {
drivers/i2c/busses/i2c-xgene-slimpro.c:		if (!wait_for_completion_timeout(&ctx->rd_complete,
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (*ctx->resp_msg == 0xffffffff)
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = data;
drivers/i2c/busses/i2c-xgene-slimpro.c:	rc = mbox_send_message(ctx->mbox_chan, &msg);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = NULL;
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = msg;
drivers/i2c/busses/i2c-xgene-slimpro.c:	rc = mbox_send_message(ctx->mbox_chan, &msg);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = NULL;
drivers/i2c/busses/i2c-xgene-slimpro.c:	paddr = dma_map_single(ctx->dev, ctx->dma_buffer, readlen, DMA_FROM_DEVICE);
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (dma_mapping_error(ctx->dev, paddr)) {
drivers/i2c/busses/i2c-xgene-slimpro.c:		dev_err(&ctx->adapter.dev, "Error in mapping dma buffer %p\n",
drivers/i2c/busses/i2c-xgene-slimpro.c:			ctx->dma_buffer);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = msg;
drivers/i2c/busses/i2c-xgene-slimpro.c:	rc = mbox_send_message(ctx->mbox_chan, &msg);
drivers/i2c/busses/i2c-xgene-slimpro.c:	memcpy(data, ctx->dma_buffer, readlen);
drivers/i2c/busses/i2c-xgene-slimpro.c:	dma_unmap_single(ctx->dev, paddr, readlen, DMA_FROM_DEVICE);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = NULL;
drivers/i2c/busses/i2c-xgene-slimpro.c:	memcpy(ctx->dma_buffer, data, writelen);
drivers/i2c/busses/i2c-xgene-slimpro.c:	paddr = dma_map_single(ctx->dev, ctx->dma_buffer, writelen,
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (dma_mapping_error(ctx->dev, paddr)) {
drivers/i2c/busses/i2c-xgene-slimpro.c:		dev_err(&ctx->adapter.dev, "Error in mapping dma buffer %p\n",
drivers/i2c/busses/i2c-xgene-slimpro.c:			ctx->dma_buffer);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = msg;
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (ctx->mbox_client.tx_block)
drivers/i2c/busses/i2c-xgene-slimpro.c:		reinit_completion(&ctx->rd_complete);
drivers/i2c/busses/i2c-xgene-slimpro.c:	rc = mbox_send_message(ctx->mbox_chan, &msg);
drivers/i2c/busses/i2c-xgene-slimpro.c:	dma_unmap_single(ctx->dev, paddr, writelen, DMA_TO_DEVICE);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->resp_msg = NULL;
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->dev = &pdev->dev;
drivers/i2c/busses/i2c-xgene-slimpro.c:	cl = &ctx->mbox_client;
drivers/i2c/busses/i2c-xgene-slimpro.c:	init_completion(&ctx->rd_complete);
drivers/i2c/busses/i2c-xgene-slimpro.c:	ctx->mbox_chan = mbox_request_channel(cl, MAILBOX_I2C_INDEX);
drivers/i2c/busses/i2c-xgene-slimpro.c:	if (IS_ERR(ctx->mbox_chan)) {
drivers/i2c/busses/i2c-xgene-slimpro.c:		return PTR_ERR(ctx->mbox_chan);
drivers/i2c/busses/i2c-xgene-slimpro.c:	adapter = &ctx->adapter;
drivers/i2c/busses/i2c-xgene-slimpro.c:		mbox_free_channel(ctx->mbox_chan);
drivers/i2c/busses/i2c-xgene-slimpro.c:	i2c_del_adapter(&ctx->adapter);
drivers/i2c/busses/i2c-xgene-slimpro.c:	mbox_free_channel(ctx->mbox_chan);
drivers/phy/phy-xgene.c:	void __iomem *sds_base = ctx->sds_base;
drivers/phy/phy-xgene.c:	void __iomem *sds_base = ctx->sds_base;
drivers/phy/phy-xgene.c:	void __iomem *sds_base = ctx->sds_base;
drivers/phy/phy-xgene.c:	void __iomem *sds_base = ctx->sds_base;
drivers/phy/phy-xgene.c:		dev_dbg(ctx->dev, "Set external reference clock\n");
drivers/phy/phy-xgene.c:		dev_dbg(ctx->dev, "Set internal reference clock\n");
drivers/phy/phy-xgene.c:		dev_dbg(ctx->dev,
drivers/phy/phy-xgene.c:			ctx->sata_param.txboostgain[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txprecursor_cn1[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txpostcursor_cp1[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txprecursor_cn2[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txamplitude[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txeyedirection[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:			ctx->sata_param.txeyetuning[lane * 3 +
drivers/phy/phy-xgene.c:			ctx->sata_param.speed[lane]]);
drivers/phy/phy-xgene.c:	void __iomem *csr_serdes = ctx->sds_base;
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "PLL calibration %s\n",
drivers/phy/phy-xgene.c:		dev_err(ctx->dev,
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "PLL calibration successful\n");
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "PHY Tx is %sready\n", val & 0x300 ? "" : "not ");
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Reset VCO and re-start again\n");
drivers/phy/phy-xgene.c:	void __iomem *sds_base = ctx->sds_base;
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Reset PHY\n");
drivers/phy/phy-xgene.c:		ctx->sata_param.txspeed[ctx->sata_param.speed[0]]);
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Set the customer pin mode to SATA\n");
drivers/phy/phy-xgene.c:		dev_err(ctx->dev, "PLL calibration failed\n");
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "PHY init clk type %d\n", clk_type);
drivers/phy/phy-xgene.c:	if (ctx->mode == MODE_SATA) {
drivers/phy/phy-xgene.c:		dev_err(ctx->dev, "Un-supported customer pin mode %d\n",
drivers/phy/phy-xgene.c:			ctx->mode);
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Generating avg calibration value for lane %d\n",
drivers/phy/phy-xgene.c:			dev_dbg(ctx->dev, "Iteration %d:\n", avg_loop);
drivers/phy/phy-xgene.c:			dev_dbg(ctx->dev, "DO 0x%x XO 0x%x EO 0x%x SO 0x%x\n",
drivers/phy/phy-xgene.c:			dev_dbg(ctx->dev, "DE 0x%x XE 0x%x EE 0x%x SE 0x%x\n",
drivers/phy/phy-xgene.c:			dev_dbg(ctx->dev, "SUM 0x%x\n", sum_cal_itr);
drivers/phy/phy-xgene.c:			dev_err(ctx->dev,
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Average Value:\n");
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "DO 0x%x XO 0x%x EO 0x%x SO 0x%x\n",
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "DE 0x%x XE 0x%x EE 0x%x SE 0x%x\n",
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "SUM 0x%x\n",
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Enable Manual Summer calibration\n");
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "Enable Manual Latch calibration\n");
drivers/phy/phy-xgene.c:		dev_err(ctx->dev, "PHY initialize failed %d\n", rc);
drivers/phy/phy-xgene.c:	if (!IS_ERR(ctx->clk)) {
drivers/phy/phy-xgene.c:		clk_prepare_enable(ctx->clk);
drivers/phy/phy-xgene.c:		clk_disable_unprepare(ctx->clk);
drivers/phy/phy-xgene.c:		clk_prepare_enable(ctx->clk);
drivers/phy/phy-xgene.c:	dev_dbg(ctx->dev, "PHY initialized\n");
drivers/phy/phy-xgene.c:	ctx->mode = args->args[0];
drivers/phy/phy-xgene.c:	return ctx->phy;
drivers/phy/phy-xgene.c:	ctx->dev = &pdev->dev;
drivers/phy/phy-xgene.c:	ctx->sds_base = devm_ioremap_resource(&pdev->dev, res);
drivers/phy/phy-xgene.c:	if (IS_ERR(ctx->sds_base))
drivers/phy/phy-xgene.c:		return PTR_ERR(ctx->sds_base);
drivers/phy/phy-xgene.c:	ctx->clk = clk_get(&pdev->dev, NULL);
drivers/phy/phy-xgene.c:		ctx->sata_param.txeyetuning, 6, default_txeye_tuning, 1);
drivers/phy/phy-xgene.c:		ctx->sata_param.txeyedirection, 6, default_txeye_direction, 1);
drivers/phy/phy-xgene.c:		ctx->sata_param.txboostgain, 6, default_txboost_gain, 1);
drivers/phy/phy-xgene.c:		ctx->sata_param.txamplitude, 6, default_txamp, 13300);
drivers/phy/phy-xgene.c:		ctx->sata_param.txprecursor_cn1, 6, default_txcn1, 18200);
drivers/phy/phy-xgene.c:		ctx->sata_param.txprecursor_cn2, 6, default_txcn2, 18200);
drivers/phy/phy-xgene.c:		ctx->sata_param.txpostcursor_cp1, 6, default_txcp1, 18200);
drivers/phy/phy-xgene.c:		ctx->sata_param.txspeed, 3, default_spd, 1);
drivers/phy/phy-xgene.c:		ctx->sata_param.speed[i] = 2; /* Default to Gen3 */
drivers/phy/phy-xgene.c:	ctx->phy = devm_phy_create(ctx->dev, NULL, &xgene_phy_ops);
drivers/phy/phy-xgene.c:	if (IS_ERR(ctx->phy)) {
drivers/phy/phy-xgene.c:		return PTR_ERR(ctx->phy);
drivers/phy/phy-xgene.c:	phy_set_drvdata(ctx->phy, ctx);
drivers/phy/phy-xgene.c:	phy_provider = devm_of_phy_provider_register(ctx->dev, xgene_phy_xlate);
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	for (i = 0; i < ctx->num_tiles; i++) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *s_image = &ctx->in;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *d_image = &ctx->out;
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->rot_mode == IPU_ROTATE_NONE)
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->rot_mode & IPU_ROT_BIT_90) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->rot_mode & IPU_ROT_BIT_HFLIP)
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->rot_mode & IPU_ROT_BIT_VFLIP)
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *s_image = &ctx->in;
drivers/gpu/ipu-v3/ipu-image-convert.c:			ctx->out_tile_map[tile] =
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	lockdep_assert_held(&ctx->chan->irqlock);
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:		tile_idx[0] = ctx->out_tile_map[0];
drivers/gpu/ipu-v3/ipu-image-convert.c:		tile_idx[1] = ctx->out_tile_map[1];
drivers/gpu/ipu-v3/ipu-image-convert.c:		addr0 = ctx->rot_intermediate[0].phys;
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (ctx->double_buffering)
drivers/gpu/ipu-v3/ipu-image-convert.c:			addr1 = ctx->rot_intermediate[1].phys;
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (ctx->double_buffering)
drivers/gpu/ipu-v3/ipu-image-convert.c:	ipu_idmac_set_double_buffer(channel, ctx->double_buffering);
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *s_image = &ctx->in;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *d_image = &ctx->out;
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:				   ctx->rot_mode, true);
drivers/gpu/ipu-v3/ipu-image-convert.c:				   ctx->rot_mode, false);
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode))
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->double_buffering) {
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (ipu_rot_mode_is_irt(ctx->rot_mode))
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->in.base.phys0 = run->in_phys;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->out.base.phys0 = run->out_phys;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->cur_buf_num = 0;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->next_tile = 1;
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (run->ctx->aborting) {
drivers/gpu/ipu-v3/ipu-image-convert.c:		run->ctx->complete(run, run->ctx->complete_context);
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (ctx->aborting) {
drivers/gpu/ipu-v3/ipu-image-convert.c:			complete(&ctx->aborted);
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *s_image = &ctx->in;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_image *d_image = &ctx->out;
drivers/gpu/ipu-v3/ipu-image-convert.c:	outch = ipu_rot_mode_is_irt(ctx->rot_mode) ?
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->aborting && !ctx->double_buffering) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->next_tile == ctx->num_tiles) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (!ctx->double_buffering) {
drivers/gpu/ipu-v3/ipu-image-convert.c:		src_tile = &s_image->tile[ctx->next_tile];
drivers/gpu/ipu-v3/ipu-image-convert.c:		dst_idx = ctx->out_tile_map[ctx->next_tile];
drivers/gpu/ipu-v3/ipu-image-convert.c:	} else if (ctx->next_tile < ctx->num_tiles - 1) {
drivers/gpu/ipu-v3/ipu-image-convert.c:		src_tile = &s_image->tile[ctx->next_tile + 1];
drivers/gpu/ipu-v3/ipu-image-convert.c:		dst_idx = ctx->out_tile_map[ctx->next_tile + 1];
drivers/gpu/ipu-v3/ipu-image-convert.c:		ipu_cpmem_set_buffer(chan->in_chan, ctx->cur_buf_num,
drivers/gpu/ipu-v3/ipu-image-convert.c:		ipu_cpmem_set_buffer(outch, ctx->cur_buf_num,
drivers/gpu/ipu-v3/ipu-image-convert.c:		ipu_idmac_select_buffer(chan->in_chan, ctx->cur_buf_num);
drivers/gpu/ipu-v3/ipu-image-convert.c:		ipu_idmac_select_buffer(outch, ctx->cur_buf_num);
drivers/gpu/ipu-v3/ipu-image-convert.c:		ctx->cur_buf_num ^= 1;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->next_tile++;
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (!ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_priv *priv = ctx->chan->priv;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->chan = chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	init_completion(&ctx->aborted);
drivers/gpu/ipu-v3/ipu-image-convert.c:	s_image = &ctx->in;
drivers/gpu/ipu-v3/ipu-image-convert.c:	d_image = &ctx->out;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->num_tiles = d_image->num_cols * d_image->num_rows;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->rot_mode = rot_mode;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->complete = complete;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->complete_context = complete_context;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->double_buffering = (ctx->num_tiles > 1 &&
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ipu_rot_mode_is_irt(ctx->rot_mode)) {
drivers/gpu/ipu-v3/ipu-image-convert.c:		ret = alloc_dma_buf(priv, &ctx->rot_intermediate[0],
drivers/gpu/ipu-v3/ipu-image-convert.c:		if (ctx->double_buffering) {
drivers/gpu/ipu-v3/ipu-image-convert.c:					    &ctx->rot_intermediate[1],
drivers/gpu/ipu-v3/ipu-image-convert.c:	list_add_tail(&ctx->list, &chan->ctx_list);
drivers/gpu/ipu-v3/ipu-image-convert.c:	free_dma_buf(priv, &ctx->rot_intermediate[1]);
drivers/gpu/ipu-v3/ipu-image-convert.c:	list_del(&ctx->list);
drivers/gpu/ipu-v3/ipu-image-convert.c:	free_dma_buf(priv, &ctx->rot_intermediate[0]);
drivers/gpu/ipu-v3/ipu-image-convert.c:	chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	if (ctx->aborting) {
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	reinit_completion(&ctx->aborted);
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->aborting = need_abort;
drivers/gpu/ipu-v3/ipu-image-convert.c:	ret = wait_for_completion_timeout(&ctx->aborted,
drivers/gpu/ipu-v3/ipu-image-convert.c:	ctx->aborting = false;
drivers/gpu/ipu-v3/ipu-image-convert.c:	struct ipu_image_convert_chan *chan = ctx->chan;
drivers/gpu/ipu-v3/ipu-image-convert.c:	list_del(&ctx->list);
drivers/gpu/ipu-v3/ipu-image-convert.c:	free_dma_buf(priv, &ctx->rot_intermediate[1]);
drivers/gpu/ipu-v3/ipu-image-convert.c:	free_dma_buf(priv, &ctx->rot_intermediate[0]);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->scale_3d_cntl);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->dst_pitch_offset_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->dp_gui_master_cntl_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->sc_top_left_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->sc_bottom_right_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->z_offset_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->z_pitch_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->z_sten_cntl_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->tex_cntl_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->misc_3d_state_cntl_reg);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->texture_clr_cmp_clr_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->texture_clr_cmp_msk_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->fog_color_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->setup_cntl);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->pm4_vc_fpu_setup);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->dp_write_mask);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->sten_ref_mask_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->plane_3d_mask_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->window_xy_offset);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->tex_size_pitch_c);
drivers/gpu/drm/r128/r128_state.c:	OUT_RING(ctx->constant_color_c);
drivers/gpu/drm/mga/mga_state.c:		DMA_BLOCK(MGA_DWGCTL, ctx->dwgctl,
drivers/gpu/drm/mga/mga_state.c:			  MGA_DWGCTL, ctx->dwgctl,
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_DSTORG, ctx->dstorg,
drivers/gpu/drm/mga/mga_state.c:		  MGA_MACCESS, ctx->maccess,
drivers/gpu/drm/mga/mga_state.c:		  MGA_PLNWT, ctx->plnwt, MGA_DWGCTL, ctx->dwgctl);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_ALPHACTRL, ctx->alphactrl,
drivers/gpu/drm/mga/mga_state.c:		  MGA_FOGCOL, ctx->fogcolor,
drivers/gpu/drm/mga/mga_state.c:		  MGA_WFLAG, ctx->wflag, MGA_ZORG, dev_priv->depth_offset);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_FCOL, ctx->fcol,
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_DSTORG, ctx->dstorg,
drivers/gpu/drm/mga/mga_state.c:		  MGA_MACCESS, ctx->maccess,
drivers/gpu/drm/mga/mga_state.c:		  MGA_PLNWT, ctx->plnwt, MGA_DWGCTL, ctx->dwgctl);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_ALPHACTRL, ctx->alphactrl,
drivers/gpu/drm/mga/mga_state.c:		  MGA_FOGCOL, ctx->fogcolor,
drivers/gpu/drm/mga/mga_state.c:		  MGA_WFLAG, ctx->wflag, MGA_ZORG, dev_priv->depth_offset);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_WFLAG1, ctx->wflag,
drivers/gpu/drm/mga/mga_state.c:		  MGA_TDUALSTAGE0, ctx->tdualstage0,
drivers/gpu/drm/mga/mga_state.c:		  MGA_TDUALSTAGE1, ctx->tdualstage1, MGA_FCOL, ctx->fcol);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_STENCIL, ctx->stencil,
drivers/gpu/drm/mga/mga_state.c:		  MGA_STENCILCTL, ctx->stencilctl,
drivers/gpu/drm/mga/mga_state.c:	if (ctx->dstorg != dev_priv->front_offset &&
drivers/gpu/drm/mga/mga_state.c:	    ctx->dstorg != dev_priv->back_offset) {
drivers/gpu/drm/mga/mga_state.c:			  ctx->dstorg, dev_priv->front_offset,
drivers/gpu/drm/mga/mga_state.c:		ctx->dstorg = 0;
drivers/gpu/drm/mga/mga_state.c:		  MGA_PLNWT, ctx->plnwt, MGA_DWGCTL, ctx->dwgctl);
drivers/gpu/drm/mga/mga_state.c:		  MGA_PLNWT, ctx->plnwt,
drivers/gpu/drm/mga/mga_state.c:		  MGA_SRCORG, dev_priv->front_offset, MGA_DWGCTL, ctx->dwgctl);
drivers/gpu/drm/mga/mga_state.c:	DMA_BLOCK(MGA_PLNWT, ctx->plnwt,
drivers/gpu/drm/mga/mga_state.c:		  MGA_PLNWT, ctx->plnwt,
drivers/gpu/drm/mga/mga_state.c:		  MGA_PITCH, dev_priv->front_pitch, MGA_DWGCTL, ctx->dwgctl);
drivers/gpu/drm/drm_context.c:	ctx->handle = drm_legacy_ctxbitmap_next(dev);
drivers/gpu/drm/drm_context.c:	if (ctx->handle == DRM_KERNEL_CONTEXT) {
drivers/gpu/drm/drm_context.c:		ctx->handle = drm_legacy_ctxbitmap_next(dev);
drivers/gpu/drm/drm_context.c:	DRM_DEBUG("%d\n", ctx->handle);
drivers/gpu/drm/drm_context.c:	if (ctx->handle == -1) {
drivers/gpu/drm/drm_context.c:	ctx_entry->handle = ctx->handle;
drivers/gpu/drm/drm_context.c:	ctx->flags = 0;
drivers/gpu/drm/drm_context.c:	DRM_DEBUG("%d\n", ctx->handle);
drivers/gpu/drm/drm_context.c:	return drm_context_switch(dev, dev->last_context, ctx->handle);
drivers/gpu/drm/drm_context.c:	DRM_DEBUG("%d\n", ctx->handle);
drivers/gpu/drm/drm_context.c:	drm_context_switch_complete(dev, file_priv, ctx->handle);
drivers/gpu/drm/drm_context.c:	DRM_DEBUG("%d\n", ctx->handle);
drivers/gpu/drm/drm_context.c:	if (ctx->handle != DRM_KERNEL_CONTEXT) {
drivers/gpu/drm/drm_context.c:			dev->driver->context_dtor(dev, ctx->handle);
drivers/gpu/drm/drm_context.c:		drm_legacy_ctxbitmap_free(dev, ctx->handle);
drivers/gpu/drm/drm_context.c:			if (pos->handle == ctx->handle) {
drivers/gpu/drm/omapdrm/dss/sdi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/gpu/drm/omapdrm/dss/sdi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/gpu/drm/omapdrm/dss/sdi.c:	ctx->dispc_cinfo.lck = lck;
drivers/gpu/drm/omapdrm/dss/sdi.c:	ctx->dispc_cinfo.pck = pck;
drivers/gpu/drm/omapdrm/dss/sdi.c:	ctx->fck = fck;
drivers/gpu/drm/omapdrm/dss/sdi.c:	return dispc_div_calc(fck, ctx->pck_min, ctx->pck_max,
drivers/gpu/drm/omapdrm/dss/dsi.c:	struct omap_video_timings *t = &ctx->dispc_vm;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.lck = lck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.pck = pck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	*t = *ctx->config->timings;
drivers/gpu/drm/omapdrm/dss/dsi.c:	t->x_res = ctx->config->timings->x_res;
drivers/gpu/drm/omapdrm/dss/dsi.c:	t->y_res = ctx->config->timings->y_res;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.mX[HSDIV_DISPC] = m_dispc;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.clkout[HSDIV_DISPC] = dispc;
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dispc_div_calc(dispc, ctx->req_pck_min, ctx->req_pck_max,
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.n = n;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.m = m;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.fint = fint;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.clkdco = clkdco;
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dss_pll_hsdiv_calc_a(ctx->pll, clkdco, ctx->req_pck_min,
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsidev = dsi->pdev;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->pll = &dsi->pll;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->config = cfg;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_min = pck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_nom = pck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_max = pck * 3 / 2;
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dss_pll_calc_a(ctx->pll, clkin,
drivers/gpu/drm/omapdrm/dss/dsi.c:	struct dsi_data *dsi = dsi_get_dsidrv_data(ctx->dsidev);
drivers/gpu/drm/omapdrm/dss/dsi.c:	const struct omap_dss_dsi_config *cfg = ctx->config;
drivers/gpu/drm/omapdrm/dss/dsi.c:	unsigned long hsclk = ctx->dsi_cinfo.clkdco / 4;
drivers/gpu/drm/omapdrm/dss/dsi.c:	req_pck_min = ctx->req_pck_min;
drivers/gpu/drm/omapdrm/dss/dsi.c:	req_pck_max = ctx->req_pck_max;
drivers/gpu/drm/omapdrm/dss/dsi.c:	req_pck_nom = ctx->req_pck_nom;
drivers/gpu/drm/omapdrm/dss/dsi.c:	dispc_pck = ctx->dispc_cinfo.pck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	dsi_vm = &ctx->dsi_vm;
drivers/gpu/drm/omapdrm/dss/dsi.c:	dispc_vm = &ctx->dispc_vm;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.lck = lck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dispc_cinfo.pck = pck;
drivers/gpu/drm/omapdrm/dss/dsi.c:	print_dispc_vm("dispc", &ctx->dispc_vm);
drivers/gpu/drm/omapdrm/dss/dsi.c:	print_dsi_vm("dsi  ", &ctx->dsi_vm);
drivers/gpu/drm/omapdrm/dss/dsi.c:	print_dispc_vm("req  ", ctx->config->timings);
drivers/gpu/drm/omapdrm/dss/dsi.c:	print_dsi_dispc_vm("act  ", &ctx->dsi_vm);
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.mX[HSDIV_DISPC] = m_dispc;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.clkout[HSDIV_DISPC] = dispc;
drivers/gpu/drm/omapdrm/dss/dsi.c:	if (ctx->config->trans_mode == OMAP_DSS_DSI_BURST_MODE)
drivers/gpu/drm/omapdrm/dss/dsi.c:		pck_max = ctx->req_pck_max + 10000000;
drivers/gpu/drm/omapdrm/dss/dsi.c:		pck_max = ctx->req_pck_max;
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dispc_div_calc(dispc, ctx->req_pck_min, pck_max,
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.n = n;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.m = m;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.fint = fint;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsi_cinfo.clkdco = clkdco;
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dss_pll_hsdiv_calc_a(ctx->pll, clkdco, ctx->req_pck_min,
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->dsidev = dsi->pdev;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->pll = &dsi->pll;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->config = cfg;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_min = t->pixelclock - 1000;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_nom = t->pixelclock;
drivers/gpu/drm/omapdrm/dss/dsi.c:	ctx->req_pck_max = t->pixelclock + 1000;
drivers/gpu/drm/omapdrm/dss/dsi.c:	byteclk_min = div64_u64((u64)ctx->req_pck_min * bitspp, ndl * 8);
drivers/gpu/drm/omapdrm/dss/dsi.c:		byteclk_max = div64_u64((u64)ctx->req_pck_max * bitspp,
drivers/gpu/drm/omapdrm/dss/dsi.c:	return dss_pll_calc_a(ctx->pll, clkin,
drivers/gpu/drm/omapdrm/dss/dpi.c:	if (ctx->pck_min >= 100000000) {
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->dispc_cinfo.lck_div = lckd;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->dispc_cinfo.pck_div = pckd;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->dispc_cinfo.lck = lck;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->dispc_cinfo.pck = pck;
drivers/gpu/drm/omapdrm/dss/dpi.c:	if (m_dispc > 1 && m_dispc % 2 != 0 && ctx->pck_min >= 100000000)
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.mX[ctx->clkout_idx] = m_dispc;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.clkout[ctx->clkout_idx] = dispc;
drivers/gpu/drm/omapdrm/dss/dpi.c:	return dispc_div_calc(dispc, ctx->pck_min, ctx->pck_max,
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.n = n;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.m = m;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.fint = fint;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll_cinfo.clkdco = clkdco;
drivers/gpu/drm/omapdrm/dss/dpi.c:	return dss_pll_hsdiv_calc_a(ctx->pll, clkdco,
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->pck_min, dss_feat_get_param_max(FEAT_PARAM_DSS_FCK),
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->fck = fck;
drivers/gpu/drm/omapdrm/dss/dpi.c:	return dispc_div_calc(fck, ctx->pck_min, ctx->pck_max,
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->pll = dpi->pll;
drivers/gpu/drm/omapdrm/dss/dpi.c:	ctx->clkout_idx = dss_pll_get_clkout_idx_for_src(dpi->clk_src);
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->pck_min = pck - 1000;
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->pck_max = pck + 1000;
drivers/gpu/drm/omapdrm/dss/dpi.c:		return dss_pll_calc_a(ctx->pll, clkin,
drivers/gpu/drm/omapdrm/dss/dpi.c:		dss_pll_calc_b(dpi->pll, clkin, pck, &ctx->pll_cinfo);
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->dispc_cinfo.lck_div = 1;
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->dispc_cinfo.pck_div = 1;
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->dispc_cinfo.lck = ctx->pll_cinfo.clkout[0];
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->dispc_cinfo.pck = ctx->dispc_cinfo.lck;
drivers/gpu/drm/omapdrm/dss/dpi.c:			ctx->pck_min = max(pck - 1000 * i * i * i, 0lu);
drivers/gpu/drm/omapdrm/dss/dpi.c:			ctx->pck_min = 0;
drivers/gpu/drm/omapdrm/dss/dpi.c:		ctx->pck_max = pck + 1000 * i * i * i;
drivers/gpu/drm/omapdrm/dss/dpi.c:		ok = dss_div_calc(pck, ctx->pck_min, dpi_calc_dss_cb, ctx);
drivers/gpu/drm/i915/i915_guc_submission.c:		struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/i915_guc_submission.c:	data[2] = i915_ggtt_offset(ctx->engine[RCS].state);
drivers/gpu/drm/i915/i915_guc_submission.c:	data[2] = i915_ggtt_offset(ctx->engine[RCS].state);
drivers/gpu/drm/i915/intel_dpll_mgr.c:	ctx->min_deviation = U64_MAX;
drivers/gpu/drm/i915/intel_dpll_mgr.c:		    deviation < ctx->min_deviation) {
drivers/gpu/drm/i915/intel_dpll_mgr.c:			ctx->min_deviation = deviation;
drivers/gpu/drm/i915/intel_dpll_mgr.c:			ctx->central_freq = central_freq;
drivers/gpu/drm/i915/intel_dpll_mgr.c:			ctx->dco_freq = dco_freq;
drivers/gpu/drm/i915/intel_dpll_mgr.c:			ctx->p = divider;
drivers/gpu/drm/i915/intel_dpll_mgr.c:		   deviation < ctx->min_deviation) {
drivers/gpu/drm/i915/intel_dpll_mgr.c:		ctx->min_deviation = deviation;
drivers/gpu/drm/i915/intel_dpll_mgr.c:		ctx->central_freq = central_freq;
drivers/gpu/drm/i915/intel_dpll_mgr.c:		ctx->dco_freq = dco_freq;
drivers/gpu/drm/i915/intel_dpll_mgr.c:		ctx->p = divider;
drivers/gpu/drm/i915/i915_drv.h:	kref_get(&ctx->ref);
drivers/gpu/drm/i915/i915_drv.h:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/i915_drv.h:	kref_put(&ctx->ref, i915_gem_context_free);
drivers/gpu/drm/i915/i915_gem_execbuffer.c:		if (ctx->flags & CONTEXT_NO_ZEROMAP)
drivers/gpu/drm/i915/i915_gem_execbuffer.c:	hs = &ctx->hang_stats;
drivers/gpu/drm/i915/i915_gem_execbuffer.c:	if (ctx->ppgtt)
drivers/gpu/drm/i915/i915_gem_execbuffer.c:		vm = &ctx->ppgtt->base;
drivers/gpu/drm/i915/intel_pm.c:			     dev_priv->vlv_pctx->stolen->start);
drivers/gpu/drm/i915/intel_pm.c:	pctx_paddr = dev_priv->mm.stolen_base + pctx->stolen->start;
drivers/gpu/drm/i915/i915_gem.c:	if (ctx->hang_stats.banned)
drivers/gpu/drm/i915/i915_gem.c:	elapsed = get_seconds() - ctx->hang_stats.guilty_ts;
drivers/gpu/drm/i915/i915_gem.c:	if (ctx->hang_stats.ban_period_seconds &&
drivers/gpu/drm/i915/i915_gem.c:	    elapsed <= ctx->hang_stats.ban_period_seconds) {
drivers/gpu/drm/i915/i915_gem.c:	struct i915_ctx_hang_stats *hs = &ctx->hang_stats;
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	desc = ctx->desc_template;				/* bits  3-4  */
drivers/gpu/drm/i915/intel_lrc.c:	desc |= (u64)ctx->hw_id << GEN8_CTX_ID_SHIFT;		/* bits 32-52 */
drivers/gpu/drm/i915/intel_lrc.c:	return ctx->engine[engine->id].lrc_desc;
drivers/gpu/drm/i915/intel_lrc.c:	atomic_notifier_call_chain(&rq->ctx->status_notifier, status, rq);
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &rq->ctx->engine[rq->engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	struct i915_hw_ppgtt *ppgtt = rq->ctx->ppgtt;
drivers/gpu/drm/i915/intel_lrc.c:		ctx->execlists_force_single_submission);
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &request->ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/intel_lrc.c:		struct drm_i915_private *dev_priv = ctx->i915;
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/intel_lrc.c:	return wa_ctx->offset = ALIGN(offset, start_alignment);
drivers/gpu/drm/i915/intel_lrc.c:	wa_ctx->size = offset - wa_ctx->offset;
drivers/gpu/drm/i915/intel_lrc.c:	WARN(wa_ctx->size % size_alignment,
drivers/gpu/drm/i915/intel_lrc.c:	     wa_ctx->size, size_alignment);
drivers/gpu/drm/i915/intel_lrc.c:	page = i915_gem_object_get_dirty_page(wa_ctx->vma->obj, 0);
drivers/gpu/drm/i915/intel_lrc.c:					       &wa_ctx->indirect_ctx,
drivers/gpu/drm/i915/intel_lrc.c:					  &wa_ctx->per_ctx,
drivers/gpu/drm/i915/intel_lrc.c:					       &wa_ctx->indirect_ctx,
drivers/gpu/drm/i915/intel_lrc.c:					  &wa_ctx->per_ctx,
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &request->ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	struct i915_hw_ppgtt *ppgtt = req->ctx->ppgtt;
drivers/gpu/drm/i915/intel_lrc.c:	if (req->ctx->ppgtt &&
drivers/gpu/drm/i915/intel_lrc.c:	    (intel_engine_flag(req->engine) & req->ctx->ppgtt->pd_dirty_rings)) {
drivers/gpu/drm/i915/intel_lrc.c:		req->ctx->ppgtt->pd_dirty_rings &= ~intel_engine_flag(req->engine);
drivers/gpu/drm/i915/intel_lrc.c:	ret = lrc_setup_hws(engine, dctx->engine[engine->id].state);
drivers/gpu/drm/i915/intel_lrc.c:	struct i915_hw_ppgtt *ppgtt = ctx->ppgtt ?: dev_priv->mm.aliasing_ppgtt;
drivers/gpu/drm/i915/intel_lrc.c:			u32 ggtt_offset = i915_ggtt_offset(wa_ctx->vma);
drivers/gpu/drm/i915/intel_lrc.c:				(ggtt_offset + wa_ctx->indirect_ctx.offset * sizeof(uint32_t)) |
drivers/gpu/drm/i915/intel_lrc.c:				(wa_ctx->indirect_ctx.size / CACHELINE_DWORDS);
drivers/gpu/drm/i915/intel_lrc.c:				(ggtt_offset + wa_ctx->per_ctx.offset * sizeof(uint32_t)) |
drivers/gpu/drm/i915/intel_lrc.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_lrc.c:	ctx_obj = i915_gem_object_create(&ctx->i915->drm, context_size);
drivers/gpu/drm/i915/intel_lrc.c:	vma = i915_vma_create(ctx_obj, &ctx->i915->ggtt.base, NULL);
drivers/gpu/drm/i915/intel_lrc.c:	ring = intel_engine_create_ring(engine, ctx->ring_size);
drivers/gpu/drm/i915/intel_lrc.c:		struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/i915_debugfs.c:	for (n = 0; n < ARRAY_SIZE(ctx->engine); n++) {
drivers/gpu/drm/i915/i915_debugfs.c:		if (ctx->engine[n].state)
drivers/gpu/drm/i915/i915_debugfs.c:			per_file_stats(0, ctx->engine[n].state->obj, data);
drivers/gpu/drm/i915/i915_debugfs.c:		if (ctx->engine[n].ring)
drivers/gpu/drm/i915/i915_debugfs.c:			per_file_stats(0, ctx->engine[n].ring->vma->obj, data);
drivers/gpu/drm/i915/i915_debugfs.c:		task = pid_task(request && request->ctx->pid ?
drivers/gpu/drm/i915/i915_debugfs.c:				request->ctx->pid : file->pid,
drivers/gpu/drm/i915/i915_debugfs.c:			struct pid *pid = req->ctx->pid;
drivers/gpu/drm/i915/i915_debugfs.c:		seq_printf(m, "HW context %u ", ctx->hw_id);
drivers/gpu/drm/i915/i915_debugfs.c:		if (ctx->pid) {
drivers/gpu/drm/i915/i915_debugfs.c:			task = get_pid_task(ctx->pid, PIDTYPE_PID);
drivers/gpu/drm/i915/i915_debugfs.c:		} else if (IS_ERR(ctx->file_priv)) {
drivers/gpu/drm/i915/i915_debugfs.c:		seq_putc(m, ctx->remap_slice ? 'R' : 'r');
drivers/gpu/drm/i915/i915_debugfs.c:			struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/i915_debugfs.c:	struct i915_vma *vma = ctx->engine[engine->id].state;
drivers/gpu/drm/i915/i915_debugfs.c:	seq_printf(m, "CONTEXT: %s %u\n", engine->name, ctx->hw_id);
drivers/gpu/drm/i915/i915_debugfs.c:				   head_req->ctx->hw_id);
drivers/gpu/drm/i915/i915_debugfs.c:	struct i915_hw_ppgtt *ppgtt = ctx->ppgtt;
drivers/gpu/drm/i915/i915_debugfs.c:			   ctx->user_handle);
drivers/gpu/drm/i915/i915_debugfs.c:		seq_printf(m, "  context %d:\n", ctx->user_handle);
drivers/gpu/drm/i915/i915_gem_context.c:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/i915_gem_context.c:	GEM_BUG_ON(!ctx->closed);
drivers/gpu/drm/i915/i915_gem_context.c:	i915_ppgtt_put(ctx->ppgtt);
drivers/gpu/drm/i915/i915_gem_context.c:		struct intel_context *ce = &ctx->engine[i];
drivers/gpu/drm/i915/i915_gem_context.c:	put_pid(ctx->pid);
drivers/gpu/drm/i915/i915_gem_context.c:	list_del(&ctx->link);
drivers/gpu/drm/i915/i915_gem_context.c:	ida_simple_remove(&ctx->i915->context_hw_ida, ctx->hw_id);
drivers/gpu/drm/i915/i915_gem_context.c:	GEM_BUG_ON(ctx->closed);
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->closed = true;
drivers/gpu/drm/i915/i915_gem_context.c:	if (ctx->ppgtt)
drivers/gpu/drm/i915/i915_gem_context.c:		i915_ppgtt_close(&ctx->ppgtt->base);
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->file_priv = ERR_PTR(-EBADF);
drivers/gpu/drm/i915/i915_gem_context.c:	ret = assign_hw_id(dev_priv, &ctx->hw_id);
drivers/gpu/drm/i915/i915_gem_context.c:	kref_init(&ctx->ref);
drivers/gpu/drm/i915/i915_gem_context.c:	list_add_tail(&ctx->link, &dev_priv->context_list);
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->i915 = dev_priv;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->ggtt_alignment = get_context_alignment(dev_priv);
drivers/gpu/drm/i915/i915_gem_context.c:		ctx->engine[RCS].state = vma;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->file_priv = file_priv;
drivers/gpu/drm/i915/i915_gem_context.c:		ctx->pid = get_task_pid(current, PIDTYPE_PID);
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->user_handle = ret;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->remap_slice = ALL_L3_SLICES(dev_priv);
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->hang_stats.ban_period_seconds = DRM_I915_CTX_BAN_PERIOD;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->ring_size = 4 * PAGE_SIZE;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->desc_template = GEN8_CTX_ADDRESSING_MODE(dev_priv) <<
drivers/gpu/drm/i915/i915_gem_context.c:	ATOMIC_INIT_NOTIFIER_HEAD(&ctx->status_notifier);
drivers/gpu/drm/i915/i915_gem_context.c:			idr_remove(&file_priv->context_idr, ctx->user_handle);
drivers/gpu/drm/i915/i915_gem_context.c:		ctx->ppgtt = ppgtt;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->execlists_force_single_submission = true;
drivers/gpu/drm/i915/i915_gem_context.c:	ctx->ring_size = 512 * PAGE_SIZE; /* Max ring buffer size */
drivers/gpu/drm/i915/i915_gem_context.c:		struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/i915_gem_context.c:				ctx->engine[engine->id].initialised = false;
drivers/gpu/drm/i915/i915_gem_context.c:			ctx->remap_slice = ALL_L3_SLICES(dev_priv);
drivers/gpu/drm/i915/i915_gem_context.c:			i915_ggtt_offset(req->ctx->engine[RCS].state) | flags);
drivers/gpu/drm/i915/i915_gem_context.c:	if (!req->ctx->engine[engine->id].state) {
drivers/gpu/drm/i915/i915_gem_context.c:	args->ctx_id = ctx->user_handle;
drivers/gpu/drm/i915/i915_gem_context.c:	idr_remove(&file_priv->context_idr, ctx->user_handle);
drivers/gpu/drm/i915/i915_gem_context.c:		args->value = ctx->hang_stats.ban_period_seconds;
drivers/gpu/drm/i915/i915_gem_context.c:		args->value = ctx->flags & CONTEXT_NO_ZEROMAP;
drivers/gpu/drm/i915/i915_gem_context.c:		if (ctx->ppgtt)
drivers/gpu/drm/i915/i915_gem_context.c:			args->value = ctx->ppgtt->base.total;
drivers/gpu/drm/i915/i915_gem_context.c:		args->value = !!(ctx->flags & CONTEXT_NO_ERROR_CAPTURE);
drivers/gpu/drm/i915/i915_gem_context.c:		else if (args->value < ctx->hang_stats.ban_period_seconds &&
drivers/gpu/drm/i915/i915_gem_context.c:			ctx->hang_stats.ban_period_seconds = args->value;
drivers/gpu/drm/i915/i915_gem_context.c:			ctx->flags &= ~CONTEXT_NO_ZEROMAP;
drivers/gpu/drm/i915/i915_gem_context.c:			ctx->flags |= args->value ? CONTEXT_NO_ZEROMAP : 0;
drivers/gpu/drm/i915/i915_gem_context.c:				ctx->flags |= CONTEXT_NO_ERROR_CAPTURE;
drivers/gpu/drm/i915/i915_gem_context.c:				ctx->flags &= ~CONTEXT_NO_ERROR_CAPTURE;
drivers/gpu/drm/i915/i915_gem_context.c:	hs = &ctx->hang_stats;
drivers/gpu/drm/i915/intel_ringbuffer.c:	ppgtt = req->ctx->ppgtt;
drivers/gpu/drm/i915/intel_ringbuffer.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_ringbuffer.c:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/intel_ringbuffer.c:		ret = i915_vma_pin(ce->state, 0, ctx->ggtt_alignment,
drivers/gpu/drm/i915/intel_ringbuffer.c:	if (ctx == ctx->i915->kernel_context)
drivers/gpu/drm/i915/intel_ringbuffer.c:	struct intel_context *ce = &ctx->engine[engine->id];
drivers/gpu/drm/i915/intel_ringbuffer.c:	lockdep_assert_held(&ctx->i915->drm.struct_mutex);
drivers/gpu/drm/i915/i915_trace.h:			__entry->vm = ctx->ppgtt ? &ctx->ppgtt->base : NULL;
drivers/gpu/drm/i915/i915_trace.h:			__entry->dev = ctx->i915->drm.primary->index;
drivers/gpu/drm/i915/i915_sysfs.c:		ctx->remap_slice |= (1<<slice);
drivers/gpu/drm/i915/i915_gpu_error.c:		erq->pid = request->ctx->pid ? pid_nr(request->ctx->pid) : 0;
drivers/gpu/drm/i915/i915_gpu_error.c:			ee->vm = request->ctx->ppgtt ?
drivers/gpu/drm/i915/i915_gpu_error.c:				&request->ctx->ppgtt->base : &ggtt->base;
drivers/gpu/drm/i915/i915_gpu_error.c:							 request->ctx->engine[i].state);
drivers/gpu/drm/i915/i915_gpu_error.c:			pid = request->ctx->pid;
drivers/gpu/drm/i915/i915_gpu_error.c:				request->ctx->flags & CONTEXT_NO_ERROR_CAPTURE;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ret = clk_set_rate(ctx->ade_pix_clk, clk_Hz);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	adj_mode->clock = clk_get_rate(ctx->ade_pix_clk) / 1000;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ret = clk_prepare_enable(ctx->media_noc_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ret = reset_control_deassert(ctx->reset);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ret = clk_prepare_enable(ctx->ade_core_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->power_on = true;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	clk_disable_unprepare(ctx->ade_core_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	reset_control_assert(ctx->reset);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	clk_disable_unprepare(ctx->media_noc_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->power_on = false;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	struct regmap *map = ctx->noc_regmap;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (!ctx->power_on)
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (!ctx->power_on) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (!ctx->power_on) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ade_dump_regs(ctx->base);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (!ctx->power_on)
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (!ctx->power_on)
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->base = devm_ioremap_resource(dev, res);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->base)) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return  PTR_ERR(ctx->base);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->reset = devm_reset_control_get(dev, NULL);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->reset))
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return PTR_ERR(ctx->reset);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->noc_regmap =
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->noc_regmap)) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return PTR_ERR(ctx->noc_regmap);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->irq = platform_get_irq(pdev, 0);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (ctx->irq < 0) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->ade_core_clk = devm_clk_get(dev, "clk_ade_core");
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->ade_core_clk)) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return PTR_ERR(ctx->ade_core_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->media_noc_clk = devm_clk_get(dev, "clk_codec_jpeg");
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->media_noc_clk)) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return PTR_ERR(ctx->media_noc_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ctx->ade_pix_clk = devm_clk_get(dev, "clk_ade_pix");
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	if (IS_ERR(ctx->ade_pix_clk)) {
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:		return PTR_ERR(ctx->ade_pix_clk);
drivers/gpu/drm/hisilicon/kirin/kirin_drm_ade.c:	ret = devm_request_irq(dev->dev, ctx->irq, ade_irq_handler,
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	void __iomem *base = ctx->base;
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	clk_disable_unprepare(ctx->pclk);
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	ret = clk_prepare_enable(ctx->pclk);
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	ctx->pclk = devm_clk_get(&pdev->dev, "pclk");
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	if (IS_ERR(ctx->pclk)) {
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:		return PTR_ERR(ctx->pclk);
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	ctx->base = devm_ioremap_resource(&pdev->dev, res);
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:	if (IS_ERR(ctx->base)) {
drivers/gpu/drm/hisilicon/kirin/dw_drm_dsi.c:		return PTR_ERR(ctx->base);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	int ret = ctx->error;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->error = 0;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	struct mipi_dsi_device *dsi = to_mipi_dsi_device(ctx->dev);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->error < 0)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		dev_err(ctx->dev, "error %zd writing dcs seq: %*ph\n", ret,
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		ctx->error = ret;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	struct mipi_dsi_device *dsi = to_mipi_dsi_device(ctx->dev);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->error < 0)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		return ctx->error;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		dev_err(ctx->dev, "error %d reading dcs seq(%#x)\n", ret, cmd);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		ctx->error = ret;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	u8 aid = aids[ctx->id >> 5];
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->flip_vertical) {
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->flip_horizontal) {
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->flip_horizontal || ctx->flip_vertical) {
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->version < 142)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->version < 142)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->version < 142)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	u8 id = ctx->id ? 0 : 0x95;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	switch (ctx->brightness) {
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->version < 142)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->error)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	gamma = ctx->variant->gamma_tables[ctx->brightness];
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->version >= 142)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	msleep(ctx->init_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	struct mipi_dsi_device *dsi = to_mipi_dsi_device(ctx->dev);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (ctx->error < 0)
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		dev_err(ctx->dev,
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		ctx->error = ret;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		dev_err(ctx->dev, "read id failed\n");
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		ctx->error = -EIO;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	dev_info(ctx->dev, "ID: 0x%2x, 0x%2x, 0x%2x\n", id[0], id[1], id[2]);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		dev_err(ctx->dev, "unsupported display version %d\n", id[1]);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		ctx->error = -EINVAL;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->variant = &s6e8aa0_variants[i];
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->version = id[1];
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->id = id[2];
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ret = regulator_bulk_enable(ARRAY_SIZE(ctx->supplies), ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	msleep(ctx->power_on_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	gpiod_set_value(ctx->reset_gpio, 0);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	gpiod_set_value(ctx->reset_gpio, 1);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	msleep(ctx->reset_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	return regulator_bulk_disable(ARRAY_SIZE(ctx->supplies), ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ret = ctx->error;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	drm_display_mode_from_videomode(&ctx->vm, mode);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	mode->width_mm = ctx->width_mm;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	mode->height_mm = ctx->height_mm;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	struct device *dev = ctx->dev;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ret = of_get_videomode(np, &ctx->vm, 0);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	of_property_read_u32(np, "power-on-delay", &ctx->power_on_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	of_property_read_u32(np, "reset-delay", &ctx->reset_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	of_property_read_u32(np, "init-delay", &ctx->init_delay);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	of_property_read_u32(np, "panel-width-mm", &ctx->width_mm);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	of_property_read_u32(np, "panel-height-mm", &ctx->height_mm);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->flip_horizontal = of_property_read_bool(np, "flip-horizontal");
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->flip_vertical = of_property_read_bool(np, "flip-vertical");
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->dev = dev;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->supplies[0].supply = "vdd3";
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->supplies[1].supply = "vci";
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ret = devm_regulator_bulk_get(dev, ARRAY_SIZE(ctx->supplies),
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:				      ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->reset_gpio = devm_gpiod_get(dev, "reset", GPIOD_OUT_HIGH);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	if (IS_ERR(ctx->reset_gpio)) {
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:			PTR_ERR(ctx->reset_gpio));
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		return PTR_ERR(ctx->reset_gpio);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->brightness = GAMMA_LEVEL_NUM - 1;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	drm_panel_init(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->panel.dev = dev;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ctx->panel.funcs = &s6e8aa0_drm_funcs;
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	ret = drm_panel_add(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:		drm_panel_remove(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-s6e8aa0.c:	drm_panel_remove(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	int ret = ctx->error;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->error = 0;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	struct spi_device *spi = to_spi_device(ctx->dev);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	if (ctx->error < 0 || len == 0)
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	dev_dbg(ctx->dev, "writing dcs seq: %*ph\n", (int)len, data);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:		dev_err(ctx->dev, "error %d writing dcs seq: %*ph\n", ret,
drivers/gpu/drm/panel/panel-samsung-ld9040.c:		ctx->error = ret;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ld9040_dcs_write(ctx, ld9040_gammas[ctx->brightness],
drivers/gpu/drm/panel/panel-samsung-ld9040.c:			 ARRAY_SIZE(ld9040_gammas[ctx->brightness]));
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ret = regulator_bulk_enable(ARRAY_SIZE(ctx->supplies), ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	msleep(ctx->power_on_delay);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	gpiod_set_value(ctx->reset_gpio, 0);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	msleep(ctx->reset_delay);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	gpiod_set_value(ctx->reset_gpio, 1);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	msleep(ctx->reset_delay);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	return regulator_bulk_disable(ARRAY_SIZE(ctx->supplies), ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	drm_display_mode_from_videomode(&ctx->vm, mode);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	mode->width_mm = ctx->width_mm;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	mode->height_mm = ctx->height_mm;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	struct device *dev = ctx->dev;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ret = of_get_videomode(np, &ctx->vm, 0);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	of_property_read_u32(np, "power-on-delay", &ctx->power_on_delay);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	of_property_read_u32(np, "reset-delay", &ctx->reset_delay);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	of_property_read_u32(np, "panel-width-mm", &ctx->width_mm);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	of_property_read_u32(np, "panel-height-mm", &ctx->height_mm);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->dev = dev;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->brightness = ARRAY_SIZE(ld9040_gammas) - 1;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->supplies[0].supply = "vdd3";
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->supplies[1].supply = "vci";
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ret = devm_regulator_bulk_get(dev, ARRAY_SIZE(ctx->supplies),
drivers/gpu/drm/panel/panel-samsung-ld9040.c:				      ctx->supplies);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->reset_gpio = devm_gpiod_get(dev, "reset", GPIOD_OUT_HIGH);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	if (IS_ERR(ctx->reset_gpio)) {
drivers/gpu/drm/panel/panel-samsung-ld9040.c:			PTR_ERR(ctx->reset_gpio));
drivers/gpu/drm/panel/panel-samsung-ld9040.c:		return PTR_ERR(ctx->reset_gpio);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	drm_panel_init(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->panel.dev = dev;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	ctx->panel.funcs = &ld9040_drm_funcs;
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	return drm_panel_add(&ctx->panel);
drivers/gpu/drm/panel/panel-samsung-ld9040.c:	drm_panel_remove(&ctx->panel);
drivers/gpu/drm/panel/panel-lg-lg4573.c:	dev_dbg(ctx->panel.dev, "writing data: %x\n", data);
drivers/gpu/drm/panel/panel-lg-lg4573.c:	return spi_sync(ctx->spi, &msg);
drivers/gpu/drm/panel/panel-lg-lg4573.c:	dev_dbg(ctx->panel.dev, "transfer display mode settings\n");
drivers/gpu/drm/panel/panel-lg-lg4573.c:	dev_dbg(ctx->panel.dev, "transfer power settings\n");
drivers/gpu/drm/panel/panel-lg-lg4573.c:	dev_dbg(ctx->panel.dev, "transfer gamma settings\n");
drivers/gpu/drm/panel/panel-lg-lg4573.c:	dev_dbg(ctx->panel.dev, "initializing LCD\n");
drivers/gpu/drm/panel/panel-lg-lg4573.c:	ctx->spi = spi;
drivers/gpu/drm/panel/panel-lg-lg4573.c:	drm_panel_init(&ctx->panel);
drivers/gpu/drm/panel/panel-lg-lg4573.c:	ctx->panel.dev = &spi->dev;
drivers/gpu/drm/panel/panel-lg-lg4573.c:	ctx->panel.funcs = &lg4573_drm_funcs;
drivers/gpu/drm/panel/panel-lg-lg4573.c:	return drm_panel_add(&ctx->panel);
drivers/gpu/drm/panel/panel-lg-lg4573.c:	drm_panel_remove(&ctx->panel);
drivers/gpu/drm/radeon/atom-bits.h:#define U8(ptr) get_u8(ctx->ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define CU8(ptr) get_u8(ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define U16(ptr) get_u16(ctx->ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define CU16(ptr) get_u16(ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define U32(ptr) get_u32(ctx->ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define CU32(ptr) get_u32(ctx->bios, (ptr))
drivers/gpu/drm/radeon/atom-bits.h:#define CSTR(ptr) (((char *)(ctx->bios))+(ptr))
drivers/gpu/drm/radeon/atom.c:	struct radeon_device *rdev = ctx->card->dev->dev_private;
drivers/gpu/drm/radeon/atom.c:			temp = ctx->card->ioreg_read(ctx->card, CU16(base + 1));
drivers/gpu/drm/radeon/atom.c:				(void)ctx->card->ioreg_read(ctx->card, CU16(base + 1));
drivers/gpu/drm/radeon/atom.c:			ctx->card->ioreg_write(ctx->card, CU16(base + 1), temp);
drivers/gpu/drm/radeon/atom.c:			    ((ctx->
drivers/gpu/drm/radeon/atom.c:	struct atom_context *gctx = ctx->ctx;
drivers/gpu/drm/radeon/atom.c:		idx += gctx->reg_block;
drivers/gpu/drm/radeon/atom.c:		switch (gctx->io_mode) {
drivers/gpu/drm/radeon/atom.c:			val = gctx->card->reg_read(gctx->card, idx);
drivers/gpu/drm/radeon/atom.c:			if (!(gctx->io_mode & 0x80)) {
drivers/gpu/drm/radeon/atom.c:			if (!gctx->iio[gctx->io_mode & 0x7F]) {
drivers/gpu/drm/radeon/atom.c:				       gctx->io_mode & 0x7F);
drivers/gpu/drm/radeon/atom.c:					     gctx->iio[gctx->io_mode & 0x7F],
drivers/gpu/drm/radeon/atom.c:		val = get_unaligned_le32((u32 *)&ctx->ps[idx]);
drivers/gpu/drm/radeon/atom.c:			val = gctx->divmul[0];
drivers/gpu/drm/radeon/atom.c:			val = gctx->divmul[1];
drivers/gpu/drm/radeon/atom.c:			val = gctx->data_block;
drivers/gpu/drm/radeon/atom.c:			val = gctx->shift;
drivers/gpu/drm/radeon/atom.c:			val = 1 << gctx->shift;
drivers/gpu/drm/radeon/atom.c:			val = ~(1 << gctx->shift);
drivers/gpu/drm/radeon/atom.c:			val = gctx->fb_base;
drivers/gpu/drm/radeon/atom.c:			val = gctx->io_attr;
drivers/gpu/drm/radeon/atom.c:			val = gctx->reg_block;
drivers/gpu/drm/radeon/atom.c:			val = ctx->ws[idx];
drivers/gpu/drm/radeon/atom.c:			if (gctx->data_block)
drivers/gpu/drm/radeon/atom.c:				DEBUG("ID[0x%04X+%04X]", idx, gctx->data_block);
drivers/gpu/drm/radeon/atom.c:		val = U32(idx + gctx->data_block);
drivers/gpu/drm/radeon/atom.c:		if ((gctx->fb_base + (idx * 4)) > gctx->scratch_size_bytes) {
drivers/gpu/drm/radeon/atom.c:				  gctx->fb_base + (idx * 4), gctx->scratch_size_bytes);
drivers/gpu/drm/radeon/atom.c:			val = gctx->scratch[(gctx->fb_base / 4) + idx];
drivers/gpu/drm/radeon/atom.c:		val = gctx->card->pll_read(gctx->card, idx);
drivers/gpu/drm/radeon/atom.c:		val = gctx->card->mc_read(gctx->card, idx);
drivers/gpu/drm/radeon/atom.c:	struct atom_context *gctx = ctx->ctx;
drivers/gpu/drm/radeon/atom.c:		idx += gctx->reg_block;
drivers/gpu/drm/radeon/atom.c:		switch (gctx->io_mode) {
drivers/gpu/drm/radeon/atom.c:				gctx->card->reg_write(gctx->card, idx,
drivers/gpu/drm/radeon/atom.c:				gctx->card->reg_write(gctx->card, idx, val);
drivers/gpu/drm/radeon/atom.c:			if (!(gctx->io_mode & 0x80)) {
drivers/gpu/drm/radeon/atom.c:			if (!gctx->iio[gctx->io_mode & 0xFF]) {
drivers/gpu/drm/radeon/atom.c:				       gctx->io_mode & 0x7F);
drivers/gpu/drm/radeon/atom.c:			atom_iio_execute(gctx, gctx->iio[gctx->io_mode & 0xFF],
drivers/gpu/drm/radeon/atom.c:		ctx->ps[idx] = cpu_to_le32(val);
drivers/gpu/drm/radeon/atom.c:			gctx->divmul[0] = val;
drivers/gpu/drm/radeon/atom.c:			gctx->divmul[1] = val;
drivers/gpu/drm/radeon/atom.c:			gctx->data_block = val;
drivers/gpu/drm/radeon/atom.c:			gctx->shift = val;
drivers/gpu/drm/radeon/atom.c:			gctx->fb_base = val;
drivers/gpu/drm/radeon/atom.c:			gctx->io_attr = val;
drivers/gpu/drm/radeon/atom.c:			gctx->reg_block = val;
drivers/gpu/drm/radeon/atom.c:			ctx->ws[idx] = val;
drivers/gpu/drm/radeon/atom.c:		if ((gctx->fb_base + (idx * 4)) > gctx->scratch_size_bytes) {
drivers/gpu/drm/radeon/atom.c:				  gctx->fb_base + (idx * 4), gctx->scratch_size_bytes);
drivers/gpu/drm/radeon/atom.c:			gctx->scratch[(gctx->fb_base / 4) + idx] = val;
drivers/gpu/drm/radeon/atom.c:		gctx->card->pll_write(gctx->card, idx, val);
drivers/gpu/drm/radeon/atom.c:		gctx->card->mc_write(gctx->card, idx, val);
drivers/gpu/drm/radeon/atom.c:	if (U16(ctx->ctx->cmd_table + 4 + 2 * idx))
drivers/gpu/drm/radeon/atom.c:		r = atom_execute_table_locked(ctx->ctx, idx, ctx->ps + ctx->ps_shift);
drivers/gpu/drm/radeon/atom.c:		ctx->abort = true;
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->cs_equal = (dst == src);
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->cs_above = (dst > src);
drivers/gpu/drm/radeon/atom.c:	SDEBUG("   result: %s %s\n", ctx->ctx->cs_equal ? "EQ" : "NE",
drivers/gpu/drm/radeon/atom.c:	       ctx->ctx->cs_above ? "GT" : "LE");
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->divmul[0] = dst / src;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->divmul[1] = dst % src;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->divmul[0] = 0;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->divmul[1] = 0;
drivers/gpu/drm/radeon/atom.c:		execute = ctx->ctx->cs_above;
drivers/gpu/drm/radeon/atom.c:		execute = ctx->ctx->cs_above || ctx->ctx->cs_equal;
drivers/gpu/drm/radeon/atom.c:		execute = !(ctx->ctx->cs_above || ctx->ctx->cs_equal);
drivers/gpu/drm/radeon/atom.c:		execute = !ctx->ctx->cs_above;
drivers/gpu/drm/radeon/atom.c:		execute = ctx->ctx->cs_equal;
drivers/gpu/drm/radeon/atom.c:		execute = !ctx->ctx->cs_equal;
drivers/gpu/drm/radeon/atom.c:		if (ctx->last_jump == (ctx->start + target)) {
drivers/gpu/drm/radeon/atom.c:			if (time_after(cjiffies, ctx->last_jump_jiffies)) {
drivers/gpu/drm/radeon/atom.c:				cjiffies -= ctx->last_jump_jiffies;
drivers/gpu/drm/radeon/atom.c:					ctx->abort = true;
drivers/gpu/drm/radeon/atom.c:				ctx->last_jump_jiffies = jiffies;
drivers/gpu/drm/radeon/atom.c:			ctx->last_jump = ctx->start + target;
drivers/gpu/drm/radeon/atom.c:			ctx->last_jump_jiffies = jiffies;
drivers/gpu/drm/radeon/atom.c:		*ptr = ctx->start + target;
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->divmul[0] = dst * src;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->data_block = 0;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->data_block = ctx->start;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->data_block = U16(ctx->ctx->data_table + 4 + 2 * idx);
drivers/gpu/drm/radeon/atom.c:	SDEBUG("   base: 0x%04X\n", ctx->ctx->data_block);
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->fb_base = atom_get_src(ctx, attr, ptr);
drivers/gpu/drm/radeon/atom.c:			ctx->ctx->io_mode = ATOM_IO_MM;
drivers/gpu/drm/radeon/atom.c:			ctx->ctx->io_mode = ATOM_IO_IIO | port;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->io_mode = ATOM_IO_PCI;
drivers/gpu/drm/radeon/atom.c:		ctx->ctx->io_mode = ATOM_IO_SYSIO;
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->reg_block = U16(*ptr);
drivers/gpu/drm/radeon/atom.c:	SDEBUG("   base: 0x%04X\n", ctx->ctx->reg_block);
drivers/gpu/drm/radeon/atom.c:				*ptr = ctx->start + target;
drivers/gpu/drm/radeon/atom.c:	ctx->ctx->cs_equal = ((dst & src) == 0);
drivers/gpu/drm/radeon/atom.c:	SDEBUG("   result: %s\n", ctx->ctx->cs_equal ? "EQ" : "NE");
drivers/gpu/drm/radeon/atom.c:	int base = CU16(ctx->cmd_table + 4 + 2 * index);
drivers/gpu/drm/radeon/atom.c:	mutex_lock(&ctx->mutex);
drivers/gpu/drm/radeon/atom.c:	ctx->data_block = 0;
drivers/gpu/drm/radeon/atom.c:	ctx->reg_block = 0;
drivers/gpu/drm/radeon/atom.c:	ctx->fb_base = 0;
drivers/gpu/drm/radeon/atom.c:	ctx->io_mode = ATOM_IO_MM;
drivers/gpu/drm/radeon/atom.c:	ctx->divmul[0] = 0;
drivers/gpu/drm/radeon/atom.c:	ctx->divmul[1] = 0;
drivers/gpu/drm/radeon/atom.c:	mutex_unlock(&ctx->mutex);
drivers/gpu/drm/radeon/atom.c:	mutex_lock(&ctx->scratch_mutex);
drivers/gpu/drm/radeon/atom.c:	mutex_unlock(&ctx->scratch_mutex);
drivers/gpu/drm/radeon/atom.c:	ctx->iio = kzalloc(2 * 256, GFP_KERNEL);
drivers/gpu/drm/radeon/atom.c:	if (!ctx->iio)
drivers/gpu/drm/radeon/atom.c:		ctx->iio[CU8(base + 1)] = base + 2;
drivers/gpu/drm/radeon/atom.c:	ctx->card = card;
drivers/gpu/drm/radeon/atom.c:	ctx->bios = bios;
drivers/gpu/drm/radeon/atom.c:	ctx->cmd_table = CU16(base + ATOM_ROM_CMD_PTR);
drivers/gpu/drm/radeon/atom.c:	ctx->data_table = CU16(base + ATOM_ROM_DATA_PTR);
drivers/gpu/drm/radeon/atom.c:	atom_index_iio(ctx, CU16(ctx->data_table + ATOM_DATA_IIO_PTR) + 4);
drivers/gpu/drm/radeon/atom.c:	if (!ctx->iio) {
drivers/gpu/drm/radeon/atom.c:	struct radeon_device *rdev = ctx->card->dev->dev_private;
drivers/gpu/drm/radeon/atom.c:	int hwi = CU16(ctx->data_table + ATOM_DATA_FWI_PTR);
drivers/gpu/drm/radeon/atom.c:	if (!CU16(ctx->cmd_table + 4 + 2 * ATOM_CMD_INIT))
drivers/gpu/drm/radeon/atom.c:		if (CU16(ctx->cmd_table + 4 + 2 * ATOM_CMD_SPDFANCNTL))
drivers/gpu/drm/radeon/atom.c:	kfree(ctx->iio);
drivers/gpu/drm/radeon/atom.c:	int idx = CU16(ctx->data_table + offset);
drivers/gpu/drm/radeon/atom.c:	u16 *mdt = (u16 *)(ctx->bios + ctx->data_table + 4);
drivers/gpu/drm/radeon/atom.c:	int idx = CU16(ctx->cmd_table + offset);
drivers/gpu/drm/radeon/atom.c:	u16 *mct = (u16 *)(ctx->bios + ctx->cmd_table + 4);
drivers/gpu/drm/radeon/atom.c:		firmware_usage = (struct _ATOM_VRAM_USAGE_BY_FIRMWARE *)(ctx->bios + data_offset);
drivers/gpu/drm/radeon/atom.c:	ctx->scratch_size_bytes = 0;
drivers/gpu/drm/radeon/atom.c:	ctx->scratch = kzalloc(usage_bytes, GFP_KERNEL);
drivers/gpu/drm/radeon/atom.c:	if (!ctx->scratch)
drivers/gpu/drm/radeon/atom.c:	ctx->scratch_size_bytes = usage_bytes;
drivers/gpu/drm/radeon/radeon_atombios.c:		i2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:		i2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:		gpio_info = (struct _ATOM_GPIO_PIN_LUT *)(ctx->bios + data_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:	obj_header = (ATOM_OBJECT_HEADER *) (ctx->bios + data_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:		(ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:							 *) (ctx->bios + igp_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:						    (ctx->bios + data_offset +
drivers/gpu/drm/radeon/radeon_atombios.c:			xtmds = (ATOM_XTMDS_INFO *)(ctx->bios + data_offset);
drivers/gpu/drm/radeon/radeon_atombios.c:	    (union atom_supported_devices *)(ctx->bios + data_offset);
drivers/gpu/drm/drm_modeset_lock.c:	ww_acquire_init(&ctx->ww_ctx, &crtc_ww_class);
drivers/gpu/drm/drm_modeset_lock.c:	INIT_LIST_HEAD(&ctx->locked);
drivers/gpu/drm/drm_modeset_lock.c:	ww_acquire_fini(&ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:	WARN_ON(ctx->contended);
drivers/gpu/drm/drm_modeset_lock.c:	while (!list_empty(&ctx->locked)) {
drivers/gpu/drm/drm_modeset_lock.c:		lock = list_first_entry(&ctx->locked,
drivers/gpu/drm/drm_modeset_lock.c:	WARN_ON(ctx->contended);
drivers/gpu/drm/drm_modeset_lock.c:	if (ctx->trylock_only) {
drivers/gpu/drm/drm_modeset_lock.c:		lockdep_assert_held(&ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:		ret = ww_mutex_lock_slow_interruptible(&lock->mutex, &ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:		ret = ww_mutex_lock_interruptible(&lock->mutex, &ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:		ww_mutex_lock_slow(&lock->mutex, &ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:		ret = ww_mutex_lock(&lock->mutex, &ctx->ww_ctx);
drivers/gpu/drm/drm_modeset_lock.c:		list_add(&lock->head, &ctx->locked);
drivers/gpu/drm/drm_modeset_lock.c:		ctx->contended = lock;
drivers/gpu/drm/drm_modeset_lock.c:	struct drm_modeset_lock *contended = ctx->contended;
drivers/gpu/drm/drm_modeset_lock.c:	ctx->contended = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_shader.c:				  shader->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_shader.c:	cmd->body.cid = shader->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_shader.c:	cmd->body.cid = shader->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_shader.c:	struct vmw_private *dev_priv = ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_so.c:				  view->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_so.c:	cmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), view->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_so.c:	struct vmw_private *dev_priv = ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_resource.c:	dev_priv     = dx_query_ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_resource.c:	cmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), dx_query_ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_resource.c:	cmd->body.cid    = dx_query_ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_cotable.c:	WARN_ON(vcotbl->ctx->id == SVGA3D_INVALID_ID);
drivers/gpu/drm/vmwgfx/vmwgfx_cotable.c:	cmd->body.cid = vcotbl->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_cotable.c:		cmd0->body.cid = vcotbl->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_cotable.c:	cmd1->body.cid = vcotbl->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_cotable.c:		cmd->body.cid = vcotbl->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c:		ret = vmw_fifo_emit_dummy_query(dev_priv, ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c:			dev_priv->query_cid = sw_context->last_query_ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd->body.cid = bi->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd->body.cid = bi->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd->body.c.cid = bi->ctx->id;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), bi->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), bi->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(ctx->dev_priv, cmd_size, ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	vmw_fifo_commit(ctx->dev_priv, cmd_size);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(ctx->dev_priv, cmd_size, ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	vmw_fifo_commit(ctx->dev_priv, cmd_size);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(ctx->dev_priv, cmd_size, ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	vmw_fifo_commit(ctx->dev_priv, cmd_size);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(ctx->dev_priv, cmd_size, ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	vmw_fifo_commit(ctx->dev_priv, cmd_size);
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	struct vmw_private *dev_priv = bi->ctx->dev_priv;
drivers/gpu/drm/vmwgfx/vmwgfx_binding.c:	cmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), bi->ctx->id);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		spin_lock(&uctx->cotable_lock);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		res = uctx->cotables[i];
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		uctx->cotables[i] = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		spin_unlock(&uctx->cotable_lock);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		vmw_cmdbuf_res_man_destroy(uctx->man);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		vmw_binding_state_kill(uctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		uctx->man = vmw_cmdbuf_res_man_create(dev_priv);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		if (IS_ERR(uctx->man)) {
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			ret = PTR_ERR(uctx->man);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			uctx->man = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	uctx->cbs = vmw_binding_state_alloc(dev_priv);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	if (IS_ERR(uctx->cbs)) {
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		ret = PTR_ERR(uctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	spin_lock_init(&uctx->cotable_lock);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			uctx->cotables[i] = vmw_cotable_alloc(dev_priv,
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:							      &uctx->res, i);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			if (unlikely(uctx->cotables[i] == NULL)) {
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	vmw_binding_state_scrub(uctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	vmw_binding_state_scrub(uctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		spin_lock(&uctx->cotable_lock);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		res = uctx->cotables[vmw_cotable_scrub_order[i]];
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		spin_unlock(&uctx->cotable_lock);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	if (uctx->dx_query_mob && uctx->dx_query_mob->dx_query_ctx &&
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		WARN_ON(uctx->dx_query_mob->dx_query_ctx != res);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		if (vmw_query_readback_all(uctx->dx_query_mob))
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	if (ctx->cbs)
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		vmw_binding_state_free(ctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	struct vmw_resource *res = &ctx->res;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	res = &ctx->res;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	ctx->base.shareable = false;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	ctx->base.tfile = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	tmp = vmw_resource_reference(&ctx->res);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	ret = ttm_base_object_init(tfile, &ctx->base, false, VMW_RES_CONTEXT,
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	arg->cid = ctx->base.hash.key;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	return vmw_binding_state_list(uctx->cbs);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		if (uctx->dx_query_mob) {
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			uctx->dx_query_mob->dx_query_ctx = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			vmw_dmabuf_unreference(&uctx->dx_query_mob);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:			uctx->dx_query_mob = NULL;
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	if (uctx->dx_query_mob && uctx->dx_query_mob != mob)
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	if (!uctx->dx_query_mob)
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:		uctx->dx_query_mob = vmw_dmabuf_reference(mob);
drivers/gpu/drm/vmwgfx/vmwgfx_context.c:	return uctx->dx_query_mob;
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	INIT_LIST_HEAD(&ctx->hw_submitted);
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	INIT_LIST_HEAD(&ctx->submitted);
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	INIT_LIST_HEAD(&ctx->preempted);
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	ctx->num_hw_submitted = 0;
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	while (ctx->num_hw_submitted < man->max_hw_submitted &&
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	      !list_empty(&ctx->submitted)) {
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		entry = list_first_entry(&ctx->submitted,
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		list_add_tail(&entry->list, &ctx->hw_submitted);
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		ctx->num_hw_submitted++;
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	list_for_each_entry_safe(entry, next, &ctx->hw_submitted, list) {
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		ctx->num_hw_submitted--;
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:			list_add(&entry->list, &ctx->preempted);
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:	if (!list_empty(&ctx->submitted))
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		if (!list_empty(&ctx->submitted) ||
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		    !list_empty(&ctx->hw_submitted) ||
drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c:		    (check_preempted && !list_empty(&ctx->preempted)))
drivers/gpu/drm/msm/msm_fence.c:	fctx->dev = dev;
drivers/gpu/drm/msm/msm_fence.c:	fctx->name = name;
drivers/gpu/drm/msm/msm_fence.c:	fctx->context = fence_context_alloc(1);
drivers/gpu/drm/msm/msm_fence.c:	init_waitqueue_head(&fctx->event);
drivers/gpu/drm/msm/msm_fence.c:	spin_lock_init(&fctx->spinlock);
drivers/gpu/drm/msm/msm_fence.c:	return (int32_t)(fctx->completed_fence - fence) >= 0;
drivers/gpu/drm/msm/msm_fence.c:	if (fence > fctx->last_fence) {
drivers/gpu/drm/msm/msm_fence.c:				fctx->name, fence, fctx->last_fence);
drivers/gpu/drm/msm/msm_fence.c:			ret = wait_event_interruptible_timeout(fctx->event,
drivers/gpu/drm/msm/msm_fence.c:			ret = wait_event_timeout(fctx->event,
drivers/gpu/drm/msm/msm_fence.c:					fence, fctx->completed_fence);
drivers/gpu/drm/msm/msm_fence.c:	spin_lock(&fctx->spinlock);
drivers/gpu/drm/msm/msm_fence.c:	fctx->completed_fence = max(fence, fctx->completed_fence);
drivers/gpu/drm/msm/msm_fence.c:	spin_unlock(&fctx->spinlock);
drivers/gpu/drm/msm/msm_fence.c:	wake_up_all(&fctx->event);
drivers/gpu/drm/msm/msm_fence.c:	return f->fctx->name;
drivers/gpu/drm/msm/msm_fence.c:	fence_init(&f->base, &msm_fence_ops, &fctx->spinlock,
drivers/gpu/drm/msm/msm_fence.c:			fctx->context, ++fctx->last_fence);
drivers/gpu/drm/msm/msm_gem_submit.c:		if (in_fence->context != gpu->fctx->context) {
drivers/gpu/drm/msm/msm_gem.c:		if (fence && (fence->context != fctx->context)) {
drivers/gpu/drm/msm/msm_gem.c:		if (fence->context != fctx->context) {
drivers/gpu/drm/msm/msm_gpu.h:	return gpu->fctx->last_fence > gpu->funcs->last_fence(gpu);
drivers/gpu/drm/msm/msm_gpu.c:	} else if (fence < gpu->fctx->last_fence) {
drivers/gpu/drm/msm/msm_gpu.c:				gpu->name, gpu->fctx->last_fence);
drivers/gpu/drm/msm/msm_gpu.c:	if (gpu->fctx->last_fence > gpu->hangcheck_fence)
drivers/gpu/drm/msm/adreno/adreno_gpu.c:	adreno_gpu->memptrs->fence = gpu->fctx->completed_fence;
drivers/gpu/drm/msm/adreno/adreno_gpu.c:			gpu->fctx->last_fence);
drivers/gpu/drm/msm/adreno/adreno_gpu.c:			gpu->fctx->last_fence);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	SDE_REG_WRITE(&ctx->hw, CTL_START, 0x1);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	return SDE_REG_READ(&ctx->hw, CTL_START);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	SDE_REG_WRITE(&ctx->hw, CTL_PREPARE, 0x1);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	if (CTL_FLUSH_MASK_ROT & ctx->pending_flush_mask) {
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		ctx->pending_flush_mask &= ~CTL_FLUSH_MASK_ROT;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		SDE_REG_WRITE(&ctx->hw, CTL_FLUSH, CTL_FLUSH_MASK_ROT);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	SDE_REG_WRITE(&ctx->hw, CTL_ROT_START, BIT(0));
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	ctx->pending_flush_mask = 0x0;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	ctx->pending_flush_mask |= flushbits;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	return ctx->pending_flush_mask;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	SDE_REG_WRITE(&ctx->hw, CTL_FLUSH, ctx->pending_flush_mask);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	return (u32)SDE_REG_READ(&ctx->hw, CTL_SW_RESET);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	pr_debug("issuing hw ctl reset for ctl:%d\n", ctx->idx - CTL_0);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:			ctx->idx - CTL_0, enable);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	pr_debug("hw ctl reset is set for ctl:%d\n", ctx->idx);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		pr_err("hw recovery is not complete for ctl:%d\n", ctx->idx);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	for (i = 0; i < ctx->mixer_count; i++) {
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		int mixer_id = ctx->mixer_hw_caps[i].id;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	stages = _mixer_stages(ctx->mixer_hw_caps, ctx->mixer_count, lm);
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		&ctx->mixer_hw_caps->features))
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_ctl.c:		sde_hw_blk_destroy(&ctx->base);
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:				!(ctx->caps->features & BIT(SDE_WB_PIPE_ALPHA)))
drivers/gpu/drm/msm/sde/sde_hw_wb.c:			(ctx->caps->features & BIT(SDE_WB_YUV_CONFIG)))
drivers/gpu/drm/msm/sde/sde_hw_wb.c:		write_config |= (ctx->mdp->highest_bank_bit << 8);
drivers/gpu/drm/msm/sde/sde_hw_wb.c:		if (IS_UBWC_20_SUPPORTED(ctx->catalog->ubwc_version))
drivers/gpu/drm/msm/sde/sde_hw_wb.c:					(ctx->mdp->ubwc_swizzle << 0) |
drivers/gpu/drm/msm/sde/sde_hw_wb.c:					(ctx->mdp->highest_bank_bit << 4));
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	if (ctx->caps && test_bit(SDE_WB_QOS_8LVL, &ctx->caps->features)) {
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_wb.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_intf.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_intf.c:	if (ctx->cap->type == INTF_EDP || ctx->cap->type == INTF_DP) {
drivers/gpu/drm/msm/sde/sde_hw_intf.c:	if (ctx->cap->type == INTF_HDMI) {
drivers/gpu/drm/msm/sde/sde_fence.c:	return f->ctx->name;
drivers/gpu/drm/msm/sde/sde_fence.c:	status = (int)(fence->seqno - f->ctx->done_count) <= 0 ? true : false;
drivers/gpu/drm/msm/sde/sde_fence.c:			status, fence->seqno, f->ctx->done_count);
drivers/gpu/drm/msm/sde/sde_fence.c:	snprintf(str, size, "%d", f->ctx->done_count);
drivers/gpu/drm/msm/sde/sde_fence.c:						sde_fence->ctx->name, val);
drivers/gpu/drm/msm/sde/sde_fence.c:	fence_init(&sde_fence->base, &sde_fence_ops, &ctx->lock,
drivers/gpu/drm/msm/sde/sde_fence.c:		ctx->context, val);
drivers/gpu/drm/msm/sde/sde_fence.c:	kref_get(&ctx->kref);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	list_add_tail(&sde_fence->fence_list, &ctx->fence_list_head);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_unlock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	strlcpy(ctx->name, name, ARRAY_SIZE(ctx->name));
drivers/gpu/drm/msm/sde/sde_fence.c:	ctx->drm_id = drm_id;
drivers/gpu/drm/msm/sde/sde_fence.c:	kref_init(&ctx->kref);
drivers/gpu/drm/msm/sde/sde_fence.c:	ctx->context = fence_context_alloc(1);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock_init(&ctx->lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock_init(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	INIT_LIST_HEAD(&ctx->fence_list_head);
drivers/gpu/drm/msm/sde/sde_fence.c:	kref_put(&ctx->kref, sde_fence_destroy);
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_lock_irqsave(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:		++ctx->commit_count;
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	if (list_empty(&ctx->fence_list_head)) {
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_unlock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	list_for_each_entry_safe(fc, next, &ctx->fence_list_head, fence_list)
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_unlock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_lock_irqsave(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:			kref_put(&ctx->kref, sde_fence_destroy);
drivers/gpu/drm/msm/sde/sde_fence.c:			spin_lock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:			list_move(&fc->fence_list, &ctx->fence_list_head);
drivers/gpu/drm/msm/sde/sde_fence.c:			spin_unlock(&ctx->list_lock);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:	trigger_value = ctx->commit_count + offset;
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:				fd, trigger_value, ctx->commit_count, offset);
drivers/gpu/drm/msm/sde/sde_fence.c:	SDE_EVT32(ctx->drm_id, trigger_value, fd);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:		if ((int)(ctx->done_count - ctx->commit_count) < 0) {
drivers/gpu/drm/msm/sde/sde_fence.c:				ctx->done_count, ctx->commit_count);
drivers/gpu/drm/msm/sde/sde_fence.c:			ctx->done_count = ctx->commit_count;
drivers/gpu/drm/msm/sde/sde_fence.c:			SDE_EVT32(ctx->drm_id, ctx->done_count,
drivers/gpu/drm/msm/sde/sde_fence.c:				ctx->commit_count, ktime_to_us(ts),
drivers/gpu/drm/msm/sde/sde_fence.c:			spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:	} else if ((int)(ctx->done_count - ctx->commit_count) < 0) {
drivers/gpu/drm/msm/sde/sde_fence.c:		++ctx->done_count;
drivers/gpu/drm/msm/sde/sde_fence.c:					ctx->done_count, ctx->commit_count);
drivers/gpu/drm/msm/sde/sde_fence.c:					ctx->done_count, ctx->commit_count);
drivers/gpu/drm/msm/sde/sde_fence.c:		SDE_EVT32(ctx->drm_id, ctx->done_count, ctx->commit_count,
drivers/gpu/drm/msm/sde/sde_fence.c:		spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/msm/sde/sde_fence.c:	SDE_EVT32(ctx->drm_id, ctx->done_count, ctx->commit_count,
drivers/gpu/drm/msm/sde/sde_fence.c:		obj_name, drm_obj->id, drm_obj->type, ctx->done_count,
drivers/gpu/drm/msm/sde/sde_fence.c:		ctx->commit_count);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	const struct sde_sspp_sub_blks *sblk = ctx->cap->sblk;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		mode_mask = SDE_REG_READ(&ctx->hw, SSPP_MULTIRECT_OPMODE + idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_MULTIRECT_OPMODE + idx, mode_mask);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (!test_bit(SDE_SSPP_SCALER_QSEED2, &ctx->cap->features) ||
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		!test_bit(SDE_SSPP_CSC, &ctx->cap->features))
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	opmode = SDE_REG_READ(&ctx->hw, SSPP_VIG_OP_MODE + idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_VIG_OP_MODE + idx, opmode);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	opmode = SDE_REG_READ(&ctx->hw, SSPP_VIG_CSC_10_OP_MODE + idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_VIG_CSC_10_OP_MODE + idx, opmode);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:			ctx->mdp->highest_bank_bit << 18);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		if (IS_UBWC_20_SUPPORTED(ctx->catalog->ubwc_version)) {
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:				alpha_en_mask | (ctx->mdp->ubwc_swizzle) |
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:				(ctx->mdp->highest_bank_bit << 4));
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (test_bit(SDE_SSPP_CSC, &ctx->cap->features))
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	else if (test_bit(SDE_SSPP_CSC_10BIT, &ctx->cap->features))
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		|| !scaler3_cfg || !ctx || !ctx->cap || !ctx->cap->sblk)
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	sde_hw_setup_scaler3(&ctx->hw, scaler3_cfg, idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:			ctx->cap->sblk->scaler_blk.version,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	return sde_hw_get_scaler3_ver(&ctx->hw, idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (ctx->cap->features & SDE_SSPP_SCALER) {
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:			SDE_REG_WRITE(&ctx->hw, SSPP_SRC0_ADDR + idx + i * 0x4,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC0_ADDR + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC2_ADDR + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC1_ADDR + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC3_ADDR + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (test_bit(SDE_SSPP_CSC_10BIT, &ctx->cap->features)) {
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	sde_hw_csc_setup(&ctx->hw, idx, data, csc10);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:			!test_bit(SDE_SSPP_SCALER_QSEED2, &ctx->cap->features))
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC_CONSTANT_COLOR + idx, color);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_SRC_CONSTANT_COLOR_REC1 + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_DANGER_LUT + idx, cfg->danger_lut);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_SAFE_LUT + idx, cfg->safe_lut);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (ctx->cap && test_bit(SDE_SSPP_QOS_8LVL, &ctx->cap->features)) {
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_CREQ_LUT_0 + idx, cfg->creq_lut);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_CREQ_LUT_1 + idx,
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		SDE_REG_WRITE(&ctx->hw, SSPP_CREQ_LUT + idx, cfg->creq_lut);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_QOS_CTRL + idx, qos_ctrl);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, SSPP_SYS_CACHE_MODE + idx, val);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	val = SDE_REG_READ(&ctx->hw, SSPP_SBUF_STATUS_PLANE0 + idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	val = SDE_REG_READ(&ctx->hw, SSPP_SBUF_STATUS_PLANE1 + idx);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	if (!ctx || !cfg || !ctx->cap)
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	cap = ctx->cap;
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, ts_offset, ts_bytes);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, ts_prefill_offset, ts_count);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:	SDE_REG_WRITE(&ctx->hw, cdp_cntl_offset, cdp_cntl);
drivers/gpu/drm/msm/sde/sde_hw_sspp.c:		sde_hw_blk_destroy(&ctx->base);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("r_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("r_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("r_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("g_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("g_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("g_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("b_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("b_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			printk("b_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->c: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_C_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->r: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_R_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->g: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_G_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->b: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_B_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->rg: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RG_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->rb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RB_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->gb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_GB_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		printk("coeffs->rgb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RGB_OFF));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:	printk("PCC_EN: %d\n", SDE_REG_READ(&ctx->hw, ctx->cap->sblk->pcc.base));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		//SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, coeffs->c);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, red);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, green);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, blue);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		//SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, coeffs->rg);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		//SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, coeffs->rb);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		//SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, coeffs->gb);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:		//SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, coeffs->rgb);
drivers/gpu/drm/msm/sde/sde_hw_dspp.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:	sde_hw_csc_setup(&ctx->hw, CDM_CSC_10_MATRIX_COEFF_0, data, true);
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:	if (ctx->hw_mdp && ctx->hw_mdp->ops.setup_cdm_output)
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:		ctx->hw_mdp->ops.setup_cdm_output(ctx->hw_mdp, &cdm_cfg);
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:	if (ctx->hw_mdp && ctx->hw_mdp->ops.setup_cdm_output)
drivers/gpu/drm/msm/sde/sde_hw_cdm.c:		ctx->hw_mdp->ops.setup_cdm_output(ctx->hw_mdp, &cdm_cfg);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	if (!hw_cfg->ctl || ctx->idx >= DSPP_MAX ||
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			hw_cfg->ctl, ctx->idx, feature);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	if (!dspp_buf[feature][ctx->idx]) {
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	op_mode = SDE_REG_READ(&ctx->hw, PA_OP_MODE_OFF);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SDE_REG_WRITE(&ctx->hw, PA_LUTV_OPMODE_OFF, 0);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SDE_REG_WRITE(&ctx->hw, PA_OP_MODE_OFF, op_mode);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	rc = reg_dma_blk_select(VLUT, dspp_mapping[ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[VLUT][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	rc = reg_dma_write(REG_BLK_WRITE_SINGLE, ctx->cap->sblk->vlut.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[VLUT][ctx->idx], VLUT,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_mapping[ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[VLUT][ctx->idx], hw_cfg->ctl);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	SDE_REG_WRITE(&ctx->hw, PA_LUTV_OPMODE_OFF, BIT(0));
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	SDE_REG_WRITE(&ctx->hw, PA_OP_MODE_OFF, op_mode | BIT(20));
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[GAMUT][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], GAMUT,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[GAMUT][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->gamut.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[GAMUT][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	op_mode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->gamut.base);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[GAMUT][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], GAMUT,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[GAMUT][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->gamut.base + GAMUT_TABLE_SEL_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		    ctx->cap->sblk->gamut.base + GAMUT_LOWER_COLOR_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			scale_tbl_off = ctx->cap->sblk->gamut.base + scale_off +
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->gamut.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[GAMUT][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gc.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[GC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], GC,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			dspp_buf[GC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->gc.base + GC_C0_INDEX_OFF +
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->gc.base + GC_C0_OFF +
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->gc.base + GC_LUT_SWAP_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->gc.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[GC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[IGC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], IGC,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		dspp_buf[IGC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->igc.base + IGC_OPMODE_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[IGC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[IGC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, DSPP_IGC, IGC, dspp_buf[IGC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			addr[j] |= IGC_DSPP_SEL_MASK(ctx->idx - 1);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], IGC,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		dspp_buf[IGC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->igc.base + IGC_DITHER_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->igc.base + IGC_OPMODE_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[IGC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[PCC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx], PCC,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		dspp_buf[PCC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->pcc.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[PCC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[PCC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		PCC, dspp_buf[PCC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->pcc.base + PCC_C_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->pcc.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[PCC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[HSIC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		HSIC, dspp_buf[HSIC][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->hsic.base + PA_HUE_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->hsic.base + PA_SAT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->hsic.base + PA_VAL_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			ctx->cap->sblk->hsic.base + PA_CONT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_SETUP_KICKOFF(kick_off, hw_cfg->ctl, dspp_buf[HSIC][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	dma_ops->reset_reg_dma_buf(dspp_buf[SIX_ZONE][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	REG_DMA_INIT_OPS(dma_write_cfg, dspp_mapping[ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		SIX_ZONE, dspp_buf[SIX_ZONE][ctx->idx]);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->sixzone.base,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	    (ctx->cap->sblk->sixzone.base + SIXZONE_ADJ_CURVE_P1_OFF),
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		ctx->cap->sblk->sixzone.base + SIXZONE_THRESHOLDS_OFF,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:		dspp_buf[SIX_ZONE][ctx->idx],
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	hold = SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			(ctx->cap->sblk->hsic.base + PA_PWL_HOLD_OFF));
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:			(ctx->cap->sblk->hsic.base + PA_PWL_HOLD_OFF), hold);
drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	const struct sde_lm_sub_blks *sblk = ctx->cap->sblk;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	const struct sde_lm_sub_blks *sblk = ctx->cap->sblk;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_hw_lm.c:	struct sde_hw_blk_reg_map *c = &ctx->hw;
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("r_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("r_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("r_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("g_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("g_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("g_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("b_rr: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("b_gg: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				printk("b_bb: %d\n", SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->c: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_C_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->r: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_R_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->g: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_G_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->b: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_B_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->rg: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RG_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->rb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RB_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->gb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_GB_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			printk("coeffs->rgb: %d\n", SDE_REG_READ(&ctx->hw, base + PCC_RGB_OFF));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	printk("PCC_EN: %d\n", SDE_REG_READ(&ctx->hw, ctx->cap->sblk->pcc.base));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	base = ctx->hw.base_off + ctx->cap->base;
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		      ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		      ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		      ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		      ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, DSPP_OP_PCC_ENABLE);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:			base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:				SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, 255);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, red);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, green);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, blue);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, red);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, green);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, blue);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, 100);
drivers/gpu/drm/msm/sde/sde_color_processing.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	op_mode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->gamut.base);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gamut.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	sde_write_3d_gamut(&ctx->hw, payload, ctx->cap->sblk->gamut.base,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, IGC_OPMODE_OFF, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			addr[j] |= IGC_DSPP_SEL_MASK(ctx->idx - 1);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw_top, offset, addr[j]);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, IGC_DITHER_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, IGC_OPMODE_OFF, IGC_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, coeffs->c);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, coeffs->rg);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, coeffs->rb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, coeffs->gb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, coeffs->rgb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_HUE_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, PA_HUE_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_SAT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, PA_SAT_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_VAL_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, PA_VAL_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_CONT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, PA_CONT_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_hue(&ctx->hw, &ctx->cap->sblk->hsic_blk, hue, SSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_sat(&ctx->hw, &ctx->cap->sblk->hsic_blk, sat, SSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_val(&ctx->hw, &ctx->cap->sblk->hsic_blk, value, SSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_cont(&ctx->hw, &ctx->cap->sblk->hsic_blk, contrast, SSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_hue(&ctx->hw, &ctx->cap->sblk->hsic, hue, DSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_sat(&ctx->hw, &ctx->cap->sblk->hsic, sat, DSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_val(&ctx->hw, &ctx->cap->sblk->hsic, val, DSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	__setup_pa_cont(&ctx->hw, &ctx->cap->sblk->hsic, cont, DSPP);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->sixzone.base, reg);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	addr = ctx->cap->sblk->sixzone.base + DSPP_SZ_ADJ_CURVE_P1_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, addr, sixzone->curve[i].p1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, (addr - 4), sixzone->curve[i].p0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	addr = ctx->cap->sblk->sixzone.base + DSPP_SZ_THRESHOLDS_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, sixzone->threshold);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (addr + 4), sixzone->adjust_p0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (addr + 8), sixzone->adjust_p1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	hold = SDE_REG_READ(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		(ctx->cap->sblk->hsic.base + DSPP_PA_PWL_HOLD_OFF));
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		(ctx->cap->sblk->hsic.base + DSPP_PA_PWL_HOLD_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	u32 base = ctx->cap->sblk->memcolor_blk.base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	op = SDE_REG_READ(&ctx->hw, base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, base, op);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_PWL0_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_PWL1_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_HUE_REGION_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_SAT_REGION_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_VAL_REGION_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_PWL2_OFF),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_BLEND_GAIN_OFF), mc->blend_gain);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	hold = SDE_REG_READ(&ctx->hw, off + MEMCOL_PWL_HOLD_OFF);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (off + MEMCOL_PWL_HOLD_OFF), hold);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, base, op);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	addr = ctx->cap->sblk->memcolor.base + offset;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->color_adjust_p0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->color_adjust_p1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->hue_region);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->sat_region);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->val_region);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	addr = ctx->cap->sblk->memcolor.base + offset;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->color_adjust_p2);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, memcolor->blend_gain);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	addr = ctx->cap->sblk->hsic.base + DSPP_PA_PWL_HOLD_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	hold = SDE_REG_READ(&ctx->hw, addr);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, addr, hold);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	opcode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->hsic.base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, opcode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	base = ctx->hw.base_off + ctx->cap->base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		      ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		      ctx->cap->sblk->pcc.base + PCC_CONST_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_R_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_G_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_B_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RG_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_GB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		      ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF + 4,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		      ctx->cap->sblk->pcc.base + PCC_RGB_COEFF_OFF + 8,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, DSPP_OP_PCC_ENABLE);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	u32 base = ctx->cap->sblk->vlut.base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	op_mode = SDE_REG_READ(&ctx->hw, base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, base, op_mode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, (offset + j),
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, (base + PA_LUT_SWAP_OFF), 1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, base, op_mode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	vlut_base = ctx->cap->sblk->vlut.base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	pa_hist_base = ctx->cap->sblk->hist.base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctrl_off, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, (vlut_base + j), tmp);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctrl_off, 1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, swap_off, 1);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		ctl->ops.get_bitmask_dspp_pavlut(ctl, &flush_mask, ctx->idx);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gc.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	c0_off = ctx->cap->sblk->gc.base + PGC_C0_INDEX_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, c0_off, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, c1_off, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, c2_off, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	c0_off = ctx->cap->sblk->gc.base + PGC_C0_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, c0_off, payload->c0[i]);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, c1_off, payload->c1[i]);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		SDE_REG_WRITE(&ctx->hw, c2_off, payload->c2[i]);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gc.base + PGC_LUT_SWAP_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gc.base, i);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	base = ctx->cap->sblk->hist.base;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	op_mode = SDE_REG_READ(&ctx->hw, base);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, offset, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, base, op_mode);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	offset = ctx->cap->sblk->hist.base + PA_HIST_DATA_DSPP_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	offset_ctl = ctx->cap->sblk->hist.base + PA_HIST_CTRL_DSPP_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:		hist_data->data[i] = SDE_REG_READ(&ctx->hw, offset + i * 4) &
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, offset_ctl, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	offset_ctl = ctx->cap->sblk->hist.base + PA_HIST_CTRL_DSPP_OFF;
drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.c:	SDE_REG_WRITE(&ctx->hw, offset_ctl, 1);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	op_mode = SDE_REG_READ(&ctx->hw, ctx->cap->sblk->gamut.base);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->gamut.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	sde_write_3d_gamut(&ctx->hw, payload, ctx->cap->sblk->gamut.base,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, IGC_OPMODE_OFF, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			addr[j] |= IGC_DSPP_SEL_MASK(ctx->idx - 1);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw_top, offset, addr[j]);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, IGC_DITHER_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, IGC_OPMODE_OFF, IGC_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, 0);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		base = ctx->cap->sblk->pcc.base + (i * sizeof(u32));
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:			SDE_REG_WRITE(&ctx->hw,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, coeffs->c);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, coeffs->rg);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, coeffs->rb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, coeffs->gb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, coeffs->rgb);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_HUE_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_SAT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_VAL_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base + PA_CONT_OFF,
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.c~:	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->hsic.base, PA_EN);
drivers/gpu/drm/nouveau/nv84_fence.c:	return fctx->dispc_vma[crtc].offset;
drivers/gpu/drm/nouveau/nv84_fence.c:		addr += fctx->vma_gart.offset;
drivers/gpu/drm/nouveau/nv84_fence.c:		addr += fctx->vma.offset;
drivers/gpu/drm/nouveau/nv84_fence.c:	return fctx->base.emit32(chan, addr, fence->base.seqno);
drivers/gpu/drm/nouveau/nv84_fence.c:		addr += fctx->vma_gart.offset;
drivers/gpu/drm/nouveau/nv84_fence.c:		addr += fctx->vma.offset;
drivers/gpu/drm/nouveau/nv84_fence.c:	return fctx->base.sync32(chan, addr, fence->base.seqno);
drivers/gpu/drm/nouveau/nv84_fence.c:		nouveau_bo_vma_del(bo, &fctx->dispc_vma[i]);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_bo_wr32(priv->bo, chan->chid * 16 / 4, fctx->base.sequence);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_bo_vma_del(priv->bo, &fctx->vma_gart);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_bo_vma_del(priv->bo, &fctx->vma);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_fence_context_del(&fctx->base);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_fence_context_free(&fctx->base);
drivers/gpu/drm/nouveau/nv84_fence.c:	nouveau_fence_context_new(chan, &fctx->base);
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.emit = nv84_fence_emit;
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.sync = nv84_fence_sync;
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.read = nv84_fence_read;
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.emit32 = nv84_fence_emit32;
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.sync32 = nv84_fence_sync32;
drivers/gpu/drm/nouveau/nv84_fence.c:	fctx->base.sequence = nv84_fence_read(chan);
drivers/gpu/drm/nouveau/nv84_fence.c:	ret = nouveau_bo_vma_add(priv->bo, cli->vm, &fctx->vma);
drivers/gpu/drm/nouveau/nv84_fence.c:					&fctx->vma_gart);
drivers/gpu/drm/nouveau/nv84_fence.c:		ret = nouveau_bo_vma_add(bo, cli->vm, &fctx->dispc_vma[i]);
drivers/gpu/drm/nouveau/nv17_fence.c:		OUT_RING  (prev, fctx->sema.handle);
drivers/gpu/drm/nouveau/nv17_fence.c:		OUT_RING  (chan, fctx->sema.handle);
drivers/gpu/drm/nouveau/nv17_fence.c:	nouveau_fence_context_new(chan, &fctx->base);
drivers/gpu/drm/nouveau/nv17_fence.c:	fctx->base.emit = nv10_fence_emit;
drivers/gpu/drm/nouveau/nv17_fence.c:	fctx->base.read = nv10_fence_read;
drivers/gpu/drm/nouveau/nv17_fence.c:	fctx->base.sync = nv17_fence_sync;
drivers/gpu/drm/nouveau/nv17_fence.c:			       &fctx->sema);
drivers/gpu/drm/nouveau/nvc0_fence.c:		fctx->base.emit32 = nvc0_fence_emit32;
drivers/gpu/drm/nouveau/nvc0_fence.c:		fctx->base.sync32 = nvc0_fence_sync32;
drivers/gpu/drm/nouveau/nv10_fence.c:	nouveau_fence_context_del(&fctx->base);
drivers/gpu/drm/nouveau/nv10_fence.c:	for (i = 0; i < ARRAY_SIZE(fctx->head); i++)
drivers/gpu/drm/nouveau/nv10_fence.c:		nvif_object_fini(&fctx->head[i]);
drivers/gpu/drm/nouveau/nv10_fence.c:	nvif_object_fini(&fctx->sema);
drivers/gpu/drm/nouveau/nv10_fence.c:	nouveau_fence_context_free(&fctx->base);
drivers/gpu/drm/nouveau/nv10_fence.c:	nouveau_fence_context_new(chan, &fctx->base);
drivers/gpu/drm/nouveau/nv10_fence.c:	fctx->base.emit = nv10_fence_emit;
drivers/gpu/drm/nouveau/nv10_fence.c:	fctx->base.read = nv10_fence_read;
drivers/gpu/drm/nouveau/nv10_fence.c:	fctx->base.sync = nv10_fence_sync;
drivers/gpu/drm/nouveau/nv04_fence.c:	nouveau_fence_context_del(&fctx->base);
drivers/gpu/drm/nouveau/nv04_fence.c:	nouveau_fence_context_free(&fctx->base);
drivers/gpu/drm/nouveau/nv04_fence.c:		nouveau_fence_context_new(chan, &fctx->base);
drivers/gpu/drm/nouveau/nv04_fence.c:		fctx->base.emit = nv04_fence_emit;
drivers/gpu/drm/nouveau/nv04_fence.c:		fctx->base.sync = nv04_fence_sync;
drivers/gpu/drm/nouveau/nv04_fence.c:		fctx->base.read = nv04_fence_read;
drivers/gpu/drm/nouveau/nouveau_fence.c:		if (!--fctx->notify_ref)
drivers/gpu/drm/nouveau/nouveau_fence.c:	spin_lock_irq(&fctx->lock);
drivers/gpu/drm/nouveau/nouveau_fence.c:	while (!list_empty(&fctx->pending)) {
drivers/gpu/drm/nouveau/nouveau_fence.c:		fence = list_entry(fctx->pending.next, typeof(*fence), head);
drivers/gpu/drm/nouveau/nouveau_fence.c:			nvif_notify_put(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:	spin_unlock_irq(&fctx->lock);
drivers/gpu/drm/nouveau/nouveau_fence.c:	nvif_notify_fini(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:	fctx->dead = 1;
drivers/gpu/drm/nouveau/nouveau_fence.c:	kref_put(&fctx->fence_ref, nouveau_fence_context_put);
drivers/gpu/drm/nouveau/nouveau_fence.c:	u32 seq = fctx->read(chan);
drivers/gpu/drm/nouveau/nouveau_fence.c:	while (!list_empty(&fctx->pending)) {
drivers/gpu/drm/nouveau/nouveau_fence.c:		fence = list_entry(fctx->pending.next, typeof(*fence), head);
drivers/gpu/drm/nouveau/nouveau_fence.c:	spin_lock_irqsave(&fctx->lock, flags);
drivers/gpu/drm/nouveau/nouveau_fence.c:	if (!list_empty(&fctx->pending)) {
drivers/gpu/drm/nouveau/nouveau_fence.c:		fence = list_entry(fctx->pending.next, typeof(*fence), head);
drivers/gpu/drm/nouveau/nouveau_fence.c:		chan = rcu_dereference_protected(fence->channel, lockdep_is_held(&fctx->lock));
drivers/gpu/drm/nouveau/nouveau_fence.c:	spin_unlock_irqrestore(&fctx->lock, flags);
drivers/gpu/drm/nouveau/nouveau_fence.c:	INIT_LIST_HEAD(&fctx->flip);
drivers/gpu/drm/nouveau/nouveau_fence.c:	INIT_LIST_HEAD(&fctx->pending);
drivers/gpu/drm/nouveau/nouveau_fence.c:	spin_lock_init(&fctx->lock);
drivers/gpu/drm/nouveau/nouveau_fence.c:	fctx->context = priv->context_base + chan->chid;
drivers/gpu/drm/nouveau/nouveau_fence.c:		strcpy(fctx->name, "copy engine channel");
drivers/gpu/drm/nouveau/nouveau_fence.c:		strcpy(fctx->name, "generic kernel channel");
drivers/gpu/drm/nouveau/nouveau_fence.c:		strcpy(fctx->name, nvxx_client(&cli->base)->name);
drivers/gpu/drm/nouveau/nouveau_fence.c:	kref_init(&fctx->fence_ref);
drivers/gpu/drm/nouveau/nouveau_fence.c:			       &fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:			   &fctx->lock, fctx->context, ++fctx->sequence);
drivers/gpu/drm/nouveau/nouveau_fence.c:			   &fctx->lock, fctx->context, ++fctx->sequence);
drivers/gpu/drm/nouveau/nouveau_fence.c:	kref_get(&fctx->fence_ref);
drivers/gpu/drm/nouveau/nouveau_fence.c:	ret = fctx->emit(fence);
drivers/gpu/drm/nouveau/nouveau_fence.c:		spin_lock_irq(&fctx->lock);
drivers/gpu/drm/nouveau/nouveau_fence.c:			nvif_notify_put(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:		list_add_tail(&fence->head, &fctx->pending);
drivers/gpu/drm/nouveau/nouveau_fence.c:		spin_unlock_irq(&fctx->lock);
drivers/gpu/drm/nouveau/nouveau_fence.c:		spin_lock_irqsave(&fctx->lock, flags);
drivers/gpu/drm/nouveau/nouveau_fence.c:		chan = rcu_dereference_protected(fence->channel, lockdep_is_held(&fctx->lock));
drivers/gpu/drm/nouveau/nouveau_fence.c:			nvif_notify_put(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:		spin_unlock_irqrestore(&fctx->lock, flags);
drivers/gpu/drm/nouveau/nouveau_fence.c:			if (prev && (prev == chan || fctx->sync(f, prev, chan) == 0))
drivers/gpu/drm/nouveau/nouveau_fence.c:			if (prev && (prev == chan || fctx->sync(f, prev, chan) == 0))
drivers/gpu/drm/nouveau/nouveau_fence.c:	return !fctx->dead ? fctx->name : "dead channel";
drivers/gpu/drm/nouveau/nouveau_fence.c:		ret = (int)(fctx->read(chan) - fence->base.seqno) >= 0;
drivers/gpu/drm/nouveau/nouveau_fence.c:	kref_put(&fctx->fence_ref, nouveau_fence_context_put);
drivers/gpu/drm/nouveau/nouveau_fence.c:	if (!fctx->notify_ref++)
drivers/gpu/drm/nouveau/nouveau_fence.c:		nvif_notify_get(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_fence.c:	else if (!--fctx->notify_ref)
drivers/gpu/drm/nouveau/nouveau_fence.c:		nvif_notify_put(&fctx->notify);
drivers/gpu/drm/nouveau/nouveau_display.c:	list_add_tail(&s->head, &fctx->flip);
drivers/gpu/drm/nouveau/nouveau_display.c:	if (list_empty(&fctx->flip)) {
drivers/gpu/drm/nouveau/nouveau_display.c:	s = list_first_entry(&fctx->flip, struct nouveau_page_flip_state, head);
drivers/gpu/drm/nouveau/nv50_fence.c:	nouveau_fence_context_new(chan, &fctx->base);
drivers/gpu/drm/nouveau/nv50_fence.c:	fctx->base.emit = nv10_fence_emit;
drivers/gpu/drm/nouveau/nv50_fence.c:	fctx->base.read = nv10_fence_read;
drivers/gpu/drm/nouveau/nv50_fence.c:	fctx->base.sync = nv17_fence_sync;
drivers/gpu/drm/nouveau/nv50_fence.c:			       &fctx->sema);
drivers/gpu/drm/nouveau/nv50_fence.c:				       &fctx->head[i]);
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:	    desc.dig_conn == ctx->desc.dig_conn)
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:	mxms_output_device(mxm, data, &ctx->desc);
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:	if ((ctx->outp[0] & 0x0000000f) != ctx->desc.outp_type)
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:		u8 link = mxm_sor_map(bios, ctx->desc.dig_conn);
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:		if ((ctx->outp[0] & 0x0f000000) != (link & 0x0f) << 24)
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:		if ((link & ((ctx->outp[1] & 0x00000030) >> 4)) != link)
drivers/gpu/drm/nouveau/nvkm/subdev/mxm/nv50.c:	if (ctx->desc.outp_type == 6 && ctx->desc.conn_type == 6 &&
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	u32 *ctxprog = ctx->ucode;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	if (ctx->mode != NVKM_GRCTX_PROG)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	BUG_ON(ctx->ctxprog_len == ctx->ctxprog_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctxprog[ctx->ctxprog_len++] = inst;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxprog_reg = (reg - 0x00400000) >> 2;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxvals_base = ctx->ctxvals_pos;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxvals_pos = ctx->ctxvals_base + length;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	cp_out(ctx, CP_CTX | (length << CP_CTX_COUNT_SHIFT) | ctx->ctxprog_reg);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	u32 *ctxprog = ctx->ucode;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	if (ctx->mode != NVKM_GRCTX_PROG)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxprog_label[name] = ctx->ctxprog_len;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	for (i = 0; i < ctx->ctxprog_len; i++) {
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:			     (ctx->ctxprog_len << CP_BRA_IP_SHIFT);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:		ip = ctx->ctxprog_label[name] << CP_BRA_IP_SHIFT;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxvals_pos = offset;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	ctx->ctxvals_base = ctx->ctxvals_pos;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	cp_lsr(ctx, ctx->ctxvals_pos);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	if (ctx->mode != NVKM_GRCTX_VALS)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	reg = (reg - ctx->ctxprog_reg) + ctx->ctxvals_base;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.h:	nvkm_wo32(ctx->data, reg * 4, val);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const u32 state_limit = min(grctx->bundle_min_gpm_fifo_depth,
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:				    grctx->bundle_size / 0x20);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const u32 token_limit = grctx->bundle_token_limit;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const int b = mmio_vram(info, grctx->bundle_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	mmio_wr32(info, 0x408008, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	mmio_wr32(info, 0x418e28, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const int b = mmio_vram(info, grctx->pagepool_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const u32  alpha = grctx->alpha_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const u32 attrib = grctx->attrib_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	const u32   size = 0x20 * (grctx->attrib_nr_max + grctx->alpha_nr_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	u32 ao = bo + grctx->attrib_nr_max * gr->tpc_total;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:			bo += grctx->attrib_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:			ao += grctx->alpha_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mmio(gr, grctx->hub);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mmio(gr, grctx->gpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mmio(gr, grctx->zcull);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mmio(gr, grctx->tpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mmio(gr, grctx->ppc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_icmd(gr, grctx->icmd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm107.c:	gf100_gr_mthd(gr, grctx->mthd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:		if (nv44_gr_class(ctx->device)) {
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:		if (!nv44_gr_class(ctx->device)) {
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	cp_ctx(ctx, 0x403420, nv40_gr_vs_count(ctx->device));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	for (i = 0; i < nv40_gr_vs_count(ctx->device); i++)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	int len = nv44_gr_class(ctx->device) ? 0x0084 : 0x0684;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	ctx->ctxvals_pos += len;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	struct nvkm_gpuobj *obj = ctx->data;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	vs_nr    = nv40_gr_vs_count(ctx->device);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	offset = ctx->ctxvals_pos;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	ctx->ctxvals_pos += (0x0300/4 + (vs_nr * vs_len));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	if (ctx->mode != NVKM_GRCTX_VALS)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv40.c:	cp_pos (ctx, ctx->ctxvals_pos);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm20b.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm20b.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm20b.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm20b.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:	const u32  alpha = grctx->alpha_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:	const u32   beta = grctx->attrib_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:	const u32   size = 0x20 * (grctx->attrib_nr_max + grctx->alpha_nr_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:	u32 ao = bo + grctx->attrib_nr_max * gr->tpc_total;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:			bo += grctx->attrib_nr_max;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf108.c:			ao += grctx->alpha_nr_max;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	cp_lsr (ctx, ctx->ctxvals_base);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos += 0x400; /* padding... no idea why you need it */
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	if (val && ctx->mode == NVKM_GRCTX_VALS) {
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			nvkm_wo32(ctx->data, 4 * (ctx->ctxvals_pos + i), val);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos += num;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	base = ctx->ctxvals_pos;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	num = ctx->ctxvals_pos - base;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos = base;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	if (val && ctx->mode == NVKM_GRCTX_VALS) {
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			nvkm_wo32(ctx->data, 4 * (ctx->ctxvals_pos + (i << 3)), val);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos += num << 3;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	offset = (ctx->ctxvals_pos+0x3f)&~0x3f;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_base = offset;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 0x1;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 0x2;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 3;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			ctx->ctxvals_pos = offset + 4 + i;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:				size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 1;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 2;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 3;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 4;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 5;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 6;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 7;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos = offset + size * 8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos = (ctx->ctxvals_pos+0x3f)&~0x3f;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	struct nvkm_device *device = ctx->device;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	offset = (ctx->ctxvals_pos+0x3f)&~0x3f;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			ctx->ctxvals_pos = offset + i;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:				size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 1;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 2;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		ctx->ctxvals_pos = offset + 3;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:		if ((ctx->ctxvals_pos-offset)/8 > size)
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:			size = (ctx->ctxvals_pos-offset)/8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos = offset + size * 8;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxnv50.c:	ctx->ctxvals_pos = (ctx->ctxvals_pos+0x3f)&~0x3f;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	const u32  alpha = grctx->alpha_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	const u32   beta = grctx->attrib_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	const u32   size = 0x20 * (grctx->attrib_nr_max + grctx->alpha_nr_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	u32 ao = bo + grctx->attrib_nr_max * gr->tpc_total;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:			bo += grctx->attrib_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:			ao += grctx->alpha_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mmio(gr, grctx->hub);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mmio(gr, grctx->gpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mmio(gr, grctx->zcull);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mmio(gr, grctx->tpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mmio(gr, grctx->ppc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_icmd(gr, grctx->icmd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf117.c:	gf100_gr_mthd(gr, grctx->mthd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/gf100.c:	gf100_gr_init_csdata(gr, grctx->hub, 0x409000, 0x000, 0x000000);
drivers/gpu/drm/nouveau/nvkm/engine/gr/gf100.c:	gf100_gr_init_csdata(gr, grctx->gpc, 0x41a000, 0x000, 0x418000);
drivers/gpu/drm/nouveau/nvkm/engine/gr/gf100.c:	gf100_gr_init_csdata(gr, grctx->tpc, 0x41a000, 0x004, 0x419800);
drivers/gpu/drm/nouveau/nvkm/engine/gr/gf100.c:	gf100_gr_init_csdata(gr, grctx->ppc, 0x41a000, 0x008, 0x41be00);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	const u32 state_limit = min(grctx->bundle_min_gpm_fifo_depth,
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:				    grctx->bundle_size / 0x20);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	const u32 token_limit = grctx->bundle_token_limit;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	const int b = mmio_vram(info, grctx->bundle_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	mmio_wr32(info, 0x408008, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	mmio_wr32(info, 0x41880c, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	const int b = mmio_vram(info, grctx->pagepool_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mmio(gr, grctx->hub);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mmio(gr, grctx->gpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mmio(gr, grctx->zcull);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mmio(gr, grctx->tpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mmio(gr, grctx->ppc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_icmd(gr, grctx->icmd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk104.c:	gf100_gr_mthd(gr, grctx->mthd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm200.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm200.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm200.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgm200.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk20a.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk20a.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk20a.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgk20a.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	const int b = mmio_vram(info, grctx->pagepool_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	const u32  alpha = grctx->alpha_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	const u32 attrib = grctx->attrib_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	const u32 pertpc = 0x20 * (grctx->attrib_nr_max + grctx->alpha_nr_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	u32 bo = ao + grctx->alpha_nr_max * gr->tpc_total;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:			bo += grctx->attrib_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:			ao += grctx->alpha_nr_max * gr->ppc_tpc_nr[gpc][ppc];
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgp100.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	const int b = mmio_vram(info, grctx->bundle_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	mmio_wr32(info, 0x408008, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	mmio_wr32(info, 0x41880c, 0x80000000 | (grctx->bundle_size >> s));
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	const int b = mmio_vram(info, grctx->pagepool_size, (1 << s), access);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	const u32 attrib = grctx->attrib_nr;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	const u32   size = 0x20 * (grctx->attrib_nr_max + grctx->alpha_nr_max);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:			bo += grctx->attrib_nr_max;
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mmio(gr, grctx->hub);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mmio(gr, grctx->gpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mmio(gr, grctx->zcull);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mmio(gr, grctx->tpc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mmio(gr, grctx->ppc);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	grctx->bundle(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	grctx->pagepool(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	grctx->attrib(info);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	grctx->unkn(gr);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_icmd(gr, grctx->icmd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	gf100_gr_mthd(gr, grctx->mthd);
drivers/gpu/drm/nouveau/nvkm/engine/gr/ctxgf100.c:	grctx->main(gr, &info);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (!test_and_set_bit(0, &ctx->irq_flags)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		val = readl(ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (ctx->i80_if) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (test_and_clear_bit(0, &ctx->irq_flags)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		val = readl(ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (ctx->i80_if) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	atomic_set(&ctx->wait_vsync_event, 1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (!wait_event_timeout(ctx->wait_vsync_queue,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:				!atomic_read(&ctx->wait_vsync_event),
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	u32 val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	u32 val = readl(ctx->regs + SHADOWCON);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + SHADOWCON);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	pm_runtime_get_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_prepare_enable(ctx->bus_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_prepare_enable(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		u32 val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:			if (ctx->driver_data->has_shadowcon)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		int pipe = ctx->pipe;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->suspended = false;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->pipe = -1;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_enable_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_wait_for_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_disable_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->pipe = pipe;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_disable_unprepare(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_disable_unprepare(ctx->bus_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	pm_runtime_put(ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->i80_if) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	lcd_rate = clk_get_rate(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->clkdiv = (clkdiv < 0x100) ? clkdiv : 0xff;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	void __iomem *timing_base = ctx->regs + ctx->driver_data->timing_base;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	u32 trg_type = ctx->driver_data->trg_type;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (ctx->driver_data->has_hw_trigger)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (ctx->driver_data->has_trigger_per_te)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	const struct fimd_driver_data *driver_data = ctx->driver_data;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	void *timing_base = ctx->regs + driver_data->timing_base;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->i80_if) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		val = ctx->i80ifcon | I80IFEN_ENABLE;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (driver_data->has_vtsel && ctx->sysreg &&
drivers/gpu/drm/exynos/exynos_drm_fimd.c:				regmap_update_bits(ctx->sysreg,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		vidcon1 = ctx->vidcon1;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(vidcon1, ctx->regs + driver_data->timing_base + VIDCON1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + driver_data->timing_base + VIDTCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + driver_data->timing_base + VIDTCON1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(ctx->vidout_con, timing_base + VIDOUT_CON);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->sysreg && regmap_update_bits(ctx->sysreg,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (driver_data->has_mic_bypass && ctx->sysreg &&
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	    regmap_update_bits(ctx->sysreg,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + driver_data->timing_base + VIDTCON2);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	val = ctx->vidcon0;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_clksel)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->clkdiv > 1)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		val |= VIDCON0_CLKVAL_F(ctx->clkdiv - 1) | VIDCON0_CLKDIR;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_limited_fmt && !win) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + VIDOSD_C(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + VIDWnALPHA0(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + VIDWnALPHA1(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(keycon0, ctx->regs + WKEYCON0_BASE(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(keycon1, ctx->regs + WKEYCON1_BASE(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_shadowcon) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	val = readl(ctx->regs + reg);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + reg);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDWx_BUF_START(win, 0));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDWx_BUF_END(win, 0));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDWx_BUF_SIZE(win, 0));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDOSD_A(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + VIDOSD_B(win));
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(val, ctx->regs + offset);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_shadowcon)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->i80_if)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		atomic_set(&ctx->win_updated, 1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_shadowcon)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (!ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->suspended = false;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	pm_runtime_get_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (test_and_clear_bit(0, &ctx->irq_flags))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_enable_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	fimd_commit(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_disable_plane(crtc, &ctx->planes[i]);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(0, ctx->regs + VIDCON0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	pm_runtime_put_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	const struct fimd_driver_data *driver_data = ctx->driver_data;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	void *timing_base = ctx->regs + driver_data->timing_base;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (atomic_read(&ctx->triggering))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	atomic_set(&ctx->triggering, 1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (!test_bit(0, &ctx->irq_flags))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		atomic_set(&ctx->triggering, 0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	u32 trg_type = ctx->driver_data->trg_type;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->pipe < 0 || !ctx->drm_dev)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (atomic_add_unless(&ctx->win_updated, -1, 0))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_trigger(ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (atomic_read(&ctx->wait_vsync_event)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		atomic_set(&ctx->wait_vsync_event, 0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		wake_up(&ctx->wait_vsync_queue);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (test_bit(0, &ctx->irq_flags))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		drm_crtc_handle_vblank(&ctx->crtc->base);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	writel(val, ctx->regs + DP_MIE_CLKCON);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	val = readl(ctx->regs + VIDINTCON1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clear_bit = ctx->i80_if ? VIDINTCON1_INT_I80 : VIDINTCON1_INT_FRAME;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		writel(clear_bit, ctx->regs + VIDINTCON1);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->pipe < 0 || !ctx->drm_dev)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (!ctx->i80_if)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		drm_crtc_handle_vblank(&ctx->crtc->base);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->i80_if) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		atomic_set(&ctx->triggering, 0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (atomic_read(&ctx->wait_vsync_event)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:			atomic_set(&ctx->wait_vsync_event, 0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:			wake_up(&ctx->wait_vsync_queue);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->drm_dev = drm_dev;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->pipe = priv->pipe++;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->configs[i].pixel_formats = fimd_formats;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->configs[i].num_pixel_formats = ARRAY_SIZE(fimd_formats);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->configs[i].zpos = i;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->configs[i].type = fimd_win_types[i];
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ret = exynos_plane_init(drm_dev, &ctx->planes[i], i,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:					1 << ctx->pipe, &ctx->configs[i]);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	exynos_plane = &ctx->planes[DEFAULT_WIN];
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->crtc = exynos_drm_crtc_create(drm_dev, &exynos_plane->base,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:					   ctx->pipe, EXYNOS_DISPLAY_TYPE_LCD,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->crtc))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		return PTR_ERR(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->driver_data->has_dp_clk) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->dp_clk.enable = fimd_dp_clock_enable;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->crtc->pipe_clk = &ctx->dp_clk;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->encoder)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		exynos_dpi_bind(drm_dev, ctx->encoder);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		fimd_clear_channels(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	fimd_disable(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	drm_iommu_detach_device(ctx->drm_dev, ctx->dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (ctx->encoder)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		exynos_dpi_remove(ctx->encoder);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->dev = dev;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->driver_data = of_device_get_match_data(dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->vidcon1 |= VIDCON1_INV_VDEN;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->vidcon1 |= VIDCON1_INV_VCLK;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->i80_if = true;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		if (ctx->driver_data->has_vidoutcon)
drivers/gpu/drm/exynos/exynos_drm_fimd.c:			ctx->vidout_con |= VIDOUT_CON_F_I80_LDI0;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:			ctx->vidcon0 |= VIDCON0_VIDOUT_I80_LDI0;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->vidcon0 |= VIDCON0_DSI_EN;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->i80ifcon = LCD_CS_SETUP(val);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->i80ifcon |= LCD_WR_SETUP(val);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->i80ifcon |= LCD_WR_ACTIVE(val);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->i80ifcon |= LCD_WR_HOLD(val);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->sysreg = syscon_regmap_lookup_by_phandle(dev->of_node,
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->sysreg)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		ctx->sysreg = NULL;
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->bus_clk = devm_clk_get(dev, "fimd");
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->bus_clk)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		return PTR_ERR(ctx->bus_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->lcd_clk = devm_clk_get(dev, "sclk_fimd");
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->lcd_clk)) {
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		return PTR_ERR(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->regs = devm_ioremap_resource(dev, res);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->regs))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		return PTR_ERR(ctx->regs);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:					   ctx->i80_if ? "lcd_sys" : "vsync");
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	init_waitqueue_head(&ctx->wait_vsync_queue);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	atomic_set(&ctx->wait_vsync_event, 0);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ctx->encoder = exynos_dpi_probe(dev);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	if (IS_ERR(ctx->encoder))
drivers/gpu/drm/exynos/exynos_drm_fimd.c:		return PTR_ERR(ctx->encoder);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_disable_unprepare(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	clk_disable_unprepare(ctx->bus_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ret = clk_prepare_enable(ctx->bus_clk);
drivers/gpu/drm/exynos/exynos_drm_fimd.c:	ret = clk_prepare_enable(ctx->lcd_clk);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mod_timer(&ctx->timer,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_lock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->suspended = false;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_unlock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_lock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_unlock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->drm_dev = drm_dev;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->pipe = priv->pipe++;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->pipe < 0)
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (drm_crtc_handle_vblank(&ctx->crtc->base))
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		mod_timer(&ctx->timer,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_lock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	rc = sprintf(buf, "%d\n", ctx->connected);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_unlock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ret = kstrtoint(buf, 0, &ctx->connected);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->connected > 1)
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (!ctx->raw_edid)
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		ctx->raw_edid = (struct edid *)fake_edid_info;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->raw_edid != (struct edid *)fake_edid_info) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	drm_helper_hpd_irq_event(ctx->drm_dev);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->connected == vidi->connection) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		ctx->raw_edid = drm_edid_duplicate(raw_edid);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		if (!ctx->raw_edid) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		if (ctx->raw_edid && ctx->raw_edid !=
drivers/gpu/drm/exynos/exynos_drm_vidi.c:			kfree(ctx->raw_edid);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:			ctx->raw_edid = NULL;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->connected = vidi->connection;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	drm_helper_hpd_irq_event(ctx->drm_dev);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	return ctx->connected ? connector_status_connected :
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	 * to ctx->raw_edid through specific ioctl.
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (!ctx->raw_edid) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	edid_len = (1 + ctx->raw_edid->extensions) * EDID_LENGTH;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	edid = kmemdup(ctx->raw_edid, edid_len, GFP_KERNEL);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	struct drm_connector *connector = &ctx->connector;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ret = drm_connector_init(ctx->drm_dev, connector,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	struct drm_encoder *encoder = &ctx->encoder;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		ret = exynos_plane_init(drm_dev, &ctx->planes[i], i,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:					1 << ctx->pipe, &plane_config);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	exynos_plane = &ctx->planes[DEFAULT_WIN];
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->crtc = exynos_drm_crtc_create(drm_dev, &exynos_plane->base,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:					   ctx->pipe, EXYNOS_DISPLAY_TYPE_VIDI,
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (IS_ERR(ctx->crtc)) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		return PTR_ERR(ctx->crtc);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	del_timer_sync(&ctx->timer);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	ctx->pdev = pdev;
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	setup_timer(&ctx->timer, vidi_fake_vblank_timer, (unsigned long)ctx);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	mutex_init(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:	if (ctx->raw_edid != (struct edid *)fake_edid_info) {
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		kfree(ctx->raw_edid);
drivers/gpu/drm/exynos/exynos_drm_vidi.c:		ctx->raw_edid = NULL;
drivers/gpu/drm/exynos/exynos_mixer.c:		(u32)readl(ctx->mixer_res.mixer_regs + reg_id)); \
drivers/gpu/drm/exynos/exynos_mixer.c:		(u32) readl(ctx->mixer_res.vp_regs + reg_id)); \
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	val = test_bit(MXR_BIT_INTERLACE, &ctx->flags) ?
drivers/gpu/drm/exynos/exynos_mixer.c:	if (ctx->mxr_ver != MXR_VER_128_0_0_184) {
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:		if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:		__set_bit(MXR_BIT_INTERLACE, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:		__clear_bit(MXR_BIT_INTERLACE, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	val = (test_bit(MXR_BIT_INTERLACE, &ctx->flags) ? ~0 : 0);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_INTERLACE, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:		__set_bit(MXR_BIT_INTERLACE, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:		__clear_bit(MXR_BIT_INTERLACE, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (ctx->mxr_ver == MXR_VER_128_0_0_184 &&
drivers/gpu/drm/exynos/exynos_mixer.c:	if (ctx->mxr_ver == MXR_VER_16_0_33_0 ||
drivers/gpu/drm/exynos/exynos_mixer.c:		ctx->mxr_ver == MXR_VER_128_0_0_184)
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:		if (test_bit(MXR_BIT_INTERLACE, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:		drm_crtc_handle_vblank(&ctx->crtc->base);
drivers/gpu/drm/exynos/exynos_mixer.c:	struct device *dev = &mixer_ctx->pdev->dev;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *mixer_res = &mixer_ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	res = platform_get_resource(mixer_ctx->pdev, IORESOURCE_MEM, 0);
drivers/gpu/drm/exynos/exynos_mixer.c:	res = platform_get_resource(mixer_ctx->pdev, IORESOURCE_IRQ, 0);
drivers/gpu/drm/exynos/exynos_mixer.c:	struct device *dev = &mixer_ctx->pdev->dev;
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *mixer_res = &mixer_ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_HAS_SCLK, &mixer_ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	res = platform_get_resource(mixer_ctx->pdev, IORESOURCE_MEM, 1);
drivers/gpu/drm/exynos/exynos_mixer.c:	mixer_ctx->drm_dev = drm_dev;
drivers/gpu/drm/exynos/exynos_mixer.c:	mixer_ctx->pipe = priv->pipe++;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &mixer_ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	ret = drm_iommu_attach_device(drm_dev, mixer_ctx->dev);
drivers/gpu/drm/exynos/exynos_mixer.c:	drm_iommu_detach_device(mixer_ctx->drm_dev, mixer_ctx->dev);
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &mixer_ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	__set_bit(MXR_BIT_VSYNC, &mixer_ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &mixer_ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	__clear_bit(MXR_BIT_VSYNC, &mixer_ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &mixer_ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &mixer_ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_POWERED, &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	pm_runtime_get_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VSYNC, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:	set_bit(MXR_BIT_POWERED, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	if (!test_bit(MXR_BIT_POWERED, &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:		mixer_disable_plane(crtc, &ctx->planes[i]);
drivers/gpu/drm/exynos/exynos_mixer.c:	pm_runtime_put(ctx->dev);
drivers/gpu/drm/exynos/exynos_mixer.c:	clear_bit(MXR_BIT_POWERED, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:						     &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:		ret = exynos_plane_init(drm_dev, &ctx->planes[i], i,
drivers/gpu/drm/exynos/exynos_mixer.c:					1 << ctx->pipe, &plane_configs[i]);
drivers/gpu/drm/exynos/exynos_mixer.c:	exynos_plane = &ctx->planes[DEFAULT_WIN];
drivers/gpu/drm/exynos/exynos_mixer.c:	ctx->crtc = exynos_drm_crtc_create(drm_dev, &exynos_plane->base,
drivers/gpu/drm/exynos/exynos_mixer.c:					   ctx->pipe, EXYNOS_DISPLAY_TYPE_HDMI,
drivers/gpu/drm/exynos/exynos_mixer.c:	if (IS_ERR(ctx->crtc)) {
drivers/gpu/drm/exynos/exynos_mixer.c:		ret = PTR_ERR(ctx->crtc);
drivers/gpu/drm/exynos/exynos_mixer.c:	ctx->pdev = pdev;
drivers/gpu/drm/exynos/exynos_mixer.c:	ctx->dev = dev;
drivers/gpu/drm/exynos/exynos_mixer.c:	ctx->mxr_ver = drv->version;
drivers/gpu/drm/exynos/exynos_mixer.c:		__set_bit(MXR_BIT_VP_ENABLED, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:		__set_bit(MXR_BIT_HAS_SCLK, &ctx->flags);
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:		if (test_bit(MXR_BIT_HAS_SCLK, &ctx->flags))
drivers/gpu/drm/exynos/exynos_mixer.c:	struct mixer_resources *res = &ctx->mixer_res;
drivers/gpu/drm/exynos/exynos_mixer.c:	if (test_bit(MXR_BIT_VP_ENABLED, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos_mixer.c:		if (test_bit(MXR_BIT_HAS_SCLK, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	val = (val & mask) | (readl(ctx->addr + reg) & ~mask);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + reg);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!test_and_set_bit(BIT_IRQS_ENABLED, &ctx->flags)) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		if (ctx->out_type & IFTYPE_I80)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDINTCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_and_clear_bit(BIT_IRQS_ENABLED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(0, ctx->addr + DECON_VIDINTCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	u32 val = !(ctx->out_type & I80_HW_TRG)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_TRIGCON);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (ctx->out_type & IFTYPE_HDMI) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_CMU);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (ctx->out_type & (IFTYPE_I80 | I80_HW_TRG))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (ctx->out_type & IFTYPE_I80) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDOUTCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDTCON2);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!(ctx->out_type & IFTYPE_I80)) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDTCON00);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDTCON01);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDTCON10);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDTCON11);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	val = readl(ctx->addr + DECON_WINCONx(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_WINCONx(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	for (i = ctx->first_win; i < WINDOWS_NR; i++)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDOSDxA(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDOSDxB(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDOSDxC(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDOSDxD(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(dma_addr, ctx->addr + DECON_VIDW0xADD0B0(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDW0xADD1B0(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!(ctx->out_type & IFTYPE_HDMI))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(val, ctx->addr + DECON_VIDW0xADD2(win));
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	for (i = ctx->first_win; i < WINDOWS_NR; i++)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (ctx->out_type & IFTYPE_I80)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		set_bit(BIT_WIN_UPDATED, &ctx->flags);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(0, ctx->addr + DECON_VIDCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		if (~readl(ctx->addr + DECON_VIDCON0) & VIDCON0_STOP_STATUS)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(VIDCON0_SWRESET, ctx->addr + DECON_VIDCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		if (~readl(ctx->addr + DECON_VIDCON0) & VIDCON0_SWRESET)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!(ctx->out_type & IFTYPE_HDMI))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(VIDCON0_CLKVALUP | VIDCON0_VLCKFREE, ctx->addr + DECON_VIDCON0);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	writel(VIDCON1_VCLK_RUN_VDEN_DISABLE, ctx->addr + DECON_VIDCON1);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	       ctx->addr + DECON_CRCCTRL);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!test_and_clear_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	pm_runtime_get_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	set_bit(BIT_CLKS_ENABLED, &ctx->flags);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_and_clear_bit(BIT_IRQS_ENABLED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		decon_enable_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	decon_commit(ctx->crtc);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_bit(BIT_SUSPENDED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	for (i = ctx->first_win; i < WINDOWS_NR; i++)
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		decon_disable_plane(crtc, &ctx->planes[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	clear_bit(BIT_CLKS_ENABLED, &ctx->flags);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	pm_runtime_put_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	set_bit(BIT_SUSPENDED, &ctx->flags);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!test_bit(BIT_CLKS_ENABLED, &ctx->flags) ||
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	    (ctx->out_type & I80_HW_TRG))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (test_and_clear_bit(BIT_WIN_UPDATED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ret = clk_prepare_enable(ctx->clks[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		clk_disable_unprepare(ctx->clks[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->drm_dev = drm_dev;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->pipe = priv->pipe++;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	for (win = ctx->first_win; win < WINDOWS_NR; win++) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		int tmp = (win == ctx->first_win) ? 0 : win;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->configs[win].pixel_formats = decon_formats;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->configs[win].num_pixel_formats = ARRAY_SIZE(decon_formats);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->configs[win].zpos = win;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->configs[win].type = decon_win_types[tmp];
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ret = exynos_plane_init(drm_dev, &ctx->planes[win], win,
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:					1 << ctx->pipe, &ctx->configs[win]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	exynos_plane = &ctx->planes[ctx->first_win];
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	out_type = (ctx->out_type & IFTYPE_HDMI) ? EXYNOS_DISPLAY_TYPE_HDMI
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->crtc = exynos_drm_crtc_create(drm_dev, &exynos_plane->base,
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:					ctx->pipe, out_type,
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (IS_ERR(ctx->crtc)) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ret = PTR_ERR(ctx->crtc);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	decon_clear_channels(ctx->crtc);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	decon_disable(ctx->crtc);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	drm_iommu_detach_device(ctx->drm_dev, ctx->dev);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (!test_bit(BIT_CLKS_ENABLED, &ctx->flags))
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	val = readl(ctx->addr + DECON_VIDINTCON1);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		writel(val, ctx->addr + DECON_VIDINTCON1);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		drm_crtc_handle_vblank(&ctx->crtc->base);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		clk_disable_unprepare(ctx->clks[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ret = clk_prepare_enable(ctx->clks[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		clk_disable_unprepare(ctx->clks[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	__set_bit(BIT_SUSPENDED, &ctx->flags);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->dev = dev;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->out_type = (unsigned long)of_device_get_match_data(dev);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (ctx->out_type & IFTYPE_HDMI) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->first_win = 1;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->out_type |= IFTYPE_I80;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		clk = devm_clk_get(ctx->dev, decon_clks_name[i]);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		ctx->clks[i] = clk;
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	ctx->addr = devm_ioremap_resource(dev, res);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:	if (IS_ERR(ctx->addr)) {
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:		return PTR_ERR(ctx->addr);
drivers/gpu/drm/exynos/exynos5433_drm_decon.c:			(ctx->out_type & IFTYPE_I80) ? "lcd_sys" : "vsync");
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel && !ctx->panel->connector)
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_attach(ctx->panel, &ctx->connector);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->vm) {
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_display_mode_from_videomode(ctx->vm, mode);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel)
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		return ctx->panel->funcs->get_modes(ctx->panel);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	struct drm_connector *connector = &ctx->connector;
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel) {
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_prepare(ctx->panel);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_enable(ctx->panel);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel) {
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_disable(ctx->panel);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_unprepare(ctx->panel);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	struct device *dev = ctx->dev;
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	ctx->panel_node = exynos_dpi_of_find_panel_node(dev);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		vm = devm_kzalloc(dev, sizeof(*ctx->vm), GFP_KERNEL);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		ctx->vm = vm;
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (!ctx->panel_node)
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	ctx->dev = dev;
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel_node) {
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		ctx->panel = of_drm_find_panel(ctx->panel_node);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		if (!ctx->panel)
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	return &ctx->encoder;
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	exynos_dpi_disable(&ctx->encoder);
drivers/gpu/drm/exynos/exynos_drm_dpi.c:	if (ctx->panel)
drivers/gpu/drm/exynos/exynos_drm_dpi.c:		drm_panel_detach(ctx->panel);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	atomic_set(&ctx->wait_vsync_event, 1);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!wait_event_timeout(ctx->wait_vsync_queue,
drivers/gpu/drm/exynos/exynos7_drm_decon.c:				!atomic_read(&ctx->wait_vsync_event),
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		u32 val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:			writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		decon_wait_for_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->drm_dev = drm_dev;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->pipe = priv->pipe++;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	decon_clear_channels(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ret = drm_iommu_attach_device(drm_dev, ctx->dev);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	drm_iommu_detach_device(ctx->drm_dev, ctx->dev);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clkdiv = DIV_ROUND_UP(clk_get_rate(ctx->vclk), ideal_clk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->i80_if) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDTCON1);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDTCON2);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDTCON3);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDTCON4);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(mode->vdisplay - 1, ctx->regs + LINECNT_OP_THRESHOLD);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VCLKCON1);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VCLKCON2);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!test_and_set_bit(0, &ctx->irq_flags)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		val = readl(ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		if (!ctx->i80_if) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (test_and_clear_bit(0, &ctx->irq_flags)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		val = readl(ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		if (!ctx->i80_if)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(val, ctx->regs + VIDINTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(keycon0, ctx->regs + WKEYCON0_BASE(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(keycon1, ctx->regs + WKEYCON1_BASE(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + SHADOWCON);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + SHADOWCON);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDW_BUF_START(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(fb->width + padding, ctx->regs + VIDW_WHOLE_X(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(fb->height, ctx->regs + VIDW_WHOLE_Y(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(state->src.x, ctx->regs + VIDW_OFFSET_X(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(state->src.y, ctx->regs + VIDW_OFFSET_Y(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDOSD_A(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDOSD_B(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(alpha, ctx->regs + VIDOSD_C(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(alpha, ctx->regs + VIDOSD_D(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + WINCON(win));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + DECON_UPDATE);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(VIDCON0_SWRESET, ctx->regs + VIDCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->i80_if)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(val, ctx->regs + VIDOUTCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	writel(VCLKCON0_CLKVALUP | VCLKCON0_VCLKFREE, ctx->regs + VCLKCON0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->i80_if)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(VIDCON1_VCLK_HOLD, ctx->regs + VIDCON1(0));
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	pm_runtime_get_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (test_and_clear_bit(0, &ctx->irq_flags))
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		decon_enable_vblank(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	decon_commit(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->suspended = false;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->suspended)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		decon_disable_plane(crtc, &ctx->planes[i]);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	pm_runtime_put_sync(ctx->dev);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->suspended = true;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	val = readl(ctx->regs + VIDINTCON1);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clear_bit = ctx->i80_if ? VIDINTCON1_INT_I80 : VIDINTCON1_INT_FRAME;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		writel(clear_bit, ctx->regs + VIDINTCON1);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->pipe < 0 || !ctx->drm_dev)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->i80_if) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		drm_crtc_handle_vblank(&ctx->crtc->base);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		if (atomic_read(&ctx->wait_vsync_event)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:			atomic_set(&ctx->wait_vsync_event, 0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:			wake_up(&ctx->wait_vsync_queue);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ctx->configs[i].pixel_formats = decon_formats;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ctx->configs[i].num_pixel_formats = ARRAY_SIZE(decon_formats);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ctx->configs[i].zpos = i;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ctx->configs[i].type = decon_win_types[i];
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = exynos_plane_init(drm_dev, &ctx->planes[i], i,
drivers/gpu/drm/exynos/exynos7_drm_decon.c:					1 << ctx->pipe, &ctx->configs[i]);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	exynos_plane = &ctx->planes[DEFAULT_WIN];
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->crtc = exynos_drm_crtc_create(drm_dev, &exynos_plane->base,
drivers/gpu/drm/exynos/exynos7_drm_decon.c:					   ctx->pipe, EXYNOS_DISPLAY_TYPE_LCD,
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->crtc)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		return PTR_ERR(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->encoder)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		exynos_dpi_bind(drm_dev, ctx->encoder);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	decon_disable(ctx->crtc);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (ctx->encoder)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		exynos_dpi_remove(ctx->encoder);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->dev = dev;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->suspended = true;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ctx->i80_if = true;
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->regs = of_iomap(dev->of_node, 0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (!ctx->regs)
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->pclk = devm_clk_get(dev, "pclk_decon0");
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->pclk)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = PTR_ERR(ctx->pclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->aclk = devm_clk_get(dev, "aclk_decon0");
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->aclk)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = PTR_ERR(ctx->aclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->eclk = devm_clk_get(dev, "decon0_eclk");
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->eclk)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = PTR_ERR(ctx->eclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->vclk = devm_clk_get(dev, "decon0_vclk");
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->vclk)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = PTR_ERR(ctx->vclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:					   ctx->i80_if ? "lcd_sys" : "vsync");
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	init_waitqueue_head(&ctx->wait_vsync_queue);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	atomic_set(&ctx->wait_vsync_event, 0);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ctx->encoder = exynos_dpi_probe(dev);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	if (IS_ERR(ctx->encoder)) {
drivers/gpu/drm/exynos/exynos7_drm_decon.c:		ret = PTR_ERR(ctx->encoder);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	iounmap(ctx->regs);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	iounmap(ctx->regs);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clk_disable_unprepare(ctx->vclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clk_disable_unprepare(ctx->eclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clk_disable_unprepare(ctx->aclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	clk_disable_unprepare(ctx->pclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ret = clk_prepare_enable(ctx->pclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ret = clk_prepare_enable(ctx->aclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ret = clk_prepare_enable(ctx->eclk);
drivers/gpu/drm/exynos/exynos7_drm_decon.c:	ret = clk_prepare_enable(ctx->vclk);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ippdrv = ipp_find_obj(&ctx->ipp_idr, &ctx->ipp_lock, ipp_id);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ippdrv = ipp_find_obj(&ctx->ipp_idr, &ctx->ipp_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		c_node = ipp_find_obj(&ctx->prop_idr, &ctx->prop_lock, prop_id);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	ret = ipp_create_id(&ctx->prop_idr, &ctx->prop_lock, c_node);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	ipp_remove_id(&ctx->prop_idr, &ctx->prop_lock, property->prop_id);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ipp_clean_mem_nodes(ctx->subdrv.drm_dev, c_node, i);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	ipp_remove_id(&ctx->prop_idr, &ctx->prop_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	queue_work(ctx->cmd_workq, &cmd_work->work);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	c_node = ipp_find_obj(&ctx->prop_idr, &ctx->prop_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	c_node = ipp_find_obj(&ctx->prop_idr, &ctx->prop_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ret = ipp_create_id(&ctx->ipp_idr, &ctx->ipp_lock, ippdrv);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ippdrv->event_workq = ctx->event_workq;
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ipp_remove_id(&ctx->ipp_idr, &ctx->ipp_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:		ipp_remove_id(&ctx->ipp_idr, &ctx->ipp_lock,
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	mutex_init(&ctx->ipp_lock);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	mutex_init(&ctx->prop_lock);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	idr_init(&ctx->ipp_idr);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	idr_init(&ctx->prop_idr);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	ctx->event_workq = create_singlethread_workqueue("ipp_event");
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	if (!ctx->event_workq) {
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	ctx->cmd_workq = create_singlethread_workqueue("ipp_cmd");
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	if (!ctx->cmd_workq) {
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	subdrv = &ctx->subdrv;
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	destroy_workqueue(ctx->cmd_workq);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	destroy_workqueue(ctx->event_workq);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	exynos_drm_subdrv_unregister(&ctx->subdrv);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	idr_destroy(&ctx->ipp_idr);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	idr_destroy(&ctx->prop_idr);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	mutex_destroy(&ctx->ipp_lock);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	mutex_destroy(&ctx->prop_lock);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	destroy_workqueue(ctx->cmd_workq);
drivers/gpu/drm/exynos/exynos_drm_ipp.c:	destroy_workqueue(ctx->event_workq);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:#define gsc_read(offset)		readl(ctx->regs + (offset))
drivers/gpu/drm/exynos/exynos_drm_gsc.c:#define gsc_write(cfg, offset)	writel(cfg, ctx->regs + (offset))
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	if (!ctx->sysreg)
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	regmap_read(ctx->sysreg, SYSREG_GSCBLK_CFG1, &gscblk_cfg);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		gscblk_cfg |= GSC_BLK_DISP1WB_DEST(ctx->id) |
drivers/gpu/drm/exynos/exynos_drm_gsc.c:				GSC_BLK_GSCL_WB_IN_SRC_SEL(ctx->id) |
drivers/gpu/drm/exynos/exynos_drm_gsc.c:				GSC_BLK_SW_RESET_WB_DEST(ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		gscblk_cfg |= GSC_BLK_PXLASYNC_LO_MASK_WB(ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	regmap_write(ctx->sysreg, SYSREG_GSCBLK_CFG1, gscblk_cfg);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->rotation = (cfg & GSC_IN_ROT_90) ? 1 : 0;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	*swap = ctx->rotation;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct gsc_scaler *sc = &ctx->sc;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->rotation = (cfg & GSC_IN_ROT_90) ? 1 : 0;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	*swap = ctx->rotation;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	if (ctx->rotation) {
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct gsc_scaler *sc = &ctx->sc;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	mutex_lock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	mutex_unlock(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		clk_prepare_enable(ctx->gsc_clk);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		ctx->suspended = false;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		clk_disable_unprepare(ctx->gsc_clk);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("gsc id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("gsc id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("gsc id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:			ctx->id, status);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:			ctx->id, status);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct gsc_scaler *sc = &ctx->sc;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	memset(&ctx->sc, 0x0, sizeof(ctx->sc));
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ret = gsc_set_prescaler(ctx, &ctx->sc,
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	gsc_set_scaler(ctx, &ctx->sc);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		ctx->sysreg = syscon_regmap_lookup_by_phandle(dev->of_node,
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		if (IS_ERR(ctx->sysreg)) {
drivers/gpu/drm/exynos/exynos_drm_gsc.c:			ctx->sysreg = NULL;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->gsc_clk = devm_clk_get(dev, "gscl");
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	if (IS_ERR(ctx->gsc_clk)) {
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		return PTR_ERR(ctx->gsc_clk);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->regs_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->regs = devm_ioremap_resource(dev, ctx->regs_res);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	if (IS_ERR(ctx->regs))
drivers/gpu/drm/exynos/exynos_drm_gsc.c:		return PTR_ERR(ctx->regs);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->irq = res->start;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ret = devm_request_threaded_irq(dev, ctx->irq, NULL, gsc_irq_handler,
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ctx->id = pdev->id;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("id[%d]ippdrv[%p]\n", ctx->id, ippdrv);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	mutex_init(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	mutex_destroy(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_gsc.c:	DRM_DEBUG_KMS("id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	return readl(ctx->regs + reg);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	writel(val, ctx->regs + reg);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	void __iomem *r = ctx->regs + reg;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	void __iomem *r = ctx->regs + reg;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	return regmap_update_bits(ctx->sysreg, SYSREG_CAMERA_BLK,
drivers/gpu/drm/exynos/exynos_drm_fimc.c:				  ctx->id << SYSREG_FIMD0WB_DEST_SHIFT);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:			ctx->id, status);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	spin_lock_irqsave(&ctx->lock, flags);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	spin_unlock_irqrestore(&ctx->lock, flags);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	DRM_DEBUG_KMS("fimc id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	memset(&ctx->sc, 0x0, sizeof(ctx->sc));
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ret = fimc_set_prescaler(ctx, &ctx->sc,
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	fimc_set_scaler(ctx, &ctx->sc);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		if (IS_ERR(ctx->clocks[i]))
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		clk_put(ctx->clocks[i]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->clocks[i] = ERR_PTR(-EINVAL);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct device *fimc_dev = ctx->ippdrv.dev;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->clocks[i] = ERR_PTR(-EINVAL);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->clocks[i] = clk_get(dev, fimc_clock_names[i]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		if (IS_ERR(ctx->clocks[i])) {
drivers/gpu/drm/exynos/exynos_drm_fimc.c:			ret = PTR_ERR(ctx->clocks[i]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	if (!IS_ERR(ctx->clocks[FIMC_CLK_PARENT])) {
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ret = clk_set_parent(ctx->clocks[FIMC_CLK_MUX],
drivers/gpu/drm/exynos/exynos_drm_fimc.c:				     ctx->clocks[FIMC_CLK_PARENT]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ret = clk_set_rate(ctx->clocks[FIMC_CLK_LCLK], ctx->clk_frequency);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ret = clk_prepare_enable(ctx->clocks[FIMC_CLK_LCLK]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct device_node *node = ctx->ippdrv.dev->of_node;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:					&ctx->clk_frequency))
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->clk_frequency = FIMC_DEFAULT_LCLK_FREQUENCY;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->id = of_alias_get_id(node, "fimc");
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	if (ctx->id < 0) {
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		dev_err(ctx->ippdrv.dev, "failed to get node alias id.\n");
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->ippdrv.dev = dev;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->sysreg = syscon_regmap_lookup_by_phandle(dev->of_node,
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	if (IS_ERR(ctx->sysreg)) {
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		return PTR_ERR(ctx->sysreg);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->regs_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->regs = devm_ioremap_resource(dev, ctx->regs_res);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	if (IS_ERR(ctx->regs))
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		return PTR_ERR(ctx->regs);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ctx->irq = res->start;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ret = devm_request_threaded_irq(dev, ctx->irq, NULL, fimc_irq_handler,
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	DRM_DEBUG_KMS("id[%d]ippdrv[%p]\n", ctx->id, ippdrv);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	spin_lock_init(&ctx->lock);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	struct exynos_drm_ippdrv *ippdrv = &ctx->ippdrv;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		clk_prepare_enable(ctx->clocks[FIMC_CLK_GATE]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		clk_prepare_enable(ctx->clocks[FIMC_CLK_WB_A]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->suspended = false;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		clk_disable_unprepare(ctx->clocks[FIMC_CLK_GATE]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		clk_disable_unprepare(ctx->clocks[FIMC_CLK_WB_A]);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:		ctx->suspended = true;
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	DRM_DEBUG_KMS("id[%d]\n", ctx->id);
drivers/gpu/drm/exynos/exynos_drm_fimc.c:	DRM_DEBUG_KMS("id[%d]\n", ctx->id);
drivers/gpu/drm/amd/amdgpu/atom.c:			temp = ctx->card->ioreg_read(ctx->card, CU16(base + 1));
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->card->ioreg_write(ctx->card, CU16(base + 1), temp);
drivers/gpu/drm/amd/amdgpu/atom.c:			    ((ctx->
drivers/gpu/drm/amd/amdgpu/atom.c:	struct atom_context *gctx = ctx->ctx;
drivers/gpu/drm/amd/amdgpu/atom.c:		idx += gctx->reg_block;
drivers/gpu/drm/amd/amdgpu/atom.c:		switch (gctx->io_mode) {
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->card->reg_read(gctx->card, idx);
drivers/gpu/drm/amd/amdgpu/atom.c:			if (!(gctx->io_mode & 0x80)) {
drivers/gpu/drm/amd/amdgpu/atom.c:			if (!gctx->iio[gctx->io_mode & 0x7F]) {
drivers/gpu/drm/amd/amdgpu/atom.c:				       gctx->io_mode & 0x7F);
drivers/gpu/drm/amd/amdgpu/atom.c:					     gctx->iio[gctx->io_mode & 0x7F],
drivers/gpu/drm/amd/amdgpu/atom.c:		val = get_unaligned_le32((u32 *)&ctx->ps[idx]);
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->divmul[0];
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->divmul[1];
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->data_block;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->shift;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = 1 << gctx->shift;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = ~(1 << gctx->shift);
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->fb_base;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->io_attr;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->reg_block;
drivers/gpu/drm/amd/amdgpu/atom.c:			val = ctx->ws[idx];
drivers/gpu/drm/amd/amdgpu/atom.c:			if (gctx->data_block)
drivers/gpu/drm/amd/amdgpu/atom.c:				DEBUG("ID[0x%04X+%04X]", idx, gctx->data_block);
drivers/gpu/drm/amd/amdgpu/atom.c:		val = U32(idx + gctx->data_block);
drivers/gpu/drm/amd/amdgpu/atom.c:		if ((gctx->fb_base + (idx * 4)) > gctx->scratch_size_bytes) {
drivers/gpu/drm/amd/amdgpu/atom.c:				  gctx->fb_base + (idx * 4), gctx->scratch_size_bytes);
drivers/gpu/drm/amd/amdgpu/atom.c:			val = gctx->scratch[(gctx->fb_base / 4) + idx];
drivers/gpu/drm/amd/amdgpu/atom.c:		val = gctx->card->pll_read(gctx->card, idx);
drivers/gpu/drm/amd/amdgpu/atom.c:		val = gctx->card->mc_read(gctx->card, idx);
drivers/gpu/drm/amd/amdgpu/atom.c:	struct atom_context *gctx = ctx->ctx;
drivers/gpu/drm/amd/amdgpu/atom.c:		idx += gctx->reg_block;
drivers/gpu/drm/amd/amdgpu/atom.c:		switch (gctx->io_mode) {
drivers/gpu/drm/amd/amdgpu/atom.c:				gctx->card->reg_write(gctx->card, idx,
drivers/gpu/drm/amd/amdgpu/atom.c:				gctx->card->reg_write(gctx->card, idx, val);
drivers/gpu/drm/amd/amdgpu/atom.c:			if (!(gctx->io_mode & 0x80)) {
drivers/gpu/drm/amd/amdgpu/atom.c:			if (!gctx->iio[gctx->io_mode & 0xFF]) {
drivers/gpu/drm/amd/amdgpu/atom.c:				       gctx->io_mode & 0x7F);
drivers/gpu/drm/amd/amdgpu/atom.c:			atom_iio_execute(gctx, gctx->iio[gctx->io_mode & 0xFF],
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ps[idx] = cpu_to_le32(val);
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->divmul[0] = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->divmul[1] = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->data_block = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->shift = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->fb_base = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->io_attr = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->reg_block = val;
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->ws[idx] = val;
drivers/gpu/drm/amd/amdgpu/atom.c:		if ((gctx->fb_base + (idx * 4)) > gctx->scratch_size_bytes) {
drivers/gpu/drm/amd/amdgpu/atom.c:				  gctx->fb_base + (idx * 4), gctx->scratch_size_bytes);
drivers/gpu/drm/amd/amdgpu/atom.c:			gctx->scratch[(gctx->fb_base / 4) + idx] = val;
drivers/gpu/drm/amd/amdgpu/atom.c:		gctx->card->pll_write(gctx->card, idx, val);
drivers/gpu/drm/amd/amdgpu/atom.c:		gctx->card->mc_write(gctx->card, idx, val);
drivers/gpu/drm/amd/amdgpu/atom.c:	if (U16(ctx->ctx->cmd_table + 4 + 2 * idx))
drivers/gpu/drm/amd/amdgpu/atom.c:		r = amdgpu_atom_execute_table_locked(ctx->ctx, idx, ctx->ps + ctx->ps_shift);
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->abort = true;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->cs_equal = (dst == src);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->cs_above = (dst > src);
drivers/gpu/drm/amd/amdgpu/atom.c:	SDEBUG("   result: %s %s\n", ctx->ctx->cs_equal ? "EQ" : "NE",
drivers/gpu/drm/amd/amdgpu/atom.c:	       ctx->ctx->cs_above ? "GT" : "LE");
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[0] = dst / src;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[1] = dst % src;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[0] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[1] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:		val64 |= ((uint64_t)ctx->ctx->divmul[1]) << 32;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[0] = lower_32_bits(val64);
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[1] = upper_32_bits(val64);
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[0] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->divmul[1] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = ctx->ctx->cs_above;
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = ctx->ctx->cs_above || ctx->ctx->cs_equal;
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = !(ctx->ctx->cs_above || ctx->ctx->cs_equal);
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = !ctx->ctx->cs_above;
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = ctx->ctx->cs_equal;
drivers/gpu/drm/amd/amdgpu/atom.c:		execute = !ctx->ctx->cs_equal;
drivers/gpu/drm/amd/amdgpu/atom.c:		if (ctx->last_jump == (ctx->start + target)) {
drivers/gpu/drm/amd/amdgpu/atom.c:			if (time_after(cjiffies, ctx->last_jump_jiffies)) {
drivers/gpu/drm/amd/amdgpu/atom.c:				cjiffies -= ctx->last_jump_jiffies;
drivers/gpu/drm/amd/amdgpu/atom.c:					ctx->abort = true;
drivers/gpu/drm/amd/amdgpu/atom.c:				ctx->last_jump_jiffies = jiffies;
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->last_jump = ctx->start + target;
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->last_jump_jiffies = jiffies;
drivers/gpu/drm/amd/amdgpu/atom.c:		*ptr = ctx->start + target;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->divmul[0] = dst * src;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->divmul[0] = lower_32_bits(val64);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->divmul[1] = upper_32_bits(val64);
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->data_block = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->data_block = ctx->start;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->data_block = U16(ctx->ctx->data_table + 4 + 2 * idx);
drivers/gpu/drm/amd/amdgpu/atom.c:	SDEBUG("   base: 0x%04X\n", ctx->ctx->data_block);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->fb_base = atom_get_src(ctx, attr, ptr);
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->ctx->io_mode = ATOM_IO_MM;
drivers/gpu/drm/amd/amdgpu/atom.c:			ctx->ctx->io_mode = ATOM_IO_IIO | port;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->io_mode = ATOM_IO_PCI;
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->ctx->io_mode = ATOM_IO_SYSIO;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->reg_block = U16(*ptr);
drivers/gpu/drm/amd/amdgpu/atom.c:	SDEBUG("   base: 0x%04X\n", ctx->ctx->reg_block);
drivers/gpu/drm/amd/amdgpu/atom.c:				*ptr = ctx->start + target;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->ctx->cs_equal = ((dst & src) == 0);
drivers/gpu/drm/amd/amdgpu/atom.c:	SDEBUG("   result: %s\n", ctx->ctx->cs_equal ? "EQ" : "NE");
drivers/gpu/drm/amd/amdgpu/atom.c:	int base = CU16(ctx->cmd_table + 4 + 2 * index);
drivers/gpu/drm/amd/amdgpu/atom.c:	mutex_lock(&ctx->mutex);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->data_block = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->reg_block = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->fb_base = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->io_mode = ATOM_IO_MM;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->divmul[0] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->divmul[1] = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	mutex_unlock(&ctx->mutex);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->iio = kzalloc(2 * 256, GFP_KERNEL);
drivers/gpu/drm/amd/amdgpu/atom.c:	if (!ctx->iio)
drivers/gpu/drm/amd/amdgpu/atom.c:		ctx->iio[CU8(base + 1)] = base + 2;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->card = card;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->bios = bios;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->cmd_table = CU16(base + ATOM_ROM_CMD_PTR);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->data_table = CU16(base + ATOM_ROM_DATA_PTR);
drivers/gpu/drm/amd/amdgpu/atom.c:	atom_index_iio(ctx, CU16(ctx->data_table + ATOM_DATA_IIO_PTR) + 4);
drivers/gpu/drm/amd/amdgpu/atom.c:	if (!ctx->iio) {
drivers/gpu/drm/amd/amdgpu/atom.c:	int hwi = CU16(ctx->data_table + ATOM_DATA_FWI_PTR);
drivers/gpu/drm/amd/amdgpu/atom.c:	if (!CU16(ctx->cmd_table + 4 + 2 * ATOM_CMD_INIT))
drivers/gpu/drm/amd/amdgpu/atom.c:	kfree(ctx->iio);
drivers/gpu/drm/amd/amdgpu/atom.c:	int idx = CU16(ctx->data_table + offset);
drivers/gpu/drm/amd/amdgpu/atom.c:	u16 *mdt = (u16 *)(ctx->bios + ctx->data_table + 4);
drivers/gpu/drm/amd/amdgpu/atom.c:	int idx = CU16(ctx->cmd_table + offset);
drivers/gpu/drm/amd/amdgpu/atom.c:	u16 *mct = (u16 *)(ctx->bios + ctx->cmd_table + 4);
drivers/gpu/drm/amd/amdgpu/atom.c:		firmware_usage = (struct _ATOM_VRAM_USAGE_BY_FIRMWARE *)(ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->scratch_size_bytes = 0;
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->scratch = kzalloc(usage_bytes, GFP_KERNEL);
drivers/gpu/drm/amd/amdgpu/atom.c:	if (!ctx->scratch)
drivers/gpu/drm/amd/amdgpu/atom.c:	ctx->scratch_size_bytes = usage_bytes;
drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c:			if (!parser->ctx->preamble_presented) {
drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c:				parser->ctx->preamble_presented = true;
drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c:	struct amd_sched_entity *entity = &p->ctx->rings[ring->idx].entity;
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:		i2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:		i2c_info = (struct _ATOM_GPIO_I2C_INFO *)(ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:		gpio_info = (struct _ATOM_GPIO_PIN_LUT *)(ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	obj_header = (ATOM_OBJECT_HEADER *) (ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	obj_header = (ATOM_OBJECT_HEADER *) (ctx->bios + data_offset);
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:	    (ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:		(ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:								(ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_atombios.c:						    (ctx->bios + data_offset +
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	lo = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->data0);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	hi = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->data1);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	mapping = amdgpu_cs_find_mapping(ctx->parser, addr, &bo);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	if (!ctx->parser->adev->uvd.address_64_bit) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		cmd = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->idx) >> 1;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	struct amdgpu_device *adev = ctx->parser->adev;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:				adev->uvd.filp[i] = ctx->parser->filp;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		r = amdgpu_uvd_cs_msg_decode(adev, msg, ctx->buf_sizes);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:				if (adev->uvd.filp[i] != ctx->parser->filp) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	lo = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->data0);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	hi = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->data1);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	mapping = amdgpu_cs_find_mapping(ctx->parser, addr, &bo);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	amdgpu_set_ib_value(ctx->parser, ctx->ib_idx, ctx->data0,
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	amdgpu_set_ib_value(ctx->parser, ctx->ib_idx, ctx->data1,
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	cmd = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->idx) >> 1;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		if ((end - start) < ctx->buf_sizes[cmd]) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:				  ctx->buf_sizes[cmd]);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		if ((end - start) < ctx->buf_sizes[4]) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:					  ctx->buf_sizes[4]);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	if (!ctx->parser->adev->uvd.address_64_bit) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		    (start >> 28) != (ctx->parser->adev->uvd.gpu_addr >> 28)) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		ctx->has_msg_cmd = true;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	} else if (!ctx->has_msg_cmd) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	struct amdgpu_ib *ib = &ctx->parser->job->ibs[ctx->ib_idx];
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	ctx->idx++;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	for (i = 0; i <= ctx->count; ++i) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		unsigned reg = ctx->reg + i;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		if (ctx->idx >= ib->length_dw) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			ctx->data0 = ctx->idx;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			ctx->data1 = ctx->idx;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		ctx->idx++;
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	struct amdgpu_ib *ib = &ctx->parser->job->ibs[ctx->ib_idx];
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:	for (ctx->idx = 0 ; ctx->idx < ib->length_dw; ) {
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:		uint32_t cmd = amdgpu_get_ib_value(ctx->parser, ctx->ib_idx, ctx->idx);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			ctx->reg = CP_PACKET0_GET_REG(cmd);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			ctx->count = CP_PACKET_GET_COUNT(cmd);
drivers/gpu/drm/amd/amdgpu/amdgpu_uvd.c:			++ctx->idx;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	ctx->adev = adev;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	kref_init(&ctx->refcount);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	spin_lock_init(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	ctx->fences = kcalloc(amdgpu_sched_jobs * AMDGPU_MAX_RINGS,
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	if (!ctx->fences)
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		ctx->rings[i].sequence = 1;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		ctx->rings[i].fences = &ctx->fences[amdgpu_sched_jobs * i];
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	ctx->reset_counter = atomic_read(&adev->gpu_reset_counter);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		r = amd_sched_entity_init(&ring->sched, &ctx->rings[i].entity,
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:					      &ctx->rings[j].entity);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		kfree(ctx->fences);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		ctx->fences = NULL;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	struct amdgpu_device *adev = ctx->adev;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:			fence_put(ctx->rings[i].fences[j]);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	kfree(ctx->fences);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	ctx->fences = NULL;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:				      &ctx->rings[i].entity);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		kref_put(&ctx->refcount, amdgpu_ctx_do_release);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	if (ctx->reset_counter == reset_counter)
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	ctx->reset_counter = reset_counter;
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		kref_get(&ctx->refcount);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	kref_put(&ctx->refcount, amdgpu_ctx_do_release);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	struct amdgpu_ctx_ring *cring = & ctx->rings[ring->idx];
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	spin_lock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	spin_unlock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	struct amdgpu_ctx_ring *cring = & ctx->rings[ring->idx];
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	spin_lock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		spin_unlock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		spin_unlock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:	spin_unlock(&ctx->ring_lock);
drivers/gpu/drm/amd/amdgpu/amdgpu_ctx.c:		if (kref_put(&ctx->refcount, amdgpu_ctx_do_release) != 1)
drivers/gpu/drm/amd/include/atom-bits.h:#define U8(ptr) get_u8(ctx->ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define CU8(ptr) get_u8(ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define U16(ptr) get_u16(ctx->ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define CU16(ptr) get_u16(ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define U32(ptr) get_u32(ctx->ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define CU32(ptr) get_u32(ctx->bios, (ptr))
drivers/gpu/drm/amd/include/atom-bits.h:#define CSTR(ptr) (((char *)(ctx->bios))+(ptr))
drivers/gpu/msm/adreno_debugfs.c:	snprintf(name, sizeof(name), "%d", ctx->base.id);
drivers/gpu/msm/adreno_debugfs.c:	ctx->debug_root = debugfs_create_file(name, 0444,
drivers/gpu/msm/adreno_debugfs.c:				(void *)(unsigned long)ctx->base.id, &ctx_fops);
drivers/gpu/msm/adreno_iommu.c:						ctx->cb_num);
drivers/gpu/msm/adreno_trace.h:		__entry->newctx = newctx ? newctx->base.id : 0;
drivers/gpu/msm/kgsl_iommu.h:	return ctx->regbase + kgsl_iommu_reg_list[reg];
drivers/gpu/msm/kgsl_iommu.c:		iommu_detach_device(iommu_pt->domain, ctx->dev);
drivers/gpu/msm/kgsl_iommu.c:	ret = iommu_attach_device(iommu_pt->domain, ctx->dev);
drivers/gpu/msm/kgsl_iommu.c:		KGSL_LOG_DUMP(ctx->kgsldev, "---- premature free ----\n");
drivers/gpu/msm/kgsl_iommu.c:		KGSL_LOG_DUMP(ctx->kgsldev,
drivers/gpu/msm/kgsl_iommu.c:	ctx->fault = 1;
drivers/gpu/msm/kgsl_iommu.c:	trace_kgsl_mmu_pagefault(ctx->kgsldev, addr,
drivers/gpu/msm/kgsl_iommu.c:		KGSL_MEM_CRIT(ctx->kgsldev,
drivers/gpu/msm/kgsl_iommu.c:		KGSL_MEM_CRIT(ctx->kgsldev,
drivers/gpu/msm/kgsl_iommu.c:			ctx->name, ptbase, contextidr,
drivers/gpu/msm/kgsl_iommu.c:			KGSL_MEM_CRIT(ctx->kgsldev,
drivers/gpu/msm/kgsl_iommu.c:			KGSL_LOG_DUMP(ctx->kgsldev,
drivers/gpu/msm/kgsl_iommu.c:				_print_entry(ctx->kgsldev, &prev);
drivers/gpu/msm/kgsl_iommu.c:				KGSL_LOG_DUMP(ctx->kgsldev, "*EMPTY*\n");
drivers/gpu/msm/kgsl_iommu.c:			KGSL_LOG_DUMP(ctx->kgsldev, " <- fault @ %8.8lX\n",
drivers/gpu/msm/kgsl_iommu.c:				_print_entry(ctx->kgsldev, &next);
drivers/gpu/msm/kgsl_iommu.c:				KGSL_LOG_DUMP(ctx->kgsldev, "*EMPTY*\n");
drivers/gpu/msm/kgsl_iommu.c:	iommu_pt = _alloc_pt(ctx->dev, mmu, pt);
drivers/gpu/msm/kgsl_iommu.c:	ctx->cb_num = cb_num;
drivers/gpu/msm/kgsl_iommu.c:	ctx->regbase = iommu->regbase + KGSL_IOMMU_CB0_OFFSET
drivers/gpu/msm/kgsl_iommu.c:		if (!kgsl_mmu_bus_secured(ctx->dev))
drivers/gpu/msm/kgsl_iommu.c:	iommu_pt = _alloc_pt(ctx->dev, mmu, pt);
drivers/gpu/msm/kgsl_iommu.c:	ctx->cb_num = cb_num;
drivers/gpu/msm/kgsl_iommu.c:	ctx->regbase = iommu->regbase + KGSL_IOMMU_CB0_OFFSET
drivers/gpu/msm/kgsl_iommu.c:	unsigned int cb_num = ctx->cb_num;
drivers/gpu/msm/kgsl_iommu.c:	iommu_pt = _alloc_pt(ctx->dev, mmu, pt);
drivers/gpu/msm/kgsl_iommu.c:	return ctx->gpu_offset + kgsl_iommu_reg_list[reg];
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->default_pt == NULL)
drivers/gpu/msm/kgsl_iommu.c:	iommu_pt = ctx->default_pt->priv;
drivers/gpu/msm/kgsl_iommu.c:	ctx->default_pt = NULL;
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->name == NULL) {
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->gpu_offset == UINT_MAX) {
drivers/gpu/msm/kgsl_iommu.c:	ctx->default_pt = mmu->defaultpagetable;
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->dev == NULL || !mmu->secured)
drivers/gpu/msm/kgsl_iommu.c:	ctx->default_pt = mmu->securepagetable;
drivers/gpu/msm/kgsl_iommu.c:	ctx->cb_num = cb_num;
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->default_pt != NULL) {
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->default_pt != NULL && ctx->fault) {
drivers/gpu/msm/kgsl_iommu.c:		ctx->fault = 0;
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->default_pt != NULL) {
drivers/gpu/msm/kgsl_iommu.c:			ctx->id = id;
drivers/gpu/msm/kgsl_iommu.c:			ctx->cb_num = -1;
drivers/gpu/msm/kgsl_iommu.c:			ctx->name = kgsl_iommu_cbs[i].name;
drivers/gpu/msm/kgsl_iommu.c:	if (ctx->id == KGSL_IOMMU_CONTEXT_SECURE)
drivers/gpu/msm/kgsl_iommu.c:	if (of_property_read_u32(node, "qcom,gpu-offset", &ctx->gpu_offset))
drivers/gpu/msm/kgsl_iommu.c:		ctx->gpu_offset = UINT_MAX;
drivers/gpu/msm/kgsl_iommu.c:	ctx->kgsldev = device;
drivers/gpu/msm/kgsl_iommu.c:		ctx->dev = &pdev->dev;
drivers/gpu/msm/kgsl_iommu.c:		ctx->dev = kgsl_mmu_get_ctx(ctx->name);
drivers/gpu/msm/kgsl_iommu.c:		if (IS_ERR(ctx->dev))
drivers/gpu/msm/kgsl_iommu.c:			return PTR_ERR(ctx->dev);
drivers/gpu/msm/kgsl_gmu.c:	ctx->dev = dev;
drivers/gpu/msm/kgsl_gmu.c:	ctx->domain = iommu_domain_alloc(&platform_bus_type);
drivers/gpu/msm/kgsl_gmu.c:	if (ctx->domain == NULL) {
drivers/gpu/msm/kgsl_gmu.c:			ctx->name);
drivers/gpu/msm/kgsl_gmu.c:	ret = iommu_attach_device(ctx->domain, dev);
drivers/gpu/msm/kgsl_gmu.c:			ctx->name);
drivers/gpu/msm/kgsl_gmu.c:		iommu_domain_free(ctx->domain);
drivers/gpu/msm/kgsl_gmu.c:			iommu_set_fault_handler(ctx->domain,
drivers/gpu/msm/kgsl_gmu.c:	iommu_unmap(ctx->domain,
drivers/gpu/msm/kgsl_gmu.c:			iommu_unmap(ctx->domain, memptr->gmuaddr, memptr->size);
drivers/gpu/msm/kgsl_gmu.c:	iommu_detach_device(ctx->domain, ctx->dev);
drivers/gpu/msm/kgsl_gmu.c:	iommu_domain_free(ctx->domain);
drivers/block/virtio_blk.c:	struct virtio_blk *vblk = hctx->queue->queuedata;
drivers/block/virtio_blk.c:	int qid = hctx->queue_num;
drivers/block/virtio_blk.c:	num = blk_rq_map_sg(hctx->queue, vbr->req, vbr->sg);
drivers/block/mtip32xx/mtip32xx.c:	return blk_mq_tag_to_rq(hctx->tags, tag);
drivers/block/mtip32xx/mtip32xx.c:	struct driver_data *dd = hctx->queue->queuedata;
drivers/block/mtip32xx/mtip32xx.c:	nents = blk_rq_map_sg(hctx->queue, rq, cmd->sg);
drivers/block/mtip32xx/mtip32xx.c:	struct driver_data *dd = hctx->queue->queuedata;
drivers/block/null_blk.c:	cmd->nq = hctx->driver_data;
drivers/block/null_blk.c:	hctx->driver_data = nq;
drivers/block/xen-blkfront.c:	int qid = hctx->queue_num;
drivers/block/xen-blkfront.c:	struct blkfront_info *info = hctx->queue->queuedata;
drivers/block/drbd/drbd_main.c:	struct drbd_resource *resource = adm_ctx->resource;
drivers/block/drbd/drbd_main.c:	int vnr = adm_ctx->volume;
drivers/block/drbd/drbd_bitmap.c:	spin_lock_irqsave(&ctx->device->resource->req_lock, flags);
drivers/block/drbd/drbd_bitmap.c:	list_del(&ctx->list);
drivers/block/drbd/drbd_bitmap.c:	spin_unlock_irqrestore(&ctx->device->resource->req_lock, flags);
drivers/block/drbd/drbd_bitmap.c:	put_ldev(ctx->device);
drivers/block/drbd/drbd_bitmap.c:	struct drbd_device *device = ctx->device;
drivers/block/drbd/drbd_bitmap.c:	if ((ctx->flags & BM_AIO_COPY_PAGES) == 0 &&
drivers/block/drbd/drbd_bitmap.c:		ctx->error = bio->bi_error;
drivers/block/drbd/drbd_bitmap.c:	if (ctx->flags & BM_AIO_COPY_PAGES)
drivers/block/drbd/drbd_bitmap.c:	if (atomic_dec_and_test(&ctx->in_flight)) {
drivers/block/drbd/drbd_bitmap.c:		ctx->done = 1;
drivers/block/drbd/drbd_bitmap.c:		kref_put(&ctx->kref, &drbd_bm_aio_ctx_destroy);
drivers/block/drbd/drbd_bitmap.c:	struct drbd_device *device = ctx->device;
drivers/block/drbd/drbd_bitmap.c:	unsigned int op = (ctx->flags & BM_AIO_READ) ? REQ_OP_READ : REQ_OP_WRITE;
drivers/block/drbd/drbd_bitmap.c:	if (ctx->flags & BM_AIO_COPY_PAGES) {
drivers/block/drbd/drbd_bitmap.c:	if (0 == (ctx->flags & ~BM_AIO_READ))
drivers/block/drbd/drbd_bitmap.c:	list_add_tail(&ctx->list, &device->pending_bitmap_io);
drivers/block/drbd/drbd_bitmap.c:			atomic_inc(&ctx->in_flight);
drivers/block/drbd/drbd_bitmap.c:			atomic_inc(&ctx->in_flight);
drivers/block/drbd/drbd_bitmap.c:			atomic_inc(&ctx->in_flight);
drivers/block/drbd/drbd_bitmap.c:	 * We initialize ctx->in_flight to one to make sure drbd_bm_endio
drivers/block/drbd/drbd_bitmap.c:	 * will not set ctx->done early, and decrement / test it here.  If there
drivers/block/drbd/drbd_bitmap.c:	if (!atomic_dec_and_test(&ctx->in_flight))
drivers/block/drbd/drbd_bitmap.c:		wait_until_done_or_force_detached(device, device->ldev, &ctx->done);
drivers/block/drbd/drbd_bitmap.c:		kref_put(&ctx->kref, &drbd_bm_aio_ctx_destroy);
drivers/block/drbd/drbd_bitmap.c:	if (ctx->error) {
drivers/block/drbd/drbd_bitmap.c:		err = -EIO; /* ctx->error ? */
drivers/block/drbd/drbd_bitmap.c:	if (atomic_read(&ctx->in_flight))
drivers/block/drbd/drbd_bitmap.c:	kref_put(&ctx->kref, &drbd_bm_aio_ctx_destroy);
drivers/block/drbd/drbd_debugfs.c:	if (ctx && ctx->done)
drivers/block/drbd/drbd_debugfs.c:		start_jif = ctx->start_jif;
drivers/block/drbd/drbd_debugfs.c:		in_flight = atomic_read(&ctx->in_flight);
drivers/block/drbd/drbd_debugfs.c:		flags = ctx->flags;
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_skb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->reply_skb) {
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_dh = genlmsg_put_reply(adm_ctx->reply_skb,
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->reply_dh) {
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_dh->minor = d_in->minor;
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_dh->ret_code = NO_ERROR;
drivers/block/drbd/drbd_nl.c:	adm_ctx->volume = VOLUME_UNSPECIFIED;
drivers/block/drbd/drbd_nl.c:		err = nla_put_nohdr(adm_ctx->reply_skb,
drivers/block/drbd/drbd_nl.c:			adm_ctx->volume = nla_get_u32(nla);
drivers/block/drbd/drbd_nl.c:			adm_ctx->resource_name = nla_data(nla);
drivers/block/drbd/drbd_nl.c:		adm_ctx->my_addr = nested_attr_tb[__nla_type(T_ctx_my_addr)];
drivers/block/drbd/drbd_nl.c:		adm_ctx->peer_addr = nested_attr_tb[__nla_type(T_ctx_peer_addr)];
drivers/block/drbd/drbd_nl.c:		if ((adm_ctx->my_addr &&
drivers/block/drbd/drbd_nl.c:		     nla_len(adm_ctx->my_addr) > sizeof(adm_ctx->connection->my_addr)) ||
drivers/block/drbd/drbd_nl.c:		    (adm_ctx->peer_addr &&
drivers/block/drbd/drbd_nl.c:		     nla_len(adm_ctx->peer_addr) > sizeof(adm_ctx->connection->peer_addr))) {
drivers/block/drbd/drbd_nl.c:	adm_ctx->minor = d_in->minor;
drivers/block/drbd/drbd_nl.c:	adm_ctx->device = minor_to_device(d_in->minor);
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->device)
drivers/block/drbd/drbd_nl.c:		kref_get(&adm_ctx->device->kref);
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->resource_name) {
drivers/block/drbd/drbd_nl.c:		adm_ctx->resource = drbd_find_resource(adm_ctx->resource_name);
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->device && (flags & DRBD_ADM_NEED_MINOR)) {
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "unknown minor");
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->resource && (flags & DRBD_ADM_NEED_RESOURCE)) {
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "unknown resource");
drivers/block/drbd/drbd_nl.c:		if (adm_ctx->resource_name)
drivers/block/drbd/drbd_nl.c:		if (adm_ctx->resource) {
drivers/block/drbd/drbd_nl.c:			drbd_msg_put_info(adm_ctx->reply_skb, "no resource name expected");
drivers/block/drbd/drbd_nl.c:		if (adm_ctx->device) {
drivers/block/drbd/drbd_nl.c:			drbd_msg_put_info(adm_ctx->reply_skb, "no minor number expected");
drivers/block/drbd/drbd_nl.c:		if (adm_ctx->my_addr && adm_ctx->peer_addr)
drivers/block/drbd/drbd_nl.c:			adm_ctx->connection = conn_get_by_addrs(nla_data(adm_ctx->my_addr),
drivers/block/drbd/drbd_nl.c:							  nla_len(adm_ctx->my_addr),
drivers/block/drbd/drbd_nl.c:							  nla_data(adm_ctx->peer_addr),
drivers/block/drbd/drbd_nl.c:							  nla_len(adm_ctx->peer_addr));
drivers/block/drbd/drbd_nl.c:		if (!adm_ctx->connection) {
drivers/block/drbd/drbd_nl.c:			drbd_msg_put_info(adm_ctx->reply_skb, "unknown connection");
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->device && adm_ctx->resource &&
drivers/block/drbd/drbd_nl.c:	    adm_ctx->device->resource != adm_ctx->resource) {
drivers/block/drbd/drbd_nl.c:				adm_ctx->minor, adm_ctx->resource->name,
drivers/block/drbd/drbd_nl.c:				adm_ctx->device->resource->name);
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "minor exists in different resource");
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->device &&
drivers/block/drbd/drbd_nl.c:	    adm_ctx->volume != VOLUME_UNSPECIFIED &&
drivers/block/drbd/drbd_nl.c:	    adm_ctx->volume != adm_ctx->device->vnr) {
drivers/block/drbd/drbd_nl.c:				adm_ctx->minor, adm_ctx->volume,
drivers/block/drbd/drbd_nl.c:				adm_ctx->device->vnr,
drivers/block/drbd/drbd_nl.c:				adm_ctx->device->resource->name);
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "minor exists as different volume");
drivers/block/drbd/drbd_nl.c:	/* still, provide adm_ctx->resource always, if possible. */
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->resource) {
drivers/block/drbd/drbd_nl.c:		adm_ctx->resource = adm_ctx->device ? adm_ctx->device->resource
drivers/block/drbd/drbd_nl.c:			: adm_ctx->connection ? adm_ctx->connection->resource : NULL;
drivers/block/drbd/drbd_nl.c:		if (adm_ctx->resource)
drivers/block/drbd/drbd_nl.c:			kref_get(&adm_ctx->resource->kref);
drivers/block/drbd/drbd_nl.c:	nlmsg_free(adm_ctx->reply_skb);
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_skb = NULL;
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->device) {
drivers/block/drbd/drbd_nl.c:		kref_put(&adm_ctx->device->kref, drbd_destroy_device);
drivers/block/drbd/drbd_nl.c:		adm_ctx->device = NULL;
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->connection) {
drivers/block/drbd/drbd_nl.c:		kref_put(&adm_ctx->connection->kref, &drbd_destroy_connection);
drivers/block/drbd/drbd_nl.c:		adm_ctx->connection = NULL;
drivers/block/drbd/drbd_nl.c:	if (adm_ctx->resource) {
drivers/block/drbd/drbd_nl.c:		kref_put(&adm_ctx->resource->kref, drbd_destroy_resource);
drivers/block/drbd/drbd_nl.c:		adm_ctx->resource = NULL;
drivers/block/drbd/drbd_nl.c:	if (!adm_ctx->reply_skb)
drivers/block/drbd/drbd_nl.c:	adm_ctx->reply_dh->ret_code = retcode;
drivers/block/drbd/drbd_nl.c:	drbd_adm_send_reply(adm_ctx->reply_skb, info);
drivers/block/drbd/drbd_nl.c:	const char *name = adm_ctx->resource_name;
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "resource name missing");
drivers/block/drbd/drbd_nl.c:		drbd_msg_put_info(adm_ctx->reply_skb, "invalid resource name");
drivers/block/drbd/drbd_receiver.c:	struct drbd_device *device = octx->device;
drivers/block/drbd/drbd_receiver.c:	struct issue_flush_context *ctx = octx->ctx;
drivers/block/drbd/drbd_receiver.c:		ctx->error = bio->bi_error;
drivers/block/drbd/drbd_receiver.c:	if (atomic_dec_and_test(&ctx->pending))
drivers/block/drbd/drbd_receiver.c:		complete(&ctx->done);
drivers/block/drbd/drbd_receiver.c:		ctx->error = -ENOMEM;
drivers/block/drbd/drbd_receiver.c:	octx->device = device;
drivers/block/drbd/drbd_receiver.c:	octx->ctx = ctx;
drivers/block/drbd/drbd_receiver.c:	atomic_inc(&ctx->pending);
drivers/power/reset/syscon-reboot.c:	regmap_write(ctx->map, ctx->offset, ctx->mask);
drivers/power/reset/syscon-reboot.c:	ctx->map = syscon_regmap_lookup_by_phandle(dev->of_node, "regmap");
drivers/power/reset/syscon-reboot.c:	if (IS_ERR(ctx->map))
drivers/power/reset/syscon-reboot.c:		return PTR_ERR(ctx->map);
drivers/power/reset/syscon-reboot.c:	if (of_property_read_u32(pdev->dev.of_node, "offset", &ctx->offset))
drivers/power/reset/syscon-reboot.c:	if (of_property_read_u32(pdev->dev.of_node, "mask", &ctx->mask))
drivers/power/reset/syscon-reboot.c:	ctx->restart_handler.notifier_call = syscon_restart_handle;
drivers/power/reset/syscon-reboot.c:	ctx->restart_handler.priority = 192;
drivers/power/reset/syscon-reboot.c:	err = register_restart_handler(&ctx->restart_handler);
drivers/power/reset/xgene-reboot.c:	writel(ctx->mask, ctx->csr);
drivers/power/reset/xgene-reboot.c:	dev_emerg(ctx->dev, "Unable to restart system\n");
drivers/power/reset/xgene-reboot.c:	ctx->csr = of_iomap(dev->of_node, 0);
drivers/power/reset/xgene-reboot.c:	if (!ctx->csr) {
drivers/power/reset/xgene-reboot.c:	if (of_property_read_u32(dev->of_node, "mask", &ctx->mask))
drivers/power/reset/xgene-reboot.c:		ctx->mask = 0xFFFFFFFF;
drivers/power/reset/xgene-reboot.c:	ctx->dev = dev;
drivers/power/reset/xgene-reboot.c:	ctx->restart_handler.notifier_call = xgene_restart_handler;
drivers/power/reset/xgene-reboot.c:	ctx->restart_handler.priority = 128;
drivers/power/reset/xgene-reboot.c:	err = register_restart_handler(&ctx->restart_handler);
drivers/power/reset/xgene-reboot.c:		iounmap(ctx->csr);
drivers/hv/vmbus_drv.c:	vmbus_onmessage(&ctx->msg);
drivers/hv/vmbus_drv.c:		INIT_WORK(&ctx->work, vmbus_onmessage_work);
drivers/hv/vmbus_drv.c:		memcpy(&ctx->msg, msg, sizeof(*msg));
drivers/hv/vmbus_drv.c:		queue_work(vmbus_connection.work_queue, &ctx->work);
fs/ubifs/dir.c:	dbg_gen("dir ino %lu, f_pos %#llx", dir->i_ino, ctx->pos);
fs/ubifs/dir.c:	if (ctx->pos > UBIFS_S_KEY_HASH_MASK || ctx->pos == 2)
fs/ubifs/dir.c:	if (ctx->pos < 2) {
fs/ubifs/dir.c:		ctx->pos = key_hash_flash(c, &dent->key);
fs/ubifs/dir.c:		 * Find the entry corresponding to @ctx->pos or the closest one.
fs/ubifs/dir.c:		dent_key_init_hash(c, &key, dir->i_ino, ctx->pos);
fs/ubifs/dir.c:		ctx->pos = key_hash_flash(c, &dent->key);
fs/ubifs/dir.c:		ctx->pos = key_hash_flash(c, &dent->key);
fs/ubifs/dir.c:	ctx->pos = 2;
fs/befs/linuxvfs.c:	befs_debug(sb, "---> %s name %pD, inode %ld, ctx->pos %lld",
fs/befs/linuxvfs.c:		  __func__, file, inode->i_ino, ctx->pos);
fs/befs/linuxvfs.c:		result = befs_btree_read(sb, ds, ctx->pos, BEFS_NAME_LEN + 1,
fs/befs/linuxvfs.c:		ctx->pos++;
fs/ufs/dir.c:	loff_t pos = ctx->pos;
fs/ufs/dir.c:			ctx->pos += PAGE_SIZE - offset;
fs/ufs/dir.c:				ctx->pos = (n<<PAGE_SHIFT) + offset;
fs/ufs/dir.c:			ctx->pos += fs16_to_cpu(sb, de->d_reclen);
fs/ufs/inode.c:	if (ctx->count && ctx->to != from) {
fs/ufs/inode.c:		ufs_free_blocks(ctx->inode, ctx->to - ctx->count, ctx->count);
fs/ufs/inode.c:		ctx->count = 0;
fs/ufs/inode.c:	ctx->count += count;
fs/ufs/inode.c:	ctx->to = from + count;
fs/nilfs2/dir.c:	loff_t pos = ctx->pos;
fs/nilfs2/dir.c:			ctx->pos += PAGE_SIZE - offset;
fs/nilfs2/dir.c:			ctx->pos += nilfs_rec_len_from_disk(de->rec_len);
fs/openpromfs/inode.c:	if (ctx->pos == 0) {
fs/openpromfs/inode.c:		ctx->pos = 1;
fs/openpromfs/inode.c:	if (ctx->pos == 1) {
fs/openpromfs/inode.c:		ctx->pos = 2;
fs/openpromfs/inode.c:	i = ctx->pos - 2;
fs/openpromfs/inode.c:		ctx->pos++;
fs/openpromfs/inode.c:		ctx->pos++;
fs/overlayfs/readdir.c:	if (!ctx->pos)
fs/overlayfs/readdir.c:		ovl_seek_cursor(od, ctx->pos);
fs/overlayfs/readdir.c:		ctx->pos++;
fs/omfs/dir.c:		ctx->pos++;
fs/omfs/dir.c:	if (ctx->pos >> 32)
fs/omfs/dir.c:	if (ctx->pos < 1 << 20) {
fs/omfs/dir.c:		ctx->pos = 1 << 20;
fs/omfs/dir.c:	hchain = (ctx->pos >> 20) - 1;
fs/omfs/dir.c:	hindex = ctx->pos & 0xfffff;
fs/omfs/dir.c:		ctx->pos = (hchain+2) << 20;
fs/udf/dir.c:	if (ctx->pos == 0) {
fs/udf/dir.c:		ctx->pos = 1;
fs/udf/dir.c:	nf_pos = (ctx->pos - 1) << 2;
fs/udf/dir.c:		ctx->pos = (nf_pos >> 2) + 1;
fs/udf/dir.c:	ctx->pos = (nf_pos >> 2) + 1;
fs/romfs/super.c:	offset = ctx->pos;
fs/romfs/super.c:			ctx->pos = offset;
fs/romfs/super.c:		ctx->pos = offset;
fs/affs/dir.c:	pr_debug("%s(ino=%lu,f_pos=%llx)\n", __func__, inode->i_ino, ctx->pos);
fs/affs/dir.c:	if (ctx->pos < 2) {
fs/affs/dir.c:	chain_pos = (ctx->pos - 2) & 0xffff;
fs/affs/dir.c:	hash_pos  = (ctx->pos - 2) >> 16;
fs/affs/dir.c:		ctx->pos = ((hash_pos << 16) | chain_pos) + 2;
fs/affs/dir.c:		ctx->pos = (hash_pos << 16) + 2;
fs/affs/dir.c:				 namelen, name, ino, hash_pos, ctx->pos);
fs/affs/dir.c:			ctx->pos++;
fs/aio.c:	struct file *aio_ring_file = ctx->aio_ring_file;
fs/aio.c:		ctx->aio_ring_file = NULL;
fs/aio.c:	for (i = 0; i < ctx->nr_pages; i++) {
fs/aio.c:				page_count(ctx->ring_pages[i]));
fs/aio.c:		page = ctx->ring_pages[i];
fs/aio.c:		ctx->ring_pages[i] = NULL;
fs/aio.c:	if (ctx->ring_pages && ctx->ring_pages != ctx->internal_pages) {
fs/aio.c:		kfree(ctx->ring_pages);
fs/aio.c:		ctx->ring_pages = NULL;
fs/aio.c:		if (ctx && ctx->aio_ring_file == file) {
fs/aio.c:			if (!atomic_read(&ctx->dead)) {
fs/aio.c:				ctx->user_id = ctx->mmap_base = vma->vm_start;
fs/aio.c:	if (!mutex_trylock(&ctx->ring_lock)) {
fs/aio.c:	if (idx < (pgoff_t)ctx->nr_pages) {
fs/aio.c:		if (ctx->ring_pages[idx] != old)
fs/aio.c:	spin_lock_irqsave(&ctx->completion_lock, flags);
fs/aio.c:	BUG_ON(ctx->ring_pages[idx] != old);
fs/aio.c:	ctx->ring_pages[idx] = new;
fs/aio.c:	spin_unlock_irqrestore(&ctx->completion_lock, flags);
fs/aio.c:	mutex_unlock(&ctx->ring_lock);
fs/aio.c:	unsigned nr_events = ctx->max_reqs;
fs/aio.c:		ctx->aio_ring_file = NULL;
fs/aio.c:	ctx->aio_ring_file = file;
fs/aio.c:	ctx->ring_pages = ctx->internal_pages;
fs/aio.c:		ctx->ring_pages = kcalloc(nr_pages, sizeof(struct page *),
fs/aio.c:		if (!ctx->ring_pages) {
fs/aio.c:		ctx->ring_pages[i] = page;
fs/aio.c:	ctx->nr_pages = i;
fs/aio.c:	ctx->mmap_size = nr_pages * PAGE_SIZE;
fs/aio.c:	pr_debug("attempting mmap of %lu bytes\n", ctx->mmap_size);
fs/aio.c:		ctx->mmap_size = 0;
fs/aio.c:	ctx->mmap_base = do_mmap_pgoff(ctx->aio_ring_file, 0, ctx->mmap_size,
fs/aio.c:	if (IS_ERR((void *)ctx->mmap_base)) {
fs/aio.c:		ctx->mmap_size = 0;
fs/aio.c:	pr_debug("mmap address: 0x%08lx\n", ctx->mmap_base);
fs/aio.c:	ctx->user_id = ctx->mmap_base;
fs/aio.c:	ctx->nr_events = nr_events; /* trusted copy */
fs/aio.c:	ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:	flush_dcache_page(ctx->ring_pages[0]);
fs/aio.c:	spin_lock_irqsave(&ctx->ctx_lock, flags);
fs/aio.c:		list_add(&req->ki_list, &ctx->active_reqs);
fs/aio.c:	spin_unlock_irqrestore(&ctx->ctx_lock, flags);
fs/aio.c:	free_percpu(ctx->cpu);
fs/aio.c:	percpu_ref_exit(&ctx->reqs);
fs/aio.c:	percpu_ref_exit(&ctx->users);
fs/aio.c:	if (ctx->rq_wait && atomic_dec_and_test(&ctx->rq_wait->count))
fs/aio.c:		complete(&ctx->rq_wait->comp);
fs/aio.c:	INIT_WORK(&ctx->free_work, free_ioctx);
fs/aio.c:	schedule_work(&ctx->free_work);
fs/aio.c: * and ctx->users has dropped to 0, so we know no more kiocbs can be submitted -
fs/aio.c:	spin_lock_irq(&ctx->ctx_lock);
fs/aio.c:	while (!list_empty(&ctx->active_reqs)) {
fs/aio.c:		req = list_first_entry(&ctx->active_reqs,
fs/aio.c:	spin_unlock_irq(&ctx->ctx_lock);
fs/aio.c:	percpu_ref_kill(&ctx->reqs);
fs/aio.c:	percpu_ref_put(&ctx->reqs);
fs/aio.c:					ctx->id = i;
fs/aio.c:					ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:					ring->id = ctx->id;
fs/aio.c:	ctx->max_reqs = nr_events;
fs/aio.c:	spin_lock_init(&ctx->ctx_lock);
fs/aio.c:	spin_lock_init(&ctx->completion_lock);
fs/aio.c:	mutex_init(&ctx->ring_lock);
fs/aio.c:	mutex_lock(&ctx->ring_lock);
fs/aio.c:	init_waitqueue_head(&ctx->wait);
fs/aio.c:	INIT_LIST_HEAD(&ctx->active_reqs);
fs/aio.c:	if (percpu_ref_init(&ctx->users, free_ioctx_users, 0, GFP_KERNEL))
fs/aio.c:	if (percpu_ref_init(&ctx->reqs, free_ioctx_reqs, 0, GFP_KERNEL))
fs/aio.c:	ctx->cpu = alloc_percpu(struct kioctx_cpu);
fs/aio.c:	if (!ctx->cpu)
fs/aio.c:	atomic_set(&ctx->reqs_available, ctx->nr_events - 1);
fs/aio.c:	ctx->req_batch = (ctx->nr_events - 1) / (num_possible_cpus() * 4);
fs/aio.c:	if (ctx->req_batch < 1)
fs/aio.c:		ctx->req_batch = 1;
fs/aio.c:	aio_nr += ctx->max_reqs;
fs/aio.c:	percpu_ref_get(&ctx->users);	/* io_setup() will drop this ref */
fs/aio.c:	percpu_ref_get(&ctx->reqs);	/* free_ioctx_users() will drop this */
fs/aio.c:	mutex_unlock(&ctx->ring_lock);
fs/aio.c:		 ctx, ctx->user_id, mm, ctx->nr_events);
fs/aio.c:	aio_nr_sub(ctx->max_reqs);
fs/aio.c:	atomic_set(&ctx->dead, 1);
fs/aio.c:	if (ctx->mmap_size)
fs/aio.c:		vm_munmap(ctx->mmap_base, ctx->mmap_size);
fs/aio.c:	mutex_unlock(&ctx->ring_lock);
fs/aio.c:	free_percpu(ctx->cpu);
fs/aio.c:	percpu_ref_exit(&ctx->reqs);
fs/aio.c:	percpu_ref_exit(&ctx->users);
fs/aio.c:	if (atomic_xchg(&ctx->dead, 1)) {
fs/aio.c:	WARN_ON(ctx != table->table[ctx->id]);
fs/aio.c:	table->table[ctx->id] = NULL;
fs/aio.c:	wake_up_all(&ctx->wait);
fs/aio.c:	aio_nr_sub(ctx->max_reqs);
fs/aio.c:	if (ctx->mmap_size)
fs/aio.c:		vm_munmap(ctx->mmap_base, ctx->mmap_size);
fs/aio.c:	ctx->rq_wait = wait;
fs/aio.c:	percpu_ref_kill(&ctx->users);
fs/aio.c:		ctx->mmap_size = 0;
fs/aio.c:	kcpu = this_cpu_ptr(ctx->cpu);
fs/aio.c:	while (kcpu->reqs_available >= ctx->req_batch * 2) {
fs/aio.c:		kcpu->reqs_available -= ctx->req_batch;
fs/aio.c:		atomic_add(ctx->req_batch, &ctx->reqs_available);
fs/aio.c:	kcpu = this_cpu_ptr(ctx->cpu);
fs/aio.c:		int old, avail = atomic_read(&ctx->reqs_available);
fs/aio.c:			if (avail < ctx->req_batch)
fs/aio.c:			avail = atomic_cmpxchg(&ctx->reqs_available,
fs/aio.c:					       avail, avail - ctx->req_batch);
fs/aio.c:		kcpu->reqs_available += ctx->req_batch;
fs/aio.c: *	called holding ctx->completion_lock.
fs/aio.c:	head %= ctx->nr_events;
fs/aio.c:		events_in_ring = ctx->nr_events - (head - tail);
fs/aio.c:	completed = ctx->completed_events;
fs/aio.c:	ctx->completed_events -= completed;
fs/aio.c:	spin_lock_irq(&ctx->completion_lock);
fs/aio.c:	if (ctx->completed_events) {
fs/aio.c:		 * ctx->completion_lock.  Even if head is invalid, the check
fs/aio.c:		 * against ctx->completed_events below will make sure we do the
fs/aio.c:		ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:		refill_reqs_available(ctx, head, ctx->tail);
fs/aio.c:	spin_unlock_irq(&ctx->completion_lock);
fs/aio.c:	percpu_ref_get(&ctx->reqs);
fs/aio.c:	if (ctx && ctx->user_id == ctx_id) {
fs/aio.c:		percpu_ref_get(&ctx->users);
fs/aio.c:		spin_lock_irqsave(&ctx->ctx_lock, flags);
fs/aio.c:		spin_unlock_irqrestore(&ctx->ctx_lock, flags);
fs/aio.c:	 * ctx->completion_lock to prevent other code from messing with the tail
fs/aio.c:	spin_lock_irqsave(&ctx->completion_lock, flags);
fs/aio.c:	tail = ctx->tail;
fs/aio.c:	if (++tail >= ctx->nr_events)
fs/aio.c:	ev_page = kmap_atomic(ctx->ring_pages[pos / AIO_EVENTS_PER_PAGE]);
fs/aio.c:	flush_dcache_page(ctx->ring_pages[pos / AIO_EVENTS_PER_PAGE]);
fs/aio.c:	ctx->tail = tail;
fs/aio.c:	ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:	flush_dcache_page(ctx->ring_pages[0]);
fs/aio.c:	ctx->completed_events++;
fs/aio.c:	if (ctx->completed_events > 1)
fs/aio.c:	spin_unlock_irqrestore(&ctx->completion_lock, flags);
fs/aio.c:	if (waitqueue_active(&ctx->wait))
fs/aio.c:		wake_up(&ctx->wait);
fs/aio.c:	percpu_ref_put(&ctx->reqs);
fs/aio.c:	mutex_lock(&ctx->ring_lock);
fs/aio.c:	/* Access to ->ring_pages here is protected by ctx->ring_lock. */
fs/aio.c:	ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:	pr_debug("h%u t%u m%u\n", head, tail, ctx->nr_events);
fs/aio.c:	head %= ctx->nr_events;
fs/aio.c:	tail %= ctx->nr_events;
fs/aio.c:		avail = (head <= tail ?  tail : ctx->nr_events) - head;
fs/aio.c:		page = ctx->ring_pages[pos / AIO_EVENTS_PER_PAGE];
fs/aio.c:		head %= ctx->nr_events;
fs/aio.c:	ring = kmap_atomic(ctx->ring_pages[0]);
fs/aio.c:	flush_dcache_page(ctx->ring_pages[0]);
fs/aio.c:	mutex_unlock(&ctx->ring_lock);
fs/aio.c:	if (unlikely(atomic_read(&ctx->dead)))
fs/aio.c:		wait_event_interruptible_hrtimeout(ctx->wait,
fs/aio.c:		ret = put_user(ioctx->user_id, ctxp);
fs/aio.c:		percpu_ref_put(&ioctx->users);
fs/aio.c:		percpu_ref_put(&ioctx->users);
fs/aio.c:	percpu_ref_put(&ctx->reqs);
fs/aio.c:	percpu_ref_put(&ctx->users);
fs/aio.c:	assert_spin_locked(&ctx->ctx_lock);
fs/aio.c:	list_for_each_entry(kiocb, &ctx->active_reqs, ki_list) {
fs/aio.c:	spin_lock_irq(&ctx->ctx_lock);
fs/aio.c:	spin_unlock_irq(&ctx->ctx_lock);
fs/aio.c:	percpu_ref_put(&ctx->users);
fs/aio.c:		percpu_ref_put(&ioctx->users);
fs/ext4/dir.c:	offset = ctx->pos & (sb->s_blocksize - 1);
fs/ext4/dir.c:	while (ctx->pos < inode->i_size) {
fs/ext4/dir.c:		map.m_lblk = ctx->pos >> EXT4_BLOCK_SIZE_BITS(sb);
fs/ext4/dir.c:					   (unsigned long long) ctx->pos);
fs/ext4/dir.c:			if (ctx->pos > inode->i_blocks << 9)
fs/ext4/dir.c:			ctx->pos += sb->s_blocksize - offset;
fs/ext4/dir.c:					(unsigned long long)ctx->pos);
fs/ext4/dir.c:			ctx->pos += sb->s_blocksize - offset;
fs/ext4/dir.c:			ctx->pos = (ctx->pos & ~(sb->s_blocksize - 1))
fs/ext4/dir.c:		while (ctx->pos < inode->i_size
fs/ext4/dir.c:				ctx->pos = (ctx->pos |
fs/ext4/dir.c:			ctx->pos += ext4_rec_len_from_disk(de->rec_len,
fs/ext4/dir.c:		if ((ctx->pos < inode->i_size) && !dir_relax_shared(inode))
fs/ext4/dir.c:	ctx->pos = hash2pos(file, fname->hash, fname->minor_hash);
fs/ext4/dir.c:		info = ext4_htree_create_dir_info(file, ctx->pos);
fs/ext4/dir.c:	if (ctx->pos == ext4_get_htree_eof(file))
fs/ext4/dir.c:	if (info->last_pos != ctx->pos) {
fs/ext4/dir.c:		info->curr_hash = pos2maj_hash(file, ctx->pos);
fs/ext4/dir.c:		info->curr_minor_hash = pos2min_hash(file, ctx->pos);
fs/ext4/dir.c:				ctx->pos = ext4_get_htree_eof(file);
fs/ext4/dir.c:				ctx->pos = ext4_get_htree_eof(file);
fs/ext4/dir.c:	info->last_pos = ctx->pos;
fs/ext4/inline.c:	offset = ctx->pos;
fs/ext4/inline.c:		ctx->pos = offset;
fs/ext4/inline.c:	while (ctx->pos < extra_size) {
fs/ext4/inline.c:		if (ctx->pos == 0) {
fs/ext4/inline.c:			ctx->pos = dotdot_offset;
fs/ext4/inline.c:		if (ctx->pos == dotdot_offset) {
fs/ext4/inline.c:			ctx->pos = dotdot_size;
fs/ext4/inline.c:			(dir_buf + ctx->pos - extra_offset);
fs/ext4/inline.c:					 extra_size, ctx->pos))
fs/ext4/inline.c:		ctx->pos += ext4_rec_len_from_disk(de->rec_len, extra_size);
fs/ext2/dir.c:	loff_t pos = ctx->pos;
fs/ext2/dir.c:			ctx->pos += PAGE_SIZE - offset;
fs/ext2/dir.c:				ctx->pos = (n<<PAGE_SHIFT) + offset;
fs/ext2/dir.c:			ctx->pos += ext2_rec_len_from_disk(de->rec_len);
fs/cramfs/inode.c:	if (ctx->pos >= inode->i_size)
fs/cramfs/inode.c:	offset = ctx->pos;
fs/cramfs/inode.c:		ctx->pos = offset = nextoffset;
fs/ntfs/index.c:	if (ictx->entry) {
fs/ntfs/index.c:		if (ictx->is_in_root) {
fs/ntfs/index.c:			if (ictx->actx)
fs/ntfs/index.c:				ntfs_attr_put_search_ctx(ictx->actx);
fs/ntfs/index.c:			if (ictx->base_ni)
fs/ntfs/index.c:				unmap_mft_record(ictx->base_ni);
fs/ntfs/index.c:			struct page *page = ictx->page;
fs/ntfs/index.c: * describe the index entry containing the matching @key.  @ictx->entry is the
fs/ntfs/index.c: * index entry and @ictx->data and @ictx->data_len are the index entry data and
fs/ntfs/index.c:	ntfs_inode *idx_ni = ictx->idx_ni;
fs/ntfs/index.c:	ir = (INDEX_ROOT*)((u8*)actx->attr +
fs/ntfs/index.c:			le16_to_cpu(actx->attr->data.resident.value_offset));
fs/ntfs/index.c:		if ((u8*)ie < (u8*)actx->mrec || (u8*)ie +
fs/ntfs/index.c:			ictx->is_in_root = true;
fs/ntfs/index.c:			ictx->ir = ir;
fs/ntfs/index.c:			ictx->actx = actx;
fs/ntfs/index.c:			ictx->base_ni = base_ni;
fs/ntfs/index.c:			ictx->ia = NULL;
fs/ntfs/index.c:			ictx->page = NULL;
fs/ntfs/index.c:			ictx->entry = ie;
fs/ntfs/index.c:			ictx->data = (u8*)ie +
fs/ntfs/index.c:			ictx->data_len = le16_to_cpu(ie->data.vi.data_length);
fs/ntfs/index.c:			ictx->is_in_root = false;
fs/ntfs/index.c:			ictx->actx = NULL;
fs/ntfs/index.c:			ictx->base_ni = NULL;
fs/ntfs/index.c:			ictx->ia = ia;
fs/ntfs/index.c:			ictx->page = page;
fs/ntfs/attrib.c: *	m = ctx->mrec;
fs/ntfs/attrib.c: *	a = ctx->attr;
fs/ntfs/attrib.c: * Assuming you cache ctx->attr in a variable @a of type ATTR_RECORD * and that
fs/ntfs/attrib.c: * you cache ctx->mrec in a variable @m of type MFT_RECORD *.
fs/ntfs/attrib.c: *	    returned, you need to check IS_ERR(@ctx->mrec) and if 'true' the @ctx
fs/ntfs/attrib.c: *	    In that case PTR_ERR(@ctx->mrec) will give you the error code for
fs/ntfs/attrib.c:		BUG_ON(IS_ERR(ctx->mrec));
fs/ntfs/attrib.c:		a = ctx->attr;
fs/ntfs/attrib.c:		BUG_ON(!ctx->attr->non_resident);
fs/ntfs/attrib.c:	a = ctx->attr;
fs/ntfs/attrib.c:			if (ctx->ntfs_ino != old_ctx.ntfs_ino) {
fs/ntfs/attrib.c:				if (ctx->base_ntfs_ino && ctx->ntfs_ino !=
fs/ntfs/attrib.c:						ctx->base_ntfs_ino) {
fs/ntfs/attrib.c:					unmap_extent_mft_record(ctx->ntfs_ino);
fs/ntfs/attrib.c:					ctx->mrec = ctx->base_mrec;
fs/ntfs/attrib.c:					BUG_ON(!ctx->mrec);
fs/ntfs/attrib.c:					ctx->mrec = map_mft_record(
fs/ntfs/attrib.c:					 * return the error code in ctx->mrec.
fs/ntfs/attrib.c:					if (IS_ERR(ctx->mrec)) {
fs/ntfs/attrib.c:						if (PTR_ERR(ctx->mrec) ==
fs/ntfs/attrib.c:			if (ctx->mrec != old_ctx.mrec) {
fs/ntfs/attrib.c:				if (!IS_ERR(ctx->mrec))
fs/ntfs/attrib.c:							(u8*)ctx->mrec +
fs/ntfs/attrib.c:				old_ctx.mrec = ctx->mrec;
fs/ntfs/attrib.c:		 * case that IS_ERR(ctx->mrec) is true this means we might lose
fs/ntfs/attrib.c: *	m = ctx->mrec;
fs/ntfs/attrib.c: *	a = ctx->attr;
fs/ntfs/attrib.c: * Assuming you cache ctx->attr in a variable @a of type ATTR_RECORD * and that
fs/ntfs/attrib.c: * you cache ctx->mrec in a variable @m of type MFT_RECORD *.
fs/ntfs/attrib.c: *	    returned, you need to check IS_ERR(@ctx->mrec) and if 'true' the @ctx
fs/ntfs/attrib.c: *	    In that case PTR_ERR(@ctx->mrec) will give you the error code for
fs/ntfs/attrib.c:		if (IS_ERR(ctx->mrec))
fs/ntfs/attrib.c:			err = PTR_ERR(ctx->mrec);
fs/ntfs/attrib.c: * mft record specified by @ctx->mrec, beginning at @ctx->attr, for an
fs/ntfs/attrib.c: * If the attribute is found, ntfs_attr_find() returns 0 and @ctx->attr will
fs/ntfs/attrib.c: * @ctx->attr will point to the attribute before which the attribute being
fs/ntfs/attrib.c: * On actual error, ntfs_attr_find() returns -EIO.  In this case @ctx->attr is
fs/ntfs/attrib.c: * If @ctx->is_first is 'true', the search begins with @ctx->attr itself.  If it
fs/ntfs/attrib.c: * is 'false', the search begins after @ctx->attr.
fs/ntfs/attrib.c: * @ctx->ntfs_ino must be set to the ntfs inode to which the mft record
fs/ntfs/attrib.c: * @ctx->mrec belongs.  This is so we can get at the ntfs volume and hence at
fs/ntfs/attrib.c:	ntfs_volume *vol = ctx->ntfs_ino->vol;
fs/ntfs/attrib.c:	 * Iterate over attributes in mft record starting at @ctx->attr, or the
fs/ntfs/attrib.c:	 * attribute following that, if @ctx->is_first is 'true'.
fs/ntfs/attrib.c:	if (ctx->is_first) {
fs/ntfs/attrib.c:		a = ctx->attr;
fs/ntfs/attrib.c:		ctx->is_first = false;
fs/ntfs/attrib.c:		a = (ATTR_RECORD*)((u8*)ctx->attr +
fs/ntfs/attrib.c:				le32_to_cpu(ctx->attr->length));
fs/ntfs/attrib.c:		if ((u8*)a < (u8*)ctx->mrec || (u8*)a > (u8*)ctx->mrec +
fs/ntfs/attrib.c:				le32_to_cpu(ctx->mrec->bytes_allocated))
fs/ntfs/attrib.c:		ctx->attr = a;
fs/ntfs/attrib.c: * On first search @ctx->ntfs_ino must be the base mft record and @ctx must
fs/ntfs/attrib.c: * calls @ctx->ntfs_ino can be any extent inode, too (@ctx->base_ntfs_ino is
fs/ntfs/attrib.c: * @ctx->attr will point to the found attribute.  @ctx->mrec will point to the
fs/ntfs/attrib.c: * mft record in which @ctx->attr is located and @ctx->al_entry will point to
fs/ntfs/attrib.c: * @ctx->attr will point to the attribute in the base mft record before which
fs/ntfs/attrib.c: * were to be desired.  @ctx->mrec will point to the mft record in which
fs/ntfs/attrib.c: * @ctx->attr is located and @ctx->al_entry will point to the attribute list
fs/ntfs/attrib.c: * @ctx->mrec (the base mft record) and if there is not enough space, the
fs/ntfs/attrib.c: * attribute list attribute at @ctx->al_entry.
fs/ntfs/attrib.c: * @ctx->attr is undefined and in particular do not rely on it not changing.
fs/ntfs/attrib.c:	ni = ctx->ntfs_ino;
fs/ntfs/attrib.c:	base_ni = ctx->base_ntfs_ino;
fs/ntfs/attrib.c:		base_ni = ctx->base_ntfs_ino = ctx->ntfs_ino;
fs/ntfs/attrib.c:		ctx->base_mrec = ctx->mrec;
fs/ntfs/attrib.c:		ctx->base_attr = ctx->attr;
fs/ntfs/attrib.c:	if (!ctx->al_entry)
fs/ntfs/attrib.c:		ctx->al_entry = (ATTR_LIST_ENTRY*)al_start;
fs/ntfs/attrib.c:	 * Iterate over entries in attribute list starting at @ctx->al_entry,
fs/ntfs/attrib.c:	 * or the entry following that, if @ctx->is_first is 'true'.
fs/ntfs/attrib.c:	if (ctx->is_first) {
fs/ntfs/attrib.c:		al_entry = ctx->al_entry;
fs/ntfs/attrib.c:		ctx->is_first = false;
fs/ntfs/attrib.c:		al_entry = (ATTR_LIST_ENTRY*)((u8*)ctx->al_entry +
fs/ntfs/attrib.c:				le16_to_cpu(ctx->al_entry->length));
fs/ntfs/attrib.c:		ctx->al_entry = al_entry;
fs/ntfs/attrib.c:				ni = ctx->ntfs_ino = base_ni;
fs/ntfs/attrib.c:				ctx->mrec = ctx->base_mrec;
fs/ntfs/attrib.c:				ctx->mrec = map_extent_mft_record(base_ni,
fs/ntfs/attrib.c:				if (IS_ERR(ctx->mrec)) {
fs/ntfs/attrib.c:					err = PTR_ERR(ctx->mrec);
fs/ntfs/attrib.c:				ctx->ntfs_ino = ni;
fs/ntfs/attrib.c:			ctx->attr = (ATTR_RECORD*)((u8*)ctx->mrec +
fs/ntfs/attrib.c:					le16_to_cpu(ctx->mrec->attrs_offset));
fs/ntfs/attrib.c:		 * ctx->vfs_ino, ctx->mrec, and ctx->attr now point to the
fs/ntfs/attrib.c:		a = ctx->attr;
fs/ntfs/attrib.c:		if ((u8*)a < (u8*)ctx->mrec || (u8*)a > (u8*)ctx->mrec +
fs/ntfs/attrib.c:				le32_to_cpu(ctx->mrec->bytes_allocated))
fs/ntfs/attrib.c:		ctx->attr = a;
fs/ntfs/attrib.c:		ctx->ntfs_ino = base_ni;
fs/ntfs/attrib.c:		ctx->mrec = ctx->base_mrec;
fs/ntfs/attrib.c:		ctx->attr = ctx->base_attr;
fs/ntfs/attrib.c:	 * @ctx->mrec and @ctx->attr indicate the position at which the
fs/ntfs/attrib.c:	 * want to preserve @ctx->al_entry we cannot reinitialize the search
fs/ntfs/attrib.c:	 * @ctx->al_entry to NULL.  Thus we do the necessary bits manually (see
fs/ntfs/attrib.c:	 * @ctx->al_entry as the remaining fields (base_*) are identical to
fs/ntfs/attrib.c:	 * their non base_ counterparts and we cannot set @ctx->base_attr
fs/ntfs/attrib.c:	 * correctly yet as we do not know what @ctx->attr will be set to by
fs/ntfs/attrib.c:	ctx->mrec = ctx->base_mrec;
fs/ntfs/attrib.c:	ctx->attr = (ATTR_RECORD*)((u8*)ctx->mrec +
fs/ntfs/attrib.c:			le16_to_cpu(ctx->mrec->attrs_offset));
fs/ntfs/attrib.c:	ctx->is_first = true;
fs/ntfs/attrib.c:	ctx->ntfs_ino = base_ni;
fs/ntfs/attrib.c:	ctx->base_ntfs_ino = NULL;
fs/ntfs/attrib.c:	ctx->base_mrec = NULL;
fs/ntfs/attrib.c:	ctx->base_attr = NULL;
fs/ntfs/attrib.c: * Find an attribute in an ntfs inode.  On first search @ctx->ntfs_ino must
fs/ntfs/attrib.c: * When 0, @ctx->attr is the found attribute and it is in mft record
fs/ntfs/attrib.c: * @ctx->mrec.  If an attribute list attribute is present, @ctx->al_entry is
fs/ntfs/attrib.c: * When -ENOENT, @ctx->attr is the attribute which collates just after the
fs/ntfs/attrib.c: * list attribute is present, @ctx->al_entry is the attribute list entry which
fs/ntfs/attrib.c: * When -errno != -ENOENT, an error occurred during the lookup.  @ctx->attr is
fs/ntfs/attrib.c:	BUG_ON(IS_ERR(ctx->mrec));
fs/ntfs/attrib.c:	if (ctx->base_ntfs_ino)
fs/ntfs/attrib.c:		base_ni = ctx->base_ntfs_ino;
fs/ntfs/attrib.c:		base_ni = ctx->ntfs_ino;
fs/ntfs/attrib.c:	if (likely(!ctx->base_ntfs_ino)) {
fs/ntfs/attrib.c:		ctx->is_first = true;
fs/ntfs/attrib.c:		ctx->attr = (ATTR_RECORD*)((u8*)ctx->mrec +
fs/ntfs/attrib.c:				le16_to_cpu(ctx->mrec->attrs_offset));
fs/ntfs/attrib.c:		 * can leave it set despite having zeroed ctx->base_ntfs_ino.
fs/ntfs/attrib.c:		ctx->al_entry = NULL;
fs/ntfs/attrib.c:	if (ctx->ntfs_ino != ctx->base_ntfs_ino)
fs/ntfs/attrib.c:		unmap_extent_mft_record(ctx->ntfs_ino);
fs/ntfs/attrib.c:	ntfs_attr_init_search_ctx(ctx, ctx->base_ntfs_ino, ctx->base_mrec);
fs/ntfs/attrib.c:	if (ctx->base_ntfs_ino && ctx->ntfs_ino != ctx->base_ntfs_ino)
fs/ntfs/attrib.c:		unmap_extent_mft_record(ctx->ntfs_ino);
fs/ntfs/attrib.c:	m = ctx->mrec;
fs/ntfs/attrib.c:	a = ctx->attr;
fs/ntfs/attrib.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/attrib.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/attrib.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/attrib.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/attrib.c:	m = ctx->mrec;
fs/ntfs/attrib.c:	a = ctx->attr;
fs/ntfs/attrib.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/attrib.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/attrib.c:		a = ctx->attr;
fs/ntfs/attrib.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/attrib.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/attrib.c:	ctx->attr->data.non_resident.highest_vcn = cpu_to_sle64(
fs/ntfs/attrib.c:	m = ctx->mrec;
fs/ntfs/attrib.c:	a = ctx->attr;
fs/ntfs/attrib.c:			flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/attrib.c:			mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/index.h:	if (ictx->is_in_root)
fs/ntfs/index.h:		flush_dcache_mft_record_page(ictx->actx->ntfs_ino);
fs/ntfs/index.h:		flush_dcache_page(ictx->page);
fs/ntfs/index.h:	if (ictx->is_in_root)
fs/ntfs/index.h:		mark_mft_record_dirty(ictx->actx->ntfs_ino);
fs/ntfs/index.h:		mark_ntfs_record_dirty(ictx->page,
fs/ntfs/index.h:				(u8*)ictx->ia - (u8*)page_address(ictx->page));
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	ret = ntfs_attr_record_resize(ctx->mrec, a, mp_size +
fs/ntfs/mft.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:		a = ctx->attr;
fs/ntfs/mft.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:		if (ntfs_attr_record_resize(ctx->mrec, a, old_alen)) {
fs/ntfs/mft.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	ret = ntfs_attr_record_resize(ctx->mrec, a, mp_size +
fs/ntfs/mft.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:		a = ctx->attr;
fs/ntfs/mft.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	ctx->attr->data.non_resident.highest_vcn =
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	if (mp_rebuilt && !IS_ERR(ctx->mrec)) {
fs/ntfs/mft.c:		if (ntfs_attr_record_resize(ctx->mrec, a, old_alen)) {
fs/ntfs/mft.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/mft.c:	} else if (IS_ERR(ctx->mrec)) {
fs/ntfs/mft.c:	a = ctx->attr;
fs/ntfs/mft.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/mft.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:	m = ctx->mrec;
fs/ntfs/file.c:	a = ctx->attr;
fs/ntfs/file.c:		m = ctx->mrec;
fs/ntfs/file.c:		a = ctx->attr;
fs/ntfs/file.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:	m = ctx->mrec;
fs/ntfs/file.c:	a = ctx->attr;
fs/ntfs/file.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:		m = ctx->mrec;
fs/ntfs/file.c:		a = ctx->attr;
fs/ntfs/file.c:				flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:				mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:				a = ctx->attr;
fs/ntfs/file.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:			flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:			mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:			m = ctx->mrec;
fs/ntfs/file.c:			a = ctx->attr;
fs/ntfs/file.c:			flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:			mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:	a = ctx->attr;
fs/ntfs/file.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/file.c:	a = ctx->attr;
fs/ntfs/file.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/file.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/dir.c:	ir = (INDEX_ROOT*)((u8*)ctx->attr +
fs/ntfs/dir.c:			le16_to_cpu(ctx->attr->data.resident.value_offset));
fs/ntfs/dir.c:		if ((u8*)ie < (u8*)ctx->mrec || (u8*)ie +
fs/ntfs/dir.c:	ir = (INDEX_ROOT*)((u8*)ctx->attr +
fs/ntfs/dir.c:			le16_to_cpu(ctx->attr->data.resident.value_offset));
fs/ntfs/dir.c:		if ((u8*)ie < (u8*)ctx->mrec || (u8*)ie +
fs/ntfs/dir.c:	rc = le32_to_cpu(ctx->attr->data.resident.value_length);
fs/ntfs/dir.c:	memcpy(ir, (u8*)ctx->attr +
fs/ntfs/dir.c:			le16_to_cpu(ctx->attr->data.resident.value_offset), rc);
fs/ntfs/lcnalloc.c: *	m = ctx->mrec;
fs/ntfs/lcnalloc.c: *	a = ctx->attr;
fs/ntfs/lcnalloc.c: * Assuming you cache ctx->attr in a variable @a of type ATTR_RECORD * and that
fs/ntfs/lcnalloc.c: * you cache ctx->mrec in a variable @m of type MFT_RECORD *.
fs/ntfs/lcnalloc.c: *	    returned, you need to check IS_ERR(@ctx->mrec) and if 'true' the @ctx
fs/ntfs/lcnalloc.c: *	    In that case PTR_ERR(@ctx->mrec) will give you the error code for
fs/ntfs/super.c:	vi = (VOLUME_INFORMATION*)((u8*)ctx->attr +
fs/ntfs/super.c:			le16_to_cpu(ctx->attr->data.resident.value_offset));
fs/ntfs/super.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/super.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/super.c:			ctx) || ctx->attr->non_resident || ctx->attr->flags) {
fs/ntfs/super.c:	vi = (VOLUME_INFORMATION*)((char*)ctx->attr +
fs/ntfs/super.c:			le16_to_cpu(ctx->attr->data.resident.value_offset));
fs/ntfs/super.c:	if ((u8*)vi < (u8*)ctx->attr || (u8*)vi +
fs/ntfs/super.c:			le32_to_cpu(ctx->attr->data.resident.value_length) >
fs/ntfs/super.c:			(u8*)ctx->attr + le32_to_cpu(ctx->attr->length))
fs/ntfs/namei.c:			a = ctx->attr;
fs/ntfs/namei.c:			fn = (FILE_NAME_ATTR*)((u8*)ctx->attr + le16_to_cpu(
fs/ntfs/namei.c:					ctx->attr->data.resident.value_offset));
fs/ntfs/namei.c:	attr = ctx->attr;
fs/ntfs/quota.c:	if (ictx->data_len < offsetof(QUOTA_CONTROL_ENTRY, sid)) {
fs/ntfs/quota.c:	qce = (QUOTA_CONTROL_ENTRY*)ictx->data;
fs/ntfs/lcnalloc.h: *	m = ctx->mrec;
fs/ntfs/lcnalloc.h: *	a = ctx->attr;
fs/ntfs/lcnalloc.h: * Assuming you cache ctx->attr in a variable @a of type ATTR_RECORD * and that
fs/ntfs/lcnalloc.h: * you cache ctx->mrec in a variable @m of type MFT_RECORD *.
fs/ntfs/lcnalloc.h: *	    returned, you need to check IS_ERR(@ctx->mrec) and if 'true' the @ctx
fs/ntfs/lcnalloc.h: *	    In that case PTR_ERR(@ctx->mrec) will give you the error code for
fs/ntfs/inode.c:	nr_links = le16_to_cpu(ctx->mrec->link_count);
fs/ntfs/inode.c:		ATTR_RECORD *attr = ctx->attr;
fs/ntfs/inode.c:		if (p < (u8*)ctx->mrec || (u8*)p > (u8*)ctx->mrec +
fs/ntfs/inode.c:				le32_to_cpu(ctx->mrec->bytes_in_use)) {
fs/ntfs/inode.c:			ntfs_error(ctx->ntfs_ino->vol->sb, "Corrupt file name "
fs/ntfs/inode.c:			ntfs_error(ctx->ntfs_ino->vol->sb, "Non-resident file "
fs/ntfs/inode.c:			ntfs_error(ctx->ntfs_ino->vol->sb, "File name with "
fs/ntfs/inode.c:			ntfs_error(ctx->ntfs_ino->vol->sb, "Unindexed file "
fs/ntfs/inode.c:		ntfs_error(ctx->ntfs_ino->vol->sb, "Inode hard link count "
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:					(u8*)ctx->mrec + vol->mft_record_size) {
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:		if (ir_end > (u8*)ctx->mrec + vol->mft_record_size) {
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:	if (ir_end > (u8*)ctx->mrec + vol->mft_record_size) {
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:					(u8*)ctx->mrec + vol->mft_record_size) {
fs/ntfs/inode.c:		a = ctx->attr;
fs/ntfs/inode.c:	m = ctx->mrec;
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/inode.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/inode.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/inode.c:		mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/inode.c:	m = ctx->mrec;
fs/ntfs/inode.c:	a = ctx->attr;
fs/ntfs/inode.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/inode.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/ntfs/inode.c:	si = (STANDARD_INFORMATION*)((u8*)ctx->attr +
fs/ntfs/inode.c:			le16_to_cpu(ctx->attr->data.resident.value_offset));
fs/ntfs/inode.c:		flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/inode.c:		if (!NInoTestSetDirty(ctx->ntfs_ino))
fs/ntfs/inode.c:			mark_ntfs_record_dirty(ctx->ntfs_ino->page,
fs/ntfs/inode.c:					ctx->ntfs_ino->page_ofs);
fs/ntfs/aops.c:	attr_len = le32_to_cpu(ctx->attr->data.resident.value_length);
fs/ntfs/aops.c:	memcpy(addr, (u8*)ctx->attr +
fs/ntfs/aops.c:			le16_to_cpu(ctx->attr->data.resident.value_offset),
fs/ntfs/aops.c:	attr_len = le32_to_cpu(ctx->attr->data.resident.value_length);
fs/ntfs/aops.c:		err = ntfs_resident_attr_value_resize(ctx->mrec, ctx->attr,
fs/ntfs/aops.c:	memcpy((u8*)ctx->attr +
fs/ntfs/aops.c:			le16_to_cpu(ctx->attr->data.resident.value_offset),
fs/ntfs/aops.c:	flush_dcache_mft_record_page(ctx->ntfs_ino);
fs/ntfs/aops.c:	mark_mft_record_dirty(ctx->ntfs_ino);
fs/hfsplus/dir.c:	if (ctx->pos == 0) {
fs/hfsplus/dir.c:		ctx->pos = 1;
fs/hfsplus/dir.c:	if (ctx->pos == 1) {
fs/hfsplus/dir.c:		ctx->pos = 2;
fs/hfsplus/dir.c:	if (ctx->pos >= inode->i_size)
fs/hfsplus/dir.c:	err = hfs_brec_goto(&fd, ctx->pos - 1);
fs/hfsplus/dir.c:		ctx->pos++;
fs/hfsplus/dir.c:		if (ctx->pos >= inode->i_size)
fs/9p/vfs_dir.c:			n = p9_client_read(file->private_data, ctx->pos, &to,
fs/9p/vfs_dir.c:			ctx->pos += reclen;
fs/9p/vfs_dir.c:						ctx->pos);
fs/9p/vfs_dir.c:			ctx->pos = curdirent.d_off;
fs/gfs2/dir.c:			if (off < ctx->pos)
fs/gfs2/dir.c:			ctx->pos = off;
fs/gfs2/dir.c:			if (off < ctx->pos)
fs/gfs2/dir.c:			ctx->pos = off;
fs/gfs2/dir.c:	/* Increment the ctx->pos by one, so the next time we come into the
fs/gfs2/dir.c:	ctx->pos++;
fs/gfs2/dir.c:	hash = gfs2_dir_offset2hash(ctx->pos);
fs/hostfs/hostfs_kern.c:	next = ctx->pos;
fs/hostfs/hostfs_kern.c:		ctx->pos = next;
fs/configfs/dir.c:	if (ctx->pos == 2)
fs/configfs/dir.c:		ctx->pos++;
fs/fat/dir.c:	cpos = ctx->pos;
fs/fat/dir.c:		if (ctx->pos == 2) {
fs/fat/dir.c:	ctx->pos = cpos - (nr_slots + 1) * sizeof(struct msdos_dir_entry);
fs/fat/dir.c:	if (fake_offset && ctx->pos < 2)
fs/fat/dir.c:		ctx->pos = 2;
fs/fat/dir.c:	ctx->pos = cpos;
fs/fat/dir.c:		ctx->pos = 2;
fs/fat/dir.c:		ctx->pos = cpos;
fs/hfs/dir.c:	if (ctx->pos >= inode->i_size)
fs/hfs/dir.c:	if (ctx->pos == 0) {
fs/hfs/dir.c:		ctx->pos = 1;
fs/hfs/dir.c:	if (ctx->pos == 1) {
fs/hfs/dir.c:		ctx->pos = 2;
fs/hfs/dir.c:	if (ctx->pos >= inode->i_size)
fs/hfs/dir.c:	err = hfs_brec_goto(&fd, ctx->pos - 1);
fs/hfs/dir.c:		ctx->pos++;
fs/hfs/dir.c:		if (ctx->pos >= inode->i_size)
fs/freevxfs/vxfs_lookup.c:	if (ctx->pos == 0) {
fs/freevxfs/vxfs_lookup.c:		ctx->pos++;
fs/freevxfs/vxfs_lookup.c:	if (ctx->pos == 1) {
fs/freevxfs/vxfs_lookup.c:		ctx->pos++;
fs/freevxfs/vxfs_lookup.c:	if (ctx->pos > limit)
fs/freevxfs/vxfs_lookup.c:	pos = ctx->pos & ~3L;
fs/freevxfs/vxfs_lookup.c:	ctx->pos = pos | 2;
fs/qnx4/dir.c:	QNX4DEBUG((KERN_INFO "pos                 = %ld\n", (long) ctx->pos));
fs/qnx4/dir.c:	while (ctx->pos < inode->i_size) {
fs/qnx4/dir.c:		blknum = qnx4_block_map(inode, ctx->pos >> QNX4_BLOCK_SIZE_BITS);
fs/qnx4/dir.c:		ix = (ctx->pos >> QNX4_DIR_ENTRY_SIZE_BITS) % QNX4_INODES_PER_BLOCK;
fs/qnx4/dir.c:		for (; ix < QNX4_INODES_PER_BLOCK; ix++, ctx->pos += QNX4_DIR_ENTRY_SIZE) {
fs/ceph/caps.c:	ctx->count = need;
fs/ceph/caps.c:	dout("unreserve caps ctx=%p count=%d\n", ctx, ctx->count);
fs/ceph/caps.c:	if (ctx->count) {
fs/ceph/caps.c:		BUG_ON(mdsc->caps_reserve_count < ctx->count);
fs/ceph/caps.c:		mdsc->caps_reserve_count -= ctx->count;
fs/ceph/caps.c:		mdsc->caps_avail_count += ctx->count;
fs/ceph/caps.c:		ctx->count = 0;
fs/ceph/caps.c:	     ctx, ctx->count, mdsc->caps_total_count, mdsc->caps_use_count,
fs/ceph/caps.c:	BUG_ON(!ctx->count);
fs/ceph/caps.c:	BUG_ON(ctx->count > mdsc->caps_reserve_count);
fs/ceph/caps.c:	ctx->count--;
fs/ceph/dir.c:	dout("__dcache_readdir %p v%u at %llx\n", dir, shared_gen, ctx->pos);
fs/ceph/dir.c:	if (ctx->pos > 2) {
fs/ceph/dir.c:			if (fpos_cmp(di->offset, ctx->pos) < 0) {
fs/ceph/dir.c:		    fpos_cmp(ctx->pos, di->offset) <= 0) {
fs/ceph/dir.c:			ctx->pos = di->offset;
fs/ceph/dir.c:			ctx->pos++;
fs/ceph/dir.c:	dout("readdir %p file %p pos %llx\n", inode, file, ctx->pos);
fs/ceph/dir.c:	if (ctx->pos == 0) {
fs/ceph/dir.c:		ctx->pos = 1;
fs/ceph/dir.c:	if (ctx->pos == 1) {
fs/ceph/dir.c:		ctx->pos = 2;
fs/ceph/dir.c:	if (need_send_readdir(fi, ctx->pos)) {
fs/ceph/dir.c:		if (is_hash_order(ctx->pos)) {
fs/ceph/dir.c:				frag = ceph_choose_frag(ci, fpos_hash(ctx->pos),
fs/ceph/dir.c:			frag = fpos_frag(ctx->pos);
fs/ceph/dir.c:				/* adjust ctx->pos to beginning of frag */
fs/ceph/dir.c:				ctx->pos = ceph_make_fpos(frag,
fs/ceph/dir.c:	     fi->frag, rinfo->dir_nr, ctx->pos,
fs/ceph/dir.c:			if (rinfo->dir_entries[i + step].offset < ctx->pos) {
fs/ceph/dir.c:		BUG_ON(rde->offset < ctx->pos);
fs/ceph/dir.c:		ctx->pos = rde->offset;
fs/ceph/dir.c:		     i, rinfo->dir_nr, ctx->pos,
fs/ceph/dir.c:		ctx->pos++;
fs/ceph/dir.c:		if (is_hash_order(ctx->pos)) {
fs/ceph/dir.c:			if (new_pos > ctx->pos)
fs/ceph/dir.c:				ctx->pos = new_pos;
fs/ceph/dir.c:			ctx->pos = ceph_make_fpos(frag, fi->next_offset, false);
fs/ceph/locks.c:		spin_lock(&ctx->flc_lock);
fs/ceph/locks.c:		list_for_each_entry(lock, &ctx->flc_posix, fl_list)
fs/ceph/locks.c:		list_for_each_entry(lock, &ctx->flc_flock, fl_list)
fs/ceph/locks.c:		spin_unlock(&ctx->flc_lock);
fs/ceph/locks.c:	spin_lock(&ctx->flc_lock);
fs/ceph/locks.c:	list_for_each_entry(lock, &ctx->flc_posix, fl_list) {
fs/ceph/locks.c:	list_for_each_entry(lock, &ctx->flc_flock, fl_list) {
fs/ceph/locks.c:	spin_unlock(&ctx->flc_lock);
fs/isofs/dir.c:	offset = ctx->pos & (bufsize - 1);
fs/isofs/dir.c:	block = ctx->pos >> bufbits;
fs/isofs/dir.c:	while (ctx->pos < inode->i_size) {
fs/isofs/dir.c:			ctx->pos = (ctx->pos + ISOFS_BLOCK_SIZE) & ~(ISOFS_BLOCK_SIZE - 1);
fs/isofs/dir.c:			block = ctx->pos >> bufbits;
fs/isofs/dir.c:			ctx->pos += de_len;
fs/isofs/dir.c:			ctx->pos += de_len;
fs/isofs/dir.c:			ctx->pos += de_len;
fs/isofs/dir.c:			ctx->pos += de_len;
fs/isofs/dir.c:		ctx->pos += de_len;
fs/squashfs/dir.c:	while (ctx->pos < 3) {
fs/squashfs/dir.c:		if (ctx->pos == 0) {
fs/squashfs/dir.c:		ctx->pos += size;
fs/squashfs/dir.c:				ctx->pos);
fs/squashfs/dir.c:			if (ctx->pos >= length)
fs/squashfs/dir.c:			ctx->pos = length;
fs/ocfs2/dir.c:	unsigned long offset = ctx->pos;
fs/ocfs2/dir.c:	while (ctx->pos < i_size_read(inode)) {
fs/ocfs2/dir.c:			ctx->pos = offset = i;
fs/ocfs2/dir.c:		de = (struct ocfs2_dir_entry *) (data->id_data + ctx->pos);
fs/ocfs2/dir.c:		if (!ocfs2_check_dir_entry(inode, de, di_bh, ctx->pos)) {
fs/ocfs2/dir.c:			ctx->pos = i_size_read(inode);
fs/ocfs2/dir.c:		ctx->pos += le16_to_cpu(de->rec_len);
fs/ocfs2/dir.c:	offset = ctx->pos & (sb->s_blocksize - 1);
fs/ocfs2/dir.c:	while (ctx->pos < i_size_read(inode)) {
fs/ocfs2/dir.c:		blk = ctx->pos >> sb->s_blocksize_bits;
fs/ocfs2/dir.c:			ctx->pos += sb->s_blocksize - offset;
fs/ocfs2/dir.c:			ctx->pos = (ctx->pos & ~(sb->s_blocksize - 1))
fs/ocfs2/dir.c:		while (ctx->pos < i_size_read(inode)
fs/ocfs2/dir.c:				ctx->pos = (ctx->pos | (sb->s_blocksize - 1)) + 1;
fs/ocfs2/dir.c:			ctx->pos += le16_to_cpu(de->rec_len);
fs/signalfd.c:	if (next_signal(&current->pending, &ctx->sigmask) ||
fs/signalfd.c:			&ctx->sigmask))
fs/signalfd.c:	ret = dequeue_signal(current, &ctx->sigmask, info);
fs/signalfd.c:		ret = dequeue_signal(current, &ctx->sigmask, info);
fs/signalfd.c:	sigmask = ctx->sigmask;
fs/signalfd.c:		ctx->sigmask = sigmask;
fs/signalfd.c:		ctx->sigmask = sigmask;
fs/sysv/dir.c:	unsigned long pos = ctx->pos;
fs/sysv/dir.c:	ctx->pos = pos = (pos + SYSV_DIRSIZE-1) & ~(SYSV_DIRSIZE-1);
fs/sysv/dir.c:		for ( ;(char*)de <= limit; de++, ctx->pos += sizeof(*de)) {
fs/f2fs/dir.c:	bit_pos = ((unsigned long)ctx->pos % d->max);
fs/f2fs/dir.c:			ctx->pos = start_pos + bit_pos;
fs/f2fs/dir.c:		ctx->pos = start_pos + bit_pos;
fs/f2fs/dir.c:	unsigned int n = ((unsigned long)ctx->pos / NR_DENTRY_IN_BLOCK);
fs/f2fs/dir.c:		ctx->pos = (n + 1) * NR_DENTRY_IN_BLOCK;
fs/f2fs/inline.c:	if (ctx->pos == NR_INLINE_DENTRY)
fs/f2fs/inline.c:		ctx->pos = NR_INLINE_DENTRY;
fs/proc/proc_sysctl.c:	if ((*pos)++ < ctx->pos)
fs/proc/proc_sysctl.c:		ctx->pos = *pos;
fs/proc/root.c:	if (ctx->pos < FIRST_PROCESS_ENTRY) {
fs/proc/root.c:		ctx->pos = FIRST_PROCESS_ENTRY;
fs/proc/generic.c:	i = ctx->pos - 2;
fs/proc/generic.c:		ctx->pos++;
fs/proc/fd.c:	for (fd = ctx->pos - 2;
fs/proc/fd.c:	     fd++, ctx->pos++) {
fs/proc/base.c:		if (vma->vm_file && ++pos > ctx->pos)
fs/proc/base.c:			if (++pos <= ctx->pos)
fs/proc/base.c:		ctx->pos++;
fs/proc/base.c:	if (ctx->pos >= nents + 2)
fs/proc/base.c:	for (p = ents + (ctx->pos - 2); p <= ents + nents - 1; p++) {
fs/proc/base.c:		ctx->pos++;
fs/proc/base.c:	loff_t pos = ctx->pos;
fs/proc/base.c:		ctx->pos = pos = pos + 1;
fs/proc/base.c:		ctx->pos = pos = pos + 1;
fs/proc/base.c:		ctx->pos = iter.tgid + TGID_OFFSET;
fs/proc/base.c:	ctx->pos = PID_MAX_LIMIT + TGID_OFFSET;
fs/proc/base.c:	for (task = first_tid(proc_pid(inode), tid, ctx->pos - 2, ns);
fs/proc/base.c:	     task = next_tid(task), ctx->pos++) {
fs/proc/namespaces.c:	if (ctx->pos >= 2 + ARRAY_SIZE(ns_entries))
fs/proc/namespaces.c:	entry = ns_entries + (ctx->pos - 2);
fs/proc/namespaces.c:		ctx->pos++;
fs/nfsd/nfs4recover.c:	list_add(&entry->list, &ctx->names);
fs/nfsd/nfs4state.c:	if (flctx && !list_empty_careful(&flctx->flc_posix)) {
fs/nfsd/nfs4state.c:		spin_lock(&flctx->flc_lock);
fs/nfsd/nfs4state.c:		list_for_each_entry(fl, &flctx->flc_posix, fl_list) {
fs/nfsd/nfs4state.c:		spin_unlock(&flctx->flc_lock);
fs/jfs/jfs_dtree.c:	if (ctx->pos == DIREND)
fs/jfs/jfs_dtree.c:		dir_index = (u32) ctx->pos;
fs/jfs/jfs_dtree.c:				ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:				ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:					ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:					ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:				ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:				ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:				ctx->pos = 1;
fs/jfs/jfs_dtree.c:			ctx->pos = 2;
fs/jfs/jfs_dtree.c:				ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:		dtpos = ctx->pos;
fs/jfs/jfs_dtree.c:			ctx->pos = 1;
fs/jfs/jfs_dtree.c:			ctx->pos = dtpos;
fs/jfs/jfs_dtree.c:			ctx->pos = dtpos;
fs/jfs/jfs_dtree.c:			ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:		if ((rc = dtReadNext(ip, &ctx->pos, &btstack))) {
fs/jfs/jfs_dtree.c:			ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:			ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:		ctx->pos = DIREND;
fs/jfs/jfs_dtree.c:			ctx->pos = jfs_dirent->position;
fs/jfs/jfs_dtree.c:			ctx->pos = DIREND;
fs/exofs/dir.c:	loff_t pos = ctx->pos;
fs/exofs/dir.c:			ctx->pos += PAGE_SIZE - offset;
fs/exofs/dir.c:				ctx->pos = (n<<PAGE_SHIFT) + offset;
fs/exofs/dir.c:			ctx->pos += le16_to_cpu(de->rec_len);
fs/ecryptfs/messaging.c:	list_move(&msg_ctx->node, &ecryptfs_msg_ctx_alloc_list);
fs/ecryptfs/messaging.c:	msg_ctx->state = ECRYPTFS_MSG_CTX_STATE_PENDING;
fs/ecryptfs/messaging.c:	msg_ctx->counter = ++ecryptfs_msg_counter;
fs/ecryptfs/messaging.c:	list_move(&(msg_ctx->node), &ecryptfs_msg_ctx_free_list);
fs/ecryptfs/messaging.c:	kfree(msg_ctx->msg);
fs/ecryptfs/messaging.c:	msg_ctx->msg = NULL;
fs/ecryptfs/messaging.c:	msg_ctx->state = ECRYPTFS_MSG_CTX_STATE_FREE;
fs/ecryptfs/messaging.c:		list_del(&msg_ctx->daemon_out_list);
fs/ecryptfs/messaging.c:		daemon->num_queued_msg_ctx--;
fs/ecryptfs/messaging.c: * that msg_ctx->state == ECRYPTFS_MSG_CTX_STATE_DONE, and then
fs/ecryptfs/messaging.c:	mutex_lock(&msg_ctx->mux);
fs/ecryptfs/messaging.c:	if (msg_ctx->state != ECRYPTFS_MSG_CTX_STATE_PENDING) {
fs/ecryptfs/messaging.c:	} else if (msg_ctx->counter != seq) {
fs/ecryptfs/messaging.c:		       msg_ctx->counter, seq);
fs/ecryptfs/messaging.c:	msg_ctx->msg = kmemdup(msg, msg_size, GFP_KERNEL);
fs/ecryptfs/messaging.c:	if (!msg_ctx->msg) {
fs/ecryptfs/messaging.c:	msg_ctx->state = ECRYPTFS_MSG_CTX_STATE_DONE;
fs/ecryptfs/messaging.c:	wake_up_process(msg_ctx->task);
fs/ecryptfs/messaging.c:	mutex_unlock(&msg_ctx->mux);
fs/ecryptfs/messaging.c:	mutex_lock(&msg_ctx->mux);
fs/ecryptfs/messaging.c:	if (msg_ctx->state != ECRYPTFS_MSG_CTX_STATE_DONE) {
fs/ecryptfs/messaging.c:			mutex_unlock(&msg_ctx->mux);
fs/ecryptfs/messaging.c:		*msg = msg_ctx->msg;
fs/ecryptfs/messaging.c:		msg_ctx->msg = NULL;
fs/ecryptfs/messaging.c:	mutex_unlock(&msg_ctx->mux);
fs/ecryptfs/file.c:	ctx->pos = buf.ctx.pos;
fs/ecryptfs/miscdev.c:	mutex_lock(&msg_ctx->mux);
fs/ecryptfs/miscdev.c:	msg_ctx->msg = msg;
fs/ecryptfs/miscdev.c:	msg_ctx->msg->index = msg_ctx->index;
fs/ecryptfs/miscdev.c:	msg_ctx->msg->data_len = data_size;
fs/ecryptfs/miscdev.c:	msg_ctx->type = msg_type;
fs/ecryptfs/miscdev.c:	memcpy(msg_ctx->msg->data, data, data_size);
fs/ecryptfs/miscdev.c:	msg_ctx->msg_size = (sizeof(*msg_ctx->msg) + data_size);
fs/ecryptfs/miscdev.c:	list_add_tail(&msg_ctx->daemon_out_list, &daemon->msg_ctx_out_queue);
fs/ecryptfs/miscdev.c:	mutex_unlock(&msg_ctx->mux);
fs/ecryptfs/miscdev.c: *  Octets 1-4: network byte order msg_ctx->counter
fs/ecryptfs/miscdev.c:	mutex_lock(&msg_ctx->mux);
fs/ecryptfs/miscdev.c:	if (msg_ctx->msg) {
fs/ecryptfs/miscdev.c:						  msg_ctx->msg_size,
fs/ecryptfs/miscdev.c:		msg_ctx->msg_size = 0;
fs/ecryptfs/miscdev.c:			+ msg_ctx->msg_size);
fs/ecryptfs/miscdev.c:	if (put_user(msg_ctx->type, buf))
fs/ecryptfs/miscdev.c:	if (put_user(cpu_to_be32(msg_ctx->counter),
fs/ecryptfs/miscdev.c:	if (msg_ctx->msg) {
fs/ecryptfs/miscdev.c:		if (copy_to_user(&buf[i], msg_ctx->msg, msg_ctx->msg_size))
fs/ecryptfs/miscdev.c:		i += msg_ctx->msg_size;
fs/ecryptfs/miscdev.c:	list_del(&msg_ctx->daemon_out_list);
fs/ecryptfs/miscdev.c:	kfree(msg_ctx->msg);
fs/ecryptfs/miscdev.c:	msg_ctx->msg = NULL;
fs/ecryptfs/miscdev.c:	if (msg_ctx->type != ECRYPTFS_MSG_REQUEST)
fs/ecryptfs/miscdev.c:	mutex_unlock(&msg_ctx->mux);
fs/ecryptfs/ecryptfs_kernel.h:	/* Inherits from msg_ctx->index */
fs/afs/dir.c:	_enter("%u,%x,%p,,",(unsigned)ctx->pos,blkoff,block);
fs/afs/dir.c:	curr = (ctx->pos - blkoff) / sizeof(union afs_dirent);
fs/afs/dir.c:				ctx->pos = blkoff +
fs/afs/dir.c:			      ctx->actor == afs_lookup_filldir ?
fs/afs/dir.c:		ctx->pos = blkoff + next * sizeof(union afs_dirent);
fs/afs/dir.c:	_enter("{%lu},%u,,", dir->i_ino, (unsigned)ctx->pos);
fs/afs/dir.c:	ctx->pos += sizeof(union afs_dirent) - 1;
fs/afs/dir.c:	ctx->pos &= ~(sizeof(union afs_dirent) - 1);
fs/afs/dir.c:	while (ctx->pos < dir->i_size) {
fs/afs/dir.c:		blkoff = ctx->pos & ~(sizeof(union afs_dir_block) - 1);
fs/afs/dir.c:		} while (ctx->pos < dir->i_size && blkoff < limit);
fs/qnx6/dir.c:	loff_t pos = ctx->pos & ~(QNX6_DIR_ENTRY_SIZE - 1);
fs/qnx6/dir.c:	ctx->pos = pos;
fs/qnx6/dir.c:	if (ctx->pos >= inode->i_size)
fs/qnx6/dir.c:			ctx->pos = (n + 1) << PAGE_SHIFT;
fs/qnx6/dir.c:		for (; i < limit; i++, de++, ctx->pos += QNX6_DIR_ENTRY_SIZE) {
fs/locks.c:	spin_lock_init(&ctx->flc_lock);
fs/locks.c:	INIT_LIST_HEAD(&ctx->flc_flock);
fs/locks.c:	INIT_LIST_HEAD(&ctx->flc_posix);
fs/locks.c:	INIT_LIST_HEAD(&ctx->flc_lease);
fs/locks.c:	if (unlikely(!list_empty(&ctx->flc_flock) ||
fs/locks.c:		     !list_empty(&ctx->flc_posix) ||
fs/locks.c:		     !list_empty(&ctx->flc_lease))) {
fs/locks.c:		locks_dump_ctx_list(&ctx->flc_flock, "FLOCK");
fs/locks.c:		locks_dump_ctx_list(&ctx->flc_posix, "POSIX");
fs/locks.c:		locks_dump_ctx_list(&ctx->flc_lease, "LEASE");
fs/locks.c:	if (!ctx || list_empty_careful(&ctx->flc_posix)) {
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(cfl, &ctx->flc_posix, fl_list) {
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_flock, fl_list) {
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_flock, fl_list) {
fs/locks.c:	locks_insert_lock_ctx(new_fl, &ctx->flc_flock);
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:		list_for_each_entry(fl, &ctx->flc_posix, fl_list) {
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_posix, fl_list) {
fs/locks.c:	list_for_each_entry_safe_from(fl, tmp, &ctx->flc_posix, fl_list) {
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	if (!ctx || list_empty_careful(&ctx->flc_posix))
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_posix, fl_list) {
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	lockdep_assert_held(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry_safe(fl, tmp, &ctx->flc_lease, fl_list) {
fs/locks.c:	lockdep_assert_held(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_lease, fl_list) {
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry_safe(fl, tmp, &ctx->flc_lease, fl_list) {
fs/locks.c:	if (list_empty(&ctx->flc_lease))
fs/locks.c:	fl = list_first_entry(&ctx->flc_lease, struct file_lock, fl_list);
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	if (ctx && !list_empty_careful(&ctx->flc_lease)) {
fs/locks.c:		spin_lock(&ctx->flc_lock);
fs/locks.c:		fl = list_first_entry_or_null(&ctx->flc_lease,
fs/locks.c:		spin_unlock(&ctx->flc_lock);
fs/locks.c:	if (ctx && !list_empty_careful(&ctx->flc_lease)) {
fs/locks.c:		spin_lock(&ctx->flc_lock);
fs/locks.c:		list_for_each_entry(fl, &ctx->flc_lease, fl_list) {
fs/locks.c:		spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_lease, fl_list) {
fs/locks.c:	locks_insert_lock_ctx(lease, &ctx->flc_lease);
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry(fl, &ctx->flc_lease, fl_list) {
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:		 * update of i_flctx->flc_posix and check for it done in
fs/locks.c:		 * update of i_flctx->flc_posix and check for it done in
fs/locks.c:	if (!ctx || list_empty(&ctx->flc_posix))
fs/locks.c:	if (list_empty(&flctx->flc_flock))
fs/locks.c:	if (list_empty(&ctx->flc_lease))
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	list_for_each_entry_safe(fl, tmp, &ctx->flc_lease, fl_list)
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/locks.c:	spin_lock(&ctx->flc_lock);
fs/locks.c:	__show_fd_locks(f, &ctx->flc_flock, &id, filp, files);
fs/locks.c:	__show_fd_locks(f, &ctx->flc_posix, &id, filp, files);
fs/locks.c:	__show_fd_locks(f, &ctx->flc_lease, &id, filp, files);
fs/locks.c:	spin_unlock(&ctx->flc_lock);
fs/userfaultfd.c:	if (!atomic_inc_not_zero(&ctx->refcount))
fs/userfaultfd.c:	if (atomic_dec_and_test(&ctx->refcount)) {
fs/userfaultfd.c:		VM_BUG_ON(spin_is_locked(&ctx->fault_pending_wqh.lock));
fs/userfaultfd.c:		VM_BUG_ON(waitqueue_active(&ctx->fault_pending_wqh));
fs/userfaultfd.c:		VM_BUG_ON(spin_is_locked(&ctx->fault_wqh.lock));
fs/userfaultfd.c:		VM_BUG_ON(waitqueue_active(&ctx->fault_wqh));
fs/userfaultfd.c:		VM_BUG_ON(spin_is_locked(&ctx->fd_wqh.lock));
fs/userfaultfd.c:		VM_BUG_ON(waitqueue_active(&ctx->fd_wqh));
fs/userfaultfd.c:		mmdrop(ctx->mm);
fs/userfaultfd.c:	struct mm_struct *mm = ctx->mm;
fs/userfaultfd.c:	BUG_ON(ctx->mm != mm);
fs/userfaultfd.c:	if (unlikely(ACCESS_ONCE(ctx->released)))
fs/userfaultfd.c:	spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	__add_wait_queue(&ctx->fault_pending_wqh, &uwq.wq);
fs/userfaultfd.c:	spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	if (likely(must_wait && !ACCESS_ONCE(ctx->released) &&
fs/userfaultfd.c:		wake_up_poll(&ctx->fd_wqh, POLLIN);
fs/userfaultfd.c:			    READ_ONCE(ctx->released) ||
fs/userfaultfd.c:		spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:		spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	struct mm_struct *mm = ctx->mm;
fs/userfaultfd.c:	ACCESS_ONCE(ctx->released) = true;
fs/userfaultfd.c:	spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	__wake_up_locked_key(&ctx->fault_pending_wqh, TASK_NORMAL, &range);
fs/userfaultfd.c:	__wake_up_locked_key(&ctx->fault_wqh, TASK_NORMAL, &range);
fs/userfaultfd.c:	spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	wake_up_poll(&ctx->fd_wqh, POLLHUP);
fs/userfaultfd.c:	VM_BUG_ON(!spin_is_locked(&ctx->fault_pending_wqh.lock));
fs/userfaultfd.c:	if (!waitqueue_active(&ctx->fault_pending_wqh))
fs/userfaultfd.c:	wq = list_last_entry(&ctx->fault_pending_wqh.task_list,
fs/userfaultfd.c:	poll_wait(file, &ctx->fd_wqh, wait);
fs/userfaultfd.c:	switch (ctx->state) {
fs/userfaultfd.c:		if (waitqueue_active(&ctx->fault_pending_wqh))
fs/userfaultfd.c:	spin_lock(&ctx->fd_wqh.lock);
fs/userfaultfd.c:	__add_wait_queue(&ctx->fd_wqh, &wait);
fs/userfaultfd.c:		spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:			write_seqcount_begin(&ctx->refile_seq);
fs/userfaultfd.c:			__add_wait_queue(&ctx->fault_wqh, &uwq->wq);
fs/userfaultfd.c:			write_seqcount_end(&ctx->refile_seq);
fs/userfaultfd.c:			spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:		spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:		spin_unlock(&ctx->fd_wqh.lock);
fs/userfaultfd.c:		spin_lock(&ctx->fd_wqh.lock);
fs/userfaultfd.c:	__remove_wait_queue(&ctx->fd_wqh, &wait);
fs/userfaultfd.c:	spin_unlock(&ctx->fd_wqh.lock);
fs/userfaultfd.c:	if (ctx->state == UFFD_STATE_WAIT_API)
fs/userfaultfd.c:	spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	if (waitqueue_active(&ctx->fault_pending_wqh))
fs/userfaultfd.c:		__wake_up_locked_key(&ctx->fault_pending_wqh, TASK_NORMAL,
fs/userfaultfd.c:	if (waitqueue_active(&ctx->fault_wqh))
fs/userfaultfd.c:		__wake_up_locked_key(&ctx->fault_wqh, TASK_NORMAL, range);
fs/userfaultfd.c:	spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:		seq = read_seqcount_begin(&ctx->refile_seq);
fs/userfaultfd.c:		need_wakeup = waitqueue_active(&ctx->fault_pending_wqh) ||
fs/userfaultfd.c:			waitqueue_active(&ctx->fault_wqh);
fs/userfaultfd.c:	} while (read_seqcount_retry(&ctx->refile_seq, seq));
fs/userfaultfd.c:	struct mm_struct *mm = ctx->mm;
fs/userfaultfd.c:	struct mm_struct *mm = ctx->mm;
fs/userfaultfd.c:	ret = validate_range(ctx->mm, uffdio_wake.start, uffdio_wake.len);
fs/userfaultfd.c:	ret = validate_range(ctx->mm, uffdio_copy.dst, uffdio_copy.len);
fs/userfaultfd.c:	if (mmget_not_zero(ctx->mm)) {
fs/userfaultfd.c:		ret = mcopy_atomic(ctx->mm, uffdio_copy.dst, uffdio_copy.src,
fs/userfaultfd.c:		mmput(ctx->mm);
fs/userfaultfd.c:	ret = validate_range(ctx->mm, uffdio_zeropage.range.start,
fs/userfaultfd.c:	if (mmget_not_zero(ctx->mm)) {
fs/userfaultfd.c:		ret = mfill_zeropage(ctx->mm, uffdio_zeropage.range.start,
fs/userfaultfd.c:		mmput(ctx->mm);
fs/userfaultfd.c:	if (ctx->state != UFFD_STATE_WAIT_API)
fs/userfaultfd.c:	ctx->state = UFFD_STATE_RUNNING;
fs/userfaultfd.c:	if (cmd != UFFDIO_API && ctx->state == UFFD_STATE_WAIT_API)
fs/userfaultfd.c:	spin_lock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	list_for_each_entry(wq, &ctx->fault_pending_wqh.task_list, task_list) {
fs/userfaultfd.c:	list_for_each_entry(wq, &ctx->fault_wqh.task_list, task_list) {
fs/userfaultfd.c:	spin_unlock(&ctx->fault_pending_wqh.lock);
fs/userfaultfd.c:	init_waitqueue_head(&ctx->fault_pending_wqh);
fs/userfaultfd.c:	init_waitqueue_head(&ctx->fault_wqh);
fs/userfaultfd.c:	init_waitqueue_head(&ctx->fd_wqh);
fs/userfaultfd.c:	seqcount_init(&ctx->refile_seq);
fs/userfaultfd.c:	atomic_set(&ctx->refcount, 1);
fs/userfaultfd.c:	ctx->flags = flags;
fs/userfaultfd.c:	ctx->state = UFFD_STATE_WAIT_API;
fs/userfaultfd.c:	ctx->released = false;
fs/userfaultfd.c:	ctx->mm = current->mm;
fs/userfaultfd.c:	atomic_inc(&ctx->mm->mm_count);
fs/userfaultfd.c:		mmdrop(ctx->mm);
fs/xfs/xfs_trace.h:		__entry->dev = VFS_I(ctx->dp)->i_sb->s_dev;
fs/xfs/xfs_trace.h:		__entry->ino = ctx->dp->i_ino;
fs/xfs/xfs_trace.h:		__entry->hashval = ctx->cursor->hashval;
fs/xfs/xfs_trace.h:		__entry->blkno = ctx->cursor->blkno;
fs/xfs/xfs_trace.h:		__entry->offset = ctx->cursor->offset;
fs/xfs/xfs_trace.h:		__entry->alist = ctx->alist;
fs/xfs/xfs_trace.h:		__entry->bufsize = ctx->bufsize;
fs/xfs/xfs_trace.h:		__entry->count = ctx->count;
fs/xfs/xfs_trace.h:		__entry->firstu = ctx->firstu;
fs/xfs/xfs_trace.h:		__entry->flags = ctx->flags;
fs/xfs/xfs_trace.h:		__entry->dev = VFS_I(ctx->dp)->i_sb->s_dev;
fs/xfs/xfs_trace.h:		__entry->ino = ctx->dp->i_ino;
fs/xfs/xfs_trace.h:		__entry->hashval = ctx->cursor->hashval;
fs/xfs/xfs_trace.h:		__entry->blkno = ctx->cursor->blkno;
fs/xfs/xfs_trace.h:		__entry->offset = ctx->cursor->offset;
fs/xfs/xfs_trace.h:		__entry->alist = ctx->alist;
fs/xfs/xfs_trace.h:		__entry->bufsize = ctx->bufsize;
fs/xfs/xfs_trace.h:		__entry->count = ctx->count;
fs/xfs/xfs_trace.h:		__entry->firstu = ctx->firstu;
fs/xfs/xfs_trace.h:		__entry->flags = ctx->flags;
fs/xfs/xfs_dir2_readdir.c:	if (xfs_dir2_dataptr_to_db(geo, ctx->pos) > geo->datablk)
fs/xfs/xfs_dir2_readdir.c:	if (ctx->pos <= dot_offset) {
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = dot_offset & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:	if (ctx->pos <= dotdot_offset) {
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = dotdot_offset & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:		if (ctx->pos > off) {
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = off & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:	ctx->pos = xfs_dir2_db_off_to_dataptr(geo, geo->datablk + 1, 0) &
fs/xfs/xfs_dir2_readdir.c:	if (xfs_dir2_dataptr_to_db(geo, ctx->pos) > geo->datablk)
fs/xfs/xfs_dir2_readdir.c:	wantoff = xfs_dir2_dataptr_to_off(geo, ctx->pos);
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = cook & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:	ctx->pos = xfs_dir2_db_off_to_dataptr(geo, geo->datablk + 1, 0) &
fs/xfs/xfs_dir2_readdir.c:	if (ctx->pos >= XFS_DIR2_MAX_DATAPTR)
fs/xfs/xfs_dir2_readdir.c:	curoff = xfs_dir2_dataptr_to_byte(ctx->pos);
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = xfs_dir2_byte_to_dataptr(curoff) & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = XFS_DIR2_MAX_DATAPTR & 0x7fffffff;
fs/xfs/xfs_dir2_readdir.c:		ctx->pos = xfs_dir2_byte_to_dataptr(curoff) & 0x7fffffff;
fs/xfs/xfs_log_cil.c:	log->l_cilp->xc_ctx->ticket = xlog_cil_ticket_alloc(log);
fs/xfs/xfs_log_cil.c:	log->l_cilp->xc_ctx->sequence = 1;
fs/xfs/xfs_log_cil.c:		lv->lv_item->li_seq = log->l_cilp->xc_ctx->sequence;
fs/xfs/xfs_log_cil.c:	ctx->nvecs += diff_iovecs;
fs/xfs/xfs_log_cil.c:		list_splice_init(&tp->t_busy, &ctx->busy_extents);
fs/xfs/xfs_log_cil.c:	if (ctx->ticket->t_curr_res == 0) {
fs/xfs/xfs_log_cil.c:		ctx->ticket->t_curr_res = ctx->ticket->t_unit_res;
fs/xfs/xfs_log_cil.c:		tp->t_ticket->t_curr_res -= ctx->ticket->t_unit_res;
fs/xfs/xfs_log_cil.c:	if (len > 0 && (ctx->space_used / iclog_space !=
fs/xfs/xfs_log_cil.c:				(ctx->space_used + len) / iclog_space)) {
fs/xfs/xfs_log_cil.c:		ctx->ticket->t_unit_res += hdrs;
fs/xfs/xfs_log_cil.c:		ctx->ticket->t_curr_res += hdrs;
fs/xfs/xfs_log_cil.c:	ctx->space_used += len;
fs/xfs/xfs_log_cil.c:	struct xfs_mount	*mp = ctx->cil->xc_log->l_mp;
fs/xfs/xfs_log_cil.c:	xfs_trans_committed_bulk(ctx->cil->xc_log->l_ailp, ctx->lv_chain,
fs/xfs/xfs_log_cil.c:					ctx->start_lsn, abort);
fs/xfs/xfs_log_cil.c:	xfs_extent_busy_sort(&ctx->busy_extents);
fs/xfs/xfs_log_cil.c:	xfs_extent_busy_clear(mp, &ctx->busy_extents,
fs/xfs/xfs_log_cil.c:	spin_lock(&ctx->cil->xc_push_lock);
fs/xfs/xfs_log_cil.c:		wake_up_all(&ctx->cil->xc_commit_wait);
fs/xfs/xfs_log_cil.c:	list_del(&ctx->committing);
fs/xfs/xfs_log_cil.c:	spin_unlock(&ctx->cil->xc_push_lock);
fs/xfs/xfs_log_cil.c:	xlog_cil_free_logvec(ctx->lv_chain);
fs/xfs/xfs_log_cil.c:	if (!list_empty(&ctx->busy_extents)) {
fs/xfs/xfs_log_cil.c:		xfs_discard_extents(mp, &ctx->busy_extents);
fs/xfs/xfs_log_cil.c:		xfs_extent_busy_clear(mp, &ctx->busy_extents, false);
fs/xfs/xfs_log_cil.c:	new_ctx->ticket = xlog_cil_ticket_alloc(log);
fs/xfs/xfs_log_cil.c:	ASSERT(push_seq <= ctx->sequence);
fs/xfs/xfs_log_cil.c:	if (push_seq < cil->xc_ctx->sequence) {
fs/xfs/xfs_log_cil.c:	list_add(&ctx->committing, &cil->xc_committing);
fs/xfs/xfs_log_cil.c:		if (!ctx->lv_chain)
fs/xfs/xfs_log_cil.c:			ctx->lv_chain = item->li_lv;
fs/xfs/xfs_log_cil.c:	INIT_LIST_HEAD(&new_ctx->committing);
fs/xfs/xfs_log_cil.c:	INIT_LIST_HEAD(&new_ctx->busy_extents);
fs/xfs/xfs_log_cil.c:	new_ctx->sequence = ctx->sequence + 1;
fs/xfs/xfs_log_cil.c:	new_ctx->cil = cil;
fs/xfs/xfs_log_cil.c:	cil->xc_current_sequence = new_ctx->sequence;
fs/xfs/xfs_log_cil.c:	tic = ctx->ticket;
fs/xfs/xfs_log_cil.c:	lvhdr.lv_next = ctx->lv_chain;
fs/xfs/xfs_log_cil.c:	error = xlog_write(log, &lvhdr, tic, &ctx->start_lsn, NULL, 0);
fs/xfs/xfs_log_cil.c:		if (new_ctx->sequence >= ctx->sequence)
fs/xfs/xfs_log_cil.c:		if (!new_ctx->commit_lsn) {
fs/xfs/xfs_log_cil.c:	ctx->log_cb.cb_func = xlog_cil_committed;
fs/xfs/xfs_log_cil.c:	ctx->log_cb.cb_arg = ctx;
fs/xfs/xfs_log_cil.c:	error = xfs_log_notify(log->l_mp, commit_iclog, &ctx->log_cb);
fs/xfs/xfs_log_cil.c:	ctx->commit_lsn = commit_lsn;
fs/xfs/xfs_log_cil.c:	xfs_log_ticket_put(new_ctx->ticket);
fs/xfs/xfs_log_cil.c:	if (cil->xc_ctx->space_used < XLOG_CIL_SPACE_LIMIT(log))
fs/xfs/xfs_log_cil.c:	tp->t_commit_lsn = cil->xc_ctx->sequence;
fs/xfs/xfs_log_cil.c:		if (ctx->sequence > sequence)
fs/xfs/xfs_log_cil.c:		if (!ctx->commit_lsn) {
fs/xfs/xfs_log_cil.c:		if (ctx->sequence != sequence)
fs/xfs/xfs_log_cil.c:		commit_lsn = ctx->commit_lsn;
fs/xfs/xfs_log_cil.c:	if (XFS_LSN_CMP(lip->li_seq, ctx->sequence) != 0)
fs/xfs/xfs_log_cil.c:	INIT_LIST_HEAD(&ctx->committing);
fs/xfs/xfs_log_cil.c:	INIT_LIST_HEAD(&ctx->busy_extents);
fs/xfs/xfs_log_cil.c:	ctx->sequence = 1;
fs/xfs/xfs_log_cil.c:	ctx->cil = cil;
fs/xfs/xfs_log_cil.c:	cil->xc_current_sequence = ctx->sequence;
fs/xfs/xfs_log_cil.c:		if (log->l_cilp->xc_ctx->ticket)
fs/xfs/xfs_log_cil.c:			xfs_log_ticket_put(log->l_cilp->xc_ctx->ticket);
fs/readdir.c:		ctx->pos = file->f_pos;
fs/readdir.c:		file->f_pos = ctx->pos;
fs/kernfs/dir.c:	for (pos = kernfs_dir_pos(ns, parent, ctx->pos, pos);
fs/kernfs/dir.c:	     pos = kernfs_dir_next_pos(ns, parent, ctx->pos, pos)) {
fs/kernfs/dir.c:		ctx->pos = pos->hash;
fs/kernfs/dir.c:	ctx->pos = INT_MAX;
fs/lockd/svcsubs.c:	if (!flctx || list_empty_careful(&flctx->flc_posix))
fs/lockd/svcsubs.c:	spin_lock(&flctx->flc_lock);
fs/lockd/svcsubs.c:	list_for_each_entry(fl, &flctx->flc_posix, fl_list) {
fs/lockd/svcsubs.c:			spin_unlock(&flctx->flc_lock);
fs/lockd/svcsubs.c:	spin_unlock(&flctx->flc_lock);
fs/lockd/svcsubs.c:	if (flctx && !list_empty_careful(&flctx->flc_posix)) {
fs/lockd/svcsubs.c:		spin_lock(&flctx->flc_lock);
fs/lockd/svcsubs.c:		list_for_each_entry(fl, &flctx->flc_posix, fl_list) {
fs/lockd/svcsubs.c:				spin_unlock(&flctx->flc_lock);
fs/lockd/svcsubs.c:		spin_unlock(&flctx->flc_lock);
fs/logfs/dir.c:	if (ctx->pos < 0)
fs/logfs/dir.c:	pos = ctx->pos - 2;
fs/logfs/dir.c:	for (;; pos++, ctx->pos++) {
fs/eventfd.c:	spin_lock_irqsave(&ctx->wqh.lock, flags);
fs/eventfd.c:	if (ULLONG_MAX - ctx->count < n)
fs/eventfd.c:		n = ULLONG_MAX - ctx->count;
fs/eventfd.c:	ctx->count += n;
fs/eventfd.c:	if (waitqueue_active(&ctx->wqh))
fs/eventfd.c:		wake_up_locked_poll(&ctx->wqh, POLLIN);
fs/eventfd.c:	spin_unlock_irqrestore(&ctx->wqh.lock, flags);
fs/eventfd.c:	kref_get(&ctx->kref);
fs/eventfd.c:	kref_put(&ctx->kref, eventfd_free);
fs/eventfd.c:	wake_up_poll(&ctx->wqh, POLLHUP);
fs/eventfd.c:	poll_wait(file, &ctx->wqh, wait);
fs/eventfd.c:	 * All writes to ctx->count occur within ctx->wqh.lock.  This read
fs/eventfd.c:	 * can be done outside ctx->wqh.lock because we know that poll_wait
fs/eventfd.c:	 *     lock ctx->wqh.lock (in poll_wait)
fs/eventfd.c:	 *     count = ctx->count
fs/eventfd.c:	 *     unlock ctx->wqh.lock
fs/eventfd.c:	 *                                        lock ctx->qwh.lock
fs/eventfd.c:	 *                                        ctx->count += n
fs/eventfd.c:	 *                                        unlock ctx->qwh.lock
fs/eventfd.c:	 *     count = ctx->count (INVALID!)
fs/eventfd.c:	 *                                        lock ctx->qwh.lock
fs/eventfd.c:	 *                                        ctx->count += n
fs/eventfd.c:	 *                                        unlock ctx->qwh.lock
fs/eventfd.c:	 *     lock ctx->wqh.lock (in poll_wait)
fs/eventfd.c:	 *     unlock ctx->wqh.lock
fs/eventfd.c:	count = READ_ONCE(ctx->count);
fs/eventfd.c:	*cnt = (ctx->flags & EFD_SEMAPHORE) ? 1 : ctx->count;
fs/eventfd.c:	ctx->count -= *cnt;
fs/eventfd.c:	spin_lock_irqsave(&ctx->wqh.lock, flags);
fs/eventfd.c:	__remove_wait_queue(&ctx->wqh, wait);
fs/eventfd.c:	if (*cnt != 0 && waitqueue_active(&ctx->wqh))
fs/eventfd.c:		wake_up_locked_poll(&ctx->wqh, POLLOUT);
fs/eventfd.c:	spin_unlock_irqrestore(&ctx->wqh.lock, flags);
fs/eventfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/eventfd.c:	if (ctx->count > 0)
fs/eventfd.c:		__add_wait_queue(&ctx->wqh, &wait);
fs/eventfd.c:			if (ctx->count > 0) {
fs/eventfd.c:			spin_unlock_irq(&ctx->wqh.lock);
fs/eventfd.c:			spin_lock_irq(&ctx->wqh.lock);
fs/eventfd.c:		__remove_wait_queue(&ctx->wqh, &wait);
fs/eventfd.c:		if (waitqueue_active(&ctx->wqh))
fs/eventfd.c:			wake_up_locked_poll(&ctx->wqh, POLLOUT);
fs/eventfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/eventfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/eventfd.c:	if (ULLONG_MAX - ctx->count > ucnt)
fs/eventfd.c:		__add_wait_queue(&ctx->wqh, &wait);
fs/eventfd.c:			if (ULLONG_MAX - ctx->count > ucnt) {
fs/eventfd.c:			spin_unlock_irq(&ctx->wqh.lock);
fs/eventfd.c:			spin_lock_irq(&ctx->wqh.lock);
fs/eventfd.c:		__remove_wait_queue(&ctx->wqh, &wait);
fs/eventfd.c:		ctx->count += ucnt;
fs/eventfd.c:		if (waitqueue_active(&ctx->wqh))
fs/eventfd.c:			wake_up_locked_poll(&ctx->wqh, POLLIN);
fs/eventfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/eventfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/eventfd.c:		   (unsigned long long)ctx->count);
fs/eventfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/eventfd.c:	kref_init(&ctx->kref);
fs/eventfd.c:	init_waitqueue_head(&ctx->wqh);
fs/eventfd.c:	ctx->count = count;
fs/eventfd.c:	ctx->flags = flags;
fs/hpfs/dir.c:	if (ctx->pos == 12) { /* diff -r requires this (note, that diff -r */
fs/hpfs/dir.c:		ctx->pos = 13; /* also fails on msdos filesystem in 2.0) */
fs/hpfs/dir.c:	if (ctx->pos == 13) {
fs/hpfs/dir.c:			if (hpfs_stop_cycles(inode->i_sb, ctx->pos, &c1, &c2, "hpfs_readdir")) {
fs/hpfs/dir.c:		if (ctx->pos == 12)
fs/hpfs/dir.c:		if (ctx->pos == 3 || ctx->pos == 4 || ctx->pos == 5) {
fs/hpfs/dir.c:			pr_err("pos==%d\n", (int)ctx->pos);
fs/hpfs/dir.c:		if (ctx->pos == 0) {
fs/hpfs/dir.c:			ctx->pos = 11;
fs/hpfs/dir.c:		if (ctx->pos == 11) {
fs/hpfs/dir.c:			ctx->pos = 1;
fs/hpfs/dir.c:		if (ctx->pos == 1) {
fs/hpfs/dir.c:			ctx->pos = ((loff_t) hpfs_de_as_down_as_possible(inode->i_sb, hpfs_inode->i_dno) << 4) + 1;
fs/hpfs/dir.c:		next_pos = ctx->pos;
fs/hpfs/dir.c:			ctx->pos = next_pos;
fs/hpfs/dir.c:					hpfs_error(inode->i_sb, "hpfs_readdir: bad ^A^A entry; pos = %08lx", (unsigned long)ctx->pos);
fs/hpfs/dir.c:					hpfs_error(inode->i_sb, "hpfs_readdir: bad \\377 entry; pos = %08lx", (unsigned long)ctx->pos);
fs/hpfs/dir.c:			ctx->pos = next_pos;
fs/hpfs/dir.c:		ctx->pos = next_pos;
fs/timerfd.c:	return ctx->clockid == CLOCK_REALTIME_ALARM ||
fs/timerfd.c:		ctx->clockid == CLOCK_BOOTTIME_ALARM ||
fs/timerfd.c:		ctx->clockid == CLOCK_POWEROFF_ALARM;
fs/timerfd.c:	spin_lock_irqsave(&ctx->wqh.lock, flags);
fs/timerfd.c:	ctx->expired = 1;
fs/timerfd.c:	ctx->ticks++;
fs/timerfd.c:	wake_up_locked(&ctx->wqh);
fs/timerfd.c:	spin_unlock_irqrestore(&ctx->wqh.lock, flags);
fs/timerfd.c: * wake-up requires ctx->ticks to be non zero, therefore we increment
fs/timerfd.c:		if (!ctx->might_cancel)
fs/timerfd.c:		spin_lock_irqsave(&ctx->wqh.lock, flags);
fs/timerfd.c:		if (ctx->moffs.tv64 != moffs.tv64) {
fs/timerfd.c:			ctx->moffs.tv64 = KTIME_MAX;
fs/timerfd.c:			ctx->ticks++;
fs/timerfd.c:			wake_up_locked(&ctx->wqh);
fs/timerfd.c:		spin_unlock_irqrestore(&ctx->wqh.lock, flags);
fs/timerfd.c:	if (ctx->might_cancel) {
fs/timerfd.c:		ctx->might_cancel = false;
fs/timerfd.c:		list_del_rcu(&ctx->clist);
fs/timerfd.c:	spin_lock(&ctx->cancel_lock);
fs/timerfd.c:	spin_unlock(&ctx->cancel_lock);
fs/timerfd.c:	if (!ctx->might_cancel || ctx->moffs.tv64 != KTIME_MAX)
fs/timerfd.c:	ctx->moffs = ktime_mono_to_real((ktime_t){ .tv64 = 0 });
fs/timerfd.c:	spin_lock(&ctx->cancel_lock);
fs/timerfd.c:	if ((ctx->clockid == CLOCK_REALTIME ||
fs/timerfd.c:	     ctx->clockid == CLOCK_REALTIME_ALARM ||
fs/timerfd.c:	     ctx->clockid == CLOCK_POWEROFF_ALARM) &&
fs/timerfd.c:		if (!ctx->might_cancel) {
fs/timerfd.c:			ctx->might_cancel = true;
fs/timerfd.c:			list_add_rcu(&ctx->clist, &cancel_list);
fs/timerfd.c:	spin_unlock(&ctx->cancel_lock);
fs/timerfd.c:		remaining = alarm_expires_remaining(&ctx->t.alarm);
fs/timerfd.c:		remaining = hrtimer_expires_remaining_adjusted(&ctx->t.tmr);
fs/timerfd.c:	int clockid = ctx->clockid;
fs/timerfd.c:	ctx->expired = 0;
fs/timerfd.c:	ctx->ticks = 0;
fs/timerfd.c:	ctx->tintv = timespec_to_ktime(ktmr->it_interval);
fs/timerfd.c:		type = clock2alarm(ctx->clockid);
fs/timerfd.c:		alarm_init(&ctx->t.alarm, type, timerfd_alarmproc);
fs/timerfd.c:		hrtimer_init(&ctx->t.tmr, clockid, htmode);
fs/timerfd.c:		hrtimer_set_expires(&ctx->t.tmr, texp);
fs/timerfd.c:		ctx->t.tmr.function = timerfd_tmrproc;
fs/timerfd.c:				alarm_start(&ctx->t.alarm, texp);
fs/timerfd.c:				alarm_start_relative(&ctx->t.alarm, texp);
fs/timerfd.c:			hrtimer_start(&ctx->t.tmr, texp, htmode);
fs/timerfd.c:	ctx->settime_flags = flags & TFD_SETTIME_FLAGS;
fs/timerfd.c:		alarm_cancel(&ctx->t.alarm);
fs/timerfd.c:		hrtimer_cancel(&ctx->t.tmr);
fs/timerfd.c:	poll_wait(file, &ctx->wqh, wait);
fs/timerfd.c:	spin_lock_irqsave(&ctx->wqh.lock, flags);
fs/timerfd.c:	if (ctx->ticks)
fs/timerfd.c:	spin_unlock_irqrestore(&ctx->wqh.lock, flags);
fs/timerfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/timerfd.c:		res = wait_event_interruptible_locked_irq(ctx->wqh, ctx->ticks);
fs/timerfd.c:		ctx->ticks = 0;
fs/timerfd.c:		ctx->expired = 0;
fs/timerfd.c:	if (ctx->ticks) {
fs/timerfd.c:		ticks = ctx->ticks;
fs/timerfd.c:		if (ctx->expired && ctx->tintv.tv64) {
fs/timerfd.c:					&ctx->t.alarm, ctx->tintv) - 1;
fs/timerfd.c:				alarm_restart(&ctx->t.alarm);
fs/timerfd.c:				ticks += hrtimer_forward_now(&ctx->t.tmr,
fs/timerfd.c:							     ctx->tintv) - 1;
fs/timerfd.c:				hrtimer_restart(&ctx->t.tmr);
fs/timerfd.c:		ctx->expired = 0;
fs/timerfd.c:		ctx->ticks = 0;
fs/timerfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/timerfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/timerfd.c:	t.it_interval = ktime_to_timespec(ctx->tintv);
fs/timerfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/timerfd.c:		   ctx->clockid,
fs/timerfd.c:		   (unsigned long long)ctx->ticks,
fs/timerfd.c:		   ctx->settime_flags,
fs/timerfd.c:		spin_lock_irq(&ctx->wqh.lock);
fs/timerfd.c:			ctx->ticks = ticks;
fs/timerfd.c:			wake_up_locked(&ctx->wqh);
fs/timerfd.c:		spin_unlock_irq(&ctx->wqh.lock);
fs/timerfd.c:	init_waitqueue_head(&ctx->wqh);
fs/timerfd.c:	spin_lock_init(&ctx->cancel_lock);
fs/timerfd.c:	ctx->clockid = clockid;
fs/timerfd.c:		type = clock2alarm(ctx->clockid);
fs/timerfd.c:		alarm_init(&ctx->t.alarm, type, timerfd_alarmproc);
fs/timerfd.c:		hrtimer_init(&ctx->t.tmr, clockid, HRTIMER_MODE_ABS);
fs/timerfd.c:	ctx->moffs = ktime_mono_to_real((ktime_t){ .tv64 = 0 });
fs/timerfd.c:		spin_lock_irq(&ctx->wqh.lock);
fs/timerfd.c:			if (alarm_try_to_cancel(&ctx->t.alarm) >= 0)
fs/timerfd.c:			if (hrtimer_try_to_cancel(&ctx->t.tmr) >= 0)
fs/timerfd.c:		spin_unlock_irq(&ctx->wqh.lock);
fs/timerfd.c:	if (ctx->expired && ctx->tintv.tv64) {
fs/timerfd.c:			alarm_forward_now(&ctx->t.alarm, ctx->tintv);
fs/timerfd.c:			hrtimer_forward_now(&ctx->t.tmr, ctx->tintv);
fs/timerfd.c:	old->it_interval = ktime_to_timespec(ctx->tintv);
fs/timerfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/timerfd.c:	if (ctx->clockid == CLOCK_POWEROFF_ALARM)
fs/timerfd.c:	spin_lock_irq(&ctx->wqh.lock);
fs/timerfd.c:	if (ctx->expired && ctx->tintv.tv64) {
fs/timerfd.c:		ctx->expired = 0;
fs/timerfd.c:			ctx->ticks +=
fs/timerfd.c:					&ctx->t.alarm, ctx->tintv) - 1;
fs/timerfd.c:			alarm_restart(&ctx->t.alarm);
fs/timerfd.c:			ctx->ticks +=
fs/timerfd.c:				hrtimer_forward_now(&ctx->t.tmr, ctx->tintv)
fs/timerfd.c:			hrtimer_restart(&ctx->t.tmr);
fs/timerfd.c:	t->it_interval = ktime_to_timespec(ctx->tintv);
fs/timerfd.c:	spin_unlock_irq(&ctx->wqh.lock);
fs/btrfs/check-integrity.c:		(struct btrfs_header *)first_block_ctx->datav[0];
fs/btrfs/check-integrity.c:				       sf->block_ctx->start, sf->nr,
fs/btrfs/check-integrity.c:			    sf->block_ctx->len) {
fs/btrfs/check-integrity.c:				       sf->block_ctx->start,
fs/btrfs/check-integrity.c:				       sf->block_ctx->dev->name);
fs/btrfs/check-integrity.c:				    sf->block_ctx->len)
fs/btrfs/check-integrity.c:				       sf->block_ctx->start,
fs/btrfs/check-integrity.c:			    sf->block_ctx->len) {
fs/btrfs/check-integrity.c:				       sf->block_ctx->start,
fs/btrfs/check-integrity.c:				       sf->block_ctx->dev->name);
fs/btrfs/check-integrity.c:	size_t start_offset = block_ctx->start & ((u64)PAGE_SIZE - 1);
fs/btrfs/check-integrity.c:	WARN_ON(offset + len > block_ctx->len);
fs/btrfs/check-integrity.c:		BUG_ON(i >= DIV_ROUND_UP(block_ctx->len, PAGE_SIZE));
fs/btrfs/check-integrity.c:		kaddr = block_ctx->datav[i];
fs/btrfs/check-integrity.c:				       next_bytenr, next_block_ctx->dev->name,
fs/btrfs/check-integrity.c:				       next_block_ctx->dev_bytenr, *mirror_nump,
fs/btrfs/check-integrity.c:				       next_bytenr, next_block_ctx->dev->name,
fs/btrfs/check-integrity.c:				       next_block_ctx->dev_bytenr, *mirror_nump,
fs/btrfs/check-integrity.c:				next_block_ctx->dev->bdev,
fs/btrfs/check-integrity.c:				next_block_ctx->dev_bytenr,
fs/btrfs/check-integrity.c:				block_ctx->dev->bdev,
fs/btrfs/check-integrity.c:				block_ctx->dev_bytenr,
fs/btrfs/check-integrity.c:		if (ret < (int)next_block_ctx->len) {
fs/btrfs/check-integrity.c:	    block_ctx->len) {
fs/btrfs/check-integrity.c:		       block_ctx->start, block_ctx->dev->name);
fs/btrfs/check-integrity.c:	    block_ctx->len) {
fs/btrfs/check-integrity.c:		       block_ctx->start, block_ctx->dev->name);
fs/btrfs/check-integrity.c:	if (block_ctx->mem_to_free) {
fs/btrfs/check-integrity.c:		BUG_ON(!block_ctx->datav);
fs/btrfs/check-integrity.c:		BUG_ON(!block_ctx->pagev);
fs/btrfs/check-integrity.c:		num_pages = (block_ctx->len + (u64)PAGE_SIZE - 1) >>
fs/btrfs/check-integrity.c:			if (block_ctx->datav[num_pages]) {
fs/btrfs/check-integrity.c:				kunmap(block_ctx->pagev[num_pages]);
fs/btrfs/check-integrity.c:				block_ctx->datav[num_pages] = NULL;
fs/btrfs/check-integrity.c:			if (block_ctx->pagev[num_pages]) {
fs/btrfs/check-integrity.c:				__free_page(block_ctx->pagev[num_pages]);
fs/btrfs/check-integrity.c:				block_ctx->pagev[num_pages] = NULL;
fs/btrfs/check-integrity.c:		kfree(block_ctx->mem_to_free);
fs/btrfs/check-integrity.c:		block_ctx->mem_to_free = NULL;
fs/btrfs/check-integrity.c:		block_ctx->pagev = NULL;
fs/btrfs/check-integrity.c:		block_ctx->datav = NULL;
fs/btrfs/check-integrity.c:	BUG_ON(block_ctx->datav);
fs/btrfs/check-integrity.c:	BUG_ON(block_ctx->pagev);
fs/btrfs/check-integrity.c:	BUG_ON(block_ctx->mem_to_free);
fs/btrfs/check-integrity.c:	if (block_ctx->dev_bytenr & ((u64)PAGE_SIZE - 1)) {
fs/btrfs/check-integrity.c:		       block_ctx->dev_bytenr);
fs/btrfs/check-integrity.c:	num_pages = (block_ctx->len + (u64)PAGE_SIZE - 1) >>
fs/btrfs/check-integrity.c:	block_ctx->mem_to_free = kzalloc((sizeof(*block_ctx->datav) +
fs/btrfs/check-integrity.c:					  sizeof(*block_ctx->pagev)) *
fs/btrfs/check-integrity.c:	if (!block_ctx->mem_to_free)
fs/btrfs/check-integrity.c:	block_ctx->datav = block_ctx->mem_to_free;
fs/btrfs/check-integrity.c:	block_ctx->pagev = (struct page **)(block_ctx->datav + num_pages);
fs/btrfs/check-integrity.c:		block_ctx->pagev[i] = alloc_page(GFP_NOFS);
fs/btrfs/check-integrity.c:		if (!block_ctx->pagev[i])
fs/btrfs/check-integrity.c:	dev_bytenr = block_ctx->dev_bytenr;
fs/btrfs/check-integrity.c:		bio->bi_bdev = block_ctx->dev->bdev;
fs/btrfs/check-integrity.c:			ret = bio_add_page(bio, block_ctx->pagev[j],
fs/btrfs/check-integrity.c:			       block_ctx->start, block_ctx->dev->name);
fs/btrfs/check-integrity.c:		block_ctx->datav[i] = kmap(block_ctx->pagev[i]);
fs/btrfs/check-integrity.c:		if (!block_ctx->datav[i]) {
fs/btrfs/check-integrity.c:			       block_ctx->dev->name);
fs/btrfs/check-integrity.c:	return block_ctx->len;
fs/btrfs/check-integrity.c:	l = btrfsic_block_link_hashtable_lookup(next_block_ctx->dev->bdev,
fs/btrfs/check-integrity.c:						next_block_ctx->dev_bytenr,
fs/btrfs/check-integrity.c:	block = btrfsic_block_hashtable_lookup(block_ctx->dev->bdev,
fs/btrfs/check-integrity.c:					       block_ctx->dev_bytenr,
fs/btrfs/check-integrity.c:		dev_state = btrfsic_dev_state_lookup(block_ctx->dev->bdev);
fs/btrfs/check-integrity.c:		block->dev_bytenr = block_ctx->dev_bytenr;
fs/btrfs/check-integrity.c:		block->logical_bytenr = block_ctx->start;
fs/btrfs/scrub.c:	atomic_inc(&sctx->refs);
fs/btrfs/scrub.c:	atomic_inc(&sctx->bios_in_flight);
fs/btrfs/scrub.c:	atomic_dec(&sctx->bios_in_flight);
fs/btrfs/scrub.c:	wake_up(&sctx->list_wait);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:	atomic_inc(&sctx->refs);
fs/btrfs/scrub.c:	atomic_inc(&sctx->workers_pending);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:	atomic_dec(&sctx->workers_pending);
fs/btrfs/scrub.c:	wake_up(&sctx->list_wait);
fs/btrfs/scrub.c:	while (!list_empty(&sctx->csum_list)) {
fs/btrfs/scrub.c:		sum = list_first_entry(&sctx->csum_list,
fs/btrfs/scrub.c:	scrub_free_wr_ctx(&sctx->wr_ctx);
fs/btrfs/scrub.c:	if (sctx->curr != -1) {
fs/btrfs/scrub.c:		struct scrub_bio *sbio = sctx->bios[sctx->curr];
fs/btrfs/scrub.c:		struct scrub_bio *sbio = sctx->bios[i];
fs/btrfs/scrub.c:	if (atomic_dec_and_test(&sctx->refs))
fs/btrfs/scrub.c:	atomic_set(&sctx->refs, 1);
fs/btrfs/scrub.c:	sctx->is_dev_replace = is_dev_replace;
fs/btrfs/scrub.c:	sctx->pages_per_rd_bio = SCRUB_PAGES_PER_RD_BIO;
fs/btrfs/scrub.c:	sctx->curr = -1;
fs/btrfs/scrub.c:	sctx->dev_root = dev->dev_root;
fs/btrfs/scrub.c:		sctx->bios[i] = sbio;
fs/btrfs/scrub.c:			sctx->bios[i]->next_free = i + 1;
fs/btrfs/scrub.c:			sctx->bios[i]->next_free = -1;
fs/btrfs/scrub.c:	sctx->first_free = 0;
fs/btrfs/scrub.c:	sctx->nodesize = dev->dev_root->nodesize;
fs/btrfs/scrub.c:	sctx->sectorsize = dev->dev_root->sectorsize;
fs/btrfs/scrub.c:	atomic_set(&sctx->bios_in_flight, 0);
fs/btrfs/scrub.c:	atomic_set(&sctx->workers_pending, 0);
fs/btrfs/scrub.c:	atomic_set(&sctx->cancel_req, 0);
fs/btrfs/scrub.c:	sctx->csum_size = btrfs_super_csum_size(fs_info->super_copy);
fs/btrfs/scrub.c:	INIT_LIST_HEAD(&sctx->csum_list);
fs/btrfs/scrub.c:	spin_lock_init(&sctx->list_lock);
fs/btrfs/scrub.c:	spin_lock_init(&sctx->stat_lock);
fs/btrfs/scrub.c:	init_waitqueue_head(&sctx->list_wait);
fs/btrfs/scrub.c:	ret = scrub_setup_wr_ctx(sctx, &sctx->wr_ctx, fs_info,
fs/btrfs/scrub.c:	fs_info = sblock->sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		++sctx->stat.malloc_errors;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:	++sctx->stat.corrected_errors;
fs/btrfs/scrub.c:	spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		++sctx->stat.uncorrectable_errors;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:			&sctx->dev_root->fs_info->dev_replace.
fs/btrfs/scrub.c:		btrfs_err_rl_in_rcu(sctx->dev_root->fs_info,
fs/btrfs/scrub.c:	fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		++sctx->stat.super_errors;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	if (sctx->is_dev_replace && !is_metadata && !have_csum) {
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		sctx->stat.read_errors++;
fs/btrfs/scrub.c:		sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.read_errors++;
fs/btrfs/scrub.c:		sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.unverified_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		if (sctx->is_dev_replace)
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.read_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.csum_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.verify_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	if (sctx->readonly) {
fs/btrfs/scrub.c:		ASSERT(!sctx->is_dev_replace);
fs/btrfs/scrub.c:		WARN_ON(sctx->is_dev_replace);
fs/btrfs/scrub.c:			if (sctx->is_dev_replace) {
fs/btrfs/scrub.c:	if (sblock_bad->no_io_error_seen && !sctx->is_dev_replace)
fs/btrfs/scrub.c:		if (!page_bad->io_error && !sctx->is_dev_replace)
fs/btrfs/scrub.c:		if (sctx->is_dev_replace) {
fs/btrfs/scrub.c:					&sctx->dev_root->
fs/btrfs/scrub.c:	if (success && !sctx->is_dev_replace) {
fs/btrfs/scrub.c:			spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:			sctx->stat.corrected_errors++;
fs/btrfs/scrub.c:			spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:				spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:				sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:				spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:				       sctx->csum_size);
fs/btrfs/scrub.c:			btrfs_warn_rl(sblock_bad->sctx->dev_root->fs_info,
fs/btrfs/scrub.c:				&sblock_bad->sctx->dev_root->fs_info->
fs/btrfs/scrub.c:				&sblock->sctx->dev_root->fs_info->dev_replace.
fs/btrfs/scrub.c:	struct scrub_wr_ctx *wr_ctx = &sctx->wr_ctx;
fs/btrfs/scrub.c:	mutex_lock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	if (!wr_ctx->wr_curr_bio) {
fs/btrfs/scrub.c:		wr_ctx->wr_curr_bio = kzalloc(sizeof(*wr_ctx->wr_curr_bio),
fs/btrfs/scrub.c:		if (!wr_ctx->wr_curr_bio) {
fs/btrfs/scrub.c:			mutex_unlock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:		wr_ctx->wr_curr_bio->sctx = sctx;
fs/btrfs/scrub.c:		wr_ctx->wr_curr_bio->page_count = 0;
fs/btrfs/scrub.c:	sbio = wr_ctx->wr_curr_bio;
fs/btrfs/scrub.c:		sbio->dev = wr_ctx->tgtdev;
fs/btrfs/scrub.c:					wr_ctx->pages_per_wr_bio);
fs/btrfs/scrub.c:				mutex_unlock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:			mutex_unlock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	if (sbio->page_count == wr_ctx->pages_per_wr_bio)
fs/btrfs/scrub.c:	mutex_unlock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	struct scrub_wr_ctx *wr_ctx = &sctx->wr_ctx;
fs/btrfs/scrub.c:	if (!wr_ctx->wr_curr_bio)
fs/btrfs/scrub.c:	sbio = wr_ctx->wr_curr_bio;
fs/btrfs/scrub.c:	wr_ctx->wr_curr_bio = NULL;
fs/btrfs/scrub.c:			&sbio->sctx->dev_root->fs_info->dev_replace;
fs/btrfs/scrub.c:	len = sctx->sectorsize;
fs/btrfs/scrub.c:	if (memcmp(csum, on_disk_csum, sctx->csum_size))
fs/btrfs/scrub.c:	struct btrfs_root *root = sctx->dev_root;
fs/btrfs/scrub.c:	memcpy(on_disk_csum, h->csum, sctx->csum_size);
fs/btrfs/scrub.c:	len = sctx->nodesize - BTRFS_CSUM_SIZE;
fs/btrfs/scrub.c:	if (memcmp(calculated_csum, on_disk_csum, sctx->csum_size))
fs/btrfs/scrub.c:	memcpy(on_disk_csum, s->csum, sctx->csum_size);
fs/btrfs/scrub.c:	if (memcmp(calculated_csum, on_disk_csum, sctx->csum_size))
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		++sctx->stat.super_errors;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	if (sctx->curr == -1)
fs/btrfs/scrub.c:	sbio = sctx->bios[sctx->curr];
fs/btrfs/scrub.c:	sctx->curr = -1;
fs/btrfs/scrub.c:	while (sctx->curr == -1) {
fs/btrfs/scrub.c:		spin_lock(&sctx->list_lock);
fs/btrfs/scrub.c:		sctx->curr = sctx->first_free;
fs/btrfs/scrub.c:		if (sctx->curr != -1) {
fs/btrfs/scrub.c:			sctx->first_free = sctx->bios[sctx->curr]->next_free;
fs/btrfs/scrub.c:			sctx->bios[sctx->curr]->next_free = -1;
fs/btrfs/scrub.c:			sctx->bios[sctx->curr]->page_count = 0;
fs/btrfs/scrub.c:			spin_unlock(&sctx->list_lock);
fs/btrfs/scrub.c:			spin_unlock(&sctx->list_lock);
fs/btrfs/scrub.c:			wait_event(sctx->list_wait, sctx->first_free != -1);
fs/btrfs/scrub.c:	sbio = sctx->bios[sctx->curr];
fs/btrfs/scrub.c:					sctx->pages_per_rd_bio);
fs/btrfs/scrub.c:	if (sbio->page_count == sctx->pages_per_rd_bio)
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sblock->sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.read_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		btrfs_err_rl_in_rcu(sctx->dev_root->fs_info,
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		btrfs_err_rl_in_rcu(sctx->dev_root->fs_info,
fs/btrfs/scrub.c:	if (sctx->is_dev_replace &&
fs/btrfs/scrub.c:	    atomic_read(&sctx->wr_ctx.flush_all_writes)) {
fs/btrfs/scrub.c:		mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:		mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:	if (WARN_ON(!sctx->is_dev_replace ||
fs/btrfs/scrub.c:	rbio = raid56_alloc_missing_rbio(sctx->dev_root, bio, bbio, length);
fs/btrfs/scrub.c:	spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:	sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:	spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:			spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:			sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:			spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:			memcpy(spage->csum, csum, sctx->csum_size);
fs/btrfs/scrub.c:	spin_lock(&sctx->list_lock);
fs/btrfs/scrub.c:	sbio->next_free = sctx->first_free;
fs/btrfs/scrub.c:	sctx->first_free = sbio->index;
fs/btrfs/scrub.c:	spin_unlock(&sctx->list_lock);
fs/btrfs/scrub.c:	if (sctx->is_dev_replace &&
fs/btrfs/scrub.c:	    atomic_read(&sctx->wr_ctx.flush_all_writes)) {
fs/btrfs/scrub.c:		mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:		mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:	int sectorsize = sparity->sctx->dev_root->sectorsize;
fs/btrfs/scrub.c:		if (!corrupted && sblock->sctx->is_dev_replace)
fs/btrfs/scrub.c:	while (!list_empty(&sctx->csum_list)) {
fs/btrfs/scrub.c:		sum = list_first_entry(&sctx->csum_list,
fs/btrfs/scrub.c:		++sctx->stat.csum_discards;
fs/btrfs/scrub.c:	index = ((u32)(logical - sum->bytenr)) / sctx->sectorsize;
fs/btrfs/scrub.c:	num_sectors = sum->len / sctx->sectorsize;
fs/btrfs/scrub.c:	memcpy(csum, sum->sums + index, sctx->csum_size);
fs/btrfs/scrub.c:		blocksize = sctx->sectorsize;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.data_extents_scrubbed++;
fs/btrfs/scrub.c:		sctx->stat.data_bytes_scrubbed += len;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		blocksize = sctx->nodesize;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.tree_extents_scrubbed++;
fs/btrfs/scrub.c:		sctx->stat.tree_bytes_scrubbed += len;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:		blocksize = sctx->sectorsize;
fs/btrfs/scrub.c:				++sctx->stat.no_csum;
fs/btrfs/scrub.c:			if (sctx->is_dev_replace && !have_csum) {
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:			spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:			sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:			spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:			memcpy(spage->csum, csum, sctx->csum_size);
fs/btrfs/scrub.c:		blocksize = sctx->sectorsize;
fs/btrfs/scrub.c:		blocksize = sctx->nodesize;
fs/btrfs/scrub.c:		blocksize = sctx->sectorsize;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.read_errors += nbits;
fs/btrfs/scrub.c:		sctx->stat.uncorrectable_errors += nbits;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	btrfs_queue_work(sparity->sctx->dev_root->fs_info->scrub_parity_workers,
fs/btrfs/scrub.c:	ret = btrfs_map_sblock(sctx->dev_root->fs_info, WRITE,
fs/btrfs/scrub.c:	rbio = raid56_parity_alloc_scrub_rbio(sctx->dev_root, bio, bbio,
fs/btrfs/scrub.c:	spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:	sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:	spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:				spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:				sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:				spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:						&sctx->csum_list, 1);
fs/btrfs/scrub.c:	mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:	mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:	wait_event(sctx->list_wait,
fs/btrfs/scrub.c:		   atomic_read(&sctx->bios_in_flight) == 0);
fs/btrfs/scrub.c:		    atomic_read(&sctx->cancel_req)) {
fs/btrfs/scrub.c:			atomic_set(&sctx->wr_ctx.flush_all_writes, 1);
fs/btrfs/scrub.c:			mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:			mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:			wait_event(sctx->list_wait,
fs/btrfs/scrub.c:				   atomic_read(&sctx->bios_in_flight) == 0);
fs/btrfs/scrub.c:			atomic_set(&sctx->wr_ctx.flush_all_writes, 0);
fs/btrfs/scrub.c:				spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:				sctx->stat.uncorrectable_errors++;
fs/btrfs/scrub.c:				spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:						       &sctx->csum_list, 1);
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:			sctx->stat.last_physical = map->stripes[num].physical +
fs/btrfs/scrub.c:			sctx->stat.last_physical = physical;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:	mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:		&sctx->dev_root->fs_info->mapping_tree;
fs/btrfs/scrub.c:	struct btrfs_root *root = sctx->dev_root;
fs/btrfs/scrub.c:		atomic_set(&sctx->wr_ctx.flush_all_writes, 1);
fs/btrfs/scrub.c:		mutex_lock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:		mutex_unlock(&sctx->wr_ctx.wr_lock);
fs/btrfs/scrub.c:		wait_event(sctx->list_wait,
fs/btrfs/scrub.c:			   atomic_read(&sctx->bios_in_flight) == 0);
fs/btrfs/scrub.c:		wait_event(sctx->list_wait,
fs/btrfs/scrub.c:			   atomic_read(&sctx->workers_pending) == 0);
fs/btrfs/scrub.c:		atomic_set(&sctx->wr_ctx.flush_all_writes, 0);
fs/btrfs/scrub.c:		if (sctx->stat.malloc_errors > 0) {
fs/btrfs/scrub.c:	struct btrfs_root *root = sctx->dev_root;
fs/btrfs/scrub.c:	wait_event(sctx->list_wait, atomic_read(&sctx->bios_in_flight) == 0);
fs/btrfs/scrub.c:	sctx->readonly = readonly;
fs/btrfs/scrub.c:	wait_event(sctx->list_wait, atomic_read(&sctx->bios_in_flight) == 0);
fs/btrfs/scrub.c:	wait_event(sctx->list_wait, atomic_read(&sctx->workers_pending) == 0);
fs/btrfs/scrub.c:		memcpy(progress, &sctx->stat, sizeof(*progress));
fs/btrfs/scrub.c:	atomic_inc(&sctx->cancel_req);
fs/btrfs/scrub.c:		memcpy(progress, &sctx->stat, sizeof(*progress));
fs/btrfs/scrub.c:	WARN_ON(wr_ctx->wr_curr_bio != NULL);
fs/btrfs/scrub.c:	mutex_init(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	wr_ctx->wr_curr_bio = NULL;
fs/btrfs/scrub.c:	wr_ctx->pages_per_wr_bio = SCRUB_PAGES_PER_WR_BIO;
fs/btrfs/scrub.c:	wr_ctx->tgtdev = dev;
fs/btrfs/scrub.c:	atomic_set(&wr_ctx->flush_all_writes, 0);
fs/btrfs/scrub.c:	mutex_lock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	kfree(wr_ctx->wr_curr_bio);
fs/btrfs/scrub.c:	wr_ctx->wr_curr_bio = NULL;
fs/btrfs/scrub.c:	mutex_unlock(&wr_ctx->wr_lock);
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	nocow_ctx->sctx = sctx;
fs/btrfs/scrub.c:	nocow_ctx->logical = logical;
fs/btrfs/scrub.c:	nocow_ctx->len = len;
fs/btrfs/scrub.c:	nocow_ctx->mirror_num = mirror_num;
fs/btrfs/scrub.c:	nocow_ctx->physical_for_dev_replace = physical_for_dev_replace;
fs/btrfs/scrub.c:	btrfs_init_work(&nocow_ctx->work, btrfs_scrubnc_helper,
fs/btrfs/scrub.c:	INIT_LIST_HEAD(&nocow_ctx->inodes);
fs/btrfs/scrub.c:			 &nocow_ctx->work);
fs/btrfs/scrub.c:	list_add_tail(&nocow_inode->list, &nocow_ctx->inodes);
fs/btrfs/scrub.c:	struct scrub_ctx *sctx = nocow_ctx->sctx;
fs/btrfs/scrub.c:	u64 logical = nocow_ctx->logical;
fs/btrfs/scrub.c:	u64 len = nocow_ctx->len;
fs/btrfs/scrub.c:	int mirror_num = nocow_ctx->mirror_num;
fs/btrfs/scrub.c:	u64 physical_for_dev_replace = nocow_ctx->physical_for_dev_replace;
fs/btrfs/scrub.c:	fs_info = sctx->dev_root->fs_info;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/scrub.c:	while (!list_empty(&nocow_ctx->inodes)) {
fs/btrfs/scrub.c:		entry = list_first_entry(&nocow_ctx->inodes,
fs/btrfs/scrub.c:	while (!list_empty(&nocow_ctx->inodes)) {
fs/btrfs/scrub.c:		entry = list_first_entry(&nocow_ctx->inodes,
fs/btrfs/scrub.c:	struct btrfs_fs_info *fs_info = nocow_ctx->sctx->dev_root->fs_info;
fs/btrfs/scrub.c:	u64 len = nocow_ctx->len;
fs/btrfs/scrub.c:	physical_for_dev_replace = nocow_ctx->physical_for_dev_replace;
fs/btrfs/scrub.c:	nocow_ctx_logical = nocow_ctx->logical;
fs/btrfs/scrub.c:							   nocow_ctx->mirror_num);
fs/btrfs/scrub.c:		err = write_page_nocow(nocow_ctx->sctx,
fs/btrfs/scrub.c:	dev = sctx->wr_ctx.tgtdev;
fs/btrfs/scrub.c:		spin_lock(&sctx->stat_lock);
fs/btrfs/scrub.c:		sctx->stat.malloc_errors++;
fs/btrfs/scrub.c:		spin_unlock(&sctx->stat_lock);
fs/btrfs/tree-log.h:	ctx->log_ret = 0;
fs/btrfs/tree-log.h:	ctx->log_transid = 0;
fs/btrfs/tree-log.h:	ctx->io_err = 0;
fs/btrfs/tree-log.h:	ctx->log_new_dentries = false;
fs/btrfs/tree-log.h:	ctx->inode = inode;
fs/btrfs/tree-log.h:	INIT_LIST_HEAD(&ctx->list);
fs/btrfs/send.c:	btrfs_err(sctx->send_root->fs_info,
fs/btrfs/send.c:		  result_string, what, sctx->cmp_key->objectid,
fs/btrfs/send.c:		  sctx->send_root->root_key.objectid,
fs/btrfs/send.c:		  (sctx->parent_root ?
fs/btrfs/send.c:		   sctx->parent_root->root_key.objectid : 0));
fs/btrfs/send.c:	return (sctx->parent_root && !sctx->cur_inode_new &&
fs/btrfs/send.c:		!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted &&
fs/btrfs/send.c:		S_ISREG(sctx->cur_inode_mode));
fs/btrfs/send.c:	int left = sctx->send_max_size - sctx->send_size;
fs/btrfs/send.c:	hdr = (struct btrfs_tlv_header *) (sctx->send_buf + sctx->send_size);
fs/btrfs/send.c:	sctx->send_size += total_len;
fs/btrfs/send.c:	return write_buf(sctx->send_filp, &hdr, sizeof(hdr),
fs/btrfs/send.c:					&sctx->send_off);
fs/btrfs/send.c:	if (WARN_ON(!sctx->send_buf))
fs/btrfs/send.c:	BUG_ON(sctx->send_size);
fs/btrfs/send.c:	sctx->send_size += sizeof(*hdr);
fs/btrfs/send.c:	hdr = (struct btrfs_cmd_header *)sctx->send_buf;
fs/btrfs/send.c:	hdr = (struct btrfs_cmd_header *)sctx->send_buf;
fs/btrfs/send.c:	hdr->len = cpu_to_le32(sctx->send_size - sizeof(*hdr));
fs/btrfs/send.c:	crc = btrfs_crc32c(0, (unsigned char *)sctx->send_buf, sctx->send_size);
fs/btrfs/send.c:	ret = write_buf(sctx->send_filp, sctx->send_buf, sctx->send_size,
fs/btrfs/send.c:					&sctx->send_off);
fs/btrfs/send.c:	sctx->total_send_size += sctx->send_size;
fs/btrfs/send.c:	sctx->cmd_send_size[le16_to_cpu(hdr->cmd)] += sctx->send_size;
fs/btrfs/send.c:	sctx->send_size = 0;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c: * Results are collected in sctx->clone_roots->ino/offset/found_refs
fs/btrfs/send.c:	found = bsearch((void *)(uintptr_t)root, bctx->sctx->clone_roots,
fs/btrfs/send.c:			bctx->sctx->clone_roots_cnt,
fs/btrfs/send.c:	if (found->root == bctx->sctx->send_root &&
fs/btrfs/send.c:	    ino == bctx->cur_objectid &&
fs/btrfs/send.c:	    offset == bctx->cur_offset) {
fs/btrfs/send.c:		bctx->found_itself = 1;
fs/btrfs/send.c:	ret = __get_inode_info(found->root, bctx->path, ino, &i_size, NULL, NULL,
fs/btrfs/send.c:	btrfs_release_path(bctx->path);
fs/btrfs/send.c:	if (offset + bctx->data_offset + bctx->extent_len > i_size)
fs/btrfs/send.c:	if (found->root == bctx->sctx->send_root) {
fs/btrfs/send.c:		if (ino >= bctx->cur_objectid)
fs/btrfs/send.c:		if (ino > bctx->cur_objectid)
fs/btrfs/send.c:		if (offset + bctx->extent_len > bctx->cur_offset)
fs/btrfs/send.c:	bctx->found++;
fs/btrfs/send.c:		if (found->offset > offset + bctx->extent_len)
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	backref_ctx->path = tmp_path;
fs/btrfs/send.c:	for (i = 0; i < sctx->clone_roots_cnt; i++) {
fs/btrfs/send.c:		cur_clone_root = sctx->clone_roots + i;
fs/btrfs/send.c:	backref_ctx->sctx = sctx;
fs/btrfs/send.c:	backref_ctx->found = 0;
fs/btrfs/send.c:	backref_ctx->cur_objectid = ino;
fs/btrfs/send.c:	backref_ctx->cur_offset = data_offset;
fs/btrfs/send.c:	backref_ctx->found_itself = 0;
fs/btrfs/send.c:	backref_ctx->extent_len = num_bytes;
fs/btrfs/send.c:		backref_ctx->data_offset = 0;
fs/btrfs/send.c:		backref_ctx->data_offset = btrfs_file_extent_offset(eb, fi);
fs/btrfs/send.c:		backref_ctx->extent_len = ino_size - data_offset;
fs/btrfs/send.c:	if (!backref_ctx->found_itself) {
fs/btrfs/send.c:	if (!backref_ctx->found)
fs/btrfs/send.c:	for (i = 0; i < sctx->clone_roots_cnt; i++) {
fs/btrfs/send.c:		if (sctx->clone_roots[i].found_refs) {
fs/btrfs/send.c:				cur_clone_root = sctx->clone_roots + i;
fs/btrfs/send.c:			else if (sctx->clone_roots[i].root == sctx->send_root)
fs/btrfs/send.c:				cur_clone_root = sctx->clone_roots + i;
fs/btrfs/send.c:		di = btrfs_lookup_dir_item(NULL, sctx->send_root,
fs/btrfs/send.c:		if (!sctx->parent_root) {
fs/btrfs/send.c:		di = btrfs_lookup_dir_item(NULL, sctx->parent_root,
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, ino, NULL, &left_gen, NULL, NULL,
fs/btrfs/send.c:	if (!sctx->parent_root) {
fs/btrfs/send.c:		ret = get_inode_info(sctx->parent_root, ino, NULL, &right_gen,
fs/btrfs/send.c:			if (ino < sctx->send_progress)
fs/btrfs/send.c:			if (ino < sctx->send_progress)
fs/btrfs/send.c:			if (ino < sctx->send_progress)
fs/btrfs/send.c:			if (ino < sctx->send_progress)
fs/btrfs/send.c:	if (!sctx->parent_root)
fs/btrfs/send.c:	if (sctx->parent_root && dir != BTRFS_FIRST_FREE_OBJECTID) {
fs/btrfs/send.c:		ret = get_inode_info(sctx->parent_root, dir, NULL, &gen, NULL,
fs/btrfs/send.c:	ret = lookup_dir_item_inode(sctx->parent_root, dir, name, name_len,
fs/btrfs/send.c:	if (other_inode > sctx->send_progress ||
fs/btrfs/send.c:		ret = get_inode_info(sctx->parent_root, other_inode, NULL,
fs/btrfs/send.c:	if (!sctx->parent_root)
fs/btrfs/send.c:	ret = lookup_dir_item_inode(sctx->send_root, dir, name, name_len,
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, ow_inode, NULL, &gen, NULL, NULL,
fs/btrfs/send.c:	if ((ow_inode < sctx->send_progress) ||
fs/btrfs/send.c:	    (ino != sctx->cur_ino && ow_inode == sctx->cur_ino &&
fs/btrfs/send.c:	     gen == sctx->cur_inode_gen))
fs/btrfs/send.c:	if (!sctx->parent_root)
fs/btrfs/send.c:	ret = get_first_ref(sctx->parent_root, ino, &dir, &dir_gen, name);
fs/btrfs/send.c:	nce_head = radix_tree_lookup(&sctx->name_cache,
fs/btrfs/send.c:		ret = radix_tree_insert(&sctx->name_cache, nce->ino, nce_head);
fs/btrfs/send.c:	list_add_tail(&nce->list, &sctx->name_cache_list);
fs/btrfs/send.c:	sctx->name_cache_size++;
fs/btrfs/send.c:	nce_head = radix_tree_lookup(&sctx->name_cache,
fs/btrfs/send.c:		btrfs_err(sctx->send_root->fs_info,
fs/btrfs/send.c:			nce->ino, sctx->name_cache_size);
fs/btrfs/send.c:	sctx->name_cache_size--;
fs/btrfs/send.c:		radix_tree_delete(&sctx->name_cache, (unsigned long)nce->ino);
fs/btrfs/send.c:	nce_head = radix_tree_lookup(&sctx->name_cache, (unsigned long)ino);
fs/btrfs/send.c:	list_add_tail(&nce->list, &sctx->name_cache_list);
fs/btrfs/send.c:	if (sctx->name_cache_size < SEND_CTX_NAME_CACHE_CLEAN_SIZE)
fs/btrfs/send.c:	while (sctx->name_cache_size > SEND_CTX_MAX_NAME_CACHE_SIZE) {
fs/btrfs/send.c:		nce = list_entry(sctx->name_cache_list.next,
fs/btrfs/send.c:	while (!list_empty(&sctx->name_cache_list)) {
fs/btrfs/send.c:		nce = list_entry(sctx->name_cache_list.next,
fs/btrfs/send.c:		if (ino < sctx->send_progress && nce->need_later_update) {
fs/btrfs/send.c:	if (ino < sctx->send_progress)
fs/btrfs/send.c:		ret = get_first_ref(sctx->send_root, ino,
fs/btrfs/send.c:		ret = get_first_ref(sctx->parent_root, ino,
fs/btrfs/send.c:	if (ino < sctx->send_progress)
fs/btrfs/send.c: * sctx->send_progress tells this function at which point in time receiving
fs/btrfs/send.c:			ret = get_first_ref(sctx->parent_root, ino,
fs/btrfs/send.c:	struct btrfs_root *send_root = sctx->send_root;
fs/btrfs/send.c:	struct btrfs_root *parent_root = sctx->parent_root;
fs/btrfs/send.c:	if (!btrfs_is_empty_uuid(sctx->send_root->root_item.received_uuid))
fs/btrfs/send.c:			    sctx->send_root->root_item.received_uuid);
fs/btrfs/send.c:			    sctx->send_root->root_item.uuid);
fs/btrfs/send.c:		    le64_to_cpu(sctx->send_root->root_item.ctransid));
fs/btrfs/send.c:			    le64_to_cpu(sctx->parent_root->root_item.ctransid));
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	ret = btrfs_search_slot(NULL, sctx->send_root, &key, path, 0, 0);
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	if (ino != sctx->cur_ino) {
fs/btrfs/send.c:		ret = get_inode_info(sctx->send_root, ino, NULL, &gen, &mode,
fs/btrfs/send.c:		gen = sctx->cur_inode_gen;
fs/btrfs/send.c:		mode = sctx->cur_inode_mode;
fs/btrfs/send.c:		rdev = sctx->cur_inode_rdev;
fs/btrfs/send.c:		btrfs_warn(sctx->send_root->fs_info, "unexpected inode type %o",
fs/btrfs/send.c:		ret = read_symlink(sctx->send_root, ino, p);
fs/btrfs/send.c:	ret = btrfs_search_slot(NULL, sctx->send_root, &key, path, 0, 0);
fs/btrfs/send.c:			ret = btrfs_next_leaf(sctx->send_root, path);
fs/btrfs/send.c:		    di_key.objectid < sctx->send_progress) {
fs/btrfs/send.c:	if (S_ISDIR(sctx->cur_inode_mode)) {
fs/btrfs/send.c:		ret = did_create_dir(sctx, sctx->cur_ino);
fs/btrfs/send.c:	ret = send_create_inode(sctx, sctx->cur_ino);
fs/btrfs/send.c:	__free_recorded_refs(&sctx->new_refs);
fs/btrfs/send.c:	__free_recorded_refs(&sctx->deleted_refs);
fs/btrfs/send.c:	struct rb_node **p = &sctx->orphan_dirs.rb_node;
fs/btrfs/send.c:	rb_insert_color(&odi->node, &sctx->orphan_dirs);
fs/btrfs/send.c:	struct rb_node *n = sctx->orphan_dirs.rb_node;
fs/btrfs/send.c:	rb_erase(&odi->node, &sctx->orphan_dirs);
fs/btrfs/send.c:	struct btrfs_root *root = sctx->parent_root;
fs/btrfs/send.c:	struct rb_node **p = &sctx->waiting_dir_moves.rb_node;
fs/btrfs/send.c:	rb_insert_color(&dm->node, &sctx->waiting_dir_moves);
fs/btrfs/send.c:	struct rb_node *n = sctx->waiting_dir_moves.rb_node;
fs/btrfs/send.c:	rb_erase(&dm->node, &sctx->waiting_dir_moves);
fs/btrfs/send.c:	struct rb_node **p = &sctx->pending_dir_moves.rb_node;
fs/btrfs/send.c:		rb_insert_color(&pm->node, &sctx->pending_dir_moves);
fs/btrfs/send.c:	struct rb_node *n = sctx->pending_dir_moves.rb_node;
fs/btrfs/send.c:			ret = get_first_ref(sctx->parent_root, ino,
fs/btrfs/send.c:	u64 orig_progress = sctx->send_progress;
fs/btrfs/send.c:		ret = get_first_ref(sctx->parent_root, pm->ino,
fs/btrfs/send.c:	sctx->send_progress = sctx->cur_ino + 1;
fs/btrfs/send.c:		ret = can_rmdir(sctx, rmdir_ino, odi->gen, sctx->cur_ino);
fs/btrfs/send.c:		ret = get_inode_info(sctx->send_root, cur->dir, NULL,
fs/btrfs/send.c:	sctx->send_progress = orig_progress;
fs/btrfs/send.c:		rb_erase(&m->node, &sctx->pending_dir_moves);
fs/btrfs/send.c:	u64 parent_ino = sctx->cur_ino;
fs/btrfs/send.c: * (in the send root) with a higher inode number than ours (sctx->cur_ino) was
fs/btrfs/send.c: * Returns 1 if the rename of sctx->cur_ino needs to be delayed, 0 if it can
fs/btrfs/send.c:	if (RB_EMPTY_ROOT(&sctx->waiting_dir_moves))
fs/btrfs/send.c:	ret = btrfs_search_slot(NULL, sctx->parent_root, &key, path, 0, 0);
fs/btrfs/send.c:	di = btrfs_match_dir_item_name(sctx->parent_root, path,
fs/btrfs/send.c:	 * parent directory with the same name that sctx->cur_ino is being
fs/btrfs/send.c:	 * if it is, we need to delay the rename of sctx->cur_ino as well, so
fs/btrfs/send.c:	ret = get_inode_info(sctx->parent_root, di_key.objectid, NULL,
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, di_key.objectid, NULL,
fs/btrfs/send.c:	/* Different inode, no need to delay the rename of sctx->cur_ino */
fs/btrfs/send.c:					   sctx->cur_ino,
fs/btrfs/send.c:					   sctx->cur_inode_gen,
fs/btrfs/send.c:					   &sctx->new_refs,
fs/btrfs/send.c:					   &sctx->deleted_refs,
fs/btrfs/send.c:			ret = is_ancestor(sctx->parent_root,
fs/btrfs/send.c:					  sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:		ret = get_first_ref(sctx->send_root, ino, &parent_ino_after,
fs/btrfs/send.c:		ret = get_first_ref(sctx->parent_root, ino, &parent_ino_before,
fs/btrfs/send.c:		if (ino > sctx->cur_ino &&
fs/btrfs/send.c:					   sctx->cur_ino,
fs/btrfs/send.c:					   sctx->cur_inode_gen,
fs/btrfs/send.c:					   &sctx->new_refs,
fs/btrfs/send.c:					   &sctx->deleted_refs,
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	btrfs_debug(fs_info, "process_recorded_refs %llu", sctx->cur_ino);
fs/btrfs/send.c:	BUG_ON(sctx->cur_ino <= BTRFS_FIRST_FREE_OBJECTID);
fs/btrfs/send.c:	if (!sctx->cur_inode_new) {
fs/btrfs/send.c:		ret = did_overwrite_first_ref(sctx, sctx->cur_ino,
fs/btrfs/send.c:				sctx->cur_inode_gen);
fs/btrfs/send.c:	if (sctx->cur_inode_new || did_overwrite) {
fs/btrfs/send.c:		ret = gen_unique_name(sctx, sctx->cur_ino,
fs/btrfs/send.c:				sctx->cur_inode_gen, valid_path);
fs/btrfs/send.c:		ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:	list_for_each_entry(cur, &sctx->new_refs, list) {
fs/btrfs/send.c:			list_for_each_entry(cur2, &sctx->new_refs, list) {
fs/btrfs/send.c:			ret = is_first_ref(sctx->parent_root,
fs/btrfs/send.c:				 * sctx->send_progress. We need to prevent
fs/btrfs/send.c:				ret = get_cur_path(sctx, sctx->cur_ino,
fs/btrfs/send.c:					   sctx->cur_inode_gen, valid_path);
fs/btrfs/send.c:		if (S_ISDIR(sctx->cur_inode_mode) && sctx->parent_root) {
fs/btrfs/send.c:		if (S_ISDIR(sctx->cur_inode_mode) && sctx->parent_root &&
fs/btrfs/send.c:			if (S_ISDIR(sctx->cur_inode_mode)) {
fs/btrfs/send.c:	if (S_ISDIR(sctx->cur_inode_mode) && sctx->cur_inode_deleted) {
fs/btrfs/send.c:		ret = can_rmdir(sctx, sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:				sctx->cur_ino);
fs/btrfs/send.c:			ret = orphanize_inode(sctx, sctx->cur_ino,
fs/btrfs/send.c:					sctx->cur_inode_gen, valid_path);
fs/btrfs/send.c:		list_for_each_entry(cur, &sctx->deleted_refs, list) {
fs/btrfs/send.c:	} else if (S_ISDIR(sctx->cur_inode_mode) &&
fs/btrfs/send.c:		   !list_empty(&sctx->deleted_refs)) {
fs/btrfs/send.c:		cur = list_entry(sctx->deleted_refs.next, struct recorded_ref,
fs/btrfs/send.c:	} else if (!S_ISDIR(sctx->cur_inode_mode)) {
fs/btrfs/send.c:		list_for_each_entry(cur, &sctx->deleted_refs, list) {
fs/btrfs/send.c:					sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:		if (cur->dir > sctx->cur_ino)
fs/btrfs/send.c:					sctx->cur_ino);
fs/btrfs/send.c:	return record_ref(sctx->send_root, num, dir, index, name,
fs/btrfs/send.c:			  ctx, &sctx->new_refs);
fs/btrfs/send.c:	return record_ref(sctx->parent_root, num, dir, index, name,
fs/btrfs/send.c:			  ctx, &sctx->deleted_refs);
fs/btrfs/send.c:	ret = iterate_inode_ref(sctx->send_root, sctx->left_path,
fs/btrfs/send.c:				sctx->cmp_key, 0, __record_new_ref, sctx);
fs/btrfs/send.c:	ret = iterate_inode_ref(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:				sctx->cmp_key, 0, __record_deleted_ref, sctx);
fs/btrfs/send.c:	if (dir == ctx->dir && fs_path_len(name) == fs_path_len(ctx->name) &&
fs/btrfs/send.c:	    strncmp(name->start, ctx->name->start, fs_path_len(name)) == 0) {
fs/btrfs/send.c:		ret = get_inode_info(ctx->root, dir, NULL, &dir_gen, NULL,
fs/btrfs/send.c:		if (dir_gen != ctx->dir_gen)
fs/btrfs/send.c:		ctx->found_idx = num;
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, dir, NULL, &dir_gen, NULL,
fs/btrfs/send.c:	ret = find_iref(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:			sctx->cmp_key, dir, dir_gen, name);
fs/btrfs/send.c:	ret = get_inode_info(sctx->parent_root, dir, NULL, &dir_gen, NULL,
fs/btrfs/send.c:	ret = find_iref(sctx->send_root, sctx->left_path, sctx->cmp_key,
fs/btrfs/send.c:	ret = iterate_inode_ref(sctx->send_root, sctx->left_path,
fs/btrfs/send.c:			sctx->cmp_key, 0, __record_changed_new_ref, sctx);
fs/btrfs/send.c:	ret = iterate_inode_ref(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:			sctx->cmp_key, 0, __record_changed_deleted_ref, sctx);
fs/btrfs/send.c:		root = sctx->send_root;
fs/btrfs/send.c:		root = sctx->parent_root;
fs/btrfs/send.c:		btrfs_err(sctx->send_root->fs_info,
fs/btrfs/send.c:	key.objectid = sctx->cmp_key->objectid;
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
fs/btrfs/send.c:			       sctx->cmp_key, __process_new_xattr, sctx);
fs/btrfs/send.c:	return iterate_dir_item(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:				sctx->cmp_key, __process_deleted_xattr, sctx);
fs/btrfs/send.c:	if (name_len == ctx->name_len &&
fs/btrfs/send.c:	    strncmp(name, ctx->name, name_len) == 0) {
fs/btrfs/send.c:		ctx->found_idx = num;
fs/btrfs/send.c:		ctx->found_data_len = data_len;
fs/btrfs/send.c:		ctx->found_data = kmemdup(data, data_len, GFP_KERNEL);
fs/btrfs/send.c:		if (!ctx->found_data)
fs/btrfs/send.c:	ret = find_xattr(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:			 sctx->cmp_key, name, name_len, &found_data,
fs/btrfs/send.c:	ret = find_xattr(sctx->send_root, sctx->left_path, sctx->cmp_key,
fs/btrfs/send.c:	ret = iterate_dir_item(sctx->send_root, sctx->left_path,
fs/btrfs/send.c:			sctx->cmp_key, __process_changed_new_xattr, sctx);
fs/btrfs/send.c:	ret = iterate_dir_item(sctx->parent_root, sctx->right_path,
fs/btrfs/send.c:			sctx->cmp_key, __process_changed_deleted_xattr, sctx);
fs/btrfs/send.c:	root = sctx->send_root;
fs/btrfs/send.c:	key.objectid = sctx->cmp_key->objectid;
fs/btrfs/send.c:	struct btrfs_root *root = sctx->send_root;
fs/btrfs/send.c:	key.objectid = sctx->cur_ino;
fs/btrfs/send.c:	memset(&sctx->ra, 0, sizeof(struct file_ra_state));
fs/btrfs/send.c:	file_ra_state_init(&sctx->ra, inode->i_mapping);
fs/btrfs/send.c:	btrfs_force_ra(inode->i_mapping, &sctx->ra, NULL, index,
fs/btrfs/send.c:		memcpy(sctx->read_buf + ret, addr + pg_offset, cur_len);
fs/btrfs/send.c:	struct btrfs_fs_info *fs_info = sctx->send_root->fs_info;
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, num_read);
fs/btrfs/send.c:	btrfs_debug(sctx->send_root->fs_info,
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	if (clone_root->root == sctx->send_root) {
fs/btrfs/send.c:		ret = get_inode_info(sctx->send_root, clone_root->ino, NULL,
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	u64 offset = sctx->cur_inode_last_extent;
fs/btrfs/send.c:	ret = get_cur_path(sctx, sctx->cur_ino, sctx->cur_inode_gen, p);
fs/btrfs/send.c:	memset(sctx->read_buf, 0, BTRFS_SEND_READ_SIZE);
fs/btrfs/send.c:		TLV_PUT(sctx, BTRFS_SEND_A_DATA, sctx->read_buf, len);
fs/btrfs/send.c:	if (sctx->flags & BTRFS_SEND_FLAG_NO_FILE_DATA)
fs/btrfs/send.c:	u64 bs = sctx->send_root->fs_info->sb->s_blocksize;
fs/btrfs/send.c:	if (offset + len > sctx->cur_inode_size)
fs/btrfs/send.c:		len = sctx->cur_inode_size - offset;
fs/btrfs/send.c:	ret = btrfs_search_slot_for_read(sctx->parent_root, &key, path, 0, 0);
fs/btrfs/send.c:		ret = btrfs_next_item(sctx->parent_root, path);
fs/btrfs/send.c:	struct btrfs_root *root = sctx->send_root;
fs/btrfs/send.c:	sctx->cur_inode_last_extent = 0;
fs/btrfs/send.c:	key.objectid = sctx->cur_ino;
fs/btrfs/send.c:	if (key.objectid != sctx->cur_ino || key.type != BTRFS_EXTENT_DATA_KEY)
fs/btrfs/send.c:				   sctx->send_root->sectorsize);
fs/btrfs/send.c:	sctx->cur_inode_last_extent = extent_end;
fs/btrfs/send.c:	if (sctx->cur_ino != key->objectid || !need_send_hole(sctx))
fs/btrfs/send.c:	if (sctx->cur_inode_last_extent == (u64)-1) {
fs/btrfs/send.c:				   sctx->send_root->sectorsize);
fs/btrfs/send.c:	    sctx->cur_inode_last_extent < key->offset) {
fs/btrfs/send.c:	if (sctx->cur_inode_last_extent < key->offset)
fs/btrfs/send.c:	sctx->cur_inode_last_extent = extent_end;
fs/btrfs/send.c:	if (S_ISLNK(sctx->cur_inode_mode))
fs/btrfs/send.c:	if (sctx->parent_root && !sctx->cur_inode_new) {
fs/btrfs/send.c:			sctx->cur_inode_size, &found_clone);
fs/btrfs/send.c:	root = sctx->send_root;
fs/btrfs/send.c:	key.objectid = sctx->cmp_key->objectid;
fs/btrfs/send.c:	if (sctx->cur_ino == 0)
fs/btrfs/send.c:	if (!at_end && sctx->cur_ino == sctx->cmp_key->objectid &&
fs/btrfs/send.c:	    sctx->cmp_key->type <= BTRFS_INODE_EXTREF_KEY)
fs/btrfs/send.c:	if (list_empty(&sctx->new_refs) && list_empty(&sctx->deleted_refs))
fs/btrfs/send.c:		sctx->send_progress = sctx->cur_ino + 1;
fs/btrfs/send.c:	if (sctx->cur_ino == 0 || sctx->cur_inode_deleted)
fs/btrfs/send.c:	if (!at_end && sctx->cmp_key->objectid == sctx->cur_ino)
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, sctx->cur_ino, NULL, NULL,
fs/btrfs/send.c:	if (!sctx->parent_root || sctx->cur_inode_new) {
fs/btrfs/send.c:		if (!S_ISLNK(sctx->cur_inode_mode))
fs/btrfs/send.c:		ret = get_inode_info(sctx->parent_root, sctx->cur_ino,
fs/btrfs/send.c:		if (!S_ISLNK(sctx->cur_inode_mode) && left_mode != right_mode)
fs/btrfs/send.c:	if (S_ISREG(sctx->cur_inode_mode)) {
fs/btrfs/send.c:			if (sctx->cur_inode_last_extent == (u64)-1 ||
fs/btrfs/send.c:			    sctx->cur_inode_last_extent <
fs/btrfs/send.c:			    sctx->cur_inode_size) {
fs/btrfs/send.c:			if (sctx->cur_inode_last_extent <
fs/btrfs/send.c:			    sctx->cur_inode_size) {
fs/btrfs/send.c:				ret = send_hole(sctx, sctx->cur_inode_size);
fs/btrfs/send.c:		ret = send_truncate(sctx, sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:				sctx->cur_inode_size);
fs/btrfs/send.c:		ret = send_chown(sctx, sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:		ret = send_chmod(sctx, sctx->cur_ino, sctx->cur_inode_gen,
fs/btrfs/send.c:	if (!is_waiting_for_move(sctx, sctx->cur_ino)) {
fs/btrfs/send.c:		sctx->send_progress = sctx->cur_ino + 1;
fs/btrfs/send.c:		ret = send_utimes(sctx, sctx->cur_ino, sctx->cur_inode_gen);
fs/btrfs/send.c:	struct btrfs_key *key = sctx->cmp_key;
fs/btrfs/send.c:	sctx->cur_ino = key->objectid;
fs/btrfs/send.c:	sctx->cur_inode_new_gen = 0;
fs/btrfs/send.c:	sctx->cur_inode_last_extent = (u64)-1;
fs/btrfs/send.c:	sctx->send_progress = sctx->cur_ino;
fs/btrfs/send.c:		left_ii = btrfs_item_ptr(sctx->left_path->nodes[0],
fs/btrfs/send.c:				sctx->left_path->slots[0],
fs/btrfs/send.c:		left_gen = btrfs_inode_generation(sctx->left_path->nodes[0],
fs/btrfs/send.c:		right_ii = btrfs_item_ptr(sctx->right_path->nodes[0],
fs/btrfs/send.c:				sctx->right_path->slots[0],
fs/btrfs/send.c:		right_gen = btrfs_inode_generation(sctx->right_path->nodes[0],
fs/btrfs/send.c:		right_ii = btrfs_item_ptr(sctx->right_path->nodes[0],
fs/btrfs/send.c:				sctx->right_path->slots[0],
fs/btrfs/send.c:		right_gen = btrfs_inode_generation(sctx->right_path->nodes[0],
fs/btrfs/send.c:		    sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
fs/btrfs/send.c:			sctx->cur_inode_new_gen = 1;
fs/btrfs/send.c:		sctx->cur_inode_gen = left_gen;
fs/btrfs/send.c:		sctx->cur_inode_new = 1;
fs/btrfs/send.c:		sctx->cur_inode_deleted = 0;
fs/btrfs/send.c:		sctx->cur_inode_size = btrfs_inode_size(
fs/btrfs/send.c:				sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:		sctx->cur_inode_mode = btrfs_inode_mode(
fs/btrfs/send.c:				sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:		sctx->cur_inode_rdev = btrfs_inode_rdev(
fs/btrfs/send.c:				sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:		if (sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID)
fs/btrfs/send.c:		sctx->cur_inode_gen = right_gen;
fs/btrfs/send.c:		sctx->cur_inode_new = 0;
fs/btrfs/send.c:		sctx->cur_inode_deleted = 1;
fs/btrfs/send.c:		sctx->cur_inode_size = btrfs_inode_size(
fs/btrfs/send.c:				sctx->right_path->nodes[0], right_ii);
fs/btrfs/send.c:		sctx->cur_inode_mode = btrfs_inode_mode(
fs/btrfs/send.c:				sctx->right_path->nodes[0], right_ii);
fs/btrfs/send.c:		if (sctx->cur_inode_new_gen) {
fs/btrfs/send.c:			sctx->cur_inode_gen = right_gen;
fs/btrfs/send.c:			sctx->cur_inode_new = 0;
fs/btrfs/send.c:			sctx->cur_inode_deleted = 1;
fs/btrfs/send.c:			sctx->cur_inode_size = btrfs_inode_size(
fs/btrfs/send.c:					sctx->right_path->nodes[0], right_ii);
fs/btrfs/send.c:			sctx->cur_inode_mode = btrfs_inode_mode(
fs/btrfs/send.c:					sctx->right_path->nodes[0], right_ii);
fs/btrfs/send.c:			sctx->cur_inode_gen = left_gen;
fs/btrfs/send.c:			sctx->cur_inode_new = 1;
fs/btrfs/send.c:			sctx->cur_inode_deleted = 0;
fs/btrfs/send.c:			sctx->cur_inode_size = btrfs_inode_size(
fs/btrfs/send.c:					sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:			sctx->cur_inode_mode = btrfs_inode_mode(
fs/btrfs/send.c:					sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:			sctx->cur_inode_rdev = btrfs_inode_rdev(
fs/btrfs/send.c:					sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:			sctx->send_progress = sctx->cur_ino + 1;
fs/btrfs/send.c:			sctx->cur_inode_gen = left_gen;
fs/btrfs/send.c:			sctx->cur_inode_new = 0;
fs/btrfs/send.c:			sctx->cur_inode_new_gen = 0;
fs/btrfs/send.c:			sctx->cur_inode_deleted = 0;
fs/btrfs/send.c:			sctx->cur_inode_size = btrfs_inode_size(
fs/btrfs/send.c:					sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:			sctx->cur_inode_mode = btrfs_inode_mode(
fs/btrfs/send.c:					sctx->left_path->nodes[0], left_ii);
fs/btrfs/send.c:	if (sctx->cur_ino != sctx->cmp_key->objectid) {
fs/btrfs/send.c:	if (!sctx->cur_inode_new_gen &&
fs/btrfs/send.c:	    sctx->cur_ino != BTRFS_FIRST_FREE_OBJECTID) {
fs/btrfs/send.c:	if (sctx->cur_ino != sctx->cmp_key->objectid) {
fs/btrfs/send.c:	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
fs/btrfs/send.c:	if (sctx->cur_ino != sctx->cmp_key->objectid) {
fs/btrfs/send.c:			leaf_l = sctx->left_path->nodes[0];
fs/btrfs/send.c:			leaf_r = sctx->right_path->nodes[0];
fs/btrfs/send.c:					      sctx->left_path->slots[0],
fs/btrfs/send.c:					      sctx->right_path->slots[0],
fs/btrfs/send.c:	if (!sctx->cur_inode_new_gen && !sctx->cur_inode_deleted) {
fs/btrfs/send.c:			ret = process_extent(sctx, sctx->left_path,
fs/btrfs/send.c:					sctx->cmp_key);
fs/btrfs/send.c:	ret = get_inode_info(sctx->send_root, dir, NULL, &new_gen, NULL, NULL,
fs/btrfs/send.c:	ret = get_inode_info(sctx->parent_root, dir, NULL, &orig_gen, NULL,
fs/btrfs/send.c:	sctx->left_path = left_path;
fs/btrfs/send.c:	sctx->right_path = right_path;
fs/btrfs/send.c:	sctx->cmp_key = key;
fs/btrfs/send.c:	struct btrfs_root *send_root = sctx->send_root;
fs/btrfs/send.c:	if (!(sctx->flags & BTRFS_SEND_FLAG_OMIT_STREAM_HEADER)) {
fs/btrfs/send.c:	if (sctx->parent_root) {
fs/btrfs/send.c:		ret = btrfs_compare_trees(sctx->send_root, sctx->parent_root,
fs/btrfs/send.c:	if (sctx->parent_root &&
fs/btrfs/send.c:	    sctx->parent_root->node != sctx->parent_root->commit_root)
fs/btrfs/send.c:	for (i = 0; i < sctx->clone_roots_cnt; i++)
fs/btrfs/send.c:		if (sctx->clone_roots[i].root->node !=
fs/btrfs/send.c:		    sctx->clone_roots[i].root->commit_root)
fs/btrfs/send.c:		return btrfs_end_transaction(trans, sctx->send_root);
fs/btrfs/send.c:		trans = btrfs_join_transaction(sctx->send_root);
fs/btrfs/send.c:	return btrfs_commit_transaction(trans, sctx->send_root);
fs/btrfs/send.c:	INIT_LIST_HEAD(&sctx->new_refs);
fs/btrfs/send.c:	INIT_LIST_HEAD(&sctx->deleted_refs);
fs/btrfs/send.c:	INIT_RADIX_TREE(&sctx->name_cache, GFP_KERNEL);
fs/btrfs/send.c:	INIT_LIST_HEAD(&sctx->name_cache_list);
fs/btrfs/send.c:	sctx->flags = arg->flags;
fs/btrfs/send.c:	sctx->send_filp = fget(arg->send_fd);
fs/btrfs/send.c:	if (!sctx->send_filp) {
fs/btrfs/send.c:	sctx->send_root = send_root;
fs/btrfs/send.c:	if (btrfs_root_dead(sctx->send_root)) {
fs/btrfs/send.c:	sctx->clone_roots_cnt = arg->clone_sources_count;
fs/btrfs/send.c:	sctx->send_max_size = BTRFS_SEND_BUF_SIZE;
fs/btrfs/send.c:	sctx->send_buf = kmalloc(sctx->send_max_size, GFP_KERNEL | __GFP_NOWARN);
fs/btrfs/send.c:	if (!sctx->send_buf) {
fs/btrfs/send.c:		sctx->send_buf = vmalloc(sctx->send_max_size);
fs/btrfs/send.c:		if (!sctx->send_buf) {
fs/btrfs/send.c:	sctx->read_buf = kmalloc(BTRFS_SEND_READ_SIZE, GFP_KERNEL | __GFP_NOWARN);
fs/btrfs/send.c:	if (!sctx->read_buf) {
fs/btrfs/send.c:		sctx->read_buf = vmalloc(BTRFS_SEND_READ_SIZE);
fs/btrfs/send.c:		if (!sctx->read_buf) {
fs/btrfs/send.c:	sctx->pending_dir_moves = RB_ROOT;
fs/btrfs/send.c:	sctx->waiting_dir_moves = RB_ROOT;
fs/btrfs/send.c:	sctx->orphan_dirs = RB_ROOT;
fs/btrfs/send.c:	sctx->clone_roots = kzalloc(alloc_size, GFP_KERNEL | __GFP_NOWARN);
fs/btrfs/send.c:	if (!sctx->clone_roots) {
fs/btrfs/send.c:		sctx->clone_roots = vzalloc(alloc_size);
fs/btrfs/send.c:		if (!sctx->clone_roots) {
fs/btrfs/send.c:			sctx->clone_roots[i].root = clone_root;
fs/btrfs/send.c:		sctx->parent_root = btrfs_read_fs_root_no_name(fs_info, &key);
fs/btrfs/send.c:		if (IS_ERR(sctx->parent_root)) {
fs/btrfs/send.c:			ret = PTR_ERR(sctx->parent_root);
fs/btrfs/send.c:		spin_lock(&sctx->parent_root->root_item_lock);
fs/btrfs/send.c:		sctx->parent_root->send_in_progress++;
fs/btrfs/send.c:		if (!btrfs_root_readonly(sctx->parent_root) ||
fs/btrfs/send.c:				btrfs_root_dead(sctx->parent_root)) {
fs/btrfs/send.c:			spin_unlock(&sctx->parent_root->root_item_lock);
fs/btrfs/send.c:		spin_unlock(&sctx->parent_root->root_item_lock);
fs/btrfs/send.c:	sctx->clone_roots[sctx->clone_roots_cnt++].root = sctx->send_root;
fs/btrfs/send.c:	sort(sctx->clone_roots, sctx->clone_roots_cnt,
fs/btrfs/send.c:			sizeof(*sctx->clone_roots), __clone_root_cmp_sort,
fs/btrfs/send.c:	if (!(sctx->flags & BTRFS_SEND_FLAG_OMIT_END_CMD)) {
fs/btrfs/send.c:	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->pending_dir_moves));
fs/btrfs/send.c:	while (sctx && !RB_EMPTY_ROOT(&sctx->pending_dir_moves)) {
fs/btrfs/send.c:		n = rb_first(&sctx->pending_dir_moves);
fs/btrfs/send.c:	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->waiting_dir_moves));
fs/btrfs/send.c:	while (sctx && !RB_EMPTY_ROOT(&sctx->waiting_dir_moves)) {
fs/btrfs/send.c:		n = rb_first(&sctx->waiting_dir_moves);
fs/btrfs/send.c:		rb_erase(&dm->node, &sctx->waiting_dir_moves);
fs/btrfs/send.c:	WARN_ON(sctx && !ret && !RB_EMPTY_ROOT(&sctx->orphan_dirs));
fs/btrfs/send.c:	while (sctx && !RB_EMPTY_ROOT(&sctx->orphan_dirs)) {
fs/btrfs/send.c:		n = rb_first(&sctx->orphan_dirs);
fs/btrfs/send.c:		for (i = 0; i < sctx->clone_roots_cnt; i++)
fs/btrfs/send.c:					sctx->clone_roots[i].root);
fs/btrfs/send.c:					sctx->clone_roots[i].root);
fs/btrfs/send.c:	if (sctx && !IS_ERR_OR_NULL(sctx->parent_root))
fs/btrfs/send.c:		btrfs_root_dec_send_in_progress(sctx->parent_root);
fs/btrfs/send.c:		if (sctx->send_filp)
fs/btrfs/send.c:			fput(sctx->send_filp);
fs/btrfs/send.c:		kvfree(sctx->clone_roots);
fs/btrfs/send.c:		kvfree(sctx->send_buf);
fs/btrfs/send.c:		kvfree(sctx->read_buf);
fs/btrfs/inode.c:	int is_curr = 0;	/* ctx->pos points to the current index? */
fs/btrfs/inode.c:	key.offset = ctx->pos;
fs/btrfs/inode.c:		if (found_key.offset < ctx->pos)
fs/btrfs/inode.c:		ctx->pos = found_key.offset;
fs/btrfs/inode.c:			ctx->pos++;
fs/btrfs/inode.c:	 * If we haven't emitted any dir entry, we must not touch ctx->pos as
fs/btrfs/inode.c:	if (ctx->pos > 2 && !emitted)
fs/btrfs/inode.c:	ctx->pos++;
fs/btrfs/inode.c:		if (ctx->pos >= INT_MAX)
fs/btrfs/inode.c:			ctx->pos = LLONG_MAX;
fs/btrfs/inode.c:			ctx->pos = INT_MAX;
fs/btrfs/delayed-inode.c:		if (curr->key.offset < ctx->pos) {
fs/btrfs/delayed-inode.c:		ctx->pos = curr->key.offset;
fs/btrfs/tree-log.c:		list_add_tail(&ctx->list, &root->log_ctxs[index]);
fs/btrfs/tree-log.c:		ctx->log_transid = root->log_transid;
fs/btrfs/tree-log.c:	list_del_init(&ctx->list);
fs/btrfs/tree-log.c:		list_del_init(&ctx->list);
fs/btrfs/tree-log.c:		ctx->log_ret = error;
fs/btrfs/tree-log.c:	log_transid = ctx->log_transid;
fs/btrfs/tree-log.c:		return ctx->log_ret;
fs/btrfs/tree-log.c:		return ctx->log_ret;
fs/btrfs/tree-log.c:				ctx->log_new_dentries = true;
fs/btrfs/tree-log.c:		ctx->io_err = -EIO;
fs/btrfs/tree-log.c:		ctx->io_err = ret;
fs/btrfs/tree-log.c:				   other_ino != btrfs_ino(ctx->inode)) {
fs/btrfs/tree-log.c:			ctx->log_new_dentries = false;
fs/btrfs/tree-log.c:			if (ctx->log_new_dentries) {
fs/btrfs/tree-log.c:				ctx->log_new_dentries = false;
fs/btrfs/tree-log.c:			if (!ret && ctx && ctx->log_new_dentries)
fs/btrfs/tree-log.c:	if (S_ISDIR(inode->i_mode) && ctx && ctx->log_new_dentries)
fs/jffs2/dir.c:		if (curofs < ctx->pos) {
fs/jffs2/dir.c:				  fd->name, fd->ino, fd->type, curofs, (unsigned long)ctx->pos);
fs/jffs2/dir.c:			ctx->pos++;
fs/jffs2/dir.c:			  (unsigned long)ctx->pos, fd->name, fd->ino, fd->type);
fs/jffs2/dir.c:		ctx->pos++;
fs/efs/dir.c:	block = ctx->pos >> EFS_DIRBSIZE_BITS;
fs/efs/dir.c:	slot  = ctx->pos & 0xff;
fs/efs/dir.c:			ctx->pos = (block << EFS_DIRBSIZE_BITS) | slot;
fs/efs/dir.c:	ctx->pos = (block << EFS_DIRBSIZE_BITS) | slot;
fs/minix/dir.c:	unsigned long pos = ctx->pos;
fs/minix/dir.c:	ctx->pos = pos = ALIGN(pos, chunk_size);
fs/minix/dir.c:			ctx->pos += chunk_size;
fs/bfs/dir.c:	if (ctx->pos & (BFS_DIRENT_SIZE - 1)) {
fs/bfs/dir.c:					(unsigned long)ctx->pos,
fs/bfs/dir.c:	while (ctx->pos < dir->i_size) {
fs/bfs/dir.c:		offset = ctx->pos & (BFS_BSIZE - 1);
fs/bfs/dir.c:		block = BFS_I(dir)->i_sblock + (ctx->pos >> BFS_BSIZE_BITS);
fs/bfs/dir.c:			ctx->pos += BFS_BSIZE - offset;
fs/bfs/dir.c:			ctx->pos += BFS_DIRENT_SIZE;
fs/bfs/dir.c:		} while ((offset < BFS_BSIZE) && (ctx->pos < dir->i_size));
fs/crypto/keyinfo.c:			ctx->master_key_descriptor);
fs/crypto/keyinfo.c:	res = derive_key_aes(ctx->nonce, master_key->raw, raw_key);
fs/crypto/crypto.c:	if (ctx->flags & FS_WRITE_PATH_FL && ctx->w.bounce_page) {
fs/crypto/crypto.c:		mempool_free(ctx->w.bounce_page, fscrypt_bounce_page_pool);
fs/crypto/crypto.c:		ctx->w.bounce_page = NULL;
fs/crypto/crypto.c:	ctx->w.control_page = NULL;
fs/crypto/crypto.c:	if (ctx->flags & FS_CTX_REQUIRES_FREE_ENCRYPT_FL) {
fs/crypto/crypto.c:		list_add(&ctx->free_list, &fscrypt_free_ctxs);
fs/crypto/crypto.c:		list_del(&ctx->free_list);
fs/crypto/crypto.c:		ctx->flags |= FS_CTX_REQUIRES_FREE_ENCRYPT_FL;
fs/crypto/crypto.c:		ctx->flags &= ~FS_CTX_REQUIRES_FREE_ENCRYPT_FL;
fs/crypto/crypto.c:	ctx->flags &= ~FS_WRITE_PATH_FL;
fs/crypto/crypto.c:	ctx->w.bounce_page = mempool_alloc(fscrypt_bounce_page_pool, gfp_flags);
fs/crypto/crypto.c:	if (ctx->w.bounce_page == NULL)
fs/crypto/crypto.c:	ctx->flags |= FS_WRITE_PATH_FL;
fs/crypto/crypto.c:	return ctx->w.bounce_page;
fs/crypto/crypto.c:	ctx->w.control_page = plaintext_page;
fs/crypto/crypto.c:	struct bio *bio = ctx->r.bio;
fs/crypto/crypto.c:	INIT_WORK(&ctx->r.work, completion_pages);
fs/crypto/crypto.c:	ctx->r.bio = bio;
fs/crypto/crypto.c:	queue_work(fscrypt_read_workqueue, &ctx->r.work);
fs/crypto/crypto.c:	*page = ctx->w.control_page;
fs/crypto/crypto.c:		list_add(&ctx->free_list, &fscrypt_free_ctxs);
fs/exfat/exfat_super.c:	cpos = ctx->pos;
fs/exfat/exfat_super.c:			ctx->pos++;
fs/exfat/exfat_super.c:	ctx->pos = cpos;
fs/exfat/exfat_super.c:	ctx->pos = cpos;
fs/reiserfs/dir.c:	make_cpu_key(&pos_key, inode, ctx->pos ?: DOT_OFFSET, TYPE_DIRENTRY, 3);
fs/reiserfs/dir.c:				ctx->pos = deh_offset(deh);
fs/reiserfs/dir.c:	ctx->pos = next_pos;
fs/adfs/dir.c:	if (ctx->pos >> 32)
fs/adfs/dir.c:	if (ctx->pos == 0) {
fs/adfs/dir.c:		ctx->pos = 1;
fs/adfs/dir.c:	if (ctx->pos == 1) {
fs/adfs/dir.c:		ctx->pos = 2;
fs/adfs/dir.c:	ret = ops->setpos(&dir, ctx->pos - 2);
fs/adfs/dir.c:		ctx->pos++;
fs/nfs/pnfs.c:		state = ctx->state;
fs/nfs/pnfs.c:	lo->plh_lc_cred = get_rpccred(ctx->cred);
fs/nfs/pnfs.c:	struct nfs4_threshold *t = ctx->mdsthreshold;
fs/nfs/pnfs.c:	if (!nfs4_valid_open_stateid(ctx->state)) {
fs/nfs/pnfs.c:			seq = read_seqbegin(&ctx->state->seqlock);
fs/nfs/pnfs.c:			nfs4_stateid_copy(&stateid, &ctx->state->stateid);
fs/nfs/pnfs.c:		} while (read_seqretry(&ctx->state->seqlock, seq));
fs/nfs/nfs4proc.c:		if (ctx->state != state)
fs/nfs/nfs4proc.c:	opendata = nfs4_opendata_alloc(ctx->dentry, state->owner, 0, 0,
fs/nfs/nfs4proc.c:		d_drop(ctx->dentry);
fs/nfs/nfs4proc.c:	ctx->state = state;
fs/nfs/nfs4proc.c:			dput(ctx->dentry);
fs/nfs/nfs4proc.c:			ctx->dentry = dentry = alias;
fs/nfs/nfs4proc.c:	struct dentry *dentry = ctx->dentry;
fs/nfs/nfs4proc.c:	struct rpc_cred *cred = ctx->cred;
fs/nfs/nfs4proc.c:	struct nfs4_threshold **ctx_th = &ctx->mdsthreshold;
fs/nfs/nfs4proc.c:	fmode_t fmode = ctx->mode & (FMODE_READ|FMODE_WRITE|FMODE_EXEC);
fs/nfs/nfs4proc.c:	state = ctx->state;
fs/nfs/nfs4proc.c:		res = ctx->state;
fs/nfs/nfs4proc.c:	label = nfs4_label_init_security(dir, ctx->dentry, attr, &l);
fs/nfs/nfs4proc.c:	if (ctx->state == NULL)
fs/nfs/nfs4proc.c:		nfs4_close_sync(ctx->state, ctx->mode);
fs/nfs/nfs4proc.c:		nfs4_close_state(ctx->state, ctx->mode);
fs/nfs/nfs4proc.c:			cred = ctx->cred;
fs/nfs/nfs4proc.c:			state = ctx->state;
fs/nfs/nfs4proc.c:		lockowner = &l_ctx->lockowner;
fs/nfs/nfs4proc.c:	return nfs4_select_rw_stateid(ctx->state, fmode, lockowner, stateid, NULL);
fs/nfs/nfs4proc.c:		.rpc_cred = ctx->cred,
fs/nfs/nfs4proc.c:		renew_lease(NFS_SERVER(d_inode(data->ctx->dentry)),
fs/nfs/nfs4proc.c:	state = ctx->state;
fs/nfs/nfs4proc.c:					&lgp->args.ctx->state->stateid)) {
fs/nfs/nfs4proc.c:			exception->state = lgp->args.ctx->state;
fs/nfs/nfs4trace.h:			__string(name, ctx->dentry->d_name.name)
fs/nfs/nfs4trace.h:			const struct nfs4_state *state = ctx->state;
fs/nfs/nfs4trace.h:			__entry->fmode = (__force unsigned int)ctx->mode;
fs/nfs/nfs4trace.h:			__entry->dev = ctx->dentry->d_sb->s_dev;
fs/nfs/nfs4trace.h:			__entry->dir = NFS_FILEID(d_inode(ctx->dentry->d_parent));
fs/nfs/nfs4trace.h:			__assign_str(name, ctx->dentry->d_name.name);
fs/nfs/nfs4trace.h:			const struct inode *inode = d_inode(ctx->dentry);
fs/nfs/nfs4trace.h:			const struct nfs4_state *state = ctx->state;
fs/nfs/file.c: * disk, but it retrieves and clears ctx->error after synching, despite
fs/nfs/file.c:	do_resend = test_and_clear_bit(NFS_CONTEXT_RESEND_WRITES, &ctx->flags);
fs/nfs/file.c:	have_error = test_and_clear_bit(NFS_CONTEXT_ERROR_WRITE, &ctx->flags);
fs/nfs/file.c:	have_error |= test_bit(NFS_CONTEXT_ERROR_WRITE, &ctx->flags);
fs/nfs/file.c:		ret = xchg(&ctx->error, 0);
fs/nfs/file.c:	do_resend |= test_bit(NFS_CONTEXT_RESEND_WRITES, &ctx->flags);
fs/nfs/file.c:	if (test_bit(NFS_CONTEXT_ERROR_WRITE, &ctx->flags) ||
fs/nfs/dir.c:		ctx->duped = 0;
fs/nfs/dir.c:		ctx->attr_gencount = nfsi->attr_gencount;
fs/nfs/dir.c:		ctx->dir_cookie = 0;
fs/nfs/dir.c:		ctx->dup_cookie = 0;
fs/nfs/dir.c:		ctx->cred = get_rpccred(cred);
fs/nfs/dir.c:		list_add(&ctx->list, &nfsi->open_files);
fs/nfs/dir.c:	list_del(&ctx->list);
fs/nfs/dir.c:	put_rpccred(ctx->cred);
fs/nfs/dir.c:	loff_t diff = desc->ctx->pos - desc->current_index;
fs/nfs/dir.c:			if (ctx->attr_gencount != nfsi->attr_gencount ||
fs/nfs/dir.c:				ctx->duped = 0;
fs/nfs/dir.c:				ctx->attr_gencount = nfsi->attr_gencount;
fs/nfs/dir.c:			} else if (new_pos < desc->ctx->pos) {
fs/nfs/dir.c:				if (ctx->duped > 0
fs/nfs/dir.c:				    && ctx->dup_cookie == *desc->dir_cookie) {
fs/nfs/dir.c:				ctx->dup_cookie = *desc->dir_cookie;
fs/nfs/dir.c:				ctx->duped = -1;
fs/nfs/dir.c:			desc->ctx->pos = new_pos;
fs/nfs/dir.c:	struct rpc_cred	*cred = ctx->cred;
fs/nfs/dir.c:	if (ctx->pos == 0)
fs/nfs/dir.c:		desc->ctx->pos++;
fs/nfs/dir.c:		if (ctx->duped != 0)
fs/nfs/dir.c:			ctx->duped = 1;
fs/nfs/dir.c:	ctx->duped = 0;
fs/nfs/dir.c:			file, (long long)ctx->pos);
fs/nfs/dir.c:	 * ctx->pos points to the dirent entry number.
fs/nfs/dir.c:	desc->dir_cookie = &dir_ctx->dir_cookie;
fs/nfs/dir.c:	if (ctx->pos == 0 || nfs_attribute_cache_expired(inode))
fs/nfs/dir.c:		dir_ctx->dir_cookie = 0;
fs/nfs/dir.c:		dir_ctx->duped = 0;
fs/nfs/dir.c:	err = nfs_finish_open(ctx, ctx->dentry, file, open_flags, opened);
fs/nfs/nfs4state.c:		state = ctx->state;
fs/nfs/nfs4state.c:		if (ctx->state != state)
fs/nfs/nfs4state.c:		set_bit(NFS_CONTEXT_BAD, &ctx->flags);
fs/nfs/nfs4state.c:	list = &flctx->flc_posix;
fs/nfs/nfs4state.c:	spin_lock(&flctx->flc_lock);
fs/nfs/nfs4state.c:		spin_unlock(&flctx->flc_lock);
fs/nfs/nfs4state.c:		spin_lock(&flctx->flc_lock);
fs/nfs/nfs4state.c:	if (list == &flctx->flc_posix) {
fs/nfs/nfs4state.c:		list = &flctx->flc_flock;
fs/nfs/nfs4state.c:	spin_unlock(&flctx->flc_lock);
fs/nfs/write.c:	ctx->error = error;
fs/nfs/write.c:	set_bit(NFS_CONTEXT_ERROR_WRITE, &ctx->flags);
fs/nfs/write.c:		    !(list_empty_careful(&flctx->flc_posix) &&
fs/nfs/write.c:		      list_empty_careful(&flctx->flc_flock))) {
fs/nfs/write.c:			do_flush |= l_ctx->lockowner.l_owner != current->files
fs/nfs/write.c:				|| l_ctx->lockowner.l_pid != current->tgid;
fs/nfs/write.c:	return rpcauth_key_timeout_notify(auth, ctx->cred);
fs/nfs/write.c:	return rpcauth_cred_key_to_expire(auth, ctx->cred);
fs/nfs/write.c:	if (!flctx || (list_empty_careful(&flctx->flc_flock) &&
fs/nfs/write.c:		       list_empty_careful(&flctx->flc_posix)))
fs/nfs/write.c:	spin_lock(&flctx->flc_lock);
fs/nfs/write.c:	if (!list_empty(&flctx->flc_posix)) {
fs/nfs/write.c:		fl = list_first_entry(&flctx->flc_posix, struct file_lock,
fs/nfs/write.c:	} else if (!list_empty(&flctx->flc_flock)) {
fs/nfs/write.c:		fl = list_first_entry(&flctx->flc_flock, struct file_lock,
fs/nfs/write.c:	spin_unlock(&flctx->flc_lock);
fs/nfs/nfstrace.h:			__string(name, ctx->dentry->d_name.name)
fs/nfs/nfstrace.h:			__entry->fmode = (__force unsigned int)ctx->mode;
fs/nfs/nfstrace.h:			__assign_str(name, ctx->dentry->d_name.name);
fs/nfs/nfstrace.h:			__string(name, ctx->dentry->d_name.name)
fs/nfs/nfstrace.h:			__entry->fmode = (__force unsigned int)ctx->mode;
fs/nfs/nfstrace.h:			__assign_str(name, ctx->dentry->d_name.name);
fs/nfs/delegation.c:	list = &flctx->flc_posix;
fs/nfs/delegation.c:	spin_lock(&flctx->flc_lock);
fs/nfs/delegation.c:		spin_unlock(&flctx->flc_lock);
fs/nfs/delegation.c:		spin_lock(&flctx->flc_lock);
fs/nfs/delegation.c:	if (list == &flctx->flc_posix) {
fs/nfs/delegation.c:		list = &flctx->flc_flock;
fs/nfs/delegation.c:	spin_unlock(&flctx->flc_lock);
fs/nfs/delegation.c:		state = ctx->state;
fs/nfs/pagelist.c:	return wait_on_atomic_t(&l_ctx->io_count, nfs_wait_atomic_killable,
fs/nfs/pagelist.c:	if (test_bit(NFS_CONTEXT_BAD, &ctx->flags))
fs/nfs/pagelist.c:	atomic_inc(&l_ctx->io_count);
fs/nfs/pagelist.c:		if (atomic_dec_and_test(&l_ctx->io_count))
fs/nfs/pagelist.c:			wake_up_atomic_t(&l_ctx->io_count);
fs/nfs/pagelist.c:		    !(list_empty_careful(&flctx->flc_posix) &&
fs/nfs/pagelist.c:		      list_empty_careful(&flctx->flc_flock)) &&
fs/nfs/inode.c:	atomic_set(&l_ctx->count, 1);
fs/nfs/inode.c:	l_ctx->lockowner.l_owner = current->files;
fs/nfs/inode.c:	l_ctx->lockowner.l_pid = current->tgid;
fs/nfs/inode.c:	INIT_LIST_HEAD(&l_ctx->list);
fs/nfs/inode.c:	atomic_set(&l_ctx->io_count, 0);
fs/nfs/inode.c:	struct nfs_lock_context *head = &ctx->lock_context;
fs/nfs/inode.c:	struct inode *inode = d_inode(ctx->dentry);
fs/nfs/inode.c:			list_add_tail(&new->list, &ctx->lock_context.list);
fs/nfs/inode.c:	struct nfs_open_context *ctx = l_ctx->open_context;
fs/nfs/inode.c:	struct inode *inode = d_inode(ctx->dentry);
fs/nfs/inode.c:	if (!atomic_dec_and_lock(&l_ctx->count, &inode->i_lock))
fs/nfs/inode.c:	list_del(&l_ctx->list);
fs/nfs/inode.c:	if (!(ctx->mode & FMODE_WRITE))
fs/nfs/inode.c:	inode = d_inode(ctx->dentry);
fs/nfs/inode.c:	ctx->dentry = dget(dentry);
fs/nfs/inode.c:	ctx->cred = cred;
fs/nfs/inode.c:	ctx->state = NULL;
fs/nfs/inode.c:	ctx->mode = f_mode;
fs/nfs/inode.c:	ctx->flags = 0;
fs/nfs/inode.c:	ctx->error = 0;
fs/nfs/inode.c:	nfs_init_lock_context(&ctx->lock_context);
fs/nfs/inode.c:	ctx->lock_context.open_context = ctx;
fs/nfs/inode.c:	INIT_LIST_HEAD(&ctx->list);
fs/nfs/inode.c:	ctx->mdsthreshold = NULL;
fs/nfs/inode.c:		atomic_inc(&ctx->lock_context.count);
fs/nfs/inode.c:	struct inode *inode = d_inode(ctx->dentry);
fs/nfs/inode.c:	struct super_block *sb = ctx->dentry->d_sb;
fs/nfs/inode.c:	if (!list_empty(&ctx->list)) {
fs/nfs/inode.c:		if (!atomic_dec_and_lock(&ctx->lock_context.count, &inode->i_lock))
fs/nfs/inode.c:		list_del(&ctx->list);
fs/nfs/inode.c:	} else if (!atomic_dec_and_test(&ctx->lock_context.count))
fs/nfs/inode.c:	if (ctx->cred != NULL)
fs/nfs/inode.c:		put_rpccred(ctx->cred);
fs/nfs/inode.c:	dput(ctx->dentry);
fs/nfs/inode.c:	kfree(ctx->mdsthreshold);
fs/nfs/inode.c:	struct inode *inode = d_inode(ctx->dentry);
fs/nfs/inode.c:	if (ctx->mode & FMODE_WRITE)
fs/nfs/inode.c:		list_add(&ctx->list, &nfsi->open_files);
fs/nfs/inode.c:		list_add_tail(&ctx->list, &nfsi->open_files);
fs/nfs/inode.c:	if (list_empty(&ctx->list))
fs/nfs/inode.c:		struct inode *inode = d_inode(ctx->dentry);
fs/nfs/inode.c:		if (ctx->error < 0)
fs/nfs/inode.c:		list_move_tail(&ctx->list, &NFS_I(inode)->open_files);
fs/cifs/asn1.c:	ctx->begin = buf;
fs/cifs/asn1.c:	ctx->end = buf + len;
fs/cifs/asn1.c:	ctx->pointer = buf;
fs/cifs/asn1.c:	ctx->error = ASN1_ERR_NOERROR;
fs/cifs/asn1.c:	if (ctx->pointer >= ctx->end) {
fs/cifs/asn1.c:		ctx->error = ASN1_ERR_DEC_EMPTY;
fs/cifs/asn1.c:	*ch = *(ctx->pointer)++;
fs/cifs/asn1.c:	if (ctx->pointer >= ctx->end) {
fs/cifs/asn1.c:		ctx->error = ASN1_ERR_DEC_EMPTY;
fs/cifs/asn1.c:	ch = *(ctx->pointer)++; /* ch has 0xa, ptr points to length octet */
fs/cifs/asn1.c:		*val = *(++(ctx->pointer)); /* value has enum value */
fs/cifs/asn1.c:	ctx->pointer++;
fs/cifs/asn1.c:	if (*len > ctx->end - ctx->pointer)
fs/cifs/asn1.c:		*eoc = ctx->pointer + len;
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_EOC_MISMATCH;
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_EOC_MISMATCH;
fs/cifs/asn1.c:		if (ctx->pointer != eoc) {
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_LENGTH_MISMATCH;
fs/cifs/asn1.c:	ctx->pointer = eoc;
fs/cifs/asn1.c:	while (ctx->pointer < eoc) {
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
fs/cifs/asn1.c:	while (ctx->pointer < eoc) {
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
fs/cifs/asn1.c:	while (ctx->pointer < eoc) {
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
fs/cifs/asn1.c:	*octets = kmalloc(eoc - ctx->pointer, GFP_ATOMIC);
fs/cifs/asn1.c:	while (ctx->pointer < eoc) {
fs/cifs/asn1.c:	size = eoc - ctx->pointer + 1;
fs/cifs/asn1.c:	while (ctx->pointer < eoc) {
fs/cifs/asn1.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
fs/cifs/file.c:	spin_lock(&flctx->flc_lock);
fs/cifs/file.c:	list_for_each(el, &flctx->flc_posix) {
fs/cifs/file.c:	spin_unlock(&flctx->flc_lock);
fs/cifs/file.c:	spin_lock(&flctx->flc_lock);
fs/cifs/file.c:	list_for_each_entry(flock, &flctx->flc_posix, fl_list) {
fs/cifs/file.c:	spin_unlock(&flctx->flc_lock);
fs/cifs/readdir.c:	rc = find_cifs_entry(xid, tcon, ctx->pos, file, &current_entry,
fs/cifs/readdir.c:		cifs_dbg(FYI, "entry %lld found\n", ctx->pos);
fs/cifs/readdir.c:		ctx->pos++;
fs/cifs/readdir.c:		if (ctx->pos ==
fs/cifs/readdir.c:				 ctx->pos, tmp_buf);
fs/orangefs/dir.c:		     "%s: ctx->pos:%lld, ptoken = %llu\n",
fs/orangefs/dir.c:		     lld(ctx->pos),
fs/orangefs/dir.c:	pos = (__u64) ctx->pos;
fs/orangefs/dir.c:	 * we stored ORANGEFS_ITERATE_NEXT in ctx->pos last time around
fs/orangefs/dir.c:	if (ctx->pos == ORANGEFS_ITERATE_NEXT)
fs/orangefs/dir.c:		ctx->pos = 0;
fs/orangefs/dir.c:	for (i = ctx->pos;
fs/orangefs/dir.c:			     ", ctx->pos %ld\n",
fs/orangefs/dir.c:			     (unsigned long)ctx->pos);
fs/orangefs/dir.c:		ctx->pos++;
fs/orangefs/dir.c:			      "%s: ctx->pos:%lld\n",
fs/orangefs/dir.c:			      lld(ctx->pos));
fs/orangefs/dir.c:		ctx->pos = ORANGEFS_ITERATE_NEXT;
fs/orangefs/dir.c:		"End of dir detected; setting ctx->pos to ORANGEFS_READDIR_END.\n");
fs/orangefs/dir.c:		ctx->pos = ORANGEFS_READDIR_END;
fs/iomap.c:	ret = iomap_to_fiemap(ctx->fi, &ctx->prev, 0);
fs/iomap.c:	ctx->prev = *iomap;
fs/fuse/dir.c:	if (ctx->pos == 0)
fs/fuse/dir.c:		ctx->pos = dirent->off;
fs/fuse/dir.c:				ctx->pos = dirent->off;
fs/fuse/dir.c:		fuse_read_fill(req, file, ctx->pos, PAGE_SIZE,
fs/fuse/dir.c:		fuse_read_fill(req, file, ctx->pos, PAGE_SIZE,
fs/ncpfs/dir.c:	ncp_dbg(2, "reading %pD2, pos=%d\n", file, (int)ctx->pos);
fs/ncpfs/dir.c:	if (ctx->pos == 2) {
fs/ncpfs/dir.c:	if (ctx->pos > ctl.head.end)
fs/ncpfs/dir.c:	ctl.fpos = ctx->pos + (NCP_DIRCACHE_START - 2);
fs/ncpfs/dir.c:			ctx->pos += 1;
fs/ncpfs/dir.c:			if (ctx->pos > ctl.head.end)
fs/ncpfs/dir.c:	if (!ctl.filled && (ctl.fpos == ctx->pos)) {
fs/ncpfs/dir.c:			ctx->pos += 1;
fs/ncpfs/dir.c:	ncp_dbg(1, "pos=%ld\n", (unsigned long)ctx->pos);
fs/ncpfs/dir.c:	ncp_dbg(1, "%pD2, fpos=%ld\n", file, (unsigned long)ctx->pos);
fs/coda/dir.c:		ret = kernel_read(host_file, ctx->pos - 2, (char *)vdir,
fs/coda/dir.c:		ctx->pos += vdir->d_reclen;
fs/libfs.c:	if (ctx->pos == 2)
fs/libfs.c:		ctx->pos++;
include/media/v4l2-mem2mem.h: *		&v4l2_m2m_ctx->q_lock.
include/media/v4l2-mem2mem.h: *		using &v4l2_m2m_ctx->q_lock.
include/media/v4l2-mem2mem.h:	m2m_ctx->out_q_ctx.buffered = buffered;
include/media/v4l2-mem2mem.h:	m2m_ctx->cap_q_ctx.buffered = buffered;
include/media/v4l2-mem2mem.h:	return m2m_ctx->out_q_ctx.num_rdy;
include/media/v4l2-mem2mem.h:	return m2m_ctx->cap_q_ctx.num_rdy;
include/media/v4l2-mem2mem.h:	return v4l2_m2m_next_buf(&m2m_ctx->out_q_ctx);
include/media/v4l2-mem2mem.h:	return v4l2_m2m_next_buf(&m2m_ctx->cap_q_ctx);
include/media/v4l2-mem2mem.h:	return &m2m_ctx->out_q_ctx.q;
include/media/v4l2-mem2mem.h:	return &m2m_ctx->cap_q_ctx.q;
include/media/v4l2-mem2mem.h:	return v4l2_m2m_buf_remove(&m2m_ctx->out_q_ctx);
include/media/v4l2-mem2mem.h:	return v4l2_m2m_buf_remove(&m2m_ctx->cap_q_ctx);
include/linux/fs.h:	 * taken are done before checking i_flctx->flc_lease. Otherwise, we
include/linux/fs.h:	if (inode->i_flctx && !list_empty_careful(&inode->i_flctx->flc_lease))
include/linux/fs.h:	 * taken are done before checking i_flctx->flc_lease. Otherwise, we
include/linux/fs.h:	if (inode->i_flctx && !list_empty_careful(&inode->i_flctx->flc_lease))
include/linux/fs.h:	if (inode->i_flctx && !list_empty_careful(&inode->i_flctx->flc_lease))
include/linux/fs.h:	return ctx->actor(ctx, name, namelen, ctx->pos, ino, type) == 0;
include/linux/fs.h:	return ctx->actor(ctx, ".", 1, ctx->pos,
include/linux/fs.h:	return ctx->actor(ctx, "..", 2, ctx->pos,
include/linux/fs.h:	if (ctx->pos == 0) {
include/linux/fs.h:		ctx->pos = 1;
include/linux/fs.h:	if (ctx->pos == 1) {
include/linux/fs.h:		ctx->pos = 2;
include/linux/nfs_fs.h:			return ctx->cred;
include/linux/ww_mutex.h:	ctx->task = current;
include/linux/ww_mutex.h:	ctx->stamp = atomic_long_inc_return(&ww_class->stamp);
include/linux/ww_mutex.h:	ctx->acquired = 0;
include/linux/ww_mutex.h:	ctx->ww_class = ww_class;
include/linux/ww_mutex.h:	ctx->done_acquire = 0;
include/linux/ww_mutex.h:	ctx->contending_lock = NULL;
include/linux/ww_mutex.h:	lockdep_init_map(&ctx->dep_map, ww_class->acquire_name,
include/linux/ww_mutex.h:	mutex_acquire(&ctx->dep_map, 0, 0, _RET_IP_);
include/linux/ww_mutex.h:	ctx->deadlock_inject_interval = 1;
include/linux/ww_mutex.h:	ctx->deadlock_inject_countdown = ctx->stamp & 0xf;
include/linux/ww_mutex.h:	DEBUG_LOCKS_WARN_ON(ctx->done_acquire);
include/linux/ww_mutex.h:	ctx->done_acquire = 1;
include/linux/ww_mutex.h:	mutex_release(&ctx->dep_map, 0, _THIS_IP_);
include/linux/ww_mutex.h:	DEBUG_LOCKS_WARN_ON(ctx->acquired);
include/linux/ww_mutex.h:		ctx->done_acquire = 1;
include/linux/ww_mutex.h:		ctx->acquired = ~0U;
include/linux/ww_mutex.h:	DEBUG_LOCKS_WARN_ON(!ctx->contending_lock);
include/linux/ww_mutex.h:	DEBUG_LOCKS_WARN_ON(!ctx->contending_lock);
include/linux/perf_event.h:	 *   modifications require ctx->lock
include/linux/perf_event.h:	 * Locked for modification by both ctx->mutex and ctx->lock; holding
include/linux/perf_event.h:	 * ctx_time already accounts for ctx->timestamp. Therefore to
include/linux/perf_event.h:					   ctx ? lockdep_is_held(&ctx->lock)
include/linux/perf_event.h:	if (ctx->contexts < sysctl_perf_event_max_contexts_per_stack) {
include/linux/perf_event.h:		struct perf_callchain_entry *entry = ctx->entry;
include/linux/perf_event.h:		++ctx->contexts;
include/linux/perf_event.h:		ctx->contexts_maxed = true;
include/linux/perf_event.h:	if (ctx->nr < ctx->max_stack && !ctx->contexts_maxed) {
include/linux/perf_event.h:		struct perf_callchain_entry *entry = ctx->entry;
include/linux/perf_event.h:		++ctx->nr;
include/net/6lowpan.h:	return test_bit(LOWPAN_IPHC_CTX_FLAG_ACTIVE, &ctx->flags);
include/net/6lowpan.h:	return test_bit(LOWPAN_IPHC_CTX_FLAG_COMPRESSION, &ctx->flags);
include/crypto/sha512_base.h:	sctx->state[0] = SHA384_H0;
include/crypto/sha512_base.h:	sctx->state[1] = SHA384_H1;
include/crypto/sha512_base.h:	sctx->state[2] = SHA384_H2;
include/crypto/sha512_base.h:	sctx->state[3] = SHA384_H3;
include/crypto/sha512_base.h:	sctx->state[4] = SHA384_H4;
include/crypto/sha512_base.h:	sctx->state[5] = SHA384_H5;
include/crypto/sha512_base.h:	sctx->state[6] = SHA384_H6;
include/crypto/sha512_base.h:	sctx->state[7] = SHA384_H7;
include/crypto/sha512_base.h:	sctx->count[0] = sctx->count[1] = 0;
include/crypto/sha512_base.h:	sctx->state[0] = SHA512_H0;
include/crypto/sha512_base.h:	sctx->state[1] = SHA512_H1;
include/crypto/sha512_base.h:	sctx->state[2] = SHA512_H2;
include/crypto/sha512_base.h:	sctx->state[3] = SHA512_H3;
include/crypto/sha512_base.h:	sctx->state[4] = SHA512_H4;
include/crypto/sha512_base.h:	sctx->state[5] = SHA512_H5;
include/crypto/sha512_base.h:	sctx->state[6] = SHA512_H6;
include/crypto/sha512_base.h:	sctx->state[7] = SHA512_H7;
include/crypto/sha512_base.h:	sctx->count[0] = sctx->count[1] = 0;
include/crypto/sha512_base.h:	unsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;
include/crypto/sha512_base.h:	sctx->count[0] += len;
include/crypto/sha512_base.h:	if (sctx->count[0] < len)
include/crypto/sha512_base.h:		sctx->count[1]++;
include/crypto/sha512_base.h:			memcpy(sctx->buf + partial, data, p);
include/crypto/sha512_base.h:			block_fn(sctx, sctx->buf, 1);
include/crypto/sha512_base.h:		memcpy(sctx->buf + partial, data, len);
include/crypto/sha512_base.h:	__be64 *bits = (__be64 *)(sctx->buf + bit_offset);
include/crypto/sha512_base.h:	unsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;
include/crypto/sha512_base.h:	sctx->buf[partial++] = 0x80;
include/crypto/sha512_base.h:		memset(sctx->buf + partial, 0x0, SHA512_BLOCK_SIZE - partial);
include/crypto/sha512_base.h:		block_fn(sctx, sctx->buf, 1);
include/crypto/sha512_base.h:	memset(sctx->buf + partial, 0x0, bit_offset - partial);
include/crypto/sha512_base.h:	bits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);
include/crypto/sha512_base.h:	bits[1] = cpu_to_be64(sctx->count[0] << 3);
include/crypto/sha512_base.h:	block_fn(sctx, sctx->buf, 1);
include/crypto/sha512_base.h:		put_unaligned_be64(sctx->state[i], digest++);
include/crypto/sha256_base.h:	sctx->state[0] = SHA224_H0;
include/crypto/sha256_base.h:	sctx->state[1] = SHA224_H1;
include/crypto/sha256_base.h:	sctx->state[2] = SHA224_H2;
include/crypto/sha256_base.h:	sctx->state[3] = SHA224_H3;
include/crypto/sha256_base.h:	sctx->state[4] = SHA224_H4;
include/crypto/sha256_base.h:	sctx->state[5] = SHA224_H5;
include/crypto/sha256_base.h:	sctx->state[6] = SHA224_H6;
include/crypto/sha256_base.h:	sctx->state[7] = SHA224_H7;
include/crypto/sha256_base.h:	sctx->count = 0;
include/crypto/sha256_base.h:	sctx->state[0] = SHA256_H0;
include/crypto/sha256_base.h:	sctx->state[1] = SHA256_H1;
include/crypto/sha256_base.h:	sctx->state[2] = SHA256_H2;
include/crypto/sha256_base.h:	sctx->state[3] = SHA256_H3;
include/crypto/sha256_base.h:	sctx->state[4] = SHA256_H4;
include/crypto/sha256_base.h:	sctx->state[5] = SHA256_H5;
include/crypto/sha256_base.h:	sctx->state[6] = SHA256_H6;
include/crypto/sha256_base.h:	sctx->state[7] = SHA256_H7;
include/crypto/sha256_base.h:	sctx->count = 0;
include/crypto/sha256_base.h:	unsigned int partial = sctx->count % SHA256_BLOCK_SIZE;
include/crypto/sha256_base.h:	sctx->count += len;
include/crypto/sha256_base.h:			memcpy(sctx->buf + partial, data, p);
include/crypto/sha256_base.h:			block_fn(sctx, sctx->buf, 1);
include/crypto/sha256_base.h:		memcpy(sctx->buf + partial, data, len);
include/crypto/sha256_base.h:	__be64 *bits = (__be64 *)(sctx->buf + bit_offset);
include/crypto/sha256_base.h:	unsigned int partial = sctx->count % SHA256_BLOCK_SIZE;
include/crypto/sha256_base.h:	sctx->buf[partial++] = 0x80;
include/crypto/sha256_base.h:		memset(sctx->buf + partial, 0x0, SHA256_BLOCK_SIZE - partial);
include/crypto/sha256_base.h:		block_fn(sctx, sctx->buf, 1);
include/crypto/sha256_base.h:	memset(sctx->buf + partial, 0x0, bit_offset - partial);
include/crypto/sha256_base.h:	*bits = cpu_to_be64(sctx->count << 3);
include/crypto/sha256_base.h:	block_fn(sctx, sctx->buf, 1);
include/crypto/sha256_base.h:		put_unaligned_be32(sctx->state[i], digest++);
include/crypto/sha1_base.h:	sctx->state[0] = SHA1_H0;
include/crypto/sha1_base.h:	sctx->state[1] = SHA1_H1;
include/crypto/sha1_base.h:	sctx->state[2] = SHA1_H2;
include/crypto/sha1_base.h:	sctx->state[3] = SHA1_H3;
include/crypto/sha1_base.h:	sctx->state[4] = SHA1_H4;
include/crypto/sha1_base.h:	sctx->count = 0;
include/crypto/sha1_base.h:	unsigned int partial = sctx->count % SHA1_BLOCK_SIZE;
include/crypto/sha1_base.h:	sctx->count += len;
include/crypto/sha1_base.h:			memcpy(sctx->buffer + partial, data, p);
include/crypto/sha1_base.h:			block_fn(sctx, sctx->buffer, 1);
include/crypto/sha1_base.h:		memcpy(sctx->buffer + partial, data, len);
include/crypto/sha1_base.h:	__be64 *bits = (__be64 *)(sctx->buffer + bit_offset);
include/crypto/sha1_base.h:	unsigned int partial = sctx->count % SHA1_BLOCK_SIZE;
include/crypto/sha1_base.h:	sctx->buffer[partial++] = 0x80;
include/crypto/sha1_base.h:		memset(sctx->buffer + partial, 0x0, SHA1_BLOCK_SIZE - partial);
include/crypto/sha1_base.h:		block_fn(sctx, sctx->buffer, 1);
include/crypto/sha1_base.h:	memset(sctx->buffer + partial, 0x0, bit_offset - partial);
include/crypto/sha1_base.h:	*bits = cpu_to_be64(sctx->count << 3);
include/crypto/sha1_base.h:	block_fn(sctx, sctx->buffer, 1);
include/crypto/sha1_base.h:		put_unaligned_be32(sctx->state[i], digest++);
kernel/workqueue.c:			put_pwq_unlocked(ctx->pwq_tbl[node]);
kernel/workqueue.c:		put_pwq_unlocked(ctx->dfl_pwq);
kernel/workqueue.c:		free_workqueue_attrs(ctx->attrs);
kernel/workqueue.c:	ctx = kzalloc(sizeof(*ctx) + nr_node_ids * sizeof(ctx->pwq_tbl[0]),
kernel/workqueue.c:	ctx->dfl_pwq = alloc_unbound_pwq(wq, new_attrs);
kernel/workqueue.c:	if (!ctx->dfl_pwq)
kernel/workqueue.c:			ctx->pwq_tbl[node] = alloc_unbound_pwq(wq, tmp_attrs);
kernel/workqueue.c:			if (!ctx->pwq_tbl[node])
kernel/workqueue.c:			ctx->dfl_pwq->refcnt++;
kernel/workqueue.c:			ctx->pwq_tbl[node] = ctx->dfl_pwq;
kernel/workqueue.c:	ctx->attrs = new_attrs;
kernel/workqueue.c:	ctx->wq = wq;
kernel/workqueue.c:	mutex_lock(&ctx->wq->mutex);
kernel/workqueue.c:	copy_workqueue_attrs(ctx->wq->unbound_attrs, ctx->attrs);
kernel/workqueue.c:		ctx->pwq_tbl[node] = numa_pwq_tbl_install(ctx->wq, node,
kernel/workqueue.c:							  ctx->pwq_tbl[node]);
kernel/workqueue.c:	link_pwq(ctx->dfl_pwq);
kernel/workqueue.c:	swap(ctx->wq->dfl_pwq, ctx->dfl_pwq);
kernel/workqueue.c:	mutex_unlock(&ctx->wq->mutex);
kernel/workqueue.c:		list_add_tail(&ctx->list, &ctxs);
kernel/locking/mutex.c:	DEBUG_LOCKS_WARN_ON(ww_ctx->done_acquire);
kernel/locking/mutex.c:	if (ww_ctx->contending_lock) {
kernel/locking/mutex.c:		DEBUG_LOCKS_WARN_ON(ww_ctx->contending_lock != ww);
kernel/locking/mutex.c:		DEBUG_LOCKS_WARN_ON(ww_ctx->acquired > 0);
kernel/locking/mutex.c:		ww_ctx->contending_lock = NULL;
kernel/locking/mutex.c:	DEBUG_LOCKS_WARN_ON(ww_ctx->ww_class != ww->ww_class);
kernel/locking/mutex.c:	ww_ctx->acquired++;
kernel/locking/mutex.c:		if (use_ww_ctx && ww_ctx->acquired > 0) {
kernel/locking/mutex.c:		DEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);
kernel/locking/mutex.c:		if (lock->ctx->acquired > 0)
kernel/locking/mutex.c:			lock->ctx->acquired--;
kernel/locking/mutex.c:	if (ctx->stamp - hold_ctx->stamp <= LONG_MAX &&
kernel/locking/mutex.c:	    (ctx->stamp != hold_ctx->stamp || ctx > hold_ctx)) {
kernel/locking/mutex.c:		DEBUG_LOCKS_WARN_ON(ctx->contending_lock);
kernel/locking/mutex.c:		ctx->contending_lock = ww;
kernel/locking/mutex.c:		if (use_ww_ctx && ww_ctx->acquired > 0) {
kernel/locking/mutex.c:	if (ctx->deadlock_inject_countdown-- == 0) {
kernel/locking/mutex.c:		tmp = ctx->deadlock_inject_interval;
kernel/locking/mutex.c:		ctx->deadlock_inject_interval = tmp;
kernel/locking/mutex.c:		ctx->deadlock_inject_countdown = tmp;
kernel/locking/mutex.c:		ctx->contending_lock = lock;
kernel/locking/mutex.c:				   0, &ctx->dep_map, _RET_IP_, ctx, 1);
kernel/locking/mutex.c:	if (!ret && ctx->acquired > 1)
kernel/locking/mutex.c:				  0, &ctx->dep_map, _RET_IP_, ctx, 1);
kernel/locking/mutex.c:	if (!ret && ctx->acquired > 1)
kernel/auditsc.c:	n = ctx->major;
kernel/auditsc.c:	switch (audit_classify_syscall(ctx->arch, n)) {
kernel/auditsc.c:		return mask & ACC_MODE(ctx->argv[1]);
kernel/auditsc.c:		return mask & ACC_MODE(ctx->argv[2]);
kernel/auditsc.c:		return ((mask & AUDIT_PERM_WRITE) && ctx->argv[0] == SYS_BIND);
kernel/auditsc.c:	list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:	if (!ctx->prio) {
kernel/auditsc.c:		ctx->prio = 1;
kernel/auditsc.c:		ctx->current_state = AUDIT_RECORD_CONTEXT;
kernel/auditsc.c:	struct audit_tree_refs *p = ctx->trees;
kernel/auditsc.c:	int left = ctx->tree_count;
kernel/auditsc.c:		ctx->tree_count = left;
kernel/auditsc.c:		ctx->trees = p;
kernel/auditsc.c:		ctx->tree_count = 30;
kernel/auditsc.c:	struct audit_tree_refs *p = ctx->trees;
kernel/auditsc.c:	ctx->trees = kzalloc(sizeof(struct audit_tree_refs), GFP_KERNEL);
kernel/auditsc.c:	if (!ctx->trees) {
kernel/auditsc.c:		ctx->trees = p;
kernel/auditsc.c:		p->next = ctx->trees;
kernel/auditsc.c:		ctx->first_trees = ctx->trees;
kernel/auditsc.c:	ctx->tree_count = 31;
kernel/auditsc.c:		p = ctx->first_trees;
kernel/auditsc.c:	for (q = p; q != ctx->trees; q = q->next, n = 31) {
kernel/auditsc.c:	while (n-- > ctx->tree_count) {
kernel/auditsc.c:	ctx->trees = p;
kernel/auditsc.c:	ctx->tree_count = count;
kernel/auditsc.c:	for (p = ctx->first_trees; p; p = q) {
kernel/auditsc.c:	for (p = ctx->first_trees; p != ctx->trees; p = p->next) {
kernel/auditsc.c:		for (n = ctx->tree_count; n < 31; n++)
kernel/auditsc.c:		list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:		list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				if (!ctx->ppid)
kernel/auditsc.c:					ctx->ppid = task_ppid_nr(tsk);
kernel/auditsc.c:				result = audit_comparator(ctx->ppid, f->op, f->val);
kernel/auditsc.c:				result = audit_comparator(ctx->arch, f->op, f->val);
kernel/auditsc.c:			if (ctx && ctx->return_valid)
kernel/auditsc.c:				result = audit_comparator(ctx->return_code, f->op, f->val);
kernel/auditsc.c:			if (ctx && ctx->return_valid) {
kernel/auditsc.c:					result = audit_comparator(ctx->return_valid, f->op, AUDITSC_SUCCESS);
kernel/auditsc.c:					result = audit_comparator(ctx->return_valid, f->op, AUDITSC_FAILURE);
kernel/auditsc.c:				list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:					list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:				if (!ctx || ctx->type != AUDIT_IPC)
kernel/auditsc.c:				if (security_audit_rule_match(ctx->ipc.osid,
kernel/auditsc.c:				result = audit_comparator(ctx->argv[f->type-AUDIT_ARG0], f->op, f->val);
kernel/auditsc.c:		if (rule->prio <= ctx->prio)
kernel/auditsc.c:			kfree(ctx->filterkey);
kernel/auditsc.c:			ctx->filterkey = kstrdup(rule->filterkey, GFP_ATOMIC);
kernel/auditsc.c:		ctx->prio = rule->prio;
kernel/auditsc.c:			if (audit_in_mask(&e->rule, ctx->major) &&
kernel/auditsc.c:				ctx->current_state = state;
kernel/auditsc.c:		if (audit_in_mask(&e->rule, ctx->major) &&
kernel/auditsc.c:			ctx->current_state = state;
kernel/auditsc.c:	list_for_each_entry(n, &ctx->names_list, list) {
kernel/auditsc.c:	if (!ctx->in_syscall)
kernel/auditsc.c:	if (!ctx->serial)
kernel/auditsc.c:		ctx->serial = audit_serial();
kernel/auditsc.c:	t->tv_sec  = ctx->ctime.tv_sec;
kernel/auditsc.c:	t->tv_nsec = ctx->ctime.tv_nsec;
kernel/auditsc.c:	*serial    = ctx->serial;
kernel/auditsc.c:	if (!ctx->prio) {
kernel/auditsc.c:		ctx->prio = 1;
kernel/auditsc.c:		ctx->current_state = AUDIT_RECORD_CONTEXT;
kernel/auditsc.c:	if (!ctx->target_pid) {
kernel/auditsc.c:		ctx->target_pid = task_tgid_nr(t);
kernel/auditsc.c:		ctx->target_auid = audit_get_loginuid(t);
kernel/auditsc.c:		ctx->target_uid = t_uid;
kernel/auditsc.c:		ctx->target_sessionid = audit_get_sessionid(t);
kernel/auditsc.c:		security_task_getsecid(t, &ctx->target_sid);
kernel/auditsc.c:		memcpy(ctx->target_comm, t->comm, TASK_COMM_LEN);
kernel/auditsc.c:	axp = (void *)ctx->aux_pids;
kernel/auditsc.c:		axp->d.next = ctx->aux_pids;
kernel/auditsc.c:		ctx->aux_pids = (void *)axp;
kernel/auditsc.c:	if (likely(!ctx || !ctx->in_syscall))
kernel/auditsc.c:	return &ctx->killed_trees;
kernel/events/callchain.c:	bool crosstask = event->ctx->task && event->ctx->task != current;
kernel/events/hw_breakpoint.c:	if (irqs_disabled() && bp->ctx && bp->ctx->task == current)
kernel/events/core.c:	return this_cpu_ptr(ctx->pmu->pmu_cpu_context);
kernel/events/core.c:	raw_spin_lock(&cpuctx->ctx.lock);
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:		raw_spin_unlock(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock(&cpuctx->ctx.lock);
kernel/events/core.c: * When !ctx->nr_events a task context will not be scheduled. This means
kernel/events/core.c: *    rely on ctx->is_active and therefore cannot use event_function_call().
kernel/events/core.c: * If ctx->nr_events, then ctx->is_active and cpuctx->task_ctx are set.
kernel/events/core.c:	struct perf_event_context *task_ctx = cpuctx->task_ctx;
kernel/events/core.c:	 * Since we do the IPI call without holding ctx->lock things can have
kernel/events/core.c:	if (ctx->task) {
kernel/events/core.c:		if (ctx->task != current) {
kernel/events/core.c:		 * above ctx->task != current test), therefore we must have
kernel/events/core.c:		 * ctx->is_active here.
kernel/events/core.c:		WARN_ON_ONCE(!ctx->is_active);
kernel/events/core.c:		 * And since we have ctx->is_active, cpuctx->task_ctx must
kernel/events/core.c:		WARN_ON_ONCE(&cpuctx->ctx != ctx);
kernel/events/core.c:	struct task_struct *task = READ_ONCE(ctx->task); /* verified in event_function */
kernel/events/core.c:		lockdep_assert_held(&ctx->mutex);
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:	task = ctx->task;
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	if (ctx->is_active) {
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	struct task_struct *task = READ_ONCE(ctx->task);
kernel/events/core.c:	task = ctx->task;
kernel/events/core.c:		if (ctx->is_active) {
kernel/events/core.c:			if (WARN_ON_ONCE(cpuctx->task_ctx != ctx))
kernel/events/core.c:		WARN_ON_ONCE(&cpuctx->ctx != ctx);
kernel/events/core.c:	if (!cpuctx->cgrp)
kernel/events/core.c:	return cgroup_is_descendant(cpuctx->cgrp->css.cgroup,
kernel/events/core.c:	struct perf_cgroup *cgrp_out = cpuctx->cgrp;
kernel/events/core.c:	 * ctx->lock held by caller
kernel/events/core.c:	if (!task || !ctx->nr_cgroups)
kernel/events/core.c:	info->timestamp = ctx->timestamp;
kernel/events/core.c:		if (cpuctx->unique_pmu != pmu)
kernel/events/core.c:		 * ctx->nr_cgroups reports the number of cgroup
kernel/events/core.c:		if (cpuctx->ctx.nr_cgroups > 0) {
kernel/events/core.c:			perf_ctx_lock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c:			perf_pmu_disable(cpuctx->ctx.pmu);
kernel/events/core.c:				cpuctx->cgrp = NULL;
kernel/events/core.c:				WARN_ON_ONCE(cpuctx->cgrp);
kernel/events/core.c:				 * we pass the cpuctx->ctx to perf_cgroup_from_task()
kernel/events/core.c:				cpuctx->cgrp = perf_cgroup_from_task(task, &cpuctx->ctx);
kernel/events/core.c:			perf_pmu_enable(cpuctx->ctx.pmu);
kernel/events/core.c:			perf_ctx_unlock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c: * Update cpuctx->cgrp so that it is set when first cgroup event is added and
kernel/events/core.c:	if (add && ctx->nr_cgroups++)
kernel/events/core.c:	else if (!add && --ctx->nr_cgroups)
kernel/events/core.c:	 * cpuctx->cgrp is NULL until a cgroup event is sched in or
kernel/events/core.c:	 * ctx->nr_cgroup == 0 .
kernel/events/core.c:		cpuctx->cgrp = event->cgrp;
kernel/events/core.c:		cpuctx->cgrp = NULL;
kernel/events/core.c:	raw_spin_lock(&cpuctx->hrtimer_lock);
kernel/events/core.c:		hrtimer_forward_now(hr, cpuctx->hrtimer_interval);
kernel/events/core.c:		cpuctx->hrtimer_active = 0;
kernel/events/core.c:	raw_spin_unlock(&cpuctx->hrtimer_lock);
kernel/events/core.c:	struct hrtimer *timer = &cpuctx->hrtimer;
kernel/events/core.c:	struct pmu *pmu = cpuctx->ctx.pmu;
kernel/events/core.c:	cpuctx->hrtimer_interval = ns_to_ktime(NSEC_PER_MSEC * interval);
kernel/events/core.c:	raw_spin_lock_init(&cpuctx->hrtimer_lock);
kernel/events/core.c:	struct hrtimer *timer = &cpuctx->hrtimer;
kernel/events/core.c:	struct pmu *pmu = cpuctx->ctx.pmu;
kernel/events/core.c:	raw_spin_lock_irqsave(&cpuctx->hrtimer_lock, flags);
kernel/events/core.c:	if (!cpuctx->hrtimer_active) {
kernel/events/core.c:		cpuctx->hrtimer_active = 1;
kernel/events/core.c:		hrtimer_forward_now(timer, cpuctx->hrtimer_interval);
kernel/events/core.c:	raw_spin_unlock_irqrestore(&cpuctx->hrtimer_lock, flags);
kernel/events/core.c:	WARN_ON(!list_empty(&ctx->active_ctx_list));
kernel/events/core.c:	list_add(&ctx->active_ctx_list, head);
kernel/events/core.c:	WARN_ON(list_empty(&ctx->active_ctx_list));
kernel/events/core.c:	list_del_init(&ctx->active_ctx_list);
kernel/events/core.c:	WARN_ON(!atomic_inc_not_zero(&ctx->refcount));
kernel/events/core.c:	kfree(ctx->task_ctx_data);
kernel/events/core.c:	if (atomic_dec_and_test(&ctx->refcount)) {
kernel/events/core.c:		if (ctx->parent_ctx)
kernel/events/core.c:			put_ctx(ctx->parent_ctx);
kernel/events/core.c:		if (ctx->task && ctx->task != TASK_TOMBSTONE)
kernel/events/core.c:			put_task_struct(ctx->task);
kernel/events/core.c:		call_rcu(&ctx->rcu_head, free_ctx);
kernel/events/core.c: * ctx->mutex we must be careful and use the below perf_event_ctx_lock()
kernel/events/core.c:	if (!atomic_inc_not_zero(&ctx->refcount)) {
kernel/events/core.c:	mutex_lock_nested(&ctx->mutex, nesting);
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
kernel/events/core.c:	mutex_unlock(&ctx->mutex);
kernel/events/core.c: * This must be done under the ctx->lock, such as to serialize against
kernel/events/core.c: * calling scheduler related locks and ctx->lock nests inside those.
kernel/events/core.c:	struct perf_event_context *parent_ctx = ctx->parent_ctx;
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:		ctx->parent_ctx = NULL;
kernel/events/core.c:	ctx->generation++;
kernel/events/core.c:	 * Since ctx->lock nests under rq->lock we must ensure the entire read
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:			raw_spin_unlock(&ctx->lock);
kernel/events/core.c:		if (ctx->task == TASK_TOMBSTONE ||
kernel/events/core.c:		    !atomic_inc_not_zero(&ctx->refcount)) {
kernel/events/core.c:			raw_spin_unlock(&ctx->lock);
kernel/events/core.c:			WARN_ON_ONCE(ctx->task != task);
kernel/events/core.c:		++ctx->pin_count;
kernel/events/core.c:		raw_spin_unlock_irqrestore(&ctx->lock, flags);
kernel/events/core.c:	raw_spin_lock_irqsave(&ctx->lock, flags);
kernel/events/core.c:	--ctx->pin_count;
kernel/events/core.c:	raw_spin_unlock_irqrestore(&ctx->lock, flags);
kernel/events/core.c:	ctx->time += now - ctx->timestamp;
kernel/events/core.c:	ctx->timestamp = now;
kernel/events/core.c:	return ctx ? ctx->time : 0;
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:	else if (ctx->is_active)
kernel/events/core.c:		run_end = ctx->time;
kernel/events/core.c:		return &ctx->pinned_groups;
kernel/events/core.c:		return &ctx->flexible_groups;
kernel/events/core.c: * Must be called with ctx->mutex and ctx->lock held.
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:	list_add_rcu(&event->event_entry, &ctx->event_list);
kernel/events/core.c:	ctx->nr_events++;
kernel/events/core.c:		ctx->nr_stat++;
kernel/events/core.c:	ctx->generation++;
kernel/events/core.c:	lockdep_assert_held(&event->ctx->lock);
kernel/events/core.c: * Must be called with ctx->mutex and ctx->lock held.
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:	ctx->nr_events--;
kernel/events/core.c:		ctx->nr_stat--;
kernel/events/core.c:	ctx->generation++;
kernel/events/core.c:	lockdep_assert_held(&event->ctx->lock);
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:		cpuctx->active_oncpu--;
kernel/events/core.c:	if (!--ctx->nr_active)
kernel/events/core.c:		ctx->nr_freq--;
kernel/events/core.c:	if (event->attr.exclusive || !cpuctx->active_oncpu)
kernel/events/core.c:		cpuctx->exclusive = 0;
kernel/events/core.c:	perf_pmu_disable(ctx->pmu);
kernel/events/core.c:	perf_pmu_enable(ctx->pmu);
kernel/events/core.c:		cpuctx->exclusive = 0;
kernel/events/core.c:	if (!ctx->nr_events && ctx->is_active) {
kernel/events/core.c:		ctx->is_active = 0;
kernel/events/core.c:		if (ctx->task) {
kernel/events/core.c:			WARN_ON_ONCE(cpuctx->task_ctx != ctx);
kernel/events/core.c:			cpuctx->task_ctx = NULL;
kernel/events/core.c: * every task struct that event->ctx->task could possibly point to
kernel/events/core.c:	lockdep_assert_held(&ctx->mutex);
kernel/events/core.c:		raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c: * every task struct that event->ctx->task could possibly point to
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	 *    tstamp - ctx->timestamp
kernel/events/core.c:		event->shadow_ctx_time = tstamp - ctx->timestamp;
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:		cpuctx->active_oncpu++;
kernel/events/core.c:	if (!ctx->nr_active++)
kernel/events/core.c:		ctx->nr_freq++;
kernel/events/core.c:		cpuctx->exclusive = 1;
kernel/events/core.c:	struct pmu *pmu = ctx->pmu;
kernel/events/core.c:	u64 now = ctx->time;
kernel/events/core.c:	if (cpuctx->exclusive)
kernel/events/core.c:	if (event->attr.exclusive && cpuctx->active_oncpu)
kernel/events/core.c:	if (!cpuctx->task_ctx)
kernel/events/core.c:	if (WARN_ON_ONCE(ctx != cpuctx->task_ctx))
kernel/events/core.c:	perf_pmu_disable(cpuctx->ctx.pmu);
kernel/events/core.c:	perf_pmu_enable(cpuctx->ctx.pmu);
kernel/events/core.c: * things like ctx->is_active and cpuctx->task_ctx are set.
kernel/events/core.c:	struct perf_event_context *task_ctx = cpuctx->task_ctx;
kernel/events/core.c:	raw_spin_lock(&cpuctx->ctx.lock);
kernel/events/core.c:	if (ctx->task) {
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:		reprogram = (ctx->task == current);
kernel/events/core.c:		 * If its not running, we don't care, ctx->lock will
kernel/events/core.c:		if (task_curr(ctx->task) && !reprogram) {
kernel/events/core.c:		WARN_ON_ONCE(reprogram && cpuctx->task_ctx && cpuctx->task_ctx != ctx);
kernel/events/core.c:		raw_spin_lock(&task_ctx->lock);
kernel/events/core.c:	struct task_struct *task = READ_ONCE(ctx->task);
kernel/events/core.c:	lockdep_assert_held(&ctx->mutex);
kernel/events/core.c:	 * Installing events is tricky because we cannot rely on ctx->is_active
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:	task = ctx->task;
kernel/events/core.c:		 * cannot happen), and we hold ctx->mutex, which serializes us
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	 * If the task is not running, ctx->lock will avoid it becoming so,
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	if (ctx->is_active)
kernel/events/core.c:	if (!ctx->is_active)
kernel/events/core.c:	task_ctx = cpuctx->task_ctx;
kernel/events/core.c:	if (ctx->task)
kernel/events/core.c: * every task struct that event->ctx->task could possibly point to
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:	int is_active = ctx->is_active;
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:	if (likely(!ctx->nr_events)) {
kernel/events/core.c:		WARN_ON_ONCE(ctx->is_active);
kernel/events/core.c:		if (ctx->task)
kernel/events/core.c:			WARN_ON_ONCE(cpuctx->task_ctx);
kernel/events/core.c:	ctx->is_active &= ~event_type;
kernel/events/core.c:	if (!(ctx->is_active & EVENT_ALL))
kernel/events/core.c:		ctx->is_active = 0;
kernel/events/core.c:	if (ctx->task) {
kernel/events/core.c:		WARN_ON_ONCE(cpuctx->task_ctx != ctx);
kernel/events/core.c:		if (!ctx->is_active)
kernel/events/core.c:			cpuctx->task_ctx = NULL;
kernel/events/core.c:	is_active ^= ctx->is_active; /* changed bits */
kernel/events/core.c:	if (!ctx->nr_active || !(is_active & EVENT_ALL))
kernel/events/core.c:	perf_pmu_disable(ctx->pmu);
kernel/events/core.c:		list_for_each_entry(event, &ctx->pinned_groups, group_entry)
kernel/events/core.c:		list_for_each_entry(event, &ctx->flexible_groups, group_entry)
kernel/events/core.c:	perf_pmu_enable(ctx->pmu);
kernel/events/core.c:	if (!ctx->nr_stat)
kernel/events/core.c:	event = list_first_entry(&ctx->event_list,
kernel/events/core.c:	next_event = list_first_entry(&next_ctx->event_list,
kernel/events/core.c:	while (&event->event_entry != &ctx->event_list &&
kernel/events/core.c:	       &next_event->event_entry != &next_ctx->event_list) {
kernel/events/core.c:	if (!cpuctx->task_ctx)
kernel/events/core.c:	parent = rcu_dereference(ctx->parent_ctx);
kernel/events/core.c:	next_parent = rcu_dereference(next_ctx->parent_ctx);
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:		raw_spin_lock_nested(&next_ctx->lock, SINGLE_DEPTH_NESTING);
kernel/events/core.c:			WRITE_ONCE(ctx->task, next);
kernel/events/core.c:			WRITE_ONCE(next_ctx->task, task);
kernel/events/core.c:			swap(ctx->task_ctx_data, next_ctx->task_ctx_data);
kernel/events/core.c:			 * ctx->task and ctx->task_ctx_data are immaterial
kernel/events/core.c:			 * ctx->lock which we're now holding.
kernel/events/core.c:		raw_spin_unlock(&next_ctx->lock);
kernel/events/core.c:		raw_spin_unlock(&ctx->lock);
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:		raw_spin_unlock(&ctx->lock);
kernel/events/core.c:	if (!--cpuctx->sched_cb_usage)
kernel/events/core.c:		list_del(&cpuctx->sched_cb_entry);
kernel/events/core.c:	if (!cpuctx->sched_cb_usage++)
kernel/events/core.c:		list_add(&cpuctx->sched_cb_entry, this_cpu_ptr(&sched_cb_list));
kernel/events/core.c:		pmu = cpuctx->unique_pmu; /* software PMUs will not have sched_task */
kernel/events/core.c:		perf_ctx_lock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c:		pmu->sched_task(cpuctx->task_ctx, sched_in);
kernel/events/core.c:		perf_ctx_unlock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c:	ctx_sched_out(&cpuctx->ctx, cpuctx, event_type);
kernel/events/core.c:	list_for_each_entry(event, &ctx->pinned_groups, group_entry) {
kernel/events/core.c:	list_for_each_entry(event, &ctx->flexible_groups, group_entry) {
kernel/events/core.c:	int is_active = ctx->is_active;
kernel/events/core.c:	lockdep_assert_held(&ctx->lock);
kernel/events/core.c:	if (likely(!ctx->nr_events))
kernel/events/core.c:	ctx->is_active |= (event_type | EVENT_TIME);
kernel/events/core.c:	if (ctx->task) {
kernel/events/core.c:			cpuctx->task_ctx = ctx;
kernel/events/core.c:			WARN_ON_ONCE(cpuctx->task_ctx != ctx);
kernel/events/core.c:	is_active ^= ctx->is_active; /* changed bits */
kernel/events/core.c:		ctx->timestamp = now;
kernel/events/core.c:	struct perf_event_context *ctx = &cpuctx->ctx;
kernel/events/core.c:	if (cpuctx->task_ctx == ctx)
kernel/events/core.c:	perf_pmu_disable(ctx->pmu);
kernel/events/core.c:	perf_pmu_enable(ctx->pmu);
kernel/events/core.c:	if (!(ctx->nr_freq || needs_unthr))
kernel/events/core.c:	raw_spin_lock(&ctx->lock);
kernel/events/core.c:	perf_pmu_disable(ctx->pmu);
kernel/events/core.c:	list_for_each_entry_rcu(event, &ctx->event_list, event_entry) {
kernel/events/core.c:	perf_pmu_enable(ctx->pmu);
kernel/events/core.c:	raw_spin_unlock(&ctx->lock);
kernel/events/core.c:	if (!ctx->rotate_disable)
kernel/events/core.c:		list_rotate_left(&ctx->flexible_groups);
kernel/events/core.c:	if (cpuctx->ctx.nr_events) {
kernel/events/core.c:		if (cpuctx->ctx.nr_events != cpuctx->ctx.nr_active)
kernel/events/core.c:	ctx = cpuctx->task_ctx;
kernel/events/core.c:	if (ctx && ctx->nr_events) {
kernel/events/core.c:		if (ctx->nr_events != ctx->nr_active)
kernel/events/core.c:	perf_ctx_lock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c:	perf_pmu_disable(cpuctx->ctx.pmu);
kernel/events/core.c:	rotate_ctx(&cpuctx->ctx);
kernel/events/core.c:	perf_pmu_enable(cpuctx->ctx.pmu);
kernel/events/core.c:	perf_ctx_unlock(cpuctx, cpuctx->task_ctx);
kernel/events/core.c:	if (!ctx || !ctx->nr_events)
kernel/events/core.c:	list_for_each_entry(event, &ctx->event_list, event_entry)
kernel/events/core.c:	if (ctx->task && cpuctx->task_ctx != ctx)
kernel/events/core.c:	raw_spin_lock(&ctx->lock);
kernel/events/core.c:	if (ctx->is_active) {
kernel/events/core.c:	raw_spin_unlock(&ctx->lock);
kernel/events/core.c:		raw_spin_lock_irqsave(&ctx->lock, flags);
kernel/events/core.c:		if (ctx->is_active) {
kernel/events/core.c:		raw_spin_unlock_irqrestore(&ctx->lock, flags);
kernel/events/core.c:	raw_spin_lock_init(&ctx->lock);
kernel/events/core.c:	mutex_init(&ctx->mutex);
kernel/events/core.c:	INIT_LIST_HEAD(&ctx->active_ctx_list);
kernel/events/core.c:	INIT_LIST_HEAD(&ctx->pinned_groups);
kernel/events/core.c:	INIT_LIST_HEAD(&ctx->flexible_groups);
kernel/events/core.c:	INIT_LIST_HEAD(&ctx->event_list);
kernel/events/core.c:	atomic_set(&ctx->refcount, 1);
kernel/events/core.c:		ctx->task = task;
kernel/events/core.c:	ctx->pmu = pmu;
kernel/events/core.c:		ctx = &cpuctx->ctx;
kernel/events/core.c:		++ctx->pin_count;
kernel/events/core.c:		++ctx->pin_count;
kernel/events/core.c:		if (task_ctx_data && !ctx->task_ctx_data) {
kernel/events/core.c:			ctx->task_ctx_data = task_ctx_data;
kernel/events/core.c:		raw_spin_unlock_irqrestore(&ctx->lock, flags);
kernel/events/core.c:			ctx->task_ctx_data = task_ctx_data;
kernel/events/core.c:			++ctx->pin_count;
kernel/events/core.c:	list_for_each_entry(iter_event, &ctx->event_list, event_entry) {
kernel/events/core.c:		 * holding ctx->mutex which would be an inversion wrt. the
kernel/events/core.c:		 * ctx->mutex.
kernel/events/core.c:	WARN_ON_ONCE(ctx->parent_ctx);
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:		mutex_lock(&ctx->mutex);
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
kernel/events/core.c:	lockdep_assert_held(&ctx->mutex);
kernel/events/core.c:	WARN_ON_ONCE(event->ctx->parent_ctx);
kernel/events/core.c:	WARN_ON_ONCE(event->ctx->parent_ctx);
kernel/events/core.c:	lockdep_assert_held(&ctx->mutex);
kernel/events/core.c:		perf_pmu_disable(ctx->pmu);
kernel/events/core.c:		perf_pmu_enable(ctx->pmu);
kernel/events/core.c:	WARN_ON_ONCE(event->ctx->parent_ctx);
kernel/events/core.c:	list_for_each_entry_rcu(event, &ctx->event_list, event_entry) {
kernel/events/core.c:	perf_iterate_ctx(&cpuctx->ctx, __perf_event_output_stop, &ro, false);
kernel/events/core.c:	if (cpuctx->task_ctx)
kernel/events/core.c:		perf_iterate_ctx(cpuctx->task_ctx, __perf_event_output_stop,
kernel/events/core.c:	if (event->ctx->task) {
kernel/events/core.c:	if (event->ctx->task)
kernel/events/core.c:					  lockdep_is_held(&event->ctx->lock));
kernel/events/core.c:		list_for_each_entry_rcu(event, &ctx->event_list, event_entry) {
kernel/events/core.c:	struct task_struct *task = READ_ONCE(event->ctx->task);
kernel/events/core.c:	mm = get_task_mm(event->ctx->task);
kernel/events/core.c:	lockdep_assert_held(&event->ctx->mutex);
kernel/events/core.c:	if (!event->ctx->task)
kernel/events/core.c:	local64_set(&event->hw.prev_count, event->ctx->time);
kernel/events/core.c:	task_clock_event_update(event, event->ctx->time);
kernel/events/core.c:	u64 delta = now - event->ctx->timestamp;
kernel/events/core.c:	u64 time = event->ctx->time + delta;
kernel/events/core.c:		if (cpuctx->unique_pmu == old_pmu)
kernel/events/core.c:			cpuctx->unique_pmu = pmu;
kernel/events/core.c:		cpuctx->hrtimer_interval = ns_to_ktime(NSEC_PER_MSEC * timer);
kernel/events/core.c:		__perf_event_init_context(&cpuctx->ctx);
kernel/events/core.c:		lockdep_set_class(&cpuctx->ctx.mutex, &cpuctx_mutex);
kernel/events/core.c:		lockdep_set_class(&cpuctx->ctx.lock, &cpuctx_lock);
kernel/events/core.c:		cpuctx->ctx.pmu = pmu;
kernel/events/core.c:		cpuctx->unique_pmu = pmu;
kernel/events/core.c:		 * This ctx->mutex can nest when we're called through
kernel/events/core.c:	if (!atomic_inc_not_zero(&gctx->refcount)) {
kernel/events/core.c:	mutex_lock_double(&gctx->mutex, &ctx->mutex);
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
kernel/events/core.c:		mutex_unlock(&gctx->mutex);
kernel/events/core.c:		if (group_leader->ctx->task != ctx->task)
kernel/events/core.c:		if (gctx->task == TASK_TOMBSTONE) {
kernel/events/core.c:		mutex_lock(&ctx->mutex);
kernel/events/core.c:	if (ctx->task == TASK_TOMBSTONE) {
kernel/events/core.c:	WARN_ON_ONCE(ctx->parent_ctx);
kernel/events/core.c:	mutex_unlock(&ctx->mutex);
kernel/events/core.c:	mutex_unlock(&ctx->mutex);
kernel/events/core.c:	WARN_ON_ONCE(ctx->parent_ctx);
kernel/events/core.c:	mutex_lock(&ctx->mutex);
kernel/events/core.c:	if (ctx->task == TASK_TOMBSTONE) {
kernel/events/core.c:	mutex_unlock(&ctx->mutex);
kernel/events/core.c:	mutex_unlock(&ctx->mutex);
kernel/events/core.c:	mutex_lock_double(&src_ctx->mutex, &dst_ctx->mutex);
kernel/events/core.c:	list_for_each_entry_safe(event, tmp, &src_ctx->event_list,
kernel/events/core.c:	mutex_unlock(&dst_ctx->mutex);
kernel/events/core.c:	mutex_unlock(&src_ctx->mutex);
kernel/events/core.c:	raw_spin_lock_irq(&child_ctx->lock);
kernel/events/core.c:	WARN_ON_ONCE(child_ctx->is_active);
kernel/events/core.c:	raw_spin_unlock_irq(&child_ctx->lock);
kernel/events/core.c:	WARN_ON_ONCE(parent_event->ctx->parent_ctx);
kernel/events/core.c:	mutex_lock(&child_ctx->mutex);
kernel/events/core.c:	raw_spin_lock_irq(&child_ctx->lock);
kernel/events/core.c:	WRITE_ONCE(child_ctx->task, TASK_TOMBSTONE);
kernel/events/core.c:	raw_spin_unlock_irq(&child_ctx->lock);
kernel/events/core.c:	list_for_each_entry_safe(child_event, next, &child_ctx->event_list, event_entry)
kernel/events/core.c:	mutex_unlock(&child_ctx->mutex);
kernel/events/core.c:	raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:	raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:		mutex_lock(&ctx->mutex);
kernel/events/core.c:		raw_spin_lock_irq(&ctx->lock);
kernel/events/core.c:		WRITE_ONCE(ctx->task, TASK_TOMBSTONE);
kernel/events/core.c:		raw_spin_unlock_irq(&ctx->lock);
kernel/events/core.c:		list_for_each_entry_safe(event, tmp, &ctx->pinned_groups,
kernel/events/core.c:		list_for_each_entry_safe(event, tmp, &ctx->flexible_groups,
kernel/events/core.c:		if (!list_empty(&ctx->pinned_groups) ||
kernel/events/core.c:				!list_empty(&ctx->flexible_groups))
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
kernel/events/core.c:	raw_spin_lock_irqsave(&child_ctx->lock, flags);
kernel/events/core.c:	raw_spin_unlock_irqrestore(&child_ctx->lock, flags);
kernel/events/core.c:		child_ctx = alloc_perf_context(parent_ctx->pmu, child);
kernel/events/core.c:	mutex_lock(&parent_ctx->mutex);
kernel/events/core.c:	list_for_each_entry(event, &parent_ctx->pinned_groups, group_entry) {
kernel/events/core.c:	 * We can't hold ctx->lock when iterating the ->flexible_group list due
kernel/events/core.c:	raw_spin_lock_irqsave(&parent_ctx->lock, flags);
kernel/events/core.c:	parent_ctx->rotate_disable = 1;
kernel/events/core.c:	raw_spin_unlock_irqrestore(&parent_ctx->lock, flags);
kernel/events/core.c:	list_for_each_entry(event, &parent_ctx->flexible_groups, group_entry) {
kernel/events/core.c:	raw_spin_lock_irqsave(&parent_ctx->lock, flags);
kernel/events/core.c:	parent_ctx->rotate_disable = 0;
kernel/events/core.c:		 * parent_ctx->lock avoids it from being uncloned.
kernel/events/core.c:		cloned_ctx = parent_ctx->parent_ctx;
kernel/events/core.c:			child_ctx->parent_ctx = cloned_ctx;
kernel/events/core.c:			child_ctx->parent_gen = parent_ctx->parent_gen;
kernel/events/core.c:			child_ctx->parent_ctx = parent_ctx;
kernel/events/core.c:			child_ctx->parent_gen = parent_ctx->generation;
kernel/events/core.c:		get_ctx(child_ctx->parent_ctx);
kernel/events/core.c:	raw_spin_unlock_irqrestore(&parent_ctx->lock, flags);
kernel/events/core.c:	mutex_unlock(&parent_ctx->mutex);
kernel/events/core.c:		mutex_lock(&ctx->mutex);
kernel/events/core.c:		raw_spin_lock(&ctx->lock);
kernel/events/core.c:		list_for_each_entry(event, &ctx->event_list, event_entry)
kernel/events/core.c:		raw_spin_unlock(&ctx->lock);
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
kernel/events/core.c:	raw_spin_lock(&ctx->lock);
kernel/events/core.c:	list_for_each_entry(event, &ctx->event_list, event_entry)
kernel/events/core.c:	raw_spin_unlock(&ctx->lock);
kernel/events/core.c:		mutex_lock(&ctx->mutex);
kernel/events/core.c:		mutex_unlock(&ctx->mutex);
lib/mpi/mpih-mul.c:	if (!ctx->tspace || ctx->tspace_size < vsize) {
lib/mpi/mpih-mul.c:		if (ctx->tspace)
lib/mpi/mpih-mul.c:			mpi_free_limb_space(ctx->tspace);
lib/mpi/mpih-mul.c:		ctx->tspace = mpi_alloc_limb_space(2 * vsize);
lib/mpi/mpih-mul.c:		if (!ctx->tspace)
lib/mpi/mpih-mul.c:		ctx->tspace_size = vsize;
lib/mpi/mpih-mul.c:	MPN_MUL_N_RECURSE(prodp, up, vp, vsize, ctx->tspace);
lib/mpi/mpih-mul.c:		if (!ctx->tp || ctx->tp_size < vsize) {
lib/mpi/mpih-mul.c:			if (ctx->tp)
lib/mpi/mpih-mul.c:				mpi_free_limb_space(ctx->tp);
lib/mpi/mpih-mul.c:			ctx->tp = mpi_alloc_limb_space(2 * vsize);
lib/mpi/mpih-mul.c:			if (!ctx->tp) {
lib/mpi/mpih-mul.c:				if (ctx->tspace)
lib/mpi/mpih-mul.c:					mpi_free_limb_space(ctx->tspace);
lib/mpi/mpih-mul.c:				ctx->tspace = NULL;
lib/mpi/mpih-mul.c:			ctx->tp_size = vsize;
lib/mpi/mpih-mul.c:			MPN_MUL_N_RECURSE(ctx->tp, up, vp, vsize, ctx->tspace);
lib/mpi/mpih-mul.c:			cy = mpihelp_add_n(prodp, prodp, ctx->tp, vsize);
lib/mpi/mpih-mul.c:			mpihelp_add_1(prodp + vsize, ctx->tp + vsize, vsize,
lib/mpi/mpih-mul.c:			if (mpihelp_mul(ctx->tspace, vp, vsize, up, usize, &tmp)
lib/mpi/mpih-mul.c:			if (!ctx->next) {
lib/mpi/mpih-mul.c:				ctx->next = kzalloc(sizeof *ctx, GFP_KERNEL);
lib/mpi/mpih-mul.c:				if (!ctx->next)
lib/mpi/mpih-mul.c:			if (mpihelp_mul_karatsuba_case(ctx->tspace,
lib/mpi/mpih-mul.c:						       ctx->next) < 0)
lib/mpi/mpih-mul.c:		cy = mpihelp_add_n(prodp, prodp, ctx->tspace, vsize);
lib/mpi/mpih-mul.c:		mpihelp_add_1(prodp + vsize, ctx->tspace + vsize, usize, cy);
lib/mpi/mpih-mul.c:	if (ctx->tp)
lib/mpi/mpih-mul.c:		mpi_free_limb_space(ctx->tp);
lib/mpi/mpih-mul.c:	if (ctx->tspace)
lib/mpi/mpih-mul.c:		mpi_free_limb_space(ctx->tspace);
lib/mpi/mpih-mul.c:	for (ctx = ctx->next; ctx; ctx = ctx2) {
lib/mpi/mpih-mul.c:		ctx2 = ctx->next;
lib/mpi/mpih-mul.c:		if (ctx->tp)
lib/mpi/mpih-mul.c:			mpi_free_limb_space(ctx->tp);
lib/mpi/mpih-mul.c:		if (ctx->tspace)
lib/mpi/mpih-mul.c:			mpi_free_limb_space(ctx->tspace);
net/ipv4/netfilter/nf_nat_snmp_basic.c:	ctx->begin = buf;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	ctx->end = buf + len;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	ctx->pointer = buf;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	ctx->error = ASN1_ERR_NOERROR;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	if (ctx->pointer >= ctx->end) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:		ctx->error = ASN1_ERR_DEC_EMPTY;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	*ch = *(ctx->pointer)++;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	if (*len > ctx->end - ctx->pointer)
net/ipv4/netfilter/nf_nat_snmp_basic.c:		*eoc = ctx->pointer + len;
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_EOC_MISMATCH;
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_EOC_MISMATCH;
net/ipv4/netfilter/nf_nat_snmp_basic.c:		if (ctx->pointer != eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_LENGTH_MISMATCH;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	ctx->pointer = eoc;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	while (ctx->pointer < eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	while (ctx->pointer < eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	while (ctx->pointer < eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	*octets = kmalloc(eoc - ctx->pointer, GFP_ATOMIC);
net/ipv4/netfilter/nf_nat_snmp_basic.c:	while (ctx->pointer < eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:	size = eoc - ctx->pointer + 1;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	while (ctx->pointer < eoc) {
net/ipv4/netfilter/nf_nat_snmp_basic.c:			ctx->error = ASN1_ERR_DEC_BADVALUE;
net/ipv4/netfilter/nf_nat_snmp_basic.c:	mangle_address(ctx->begin, ctx->pointer - 4, map, check);
net/ipv4/tcp_fastopen.c:	crypto_free_cipher(ctx->tfm);
net/ipv4/tcp_fastopen.c:	ctx->tfm = crypto_alloc_cipher("aes", 0, 0);
net/ipv4/tcp_fastopen.c:	if (IS_ERR(ctx->tfm)) {
net/ipv4/tcp_fastopen.c:		err = PTR_ERR(ctx->tfm);
net/ipv4/tcp_fastopen.c:	err = crypto_cipher_setkey(ctx->tfm, key, len);
net/ipv4/tcp_fastopen.c:		crypto_free_cipher(ctx->tfm);
net/ipv4/tcp_fastopen.c:	memcpy(ctx->key, key, len);
net/ipv4/tcp_fastopen.c:		call_rcu(&octx->rcu, tcp_fastopen_ctx_free);
net/ipv4/tcp_fastopen.c:		crypto_cipher_encrypt_one(ctx->tfm, foc->val, path);
net/bridge/netfilter/nft_reject_bridge.c:	return nft_chain_validate_hooks(ctx->chain, (1 << NF_BR_PRE_ROUTING) |
net/key/af_key.c:			    sec_ctx->sadb_x_ctx_len,
net/key/af_key.c:	int len = sec_ctx->sadb_x_ctx_len;
net/key/af_key.c:	if (sec_ctx->sadb_x_sec_len != len)
net/key/af_key.c:	int ctx_size = sec_ctx->sadb_x_ctx_len;
net/key/af_key.c:	uctx->len = pfkey_sec_ctx_len(sec_ctx);
net/key/af_key.c:	uctx->exttype = sec_ctx->sadb_x_sec_exttype;
net/key/af_key.c:	uctx->ctx_doi = sec_ctx->sadb_x_ctx_doi;
net/key/af_key.c:	uctx->ctx_alg = sec_ctx->sadb_x_ctx_alg;
net/key/af_key.c:	uctx->ctx_len = sec_ctx->sadb_x_ctx_len;
net/key/af_key.c:	       uctx->ctx_len);
net/key/af_key.c:		ctx_size = PFKEY_ALIGN8(xfrm_ctx->ctx_len);
net/key/af_key.c:		sec_ctx->sadb_x_sec_len =
net/key/af_key.c:		sec_ctx->sadb_x_sec_exttype = SADB_X_EXT_SEC_CTX;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_doi = xfrm_ctx->ctx_doi;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_alg = xfrm_ctx->ctx_alg;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_len = xfrm_ctx->ctx_len;
net/key/af_key.c:		memcpy(sec_ctx + 1, xfrm_ctx->ctx_str,
net/key/af_key.c:		       xfrm_ctx->ctx_len);
net/key/af_key.c:		len += xfrm_ctx->ctx_len;
net/key/af_key.c:		sec_ctx->sadb_x_sec_len = ctx_size / sizeof(uint64_t);
net/key/af_key.c:		sec_ctx->sadb_x_sec_exttype = SADB_X_EXT_SEC_CTX;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_doi = xfrm_ctx->ctx_doi;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_alg = xfrm_ctx->ctx_alg;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_len = xfrm_ctx->ctx_len;
net/key/af_key.c:		memcpy(sec_ctx + 1, xfrm_ctx->ctx_str,
net/key/af_key.c:		       xfrm_ctx->ctx_len);
net/key/af_key.c:		ctx_size = PFKEY_ALIGN8(xfrm_ctx->ctx_len);
net/key/af_key.c:		sec_ctx->sadb_x_sec_len =
net/key/af_key.c:		sec_ctx->sadb_x_sec_exttype = SADB_X_EXT_SEC_CTX;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_doi = xfrm_ctx->ctx_doi;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_alg = xfrm_ctx->ctx_alg;
net/key/af_key.c:		sec_ctx->sadb_x_ctx_len = xfrm_ctx->ctx_len;
net/key/af_key.c:		memcpy(sec_ctx + 1, xfrm_ctx->ctx_str,
net/key/af_key.c:		       xfrm_ctx->ctx_len);
net/key/af_key.c:		    sec_ctx->sadb_x_sec_len) {
net/xfrm/xfrm_user.c:	if (uctx->len != (sizeof(struct xfrm_user_sec_ctx) + uctx->ctx_len))
net/xfrm/xfrm_user.c:		len += xfrm_ctx->ctx_len;
net/xfrm/xfrm_user.c:	uctx->exttype = XFRMA_SEC_CTX;
net/xfrm/xfrm_user.c:	uctx->len = ctx_size;
net/xfrm/xfrm_user.c:	uctx->ctx_doi = s->ctx_doi;
net/xfrm/xfrm_user.c:	uctx->ctx_alg = s->ctx_alg;
net/xfrm/xfrm_user.c:	uctx->ctx_len = s->ctx_len;
net/xfrm/xfrm_state.c:				 ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);
net/xfrm/xfrm_policy.c:				 ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);
net/netfilter/nft_ct.c:		switch (ctx->afi->family) {
net/netfilter/nft_ct.c:	err = nft_ct_l3proto_try_module_get(ctx->afi->family);
net/netfilter/nft_ct.c:		nf_ct_set_acct(ctx->net, true);
net/netfilter/nft_ct.c:		err = nf_connlabels_get(ctx->net, (len * BITS_PER_BYTE) - 1);
net/netfilter/nft_ct.c:	err = nft_ct_l3proto_try_module_get(ctx->afi->family);
net/netfilter/nft_ct.c:		nf_connlabels_put(ctx->net);
net/netfilter/nft_ct.c:	nft_ct_l3proto_module_put(ctx->afi->family);
net/netfilter/nft_ct.c:		nf_connlabels_put(ctx->net);
net/netfilter/nft_ct.c:	nft_ct_l3proto_module_put(ctx->afi->family);
net/netfilter/nft_meta.c:	switch (ctx->afi->family) {
net/netfilter/nft_meta.c:	return nft_chain_validate_hooks(ctx->chain, hooks);
net/netfilter/nft_nat.c:	err = nft_chain_validate_dependency(ctx->chain, NFT_CHAIN_T_NAT);
net/netfilter/nft_nat.c:		err = nft_chain_validate_hooks(ctx->chain,
net/netfilter/nft_nat.c:		err = nft_chain_validate_hooks(ctx->chain,
net/netfilter/nft_nat.c:	if (family != ctx->afi->family)
net/netfilter/nft_masq.c:	err = nft_chain_validate_dependency(ctx->chain, NFT_CHAIN_T_NAT);
net/netfilter/nft_masq.c:	return nft_chain_validate_hooks(ctx->chain,
net/netfilter/nft_dynset.c:	u8 genmask = nft_genmask_next(ctx->net);
net/netfilter/nft_dynset.c:	set = nf_tables_set_lookup(ctx->table, tb[NFTA_DYNSET_SET_NAME],
net/netfilter/nft_dynset.c:			set = nf_tables_set_lookup_byid(ctx->net,
net/netfilter/nft_lookup.c:	u8 genmask = nft_genmask_next(ctx->net);
net/netfilter/nft_lookup.c:	set = nf_tables_set_lookup(ctx->table, tb[NFTA_LOOKUP_SET], genmask);
net/netfilter/nft_lookup.c:			set = nf_tables_set_lookup_byid(ctx->net,
net/netfilter/nft_reject.c:	return nft_chain_validate_hooks(ctx->chain,
net/netfilter/nft_log.c:	err = nf_logger_find_get(ctx->afi->family, li->type);
net/netfilter/nft_log.c:	nf_logger_put(ctx->afi->family, li->type);
net/netfilter/nft_compat.c:	par->net	= ctx->net;
net/netfilter/nft_compat.c:	par->table	= ctx->table->name;
net/netfilter/nft_compat.c:	switch (ctx->afi->family) {
net/netfilter/nft_compat.c:	if (ctx->chain->flags & NFT_BASE_CHAIN) {
net/netfilter/nft_compat.c:						nft_base_chain(ctx->chain);
net/netfilter/nft_compat.c:	par->family	= ctx->afi->family;
net/netfilter/nft_compat.c:	ret = nft_compat_chain_validate_dependency(target->table, ctx->chain);
net/netfilter/nft_compat.c:	if (ctx->nla[NFTA_RULE_COMPAT]) {
net/netfilter/nft_compat.c:		ret = nft_parse_compat(ctx->nla[NFTA_RULE_COMPAT], &proto, &inv);
net/netfilter/nft_compat.c:	par.net = ctx->net;
net/netfilter/nft_compat.c:	par.family = ctx->afi->family;
net/netfilter/nft_compat.c:	if (ctx->chain->flags & NFT_BASE_CHAIN) {
net/netfilter/nft_compat.c:						nft_base_chain(ctx->chain);
net/netfilter/nft_compat.c:							   ctx->chain);
net/netfilter/nft_compat.c:	par->net	= ctx->net;
net/netfilter/nft_compat.c:	par->table	= ctx->table->name;
net/netfilter/nft_compat.c:	switch (ctx->afi->family) {
net/netfilter/nft_compat.c:	if (ctx->chain->flags & NFT_BASE_CHAIN) {
net/netfilter/nft_compat.c:						nft_base_chain(ctx->chain);
net/netfilter/nft_compat.c:	par->family	= ctx->afi->family;
net/netfilter/nft_compat.c:	ret = nft_compat_chain_validate_dependency(match->table, ctx->chain);
net/netfilter/nft_compat.c:	if (ctx->nla[NFTA_RULE_COMPAT]) {
net/netfilter/nft_compat.c:		ret = nft_parse_compat(ctx->nla[NFTA_RULE_COMPAT], &proto, &inv);
net/netfilter/nft_compat.c:	par.net = ctx->net;
net/netfilter/nft_compat.c:	par.family = ctx->afi->family;
net/netfilter/nft_compat.c:	if (ctx->chain->flags & NFT_BASE_CHAIN) {
net/netfilter/nft_compat.c:						nft_base_chain(ctx->chain);
net/netfilter/nft_compat.c:							   ctx->chain);
net/netfilter/nft_compat.c:	family = ctx->afi->family;
net/netfilter/nft_compat.c:	family = ctx->afi->family;
net/netfilter/nf_tables_netdev.c:	struct nft_base_chain *basechain = nft_base_chain(ctx->chain);
net/netfilter/nft_redir.c:	err = nft_chain_validate_dependency(ctx->chain, NFT_CHAIN_T_NAT);
net/netfilter/nft_redir.c:	return nft_chain_validate_hooks(ctx->chain,
net/netfilter/nf_tables_api.c:	ctx->net	= net;
net/netfilter/nf_tables_api.c:	ctx->afi	= afi;
net/netfilter/nf_tables_api.c:	ctx->table	= table;
net/netfilter/nf_tables_api.c:	ctx->chain	= chain;
net/netfilter/nf_tables_api.c:	ctx->nla   	= nla;
net/netfilter/nf_tables_api.c:	ctx->portid	= NETLINK_CB(skb).portid;
net/netfilter/nf_tables_api.c:	ctx->report	= nlmsg_report(nlh);
net/netfilter/nf_tables_api.c:	ctx->seq	= nlh->nlmsg_seq;
net/netfilter/nf_tables_api.c:		nft_activate_next(ctx->net, ctx->table);
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	nft_deactivate_next(ctx->net, ctx->table);
net/netfilter/nf_tables_api.c:		nft_activate_next(ctx->net, ctx->chain);
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	ctx->table->use--;
net/netfilter/nf_tables_api.c:	nft_deactivate_next(ctx->net, ctx->chain);
net/netfilter/nf_tables_api.c:	if (nft_is_active_next(ctx->net, rule)) {
net/netfilter/nf_tables_api.c:		nft_deactivate_next(ctx->net, rule);
net/netfilter/nf_tables_api.c:		ctx->chain->use--;
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	list_for_each_entry(rule, &ctx->chain->rules, list) {
net/netfilter/nf_tables_api.c:	if (msg_type == NFT_MSG_NEWSET && ctx->nla[NFTA_SET_ID] != NULL) {
net/netfilter/nf_tables_api.c:			ntohl(nla_get_be32(ctx->nla[NFTA_SET_ID]));
net/netfilter/nf_tables_api.c:		nft_activate_next(ctx->net, set);
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	nft_deactivate_next(ctx->net, set);
net/netfilter/nf_tables_api.c:	ctx->table->use--;
net/netfilter/nf_tables_api.c:	if (!ctx->report &&
net/netfilter/nf_tables_api.c:	    !nfnetlink_has_listeners(ctx->net, NFNLGRP_NFTABLES))
net/netfilter/nf_tables_api.c:	err = nf_tables_fill_table_info(skb, ctx->net, ctx->portid, ctx->seq,
net/netfilter/nf_tables_api.c:					event, 0, ctx->afi->family, ctx->table);
net/netfilter/nf_tables_api.c:	err = nfnetlink_send(skb, ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:			     ctx->report, GFP_KERNEL);
net/netfilter/nf_tables_api.c:		nfnetlink_set_err(ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:	if (!ctx->nla[NFTA_TABLE_FLAGS])
net/netfilter/nf_tables_api.c:	flags = ntohl(nla_get_be32(ctx->nla[NFTA_TABLE_FLAGS]));
net/netfilter/nf_tables_api.c:	if (flags == ctx->table->flags)
net/netfilter/nf_tables_api.c:	    !(ctx->table->flags & NFT_TABLE_F_DORMANT)) {
net/netfilter/nf_tables_api.c:		   ctx->table->flags & NFT_TABLE_F_DORMANT) {
net/netfilter/nf_tables_api.c:		ret = nf_tables_table_enable(ctx->net, ctx->afi, ctx->table);
net/netfilter/nf_tables_api.c:			ctx->table->flags &= ~NFT_TABLE_F_DORMANT;
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	list_for_each_entry(chain, &ctx->table->chains, list) {
net/netfilter/nf_tables_api.c:		if (!nft_is_active_next(ctx->net, chain))
net/netfilter/nf_tables_api.c:		ctx->chain = chain;
net/netfilter/nf_tables_api.c:	list_for_each_entry_safe(set, ns, &ctx->table->sets, list) {
net/netfilter/nf_tables_api.c:		if (!nft_is_active_next(ctx->net, set))
net/netfilter/nf_tables_api.c:	list_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {
net/netfilter/nf_tables_api.c:		if (!nft_is_active_next(ctx->net, chain))
net/netfilter/nf_tables_api.c:		ctx->chain = chain;
net/netfilter/nf_tables_api.c:	const struct nlattr * const *nla = ctx->nla;
net/netfilter/nf_tables_api.c:	list_for_each_entry(afi, &ctx->net->nft.af_info, list) {
net/netfilter/nf_tables_api.c:		ctx->afi = afi;
net/netfilter/nf_tables_api.c:			if (!nft_is_active_next(ctx->net, table))
net/netfilter/nf_tables_api.c:			ctx->table = table;
net/netfilter/nf_tables_api.c:	BUG_ON(ctx->table->use > 0);
net/netfilter/nf_tables_api.c:	kfree(ctx->table);
net/netfilter/nf_tables_api.c:	module_put(ctx->afi->owner);
net/netfilter/nf_tables_api.c:	if (!ctx->report &&
net/netfilter/nf_tables_api.c:	    !nfnetlink_has_listeners(ctx->net, NFNLGRP_NFTABLES))
net/netfilter/nf_tables_api.c:	err = nf_tables_fill_chain_info(skb, ctx->net, ctx->portid, ctx->seq,
net/netfilter/nf_tables_api.c:					event, 0, ctx->afi->family, ctx->table,
net/netfilter/nf_tables_api.c:					ctx->chain);
net/netfilter/nf_tables_api.c:	err = nfnetlink_send(skb, ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:			     ctx->report, GFP_KERNEL);
net/netfilter/nf_tables_api.c:		nfnetlink_set_err(ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:	type = nft_expr_type_get(ctx->afi->family, tb[NFTA_EXPR_NAME]);
net/netfilter/nf_tables_api.c:	if (!ctx->report &&
net/netfilter/nf_tables_api.c:	    !nfnetlink_has_listeners(ctx->net, NFNLGRP_NFTABLES))
net/netfilter/nf_tables_api.c:	err = nf_tables_fill_rule_info(skb, ctx->net, ctx->portid, ctx->seq,
net/netfilter/nf_tables_api.c:				       event, 0, ctx->afi->family, ctx->table,
net/netfilter/nf_tables_api.c:				       ctx->chain, rule);
net/netfilter/nf_tables_api.c:	err = nfnetlink_send(skb, ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:			     ctx->report, GFP_KERNEL);
net/netfilter/nf_tables_api.c:		nfnetlink_set_err(ctx->net, ctx->portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:			if (ctx && ctx->table[0] &&
net/netfilter/nf_tables_api.c:			    strcmp(ctx->table, table->name) != 0)
net/netfilter/nf_tables_api.c:				if (ctx && ctx->chain[0] &&
net/netfilter/nf_tables_api.c:				    strcmp(ctx->chain, chain->name) != 0)
net/netfilter/nf_tables_api.c:				nla_strlcpy(ctx->table, nla[NFTA_RULE_TABLE],
net/netfilter/nf_tables_api.c:					    sizeof(ctx->table));
net/netfilter/nf_tables_api.c:				nla_strlcpy(ctx->chain, nla[NFTA_RULE_CHAIN],
net/netfilter/nf_tables_api.c:					    sizeof(ctx->chain));
net/netfilter/nf_tables_api.c:		list_for_each_entry(i, &ctx->table->sets, list) {
net/netfilter/nf_tables_api.c:			if (!nft_is_active_next(ctx->net, set))
net/netfilter/nf_tables_api.c:	list_for_each_entry(i, &ctx->table->sets, list) {
net/netfilter/nf_tables_api.c:		if (!nft_is_active_next(ctx->net, i))
net/netfilter/nf_tables_api.c:	u32 portid = ctx->portid;
net/netfilter/nf_tables_api.c:	u32 seq = ctx->seq;
net/netfilter/nf_tables_api.c:	nfmsg->nfgen_family	= ctx->afi->family;
net/netfilter/nf_tables_api.c:	nfmsg->res_id		= htons(ctx->net->nft.base_seq & 0xffff);
net/netfilter/nf_tables_api.c:	if (nla_put_string(skb, NFTA_SET_TABLE, ctx->table->name))
net/netfilter/nf_tables_api.c:	u32 portid = ctx->portid;
net/netfilter/nf_tables_api.c:	if (!ctx->report &&
net/netfilter/nf_tables_api.c:	    !nfnetlink_has_listeners(ctx->net, NFNLGRP_NFTABLES))
net/netfilter/nf_tables_api.c:	err = nfnetlink_send(skb, ctx->net, portid, NFNLGRP_NFTABLES,
net/netfilter/nf_tables_api.c:			     ctx->report, gfp_flags);
net/netfilter/nf_tables_api.c:		nfnetlink_set_err(ctx->net, portid, NFNLGRP_NFTABLES, err);
net/netfilter/nf_tables_api.c:		if (ctx->afi && ctx->afi != afi)
net/netfilter/nf_tables_api.c:			if (ctx->table && ctx->table != table)
net/netfilter/nf_tables_api.c:		iter.genmask	= nft_genmask_next(ctx->net);
net/netfilter/nf_tables_api.c:	binding->chain = ctx->chain;
net/netfilter/nf_tables_api.c:	    nft_is_active(ctx->net, set))
net/netfilter/nf_tables_api.c:	nfmsg->nfgen_family	= ctx->afi->family;
net/netfilter/nf_tables_api.c:	nfmsg->res_id		= htons(ctx->net->nft.base_seq & 0xffff);
net/netfilter/nf_tables_api.c:	if (nla_put_string(skb, NFTA_SET_TABLE, ctx->table->name))
net/netfilter/nf_tables_api.c:	struct net *net = ctx->net;
net/netfilter/nf_tables_api.c:	u32 portid = ctx->portid;
net/netfilter/nf_tables_api.c:	if (!ctx->report && !nfnetlink_has_listeners(net, NFNLGRP_NFTABLES))
net/netfilter/nf_tables_api.c:	err = nfnetlink_send(skb, net, portid, NFNLGRP_NFTABLES, ctx->report,
net/netfilter/nf_tables_api.c:				.net	= ctx->net,
net/netfilter/nf_tables_api.c:				.afi	= ctx->afi,
net/netfilter/nf_tables_api.c:				.table	= ctx->table,
net/netfilter/nf_tables_api.c:	ext->genmask = nft_genmask_cur(ctx->net) | NFT_SET_ELEM_BUSY_MASK;
net/netfilter/nf_tables_api.c:	err = set->ops->insert(ctx->net, set, &elem, &ext2);
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	priv = set->ops->deactivate(ctx->net, set, &elem);
net/netfilter/nf_tables_api.c:	list_add_tail(&trans->list, &ctx->net->nft.commit_list);
net/netfilter/nf_tables_api.c:	if (ctx->chain == chain)
net/netfilter/nf_tables_api.c:	list_for_each_entry(set, &ctx->table->sets, list) {
net/netfilter/nf_tables_api.c:		if (!nft_is_active_next(ctx->net, set))
net/netfilter/nf_tables_api.c:			iter.genmask	= nft_genmask_next(ctx->net);
net/netfilter/nf_tables_api.c:			if (ctx->chain->level + 1 >
net/netfilter/nf_tables_api.c:				if (ctx->chain->level + 1 == NFT_JUMP_STACK_SIZE)
net/netfilter/nf_tables_api.c:				data->verdict.chain->level = ctx->chain->level + 1;
net/netfilter/nf_tables_api.c:	u8 genmask = nft_genmask_next(ctx->net);
net/netfilter/nf_tables_api.c:		chain = nf_tables_chain_lookup(ctx->table,
net/netfilter/nf_tables_api.c:	BUG_ON(!(ctx->chain->flags & NFT_BASE_CHAIN));
net/netfilter/nf_tables_api.c:	nf_tables_unregister_hooks(ctx->net, ctx->chain->table, ctx->chain,
net/netfilter/nf_tables_api.c:				   ctx->afi->nops);
net/netfilter/nf_tables_api.c:	list_for_each_entry_safe(rule, nr, &ctx->chain->rules, list) {
net/netfilter/nf_tables_api.c:		ctx->chain->use--;
net/netfilter/nf_tables_api.c:	list_del(&ctx->chain->list);
net/netfilter/nf_tables_api.c:	ctx->table->use--;
net/netfilter/nf_tables_api.c:	nf_tables_chain_destroy(ctx->chain);
net/6lowpan/debugfs.c:		set_bit(LOWPAN_IPHC_CTX_FLAG_ACTIVE, &ctx->flags);
net/6lowpan/debugfs.c:		clear_bit(LOWPAN_IPHC_CTX_FLAG_ACTIVE, &ctx->flags);
net/6lowpan/debugfs.c:		set_bit(LOWPAN_IPHC_CTX_FLAG_COMPRESSION, &ctx->flags);
net/6lowpan/debugfs.c:		clear_bit(LOWPAN_IPHC_CTX_FLAG_COMPRESSION, &ctx->flags);
net/6lowpan/debugfs.c:		container_of(ctx, struct lowpan_iphc_ctx_table, table[ctx->id]);
net/6lowpan/debugfs.c:	ctx->plen = val;
net/6lowpan/debugfs.c:		container_of(ctx, struct lowpan_iphc_ctx_table, table[ctx->id]);
net/6lowpan/debugfs.c:	*val = ctx->plen;
net/6lowpan/debugfs.c:		container_of(ctx, struct lowpan_iphc_ctx_table, table[ctx->id]);
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[0]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[1]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[2]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[3]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[4]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[5]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[6]),
net/6lowpan/debugfs.c:		   be16_to_cpu(ctx->pfx.s6_addr16[7]));
net/6lowpan/debugfs.c:		container_of(ctx, struct lowpan_iphc_ctx_table, table[ctx->id]);
net/6lowpan/debugfs.c:		ctx->pfx.s6_addr16[i] = cpu_to_be16(addr[i] & 0xffff);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(ipaddr, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(ipaddr, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(ipaddr, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:	ipaddr->s6_addr[3] = ctx->plen;
net/6lowpan/iphc.c:	ipv6_addr_prefix(&network_pfx, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(&tmp, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(&tmp, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:		ipv6_addr_prefix_copy(&tmp, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:	ipv6_addr_prefix_copy(&tmp, &ctx->pfx, ctx->plen);
net/6lowpan/iphc.c:	ipv6_addr_prefix_copy(&tmp, &ctx->pfx, ctx->plen);
net/nfc/netlink.c:	if (nla_put_u32(msg, NFC_ATTR_DEVICE_INDEX, ctx->dev_idx) ||
net/nfc/netlink.c:	    nla_put_u32(msg, NFC_ATTR_SE_INDEX, ctx->se_idx) ||
net/nfc/netlink.c:	ctx->dev_idx = dev_idx;
net/nfc/netlink.c:	ctx->se_idx = se_idx;
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->locale */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_buffer(xdr, &ctx->locale);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->server_ctx */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_buffer(xdr, &ctx->server_ctx);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->options */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->exported_context_token */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_buffer(xdr, &ctx->exported_context_token);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->state */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_buffer(xdr, &ctx->state);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->need_release */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_bool(xdr, ctx->need_release);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->mech */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_buffer(xdr, &ctx->mech);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->src_name */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_name(xdr, &ctx->src_name);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->targ_name */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_name(xdr, &ctx->targ_name);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->lifetime */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	p = xdr_encode_hyper(p, ctx->lifetime);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->ctx_flags */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	p = xdr_encode_hyper(p, ctx->ctx_flags);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->locally_initiated */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_bool(xdr, ctx->locally_initiated);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->open */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_enc_bool(xdr, ctx->open);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->options */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = dummy_enc_opt_array(xdr, &ctx->options);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->exported_context_token */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_buffer(xdr, &ctx->exported_context_token);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->state */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_buffer(xdr, &ctx->state);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->need_release */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_bool(xdr, &ctx->need_release);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->mech */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_buffer(xdr, &ctx->mech);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->src_name */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_name(xdr, &ctx->src_name);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->targ_name */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_name(xdr, &ctx->targ_name);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->lifetime */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	p = xdr_decode_hyper(p, &ctx->lifetime);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->ctx_flags */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	p = xdr_decode_hyper(p, &ctx->ctx_flags);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->locally_initiated */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_bool(xdr, &ctx->locally_initiated);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->open */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = gssx_dec_bool(xdr, &ctx->open);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	/* ctx->options */
net/sunrpc/auth_gss/gss_rpc_xdr.c:	err = dummy_dec_opt_array(xdr, &ctx->options);
net/sunrpc/auth_gss/gss_krb5_seqnum.c:	cipher = crypto_alloc_skcipher(kctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_seqnum.c:	if (kctx->enctype == ENCTYPE_ARCFOUR_HMAC)
net/sunrpc/auth_gss/gss_krb5_seqnum.c:	cipher = crypto_alloc_skcipher(kctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_seqnum.c:	struct crypto_skcipher *key = kctx->seq;
net/sunrpc/auth_gss/gss_krb5_seqnum.c:	if (kctx->enctype == ENCTYPE_ARCFOUR_HMAC)
net/sunrpc/auth_gss/gss_krb5_seal.c:	int body_size = GSS_KRB5_TOK_HDR_LEN + ctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_seal.c:	token->len = g_token_size(&ctx->mech_used, body_size);
net/sunrpc/auth_gss/gss_krb5_seal.c:	g_make_token_header(&ctx->mech_used, body_size, (unsigned char **)&ptr);
net/sunrpc/auth_gss/gss_krb5_seal.c:	*ptr++ = (__force u16)cpu_to_le16(ctx->gk5e->signalg);
net/sunrpc/auth_gss/gss_krb5_seal.c:	if ((ctx->flags & KRB5_CTX_FLAG_INITIATOR) == 0)
net/sunrpc/auth_gss/gss_krb5_seal.c:	if (ctx->flags & KRB5_CTX_FLAG_ACCEPTOR_SUBKEY)
net/sunrpc/auth_gss/gss_krb5_seal.c:	token->len = GSS_KRB5_TOK_HDR_LEN + ctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_seal.c:	if (ctx->gk5e->keyed_cksum)
net/sunrpc/auth_gss/gss_krb5_seal.c:		cksumkey = ctx->cksum;
net/sunrpc/auth_gss/gss_krb5_seal.c:	seq_send = ctx->seq_send++;
net/sunrpc/auth_gss/gss_krb5_seal.c:	if (krb5_make_seq_num(ctx, ctx->seq, ctx->initiate ? 0 : 0xff,
net/sunrpc/auth_gss/gss_krb5_seal.c:	return (ctx->endtime < now) ? GSS_S_CONTEXT_EXPIRED : GSS_S_COMPLETE;
net/sunrpc/auth_gss/gss_krb5_seal.c:	seq_send = ctx->seq_send64++;
net/sunrpc/auth_gss/gss_krb5_seal.c:	if (ctx->initiate) {
net/sunrpc/auth_gss/gss_krb5_seal.c:		cksumkey = ctx->initiator_sign;
net/sunrpc/auth_gss/gss_krb5_seal.c:		cksumkey = ctx->acceptor_sign;
net/sunrpc/auth_gss/gss_krb5_seal.c:	return (ctx->endtime < now) ? GSS_S_CONTEXT_EXPIRED : GSS_S_COMPLETE;
net/sunrpc/auth_gss/gss_krb5_seal.c:	struct krb5_ctx		*ctx = gss_ctx->internal_ctx_id;
net/sunrpc/auth_gss/gss_krb5_seal.c:	switch (ctx->enctype) {
net/sunrpc/auth_gss/auth_gss.c:	atomic_inc(&ctx->count);
net/sunrpc/auth_gss/auth_gss.c:	if (atomic_dec_and_test(&ctx->count))
net/sunrpc/auth_gss/auth_gss.c:		ctx->gc_proc = RPC_GSS_PROC_DATA;
net/sunrpc/auth_gss/auth_gss.c:		ctx->gc_seq = 1;	/* NetApp 6.4R1 doesn't accept seq. no. 0 */
net/sunrpc/auth_gss/auth_gss.c:		spin_lock_init(&ctx->gc_seq_lock);
net/sunrpc/auth_gss/auth_gss.c:		atomic_set(&ctx->count,1);
net/sunrpc/auth_gss/auth_gss.c:	ctx->gc_expiry = now + ((unsigned long)timeout * HZ);
net/sunrpc/auth_gss/auth_gss.c:	ctx->gc_win = window_size;
net/sunrpc/auth_gss/auth_gss.c:	/* gssd signals an error by passing ctx->gc_win = 0: */
net/sunrpc/auth_gss/auth_gss.c:	if (ctx->gc_win == 0) {
net/sunrpc/auth_gss/auth_gss.c:	p = simple_get_netobj(p, end, &ctx->gc_wire_ctx);
net/sunrpc/auth_gss/auth_gss.c:	ret = gss_import_sec_context(p, seclen, gm, &ctx->gc_gss_ctx, NULL, GFP_NOFS);
net/sunrpc/auth_gss/auth_gss.c:	p = simple_get_netobj(q, end, &ctx->gc_acceptor);
net/sunrpc/auth_gss/auth_gss.c:		__func__, ctx->gc_expiry, now, timeout, ctx->gc_acceptor.len,
net/sunrpc/auth_gss/auth_gss.c:		ctx->gc_acceptor.data);
net/sunrpc/auth_gss/auth_gss.c:	ctx->gc_proc = RPC_GSS_PROC_DESTROY;
net/sunrpc/auth_gss/auth_gss.c:	gss_delete_sec_context(&ctx->gc_gss_ctx);
net/sunrpc/auth_gss/auth_gss.c:	kfree(ctx->gc_wire_ctx.data);
net/sunrpc/auth_gss/auth_gss.c:	kfree(ctx->gc_acceptor.data);
net/sunrpc/auth_gss/auth_gss.c:	call_rcu(&ctx->gc_rcu, gss_free_ctx_callback);
net/sunrpc/auth_gss/auth_gss.c:	len = ctx->gc_acceptor.len;
net/sunrpc/auth_gss/auth_gss.c:	if (!ctx || !ctx->gc_acceptor.len) {
net/sunrpc/auth_gss/auth_gss.c:	acceptor = &ctx->gc_acceptor;
net/sunrpc/auth_gss/auth_gss.c:	if (!ctx || time_after(timeout, ctx->gc_expiry))
net/sunrpc/auth_gss/auth_gss.c:	if (!ctx || time_after(jiffies, ctx->gc_expiry)) {
net/sunrpc/auth_gss/auth_gss.c:	spin_lock(&ctx->gc_seq_lock);
net/sunrpc/auth_gss/auth_gss.c:	req->rq_seqno = ctx->gc_seq++;
net/sunrpc/auth_gss/auth_gss.c:	spin_unlock(&ctx->gc_seq_lock);
net/sunrpc/auth_gss/auth_gss.c:	*p++ = htonl((u32) ctx->gc_proc);
net/sunrpc/auth_gss/auth_gss.c:	p = xdr_encode_netobj(p, &ctx->gc_wire_ctx);
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_get_mic(ctx->gc_gss_ctx, &verf_buf, &mic);
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_verify_mic(ctx->gc_gss_ctx, &verf_buf, &mic);
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_get_mic(ctx->gc_gss_ctx, &integ_buf, &mic);
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_wrap(ctx->gc_gss_ctx, offset, snd_buf, inpages);
net/sunrpc/auth_gss/auth_gss.c:	if (ctx->gc_proc != RPC_GSS_PROC_DATA) {
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_verify_mic(ctx->gc_gss_ctx, &integ_buf, &mic);
net/sunrpc/auth_gss/auth_gss.c:	maj_stat = gss_unwrap(ctx->gc_gss_ctx, offset, rcv_buf);
net/sunrpc/auth_gss/auth_gss.c:	if (ctx->gc_proc != RPC_GSS_PROC_DATA)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	u32			conflen = kctx->gk5e->conflen;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	blocksize = crypto_skcipher_blocksize(kctx->enc);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	headlen = g_token_size(&kctx->mech_used,
net/sunrpc/auth_gss/gss_krb5_wrap.c:		GSS_KRB5_TOK_HDR_LEN + kctx->gk5e->cksumlength + plainlen) -
net/sunrpc/auth_gss/gss_krb5_wrap.c:	g_make_token_header(&kctx->mech_used,
net/sunrpc/auth_gss/gss_krb5_wrap.c:				kctx->gk5e->cksumlength + plainlen, &ptr);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	msg_start = ptr + GSS_KRB5_TOK_HDR_LEN + kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	*(__le16 *)(ptr + 2) = cpu_to_le16(kctx->gk5e->signalg);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	*(__le16 *)(ptr + 4) = cpu_to_le16(kctx->gk5e->sealalg);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->gk5e->keyed_cksum)
net/sunrpc/auth_gss/gss_krb5_wrap.c:		cksumkey = kctx->cksum;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	seq_send = kctx->seq_send++;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if ((krb5_make_seq_num(kctx, kctx->seq, kctx->initiate ? 0 : 0xff,
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->enctype == ENCTYPE_ARCFOUR_HMAC) {
net/sunrpc/auth_gss/gss_krb5_wrap.c:		cipher = crypto_alloc_skcipher(kctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_wrap.c:		if (gss_encrypt_xdr_buf(kctx->enc, buf,
net/sunrpc/auth_gss/gss_krb5_wrap.c:	return (kctx->endtime < now) ? GSS_S_CONTEXT_EXPIRED : GSS_S_COMPLETE;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	u32			conflen = kctx->gk5e->conflen;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (g_verify_token_header(&kctx->mech_used, &bodysize, &ptr,
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (signalg != kctx->gk5e->signalg)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (sealalg != kctx->gk5e->sealalg)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	crypt_offset = ptr + (GSS_KRB5_TOK_HDR_LEN + kctx->gk5e->cksumlength) -
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if ((kctx->initiate && direction != 0xff) ||
net/sunrpc/auth_gss/gss_krb5_wrap.c:	    (!kctx->initiate && direction != 0))
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->enctype == ENCTYPE_ARCFOUR_HMAC) {
net/sunrpc/auth_gss/gss_krb5_wrap.c:		cipher = crypto_alloc_skcipher(kctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_wrap.c:		if (gss_decrypt_xdr_buf(kctx->enc, buf, crypt_offset))
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->gk5e->keyed_cksum)
net/sunrpc/auth_gss/gss_krb5_wrap.c:		cksumkey = kctx->cksum;
net/sunrpc/auth_gss/gss_krb5_wrap.c:						kctx->gk5e->cksumlength))
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (now > kctx->endtime)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	blocksize = crypto_skcipher_blocksize(kctx->enc);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	data_start = ptr + (GSS_KRB5_TOK_HDR_LEN + kctx->gk5e->cksumlength) +
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->gk5e->encrypt_v2 == NULL)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if ((kctx->flags & KRB5_CTX_FLAG_INITIATOR) == 0)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if ((kctx->flags & KRB5_CTX_FLAG_ACCEPTOR_SUBKEY) != 0)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	blocksize = crypto_skcipher_blocksize(kctx->acceptor_enc);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	*be64ptr = cpu_to_be64(kctx->seq_send64++);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	err = (*kctx->gk5e->encrypt_v2)(kctx, offset, buf, pages);
net/sunrpc/auth_gss/gss_krb5_wrap.c:	return (kctx->endtime < now) ? GSS_S_CONTEXT_EXPIRED : GSS_S_COMPLETE;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (kctx->gk5e->decrypt_v2 == NULL)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if ((!kctx->initiate && (flags & KG2_TOKEN_FLAG_SENTBYACCEPTOR)) ||
net/sunrpc/auth_gss/gss_krb5_wrap.c:	    (kctx->initiate && !(flags & KG2_TOKEN_FLAG_SENTBYACCEPTOR)))
net/sunrpc/auth_gss/gss_krb5_wrap.c:	err = (*kctx->gk5e->decrypt_v2)(kctx, offset, buf,
net/sunrpc/auth_gss/gss_krb5_wrap.c:	if (now > kctx->endtime)
net/sunrpc/auth_gss/gss_krb5_wrap.c:	struct krb5_ctx	*kctx = gctx->internal_ctx_id;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	switch (kctx->enctype) {
net/sunrpc/auth_gss/gss_krb5_wrap.c:	struct krb5_ctx	*kctx = gctx->internal_ctx_id;
net/sunrpc/auth_gss/gss_krb5_wrap.c:	switch (kctx->enctype) {
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (g_verify_token_header(&ctx->mech_used, &bodysize, &ptr,
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (signalg != ctx->gk5e->signalg)
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (ctx->gk5e->keyed_cksum)
net/sunrpc/auth_gss/gss_krb5_unseal.c:		cksumkey = ctx->cksum;
net/sunrpc/auth_gss/gss_krb5_unseal.c:					ctx->gk5e->cksumlength))
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (now > ctx->endtime)
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if ((ctx->initiate && direction != 0xff) ||
net/sunrpc/auth_gss/gss_krb5_unseal.c:	    (!ctx->initiate && direction != 0))
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if ((!ctx->initiate && (flags & KG2_TOKEN_FLAG_SENTBYACCEPTOR)) ||
net/sunrpc/auth_gss/gss_krb5_unseal.c:	    (ctx->initiate && !(flags & KG2_TOKEN_FLAG_SENTBYACCEPTOR)))
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (ctx->initiate) {
net/sunrpc/auth_gss/gss_krb5_unseal.c:		cksumkey = ctx->acceptor_sign;
net/sunrpc/auth_gss/gss_krb5_unseal.c:		cksumkey = ctx->initiator_sign;
net/sunrpc/auth_gss/gss_krb5_unseal.c:				ctx->gk5e->cksumlength))
net/sunrpc/auth_gss/gss_krb5_unseal.c:	if (now > ctx->endtime)
net/sunrpc/auth_gss/gss_krb5_unseal.c:	struct krb5_ctx *ctx = gss_ctx->internal_ctx_id;
net/sunrpc/auth_gss/gss_krb5_unseal.c:	switch (ctx->enctype) {
net/sunrpc/auth_gss/svcauth_gss.c:	name = gss_service_to_auth_domain_name(ctx->mech_type, svc);
net/sunrpc/auth_gss/svcauth_gss.c:					rsci->mechctx->mech_type,
net/sunrpc/auth_gss/gss_krb5_mech.c:	*res = crypto_alloc_skcipher(ctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_mech.c:			"crypto algorithm %s\n", ctx->gk5e->encrypt_name);
net/sunrpc/auth_gss/gss_krb5_mech.c:			"crypto algorithm %s\n", ctx->gk5e->encrypt_name);
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->initiate, sizeof(ctx->initiate));
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->enctype = ENCTYPE_DES_CBC_RAW;
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->gk5e = get_gss_krb5_enctype(ctx->enctype);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->gk5e == NULL) {
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->endtime, sizeof(ctx->endtime));
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->seq_send, sizeof(ctx->seq_send));
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_netobj(p, end, &ctx->mech_used);
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = get_key(p, end, ctx, &ctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = get_key(p, end, ctx, &ctx->seq);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->seq);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	kfree(ctx->mech_used.data);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (crypto_skcipher_setkey(cp, key, ctx->gk5e->keylength)) {
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyin.data = ctx->Ksess;
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyin.len = ctx->gk5e->keylength;
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.len = ctx->gk5e->keylength;
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->seq = context_v2_alloc_cipher(ctx, ctx->gk5e->encrypt_name,
net/sunrpc/auth_gss/gss_krb5_mech.c:					   ctx->Ksess);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->seq == NULL)
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->enc = context_v2_alloc_cipher(ctx, ctx->gk5e->encrypt_name,
net/sunrpc/auth_gss/gss_krb5_mech.c:					   ctx->Ksess);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->enc == NULL)
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->cksum;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->seq);
net/sunrpc/auth_gss/gss_krb5_mech.c:	hmac = crypto_alloc_shash(ctx->gk5e->cksum_name, 0, 0);
net/sunrpc/auth_gss/gss_krb5_mech.c:			__func__, PTR_ERR(hmac), ctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = crypto_shash_setkey(hmac, ctx->Ksess, ctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_mech.c:			__func__, ctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = crypto_shash_digest(desc, sigkeyconstant, slen, ctx->cksum);
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->enc = crypto_alloc_skcipher(ctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (IS_ERR(ctx->enc)) {
net/sunrpc/auth_gss/gss_krb5_mech.c:		err = PTR_ERR(ctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->seq = crypto_alloc_skcipher(ctx->gk5e->encrypt_name, 0,
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (IS_ERR(ctx->seq)) {
net/sunrpc/auth_gss/gss_krb5_mech.c:		crypto_free_skcipher(ctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:		err = PTR_ERR(ctx->seq);
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyin.data = ctx->Ksess;
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyin.len = ctx->gk5e->keylength;
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.len = ctx->gk5e->keylength;
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->initiator_seal;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->initiator_enc = context_v2_alloc_cipher(ctx,
net/sunrpc/auth_gss/gss_krb5_mech.c:						     ctx->gk5e->encrypt_name,
net/sunrpc/auth_gss/gss_krb5_mech.c:						     ctx->initiator_seal);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->initiator_enc == NULL)
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->acceptor_seal;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->acceptor_enc = context_v2_alloc_cipher(ctx,
net/sunrpc/auth_gss/gss_krb5_mech.c:						    ctx->gk5e->encrypt_name,
net/sunrpc/auth_gss/gss_krb5_mech.c:						    ctx->acceptor_seal);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->acceptor_enc == NULL)
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->initiator_sign;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->acceptor_sign;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->initiator_integ;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	keyout.data = ctx->acceptor_integ;
net/sunrpc/auth_gss/gss_krb5_mech.c:	err = krb5_derive_key(ctx->gk5e, &keyin, &keyout, &c, gfp_mask);
net/sunrpc/auth_gss/gss_krb5_mech.c:	switch (ctx->enctype) {
net/sunrpc/auth_gss/gss_krb5_mech.c:		ctx->initiator_enc_aux =
net/sunrpc/auth_gss/gss_krb5_mech.c:						ctx->initiator_seal);
net/sunrpc/auth_gss/gss_krb5_mech.c:		if (ctx->initiator_enc_aux == NULL)
net/sunrpc/auth_gss/gss_krb5_mech.c:		ctx->acceptor_enc_aux =
net/sunrpc/auth_gss/gss_krb5_mech.c:						ctx->acceptor_seal);
net/sunrpc/auth_gss/gss_krb5_mech.c:		if (ctx->acceptor_enc_aux == NULL) {
net/sunrpc/auth_gss/gss_krb5_mech.c:			crypto_free_skcipher(ctx->initiator_enc_aux);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->acceptor_enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(ctx->initiator_enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->flags, sizeof(ctx->flags));
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->initiate = ctx->flags & KRB5_CTX_FLAG_INITIATOR;
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->endtime, sizeof(ctx->endtime));
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->seq_send64, sizeof(ctx->seq_send64));
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->seq_send = ctx->seq_send64;
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->seq_send64 != ctx->seq_send) {
net/sunrpc/auth_gss/gss_krb5_mech.c:			(unsigned long)ctx->seq_send64, ctx->seq_send);
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, &ctx->enctype, sizeof(ctx->enctype));
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->enctype == ENCTYPE_DES3_CBC_SHA1)
net/sunrpc/auth_gss/gss_krb5_mech.c:		ctx->enctype = ENCTYPE_DES3_CBC_RAW;
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->gk5e = get_gss_krb5_enctype(ctx->enctype);
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (ctx->gk5e == NULL) {
net/sunrpc/auth_gss/gss_krb5_mech.c:			ctx->enctype);
net/sunrpc/auth_gss/gss_krb5_mech.c:	keylen = ctx->gk5e->keylength;
net/sunrpc/auth_gss/gss_krb5_mech.c:	p = simple_get_bytes(p, end, ctx->Ksess, keylen);
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->mech_used.data = kmemdup(gss_kerberos_mech.gm_oid.data,
net/sunrpc/auth_gss/gss_krb5_mech.c:	if (unlikely(ctx->mech_used.data == NULL)) {
net/sunrpc/auth_gss/gss_krb5_mech.c:	ctx->mech_used.len = gss_kerberos_mech.gm_oid.len;
net/sunrpc/auth_gss/gss_krb5_mech.c:	switch (ctx->enctype) {
net/sunrpc/auth_gss/gss_krb5_mech.c:			*endtime = ctx->endtime;
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->seq);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->acceptor_enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->initiator_enc);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->acceptor_enc_aux);
net/sunrpc/auth_gss/gss_krb5_mech.c:	crypto_free_skcipher(kctx->initiator_enc_aux);
net/sunrpc/auth_gss/gss_krb5_mech.c:	kfree(kctx->mech_used.data);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (cksumout->len < kctx->gk5e->cksumlength) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, cksumout->len, kctx->gk5e->name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	hmac_md5 = crypto_alloc_ahash(kctx->gk5e->cksum_name, 0,
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_ahash_setkey(hmac_md5, cksumkey, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	memcpy(cksumout->data, checksumdata, kctx->gk5e->cksumlength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	cksumout->len = kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (kctx->gk5e->ctype == CKSUMTYPE_HMAC_MD5_ARCFOUR)
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (cksumout->len < kctx->gk5e->cksumlength) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, cksumout->len, kctx->gk5e->name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	tfm = crypto_alloc_ahash(kctx->gk5e->cksum_name, 0, CRYPTO_ALG_ASYNC);
net/sunrpc/auth_gss/gss_krb5_crypto.c:					  kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	switch (kctx->gk5e->ctype) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:		err = kctx->gk5e->encrypt(kctx->seq, NULL, checksumdata,
net/sunrpc/auth_gss/gss_krb5_crypto.c:		       checksumdata + checksumlen - kctx->gk5e->cksumlength,
net/sunrpc/auth_gss/gss_krb5_crypto.c:		       kctx->gk5e->cksumlength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:		memcpy(cksumout->data, checksumdata, kctx->gk5e->cksumlength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	cksumout->len = kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (kctx->gk5e->keyed_cksum == 0) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, kctx->gk5e->name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, kctx->gk5e->name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	tfm = crypto_alloc_ahash(kctx->gk5e->cksum_name, 0, CRYPTO_ALG_ASYNC);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_ahash_setkey(tfm, cksumkey, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	cksumout->len = kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	switch (kctx->gk5e->ctype) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:		memcpy(cksumout->data, checksumdata, kctx->gk5e->cksumlength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (kctx->initiate) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cipher = kctx->initiator_enc;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		aux_cipher = kctx->initiator_enc_aux;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cksumkey = kctx->initiator_integ;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cipher = kctx->acceptor_enc;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		aux_cipher = kctx->acceptor_enc_aux;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cksumkey = kctx->acceptor_integ;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (xdr_extend_head(buf, offset, kctx->gk5e->conflen))
net/sunrpc/auth_gss/gss_krb5_crypto.c:	gss_krb5_make_confounder(buf->head[0].iov_base + offset, kctx->gk5e->conflen);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	buf->tail[0].iov_len += kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	buf->len += kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (kctx->initiate) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cipher = kctx->acceptor_enc;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		aux_cipher = kctx->acceptor_enc_aux;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cksum_key = kctx->acceptor_integ;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cipher = kctx->initiator_enc;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		aux_cipher = kctx->initiator_enc_aux;
net/sunrpc/auth_gss/gss_krb5_crypto.c:		cksum_key = kctx->initiator_integ;
net/sunrpc/auth_gss/gss_krb5_crypto.c:				     kctx->gk5e->cksumlength));
net/sunrpc/auth_gss/gss_krb5_crypto.c:	ret = read_bytes_from_xdr_buf(buf, buf->len - kctx->gk5e->cksumlength,
net/sunrpc/auth_gss/gss_krb5_crypto.c:				      pkt_hmac, kctx->gk5e->cksumlength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	if (crypto_memneq(pkt_hmac, our_hmac, kctx->gk5e->cksumlength) != 0) {
net/sunrpc/auth_gss/gss_krb5_crypto.c:	*headskip = kctx->gk5e->conflen;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	*tailskip = kctx->gk5e->cksumlength;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	hmac = crypto_alloc_shash(kctx->gk5e->cksum_name, 0, 0);
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, PTR_ERR(hmac), kctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, kctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_shash_setkey(hmac, kctx->Ksess, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_shash_setkey(hmac, Kseq, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_skcipher_setkey(cipher, Kseq, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c: * Set the key of cipher kctx->enc.
net/sunrpc/auth_gss/gss_krb5_crypto.c:	hmac = crypto_alloc_shash(kctx->gk5e->cksum_name, 0, 0);
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, PTR_ERR(hmac), kctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:			__func__, kctx->gk5e->cksum_name);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	for (i = 0; i < kctx->gk5e->keylength; i++)
net/sunrpc/auth_gss/gss_krb5_crypto.c:		Kcrypt[i] = kctx->Ksess[i] ^ 0xf0;
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_shash_setkey(hmac, Kcrypt, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_shash_setkey(hmac, Kcrypt, kctx->gk5e->keylength);
net/sunrpc/auth_gss/gss_krb5_crypto.c:	err = crypto_skcipher_setkey(cipher, Kcrypt, kctx->gk5e->keylength);
net/mac80211/util.c:		ctx->driver_present = false;
net/mac80211/util.c:			if (ctx->replace_state !=
net/mac80211/util.c:		if (ctx->replace_state == IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/util.c:		chandef = ctx->conf.def;
net/mac80211/util.c:	if (WARN_ON(ctx->replace_state == IEEE80211_CHANCTX_WILL_BE_REPLACED))
net/mac80211/util.c:	list_for_each_entry(sdata, &ctx->reserved_vifs, reserved_chanctx_list)
net/mac80211/util.c:	WARN_ON(ctx->replace_state == IEEE80211_CHANCTX_REPLACES_OTHER &&
net/mac80211/util.c:		!list_empty(&ctx->assigned_vifs));
net/mac80211/util.c:	list_for_each_entry(sdata, &ctx->assigned_vifs, assigned_chanctx_list)
net/mac80211/util.c:		if (ctx->replace_state == IEEE80211_CHANCTX_WILL_BE_REPLACED)
net/mac80211/util.c:		if (ctx->mode == IEEE80211_CHANCTX_EXCLUSIVE) {
net/mac80211/util.c:						&ctx->conf.def))
net/mac80211/util.c:		if (ctx->replace_state == IEEE80211_CHANCTX_WILL_BE_REPLACED)
net/mac80211/tkip.c:	u16 *p1k = ctx->p1k;
net/mac80211/tkip.c:	ctx->state = TKIP_STATE_PHASE1_DONE;
net/mac80211/tkip.c:	ctx->p1k_iv32 = tsc_IV32;
net/mac80211/tkip.c:	const u16 *p1k = ctx->p1k;
net/mac80211/tkip.c:	if (ctx->p1k_iv32 != iv32 || ctx->state == TKIP_STATE_NOT_INIT)
net/mac80211/tkip.c:	memcpy(p1k, ctx->p1k, sizeof(ctx->p1k));
net/mac80211/tkip.c:	if (rx_ctx->ctx.state != TKIP_STATE_NOT_INIT &&
net/mac80211/tkip.c:	    (iv32 < rx_ctx->iv32 ||
net/mac80211/tkip.c:	     (iv32 == rx_ctx->iv32 && iv16 <= rx_ctx->iv16)))
net/mac80211/tkip.c:		rx_ctx->ctx.state = TKIP_STATE_PHASE1_HW_UPLOADED;
net/mac80211/tkip.c:	if (rx_ctx->ctx.state == TKIP_STATE_NOT_INIT ||
net/mac80211/tkip.c:	    rx_ctx->iv32 != iv32) {
net/mac80211/tkip.c:		tkip_mixing_phase1(tk, &rx_ctx->ctx, ta, iv32);
net/mac80211/tkip.c:	    rx_ctx->ctx.state != TKIP_STATE_PHASE1_HW_UPLOADED) {
net/mac80211/tkip.c:				iv32, rx_ctx->ctx.p1k);
net/mac80211/tkip.c:		rx_ctx->ctx.state = TKIP_STATE_PHASE1_HW_UPLOADED;
net/mac80211/tkip.c:	tkip_mixing_phase2(tk, &rx_ctx->ctx, iv16, rc4key);
net/mac80211/michael.c:	mctx->l ^= val;
net/mac80211/michael.c:	mctx->r ^= rol32(mctx->l, 17);
net/mac80211/michael.c:	mctx->l += mctx->r;
net/mac80211/michael.c:	mctx->r ^= ((mctx->l & 0xff00ff00) >> 8) |
net/mac80211/michael.c:		   ((mctx->l & 0x00ff00ff) << 8);
net/mac80211/michael.c:	mctx->l += mctx->r;
net/mac80211/michael.c:	mctx->r ^= rol32(mctx->l, 3);
net/mac80211/michael.c:	mctx->l += mctx->r;
net/mac80211/michael.c:	mctx->r ^= ror32(mctx->l, 2);
net/mac80211/michael.c:	mctx->l += mctx->r;
net/mac80211/michael.c:	mctx->l = get_unaligned_le32(key);
net/mac80211/michael.c:	mctx->r = get_unaligned_le32(key + 4);
net/mac80211/mlme.c:					    chanctx->mode, false);
net/mac80211/driver-ops.h:		ret = local->ops->add_chanctx(&local->hw, &ctx->conf);
net/mac80211/driver-ops.h:		ctx->driver_present = true;
net/mac80211/driver-ops.h:	if (WARN_ON(!ctx->driver_present))
net/mac80211/driver-ops.h:		local->ops->remove_chanctx(&local->hw, &ctx->conf);
net/mac80211/driver-ops.h:	ctx->driver_present = false;
net/mac80211/driver-ops.h:		WARN_ON_ONCE(!ctx->driver_present);
net/mac80211/driver-ops.h:		local->ops->change_chanctx(&local->hw, &ctx->conf, changed);
net/mac80211/driver-ops.h:		WARN_ON_ONCE(!ctx->driver_present);
net/mac80211/driver-ops.h:						     &ctx->conf);
net/mac80211/driver-ops.h:		WARN_ON_ONCE(!ctx->driver_present);
net/mac80211/driver-ops.h:						 &ctx->conf);
net/mac80211/driver-ops.c:		WARN_ON_ONCE(!old_ctx->driver_present);
net/mac80211/driver-ops.c:			      new_ctx->driver_present) ||
net/mac80211/driver-ops.c:			      !new_ctx->driver_present));
net/mac80211/driver-ops.c:			new_ctx->driver_present = true;
net/mac80211/driver-ops.c:			old_ctx->driver_present = false;
net/mac80211/cfg.c:					    chanctx->mode,
net/mac80211/cfg.c:	err = ieee80211_check_combinations(sdata, NULL, chanctx->mode, 0);
net/mac80211/chan.c:	list_for_each_entry(sdata, &ctx->assigned_vifs, assigned_chanctx_list)
net/mac80211/chan.c:	list_for_each_entry(sdata, &ctx->reserved_vifs, reserved_chanctx_list)
net/mac80211/chan.c:	list_for_each_entry(sdata, &ctx->reserved_vifs,
net/mac80211/chan.c:	list_for_each_entry(sdata, &ctx->assigned_vifs,
net/mac80211/chan.c:	if (!list_empty(&ctx->reserved_vifs) &&
net/mac80211/chan.c:		if (ctx->replace_state == IEEE80211_CHANCTX_WILL_BE_REPLACED)
net/mac80211/chan.c:		if (ctx->mode == IEEE80211_CHANCTX_EXCLUSIVE)
net/mac80211/chan.c:		 * ctx->conf.min_def, we have to make sure to take
net/mac80211/chan.c:	if (ctx->conf.def.width == NL80211_CHAN_WIDTH_5 ||
net/mac80211/chan.c:	    ctx->conf.def.width == NL80211_CHAN_WIDTH_10 ||
net/mac80211/chan.c:	    ctx->conf.radar_enabled) {
net/mac80211/chan.c:		ctx->conf.min_def = ctx->conf.def;
net/mac80211/chan.c:	max_bw = ieee80211_get_chanctx_max_required_bw(local, &ctx->conf);
net/mac80211/chan.c:	min_def = ctx->conf.def;
net/mac80211/chan.c:	if (cfg80211_chandef_identical(&ctx->conf.min_def, &min_def))
net/mac80211/chan.c:	ctx->conf.min_def = min_def;
net/mac80211/chan.c:	if (!ctx->driver_present)
net/mac80211/chan.c:	if (cfg80211_chandef_identical(&ctx->conf.def, chandef)) {
net/mac80211/chan.c:	WARN_ON(!cfg80211_chandef_compatible(&ctx->conf.def, chandef));
net/mac80211/chan.c:	ctx->conf.def = *chandef;
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACE_NONE)
net/mac80211/chan.c:		if (ctx->mode == IEEE80211_CHANCTX_EXCLUSIVE)
net/mac80211/chan.c:		compat = cfg80211_chandef_compatible(&ctx->conf.def, chandef);
net/mac80211/chan.c:	struct ieee80211_chanctx_conf *conf = &ctx->conf;
net/mac80211/chan.c:	INIT_LIST_HEAD(&ctx->assigned_vifs);
net/mac80211/chan.c:	INIT_LIST_HEAD(&ctx->reserved_vifs);
net/mac80211/chan.c:	ctx->conf.def = *chandef;
net/mac80211/chan.c:	ctx->conf.rx_chains_static = 1;
net/mac80211/chan.c:	ctx->conf.rx_chains_dynamic = 1;
net/mac80211/chan.c:	ctx->mode = mode;
net/mac80211/chan.c:	ctx->conf.radar_enabled = false;
net/mac80211/chan.c:		local->hw.conf.radar_enabled = ctx->conf.radar_enabled;
net/mac80211/chan.c:		local->_oper_chandef = ctx->conf.def;
net/mac80211/chan.c:	list_add_rcu(&ctx->list, &local->chanctx_list);
net/mac80211/chan.c:	list_del_rcu(&ctx->list);
net/mac80211/chan.c:	struct ieee80211_chanctx_conf *conf = &ctx->conf;
net/mac80211/chan.c:	if (radar_enabled == chanctx->conf.radar_enabled)
net/mac80211/chan.c:	chanctx->conf.radar_enabled = radar_enabled;
net/mac80211/chan.c:		local->hw.conf.radar_enabled = chanctx->conf.radar_enabled;
net/mac80211/chan.c:		conf = &new_ctx->conf;
net/mac80211/chan.c:			 &new_ctx->assigned_vifs);
net/mac80211/chan.c:						&chanctx->conf)
net/mac80211/chan.c:	    rcu_access_pointer(sdata->vif.chanctx_conf) == &chanctx->conf)
net/mac80211/chan.c:	if (rx_chains_static == chanctx->conf.rx_chains_static &&
net/mac80211/chan.c:	    rx_chains_dynamic == chanctx->conf.rx_chains_dynamic)
net/mac80211/chan.c:	chanctx->conf.rx_chains_static = rx_chains_static;
net/mac80211/chan.c:	chanctx->conf.rx_chains_dynamic = rx_chains_dynamic;
net/mac80211/chan.c:		if (ctx->replace_state == IEEE80211_CHANCTX_REPLACES_OTHER) {
net/mac80211/chan.c:			if (WARN_ON(!ctx->replace_ctx))
net/mac80211/chan.c:			WARN_ON(ctx->replace_ctx->replace_state !=
net/mac80211/chan.c:			WARN_ON(ctx->replace_ctx->replace_ctx != ctx);
net/mac80211/chan.c:			ctx->replace_ctx->replace_ctx = NULL;
net/mac80211/chan.c:			ctx->replace_ctx->replace_state =
net/mac80211/chan.c:			list_del_rcu(&ctx->list);
net/mac80211/chan.c:			    (curr_ctx->replace_state ==
net/mac80211/chan.c:			    !list_empty(&curr_ctx->reserved_vifs)) {
net/mac80211/chan.c:					if (ctx->replace_state !=
net/mac80211/chan.c:					if (!list_empty(&ctx->reserved_vifs))
net/mac80211/chan.c:			    (curr_ctx->replace_state ==
net/mac80211/chan.c:			    !list_empty(&curr_ctx->reserved_vifs))
net/mac80211/chan.c:			new_ctx->replace_ctx = curr_ctx;
net/mac80211/chan.c:			new_ctx->replace_state =
net/mac80211/chan.c:			curr_ctx->replace_ctx = new_ctx;
net/mac80211/chan.c:			curr_ctx->replace_state =
net/mac80211/chan.c:			list_add_rcu(&new_ctx->list, &local->chanctx_list);
net/mac80211/chan.c:	list_add(&sdata->reserved_chanctx_list, &new_ctx->reserved_vifs);
net/mac80211/chan.c:	if (WARN_ON(new_ctx->replace_state ==
net/mac80211/chan.c:	vif_chsw[0].old_ctx = &old_ctx->conf;
net/mac80211/chan.c:	vif_chsw[0].new_ctx = &new_ctx->conf;
net/mac80211/chan.c:	list_move(&sdata->assigned_chanctx_list, &new_ctx->assigned_vifs);
net/mac80211/chan.c:	rcu_assign_pointer(sdata->vif.chanctx_conf, &new_ctx->conf);
net/mac80211/chan.c:	if (WARN_ON(new_ctx->replace_state ==
net/mac80211/chan.c:	if (old_ctx->replace_state != IEEE80211_CHANCTX_WILL_BE_REPLACED)
net/mac80211/chan.c:	if (new_ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:	local->hw.conf.radar_enabled = new_ctx->conf.radar_enabled;
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		if (WARN_ON(!ctx->replace_ctx)) {
net/mac80211/chan.c:		list_for_each_entry(sdata, &ctx->reserved_vifs,
net/mac80211/chan.c:			vif_chsw[i].old_ctx = &old_ctx->conf;
net/mac80211/chan.c:			vif_chsw[i].new_ctx = &ctx->conf;
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		if (!list_empty(&ctx->replace_ctx->assigned_vifs))
net/mac80211/chan.c:		ieee80211_del_chanctx(local, ctx->replace_ctx);
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		if (!list_empty(&ctx->replace_ctx->assigned_vifs))
net/mac80211/chan.c:		WARN_ON(ieee80211_add_chanctx(local, ctx->replace_ctx));
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		if (WARN_ON(!ctx->replace_ctx)) {
net/mac80211/chan.c:		list_for_each_entry(sdata, &ctx->replace_ctx->assigned_vifs,
net/mac80211/chan.c:		ctx->conf.radar_enabled = false;
net/mac80211/chan.c:		list_for_each_entry(sdata, &ctx->reserved_vifs,
net/mac80211/chan.c:				if (old_ctx->replace_state ==
net/mac80211/chan.c:				ctx->conf.radar_enabled = true;
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		if (WARN_ON(!ctx->replace_ctx)) {
net/mac80211/chan.c:		list_for_each_entry(sdata, &ctx->reserved_vifs,
net/mac80211/chan.c:			rcu_assign_pointer(sdata->vif.chanctx_conf, &ctx->conf);
net/mac80211/chan.c:		list_for_each_entry_safe(sdata, sdata_tmp, &ctx->reserved_vifs,
net/mac80211/chan.c:				  &ctx->assigned_vifs);
net/mac80211/chan.c:		list_for_each_entry_safe(sdata, sdata_tmp, &ctx->reserved_vifs,
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_WILL_BE_REPLACED)
net/mac80211/chan.c:		ctx->replace_ctx->replace_ctx = NULL;
net/mac80211/chan.c:		ctx->replace_ctx->replace_state =
net/mac80211/chan.c:		list_del_rcu(&ctx->list);
net/mac80211/chan.c:		if (ctx->replace_state != IEEE80211_CHANCTX_REPLACES_OTHER)
net/mac80211/chan.c:		list_for_each_entry_safe(sdata, sdata_tmp, &ctx->reserved_vifs,
net/mac80211/chan.c:		if (sdata->reserved_chanctx->replace_state ==
net/mac80211/chan.c:	if (WARN_ON(new_ctx->replace_state ==
net/mac80211/chan.c:	if (new_ctx->replace_state == IEEE80211_CHANCTX_REPLACE_NONE) {
net/mac80211/chan.c:	     old_ctx->replace_state == IEEE80211_CHANCTX_WILL_BE_REPLACED) ||
net/mac80211/chan.c:	    new_ctx->replace_state == IEEE80211_CHANCTX_REPLACES_OTHER) {
net/mac80211/chan.c:			if (new_ctx->replace_state ==
net/mac80211/chan.c:	switch (ctx->replace_state) {
net/mac80211/chan.c:		if (ctx->driver_present)
net/mac80211/chan.c:			iter(hw, &ctx->conf, iter_data);
net/mac80211/trace.h:#define CHANCTX_ASSIGN	CHANDEF_ASSIGN(&ctx->conf.def)					\
net/mac80211/trace.h:			MIN_CHANDEF_ASSIGN(&ctx->conf.min_def)				\
net/mac80211/trace.h:			__entry->rx_chains_static = ctx->conf.rx_chains_static;		\
net/mac80211/trace.h:			__entry->rx_chains_dynamic = ctx->conf.rx_chains_dynamic
net/mac80211/trace.h:						old_ctx->def.chan->center_freq);
net/mac80211/trace.h:						    old_ctx->def.width);
net/mac80211/trace.h:						    old_ctx->def.center_freq1);
net/mac80211/trace.h:						    old_ctx->def.center_freq2);
net/mac80211/trace.h:						new_ctx->def.chan->center_freq);
net/mac80211/trace.h:						    new_ctx->def.width);
net/mac80211/trace.h:						    new_ctx->def.center_freq1);
net/mac80211/trace.h:						    new_ctx->def.center_freq2);
net/wireguard/tools/config.c:		ctx->is_peer_section = false;
net/wireguard/tools/config.c:		ctx->is_device_section = true;
net/wireguard/tools/config.c:		ctx->last_allowedip = NULL;
net/wireguard/tools/config.c:		if (ctx->last_peer)
net/wireguard/tools/config.c:			ctx->last_peer->next_peer = new_peer;
net/wireguard/tools/config.c:			ctx->device->first_peer = new_peer;
net/wireguard/tools/config.c:		ctx->last_peer = new_peer;
net/wireguard/tools/config.c:		ctx->is_peer_section = true;
net/wireguard/tools/config.c:		ctx->is_device_section = false;
net/wireguard/tools/config.c:		ctx->last_peer->flags |= WGPEER_REPLACE_ALLOWEDIPS;
net/wireguard/tools/config.c:	if (ctx->is_device_section) {
net/wireguard/tools/config.c:			ret = parse_port(&ctx->device->listen_port, &ctx->device->flags, value);
net/wireguard/tools/config.c:			ret = parse_fwmark(&ctx->device->fwmark, &ctx->device->flags, value);
net/wireguard/tools/config.c:			ret = parse_key(ctx->device->private_key, value);
net/wireguard/tools/config.c:				ctx->device->flags |= WGDEVICE_HAS_PRIVATE_KEY;
net/wireguard/tools/config.c:	} else if (ctx->is_peer_section) {
net/wireguard/tools/config.c:			ret = parse_endpoint(&ctx->last_peer->endpoint.addr, value);
net/wireguard/tools/config.c:			ret = parse_key(ctx->last_peer->public_key, value);
net/wireguard/tools/config.c:				ctx->last_peer->flags |= WGPEER_HAS_PUBLIC_KEY;
net/wireguard/tools/config.c:			ret = parse_allowedips(ctx->last_peer, &ctx->last_allowedip, value);
net/wireguard/tools/config.c:			ret = parse_persistent_keepalive(&ctx->last_peer->persistent_keepalive_interval, &ctx->last_peer->flags, value);
net/wireguard/tools/config.c:			ret = parse_key(ctx->last_peer->preshared_key, value);
net/wireguard/tools/config.c:				ctx->last_peer->flags |= WGPEER_HAS_PRESHARED_KEY;
net/wireguard/tools/config.c:		free_wgdevice(ctx->device);
net/wireguard/tools/config.c:	ctx->device = calloc(1, sizeof(struct wgdevice));
net/wireguard/tools/config.c:	if (!ctx->device) {
net/wireguard/tools/config.c:		ctx->device->flags |= WGDEVICE_REPLACE_PEERS | WGDEVICE_HAS_PRIVATE_KEY | WGDEVICE_HAS_FWMARK | WGDEVICE_HAS_LISTEN_PORT;
net/wireguard/tools/config.c:	for_each_wgpeer(ctx->device, peer) {
net/wireguard/tools/config.c:	return ctx->device;
net/wireguard/tools/config.c:	free_wgdevice(ctx->device);
net/wireguard/selftest/allowedips.h:	wctx->count++;
net/wireguard/selftest/allowedips.h:		wctx->found_a = true;
net/wireguard/selftest/allowedips.h:		wctx->found_b = true;
net/wireguard/selftest/allowedips.h:		wctx->found_c = true;
net/wireguard/selftest/allowedips.h:		wctx->found_d = true;
net/wireguard/selftest/allowedips.h:		wctx->found_e = true;
net/wireguard/selftest/allowedips.h:		wctx->found_other = true;
net/wireguard/netlink.c:	allowedip_nest = nla_nest_start(actx->skb, actx->i++);
net/wireguard/netlink.c:	if (nla_put_u8(actx->skb, WGALLOWEDIP_A_CIDR_MASK, cidr) || nla_put_u16(actx->skb, WGALLOWEDIP_A_FAMILY, family) ||
net/wireguard/netlink.c:	    nla_put(actx->skb, WGALLOWEDIP_A_IPADDR, family == AF_INET6 ? sizeof(struct in6_addr) : sizeof(struct in_addr), ip)) {
net/wireguard/netlink.c:		nla_nest_cancel(actx->skb, allowedip_nest);
net/wireguard/netlink.c:	nla_nest_end(actx->skb, allowedip_nest);
net/wireguard/crypto/poly1305.c:	ctx->nonce[0] = le32_to_cpup((__le32 *)&key[16]);
net/wireguard/crypto/poly1305.c:	ctx->nonce[1] = le32_to_cpup((__le32 *)&key[20]);
net/wireguard/crypto/poly1305.c:	ctx->nonce[2] = le32_to_cpup((__le32 *)&key[24]);
net/wireguard/crypto/poly1305.c:	ctx->nonce[3] = le32_to_cpup((__le32 *)&key[28]);
net/wireguard/crypto/poly1305.c:	poly1305_init_x86_64(ctx->opaque, key);
net/wireguard/crypto/poly1305.c:	poly1305_init_arm(ctx->opaque, key);
net/wireguard/crypto/poly1305.c:	poly1305_init_mips(ctx->opaque, key);
net/wireguard/crypto/poly1305.c:	poly1305_init_generic(ctx->opaque, key);
net/wireguard/crypto/poly1305.c:	ctx->num = 0;
net/wireguard/crypto/poly1305.c:	const size_t num = ctx->num % POLY1305_BLOCK_SIZE;
net/wireguard/crypto/poly1305.c:			memcpy(ctx->data + num, inp, rem);
net/wireguard/crypto/poly1305.c:			poly1305_blocks(ctx->opaque, ctx->data, POLY1305_BLOCK_SIZE, 1, have_simd);
net/wireguard/crypto/poly1305.c:			memcpy(ctx->data + num, inp, len);
net/wireguard/crypto/poly1305.c:			ctx->num = num + len;
net/wireguard/crypto/poly1305.c:		poly1305_blocks(ctx->opaque, inp, len, 1, have_simd);
net/wireguard/crypto/poly1305.c:		memcpy(ctx->data, inp, rem);
net/wireguard/crypto/poly1305.c:	ctx->num = rem;
net/wireguard/crypto/poly1305.c:	size_t num = ctx->num % POLY1305_BLOCK_SIZE;
net/wireguard/crypto/poly1305.c:		ctx->data[num++] = 1;   /* pad bit */
net/wireguard/crypto/poly1305.c:			ctx->data[num++] = 0;
net/wireguard/crypto/poly1305.c:		poly1305_blocks(ctx->opaque, ctx->data, POLY1305_BLOCK_SIZE, 0, have_simd);
net/wireguard/crypto/poly1305.c:	poly1305_emit(ctx->opaque, mac, ctx->nonce, have_simd);
net/ipc_router/ipc_router_core.c:	sub_log_ctx->log_ctx = ipc_log_context_create(
net/ipc_router/ipc_router_core.c:	if (!sub_log_ctx->log_ctx) {
net/ipc_router/ipc_router_core.c:	strlcpy(sub_log_ctx->log_ctx_name, name, LOG_CTX_NAME_LEN);
net/ipc_router/ipc_router_core.c:	INIT_LIST_HEAD(&sub_log_ctx->list);
net/ipc_router/ipc_router_core.c:	list_add_tail(&sub_log_ctx->list, &log_ctx_list);
net/ipc_router/ipc_router_core.c:	return sub_log_ctx->log_ctx;
net/ipc_router/ipc_router_core.c:		if (!strcmp(temp_log_ctx->log_ctx_name, sub_name)) {
net/ipc_router/ipc_router_core.c:			log_ctx = temp_log_ctx->log_ctx;
Binary file out/arch/arm64/boot/Image matches
Binary file out/fs/aio.o matches
Binary file out/fs/timerfd.o matches
Binary file out/fs/built-in.o matches
Binary file out/fs/eventfd.o matches
Binary file out/.tmp_vmlinux2 matches
Binary file out/kernel/events/core.o matches
Binary file out/kernel/events/built-in.o matches
Binary file out/kernel/built-in.o matches
Binary file out/vmlinux.o matches
Binary file out/vmlinux matches
Binary file out/.tmp_vmlinux1 matches
Binary file out/drivers/media/platform/msm/camera/built-in.o matches
Binary file out/drivers/media/platform/msm/camera/cam_core/cam_context.o matches
Binary file out/drivers/media/platform/msm/camera/cam_core/built-in.o matches
Binary file out/drivers/media/platform/msm/sde/built-in.o matches
Binary file out/drivers/media/platform/msm/sde/rotator/sde_rotator_dev.o matches
Binary file out/drivers/media/platform/msm/sde/rotator/sde_rotator_r3.o matches
Binary file out/drivers/media/platform/msm/sde/rotator/built-in.o matches
Binary file out/drivers/media/platform/msm/built-in.o matches
Binary file out/drivers/media/platform/built-in.o matches
Binary file out/drivers/media/v4l2-core/v4l2-mem2mem.o matches
Binary file out/drivers/media/v4l2-core/built-in.o matches
Binary file out/drivers/media/built-in.o matches
Binary file out/drivers/soc/qcom/glink.o matches
Binary file out/drivers/soc/qcom/built-in.o matches
Binary file out/drivers/soc/built-in.o matches
Binary file out/drivers/platform/msm/ipa/test/ipa_ut_framework.o matches
Binary file out/drivers/platform/msm/ipa/test/ipa_ut_mod.o matches
Binary file out/drivers/platform/msm/ipa/test/built-in.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/ipa.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/ipat.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/rmnet_ipa.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/ipa_uc.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/built-in.o matches
Binary file out/drivers/platform/msm/ipa/ipa_v3/ipa_pm.o matches
Binary file out/drivers/platform/msm/ipa/built-in.o matches
Binary file out/drivers/platform/msm/ipa/ipa_clients/ipa_wdi3.o matches
Binary file out/drivers/platform/msm/ipa/ipa_clients/ipa_usb.o matches
Binary file out/drivers/platform/msm/ipa/ipa_clients/odu_bridge.o matches
Binary file out/drivers/platform/msm/ipa/ipa_clients/built-in.o matches
Binary file out/drivers/platform/msm/built-in.o matches
Binary file out/drivers/platform/msm/gsi/gsi.o matches
Binary file out/drivers/platform/msm/gsi/built-in.o matches
Binary file out/drivers/platform/built-in.o matches
Binary file out/drivers/built-in.o matches
Binary file out/drivers/crypto/msm/qcrypto.o matches
Binary file out/drivers/crypto/msm/built-in.o matches
Binary file out/drivers/crypto/built-in.o matches
Binary file out/drivers/gpu/drm/msm/msm_drm.o matches
Binary file out/drivers/gpu/drm/msm/msm_fence.o matches
Binary file out/drivers/gpu/drm/msm/sde/sde_hw_reg_dma_v1_color_proc.o matches
Binary file out/drivers/gpu/drm/msm/sde/sde_hw_color_processing_v1_7.o matches
Binary file out/drivers/gpu/drm/msm/sde/sde_hw_color_proc_v4.o matches
Binary file out/drivers/gpu/drm/msm/built-in.o matches
Binary file out/drivers/gpu/drm/built-in.o matches
Binary file out/drivers/gpu/built-in.o matches
patch.patch: 		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, 0);
patch.patch: 		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, coeffs->c);
patch.patch:-			SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, (coeffs->r * r)/256);
patch.patch:-		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, coeffs->r);
patch.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF,
patch.patch:-			SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, (coeffs->g * g)/256);
patch.patch:-		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, coeffs->g);
patch.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF,
patch.patch:-			SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, (coeffs->b * b)/256);
patch.patch:-		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, coeffs->b);
patch.patch:+		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF,
patch.patch: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, coeffs->rg);
patch.patch: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, coeffs->rb);
patch.patch: 		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, coeffs->gb);
patch.patch: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, coeffs->rgb);
patch.patch: 	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, 0);
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, base + PCC_C_OFF, coeffs->c);
patch.patch~:-			SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, (coeffs->r * r)/256);
patch.patch~:-		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF, coeffs->r);
patch.patch~:+		SDE_REG_WRITE(&ctx->hw, base + PCC_R_OFF,
patch.patch~:-			SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, (coeffs->g * g)/256);
patch.patch~:-		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF, coeffs->g);
patch.patch~:+		SDE_REG_WRITE(&ctx->hw, base + PCC_G_OFF,
patch.patch~:-			SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, (coeffs->b * b)/256);
patch.patch~:-		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF, coeffs->b);
patch.patch~:+		SDE_REG_WRITE(&ctx->hw, base + PCC_B_OFF,
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RG_OFF, coeffs->rg);
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RB_OFF, coeffs->rb);
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, base + PCC_GB_OFF, coeffs->gb);
patch.patch~: 		SDE_REG_WRITE(&ctx->hw, base + PCC_RGB_OFF, coeffs->rgb);
patch.patch~: 	SDE_REG_WRITE(&ctx->hw, ctx->cap->sblk->pcc.base, PCC_EN);
samples/bpf/trace_event_kern.c:	if (ctx->sample_period < 10000)
samples/bpf/trace_event_kern.c:		bpf_trace_printk(fmt, sizeof(fmt), cpu, ctx->sample_period,
samples/bpf/trace_event_kern.c:				 PT_REGS_IP(&ctx->regs));
samples/bpf/xdp2_kern.c:	void *data_end = (void *)(long)ctx->data_end;
samples/bpf/xdp2_kern.c:	void *data = (void *)(long)ctx->data;
samples/bpf/offwaketime_kern.c:	u32 pid = ctx->prev_pid;
samples/bpf/sampleip_kern.c:	ip = PT_REGS_IP(&ctx->regs);
samples/bpf/xdp1_kern.c:	void *data_end = (void *)(long)ctx->data_end;
samples/bpf/xdp1_kern.c:	void *data = (void *)(long)ctx->data;
samples/seccomp/bpf-direct.c:	syscall = ctx->uc_mcontext.gregs[REG_SYSCALL];
samples/seccomp/bpf-direct.c:	buf = (char *) ctx->uc_mcontext.gregs[REG_ARG1];
samples/seccomp/bpf-direct.c:	len = (size_t) ctx->uc_mcontext.gregs[REG_ARG2];
samples/seccomp/bpf-direct.c:	if (ctx->uc_mcontext.gregs[REG_ARG0] != STDERR_FILENO)
samples/seccomp/bpf-direct.c:	ctx->uc_mcontext.gregs[REG_RESULT] = -1;
samples/seccomp/bpf-direct.c:		ctx->uc_mcontext.gregs[REG_RESULT] = bytes;
scripts/mod/sumversion.c:	le32_to_cpu_array(ctx->block, sizeof(ctx->block) / sizeof(uint32_t));
scripts/mod/sumversion.c:	md4_transform(ctx->hash, ctx->block);
scripts/mod/sumversion.c:	mctx->hash[0] = 0x67452301;
scripts/mod/sumversion.c:	mctx->hash[1] = 0xefcdab89;
scripts/mod/sumversion.c:	mctx->hash[2] = 0x98badcfe;
scripts/mod/sumversion.c:	mctx->hash[3] = 0x10325476;
scripts/mod/sumversion.c:	mctx->byte_count = 0;
scripts/mod/sumversion.c:	const uint32_t avail = sizeof(mctx->block) - (mctx->byte_count & 0x3f);
scripts/mod/sumversion.c:	mctx->byte_count += len;
scripts/mod/sumversion.c:		memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
scripts/mod/sumversion.c:	memcpy((char *)mctx->block + (sizeof(mctx->block) - avail),
scripts/mod/sumversion.c:	while (len >= sizeof(mctx->block)) {
scripts/mod/sumversion.c:		memcpy(mctx->block, data, sizeof(mctx->block));
scripts/mod/sumversion.c:		data += sizeof(mctx->block);
scripts/mod/sumversion.c:		len -= sizeof(mctx->block);
scripts/mod/sumversion.c:	memcpy(mctx->block, data, len);
scripts/mod/sumversion.c:	const unsigned int offset = mctx->byte_count & 0x3f;
scripts/mod/sumversion.c:	char *p = (char *)mctx->block + offset;
scripts/mod/sumversion.c:		p = (char *)mctx->block;
scripts/mod/sumversion.c:	mctx->block[14] = mctx->byte_count << 3;
scripts/mod/sumversion.c:	mctx->block[15] = mctx->byte_count >> 29;
scripts/mod/sumversion.c:	le32_to_cpu_array(mctx->block, (sizeof(mctx->block) -
scripts/mod/sumversion.c:	md4_transform(mctx->hash, mctx->block);
scripts/mod/sumversion.c:	cpu_to_le32_array(mctx->hash, sizeof(mctx->hash) / sizeof(uint32_t));
scripts/mod/sumversion.c:		 mctx->hash[0], mctx->hash[1], mctx->hash[2], mctx->hash[3]);
security/selinux/xfrm.c:		(ctx->ctx_doi == XFRM_SC_DOI_LSM) &&
security/selinux/xfrm.c:		(ctx->ctx_alg == XFRM_SC_ALG_SELINUX));
security/selinux/xfrm.c:	    uctx->ctx_doi != XFRM_SC_DOI_LSM ||
security/selinux/xfrm.c:	    uctx->ctx_alg != XFRM_SC_ALG_SELINUX)
security/selinux/xfrm.c:	str_len = uctx->ctx_len;
security/selinux/xfrm.c:	ctx->ctx_doi = XFRM_SC_DOI_LSM;
security/selinux/xfrm.c:	ctx->ctx_alg = XFRM_SC_ALG_SELINUX;
security/selinux/xfrm.c:	ctx->ctx_len = str_len;
security/selinux/xfrm.c:	memcpy(ctx->ctx_str, &uctx[1], str_len);
security/selinux/xfrm.c:	ctx->ctx_str[str_len] = '\0';
security/selinux/xfrm.c:	rc = security_context_to_sid(ctx->ctx_str, str_len, &ctx->ctx_sid, gfp);
security/selinux/xfrm.c:	rc = avc_has_perm(tsec->sid, ctx->ctx_sid,
security/selinux/xfrm.c:	return avc_has_perm(tsec->sid, ctx->ctx_sid,
security/selinux/xfrm.c:	rc = avc_has_perm(fl_secid, ctx->ctx_sid,
security/selinux/xfrm.c:					sid_session = ctx->ctx_sid;
security/selinux/xfrm.c:				} else if (sid_session != ctx->ctx_sid) {
security/selinux/xfrm.c:	new_ctx = kmemdup(old_ctx, sizeof(*old_ctx) + old_ctx->ctx_len,
security/selinux/xfrm.c:	ctx->ctx_doi = XFRM_SC_DOI_LSM;
security/selinux/xfrm.c:	ctx->ctx_alg = XFRM_SC_ALG_SELINUX;
security/selinux/xfrm.c:	ctx->ctx_sid = secid;
security/selinux/xfrm.c:	ctx->ctx_len = str_len;
security/selinux/xfrm.c:	memcpy(ctx->ctx_str, ctx_str, str_len);
security/selinux/xfrm.c:				peer_sid = ctx->ctx_sid;
security/selinux/ss/services.c:	ctx->user = usrdatum->value;
security/selinux/ss/services.c:	ctx->role = role->value;
security/selinux/ss/services.c:	ctx->type = typdatum->value;
security/selinux/ss/services.c:		ctx_new.user = ctx->user;
security/selinux/ss/services.c:		ctx_new.role = ctx->role;
security/selinux/ss/services.c:		ctx_new.type = ctx->type;
security/selinux/ss/services.c:	secattr->domain = kstrdup(sym_name(&policydb, SYM_TYPES, ctx->type - 1),
security/keys/keyring.c:	       key->type->name, key->serial, ctx->count, ctx->buflen);
security/keys/keyring.c:	if (ctx->count >= ctx->buflen)
security/keys/keyring.c:	ret = put_user(key->serial, ctx->buffer);
security/keys/keyring.c:	ctx->buffer++;
security/keys/keyring.c:	ctx->count += sizeof(key->serial);
security/keys/keyring.c:	if (key->type != ctx->index_key.type) {
security/keys/keyring.c:	if (ctx->flags & KEYRING_SEARCH_DO_STATE_CHECK) {
security/keys/keyring.c:			ctx->result = ERR_PTR(-EKEYREVOKED);
security/keys/keyring.c:			kleave(" = %d [invrev]", ctx->skipped_ret);
security/keys/keyring.c:		if (key->expiry && ctx->now.tv_sec >= key->expiry) {
security/keys/keyring.c:			if (!(ctx->flags & KEYRING_SEARCH_SKIP_EXPIRED))
security/keys/keyring.c:				ctx->result = ERR_PTR(-EKEYEXPIRED);
security/keys/keyring.c:			kleave(" = %d [expire]", ctx->skipped_ret);
security/keys/keyring.c:	if (!ctx->match_data.cmp(key, &ctx->match_data)) {
security/keys/keyring.c:	if (!(ctx->flags & KEYRING_SEARCH_NO_CHECK_PERM) &&
security/keys/keyring.c:	    key_task_permission(make_key_ref(key, ctx->possessed),
security/keys/keyring.c:				ctx->cred, KEY_NEED_SEARCH) < 0) {
security/keys/keyring.c:		ctx->result = ERR_PTR(-EACCES);
security/keys/keyring.c:		kleave(" = %d [!perm]", ctx->skipped_ret);
security/keys/keyring.c:	if (ctx->flags & KEYRING_SEARCH_DO_STATE_CHECK) {
security/keys/keyring.c:			ctx->result = ERR_PTR(state);
security/keys/keyring.c:			kleave(" = %d [neg]", ctx->skipped_ret);
security/keys/keyring.c:	ctx->result = make_key_ref(key, ctx->possessed);
security/keys/keyring.c:	return ctx->skipped_ret;
security/keys/keyring.c:	if (ctx->match_data.lookup_type == KEYRING_SEARCH_LOOKUP_DIRECT) {
security/keys/keyring.c:					  &ctx->index_key);
security/keys/keyring.c:		return object ? ctx->iterator(object, ctx) : 0;
security/keys/keyring.c:	return assoc_array_iterate(&keyring->keys, ctx->iterator, ctx);
security/keys/keyring.c:	       ctx->index_key.type->name,
security/keys/keyring.c:	       ctx->index_key.description);
security/keys/keyring.c:	BUG_ON((ctx->flags & STATE_CHECKS) == 0 ||
security/keys/keyring.c:	       (ctx->flags & STATE_CHECKS) == STATE_CHECKS);
security/keys/keyring.c:	if (ctx->index_key.description)
security/keys/keyring.c:		ctx->index_key.desc_len = strlen(ctx->index_key.description);
security/keys/keyring.c:	if (ctx->match_data.lookup_type == KEYRING_SEARCH_LOOKUP_ITERATE ||
security/keys/keyring.c:	    keyring_compare_object(keyring, &ctx->index_key)) {
security/keys/keyring.c:		ctx->skipped_ret = 2;
security/keys/keyring.c:		switch (ctx->iterator(keyring_key_to_ptr(keyring), ctx)) {
security/keys/keyring.c:	ctx->skipped_ret = 0;
security/keys/keyring.c:			if (ctx->flags & KEYRING_SEARCH_DETECT_TOO_DEEP) {
security/keys/keyring.c:				ctx->result = ERR_PTR(-ELOOP);
security/keys/keyring.c:		if (!(ctx->flags & KEYRING_SEARCH_NO_CHECK_PERM) &&
security/keys/keyring.c:		    key_task_permission(make_key_ref(key, ctx->possessed),
security/keys/keyring.c:					ctx->cred, KEY_NEED_SEARCH) < 0)
security/keys/keyring.c:	key = key_ref_to_ptr(ctx->result);
security/keys/keyring.c:	if (!(ctx->flags & KEYRING_SEARCH_NO_UPDATE_TIME)) {
security/keys/keyring.c:		key->last_used_at = ctx->now.tv_sec;
security/keys/keyring.c:		keyring->last_used_at = ctx->now.tv_sec;
security/keys/keyring.c:			stack[--sp].keyring->last_used_at = ctx->now.tv_sec;
security/keys/keyring.c:	ctx->iterator = keyring_search_iterator;
security/keys/keyring.c:	ctx->possessed = is_key_possessed(keyring_ref);
security/keys/keyring.c:	ctx->result = ERR_PTR(-EAGAIN);
security/keys/keyring.c:	if (!(ctx->flags & KEYRING_SEARCH_NO_CHECK_PERM)) {
security/keys/keyring.c:		err = key_task_permission(keyring_ref, ctx->cred, KEY_NEED_SEARCH);
security/keys/keyring.c:	ctx->now = current_kernel_time();
security/keys/keyring.c:		__key_get(key_ref_to_ptr(ctx->result));
security/keys/keyring.c:	return ctx->result;
security/keys/keyring.c:	if (key != ctx->match_data.raw_data)
security/keys/keyring.c:	ctx->result = ERR_PTR(-EDEADLK);
security/keys/request_key.c:	       ctx->index_key.type->name, ctx->index_key.description);
security/keys/request_key.c:	if (ctx->index_key.type->read)
security/keys/request_key.c:	if (ctx->index_key.type == &key_type_keyring ||
security/keys/request_key.c:	    ctx->index_key.type->update)
security/keys/request_key.c:	key = key_alloc(ctx->index_key.type, ctx->index_key.description,
security/keys/request_key.c:			ctx->cred->fsuid, ctx->cred->fsgid, ctx->cred,
security/keys/request_key.c:		ret = __key_link_begin(dest_keyring, &ctx->index_key, &edit);
security/keys/request_key.c:		__key_link_end(dest_keyring, &ctx->index_key, edit);
security/keys/request_key.c:		__key_link_end(dest_keyring, &ctx->index_key, edit);
security/keys/request_key.c:	if (ctx->index_key.type == &key_type_keyring)
security/keys/process_keys.c:	if (ctx->cred->thread_keyring) {
security/keys/process_keys.c:			make_key_ref(ctx->cred->thread_keyring, 1), ctx);
security/keys/process_keys.c:	if (ctx->cred->process_keyring) {
security/keys/process_keys.c:			make_key_ref(ctx->cred->process_keyring, 1), ctx);
security/keys/process_keys.c:	if (ctx->cred->session_keyring) {
security/keys/process_keys.c:			make_key_ref(rcu_dereference(ctx->cred->session_keyring), 1),
security/keys/process_keys.c:	else if (ctx->cred->user->session_keyring) {
security/keys/process_keys.c:			make_key_ref(ctx->cred->user->session_keyring, 1),
security/keys/process_keys.c:	if (ctx->cred->request_key_auth &&
security/keys/process_keys.c:	    ctx->cred == current_cred() &&
security/keys/process_keys.c:	    ctx->index_key.type != &key_type_request_key_auth
security/keys/process_keys.c:		const struct cred *cred = ctx->cred;
security/keys/process_keys.c:		if (key_validate(ctx->cred->request_key_auth) == 0) {
security/keys/process_keys.c:			rka = ctx->cred->request_key_auth->payload.data[0];
security/keys/process_keys.c:			ctx->cred = rka->cred;
security/keys/process_keys.c:			ctx->cred = cred;
sound/usb/endpoint.c:		ep->retire_data_urb(ep->data_subs, urb_ctx->urb);
sound/usb/endpoint.c:	struct urb *urb = urb_ctx->urb;
sound/usb/endpoint.c:	struct urb *urb = ctx->urb;
sound/usb/endpoint.c:	for (i = 0; i < ctx->packets; ++i) {
sound/usb/endpoint.c:		if (ctx->packet_size[i])
sound/usb/endpoint.c:			counts = ctx->packet_size[i];
sound/usb/endpoint.c:	urb->number_of_packets = ctx->packets;
sound/usb/endpoint.c:	urb->transfer_buffer_length = offs * ep->stride + ctx->packets * extra;
sound/usb/endpoint.c:	struct urb *urb = ctx->urb;
sound/usb/endpoint.c:	struct urb *urb = urb_ctx->urb;
sound/usb/endpoint.c:		for (i = 0; i < urb_ctx->packets; i++) {
sound/usb/endpoint.c:		urb->number_of_packets = urb_ctx->packets;
sound/usb/endpoint.c:		list_del_init(&ctx->ready_list);
sound/usb/endpoint.c:		urb = ctx->urb;
sound/usb/endpoint.c:			ctx->packet_size[i] = packet->packet_size[i];
sound/usb/endpoint.c:		err = usb_submit_urb(ctx->urb, GFP_ATOMIC);
sound/usb/endpoint.c:				ctx->index, err, ctx->urb);
sound/usb/endpoint.c:			set_bit(ctx->index, &ep->active_mask);
sound/usb/endpoint.c:	struct snd_usb_endpoint *ep = ctx->ep;
sound/usb/endpoint.c:			list_add_tail(&ctx->ready_list, &ep->ready_playback_urbs);
sound/usb/endpoint.c:	clear_bit(ctx->index, &ep->active_mask);
sound/usb/endpoint.c:			list_add_tail(&ctx->ready_list, &ep->ready_playback_urbs);
sound/usb/endpoint.c:		for (i = 0; i < in_ctx->packets; i++)
sound/usb/endpoint.c:		out_packet->packets = in_ctx->packets;
sound/usb/endpoint.c:		for (i = 0; i < in_ctx->packets; i++) {
sound/usb/pcm.c:	for (i = 0; i < ctx->packets; i++) {
sound/usb/pcm.c:		if (ctx->packet_size[i])
sound/usb/pcm.c:			counts = ctx->packet_size[i];
sound/usb/pcm.c:				if (i < ctx->packets) {
sound/core/seq/oss/seq_oss_readq.c:	return snd_seq_oss_readq_puts(ctx->readq, ctx->dev, buf, count);
sound/soc/au1x/i2sc.c:	return __raw_readl(ctx->mmio + reg);
sound/soc/au1x/i2sc.c:	__raw_writel(v, ctx->mmio + reg);
sound/soc/au1x/i2sc.c:	c = ctx->cfg;
sound/soc/au1x/i2sc.c:	ctx->cfg = c;
sound/soc/au1x/i2sc.c:		ctx->cfg |= (stype == PCM_TX) ? CFG_TN : CFG_RN;
sound/soc/au1x/i2sc.c:		WR(ctx, I2S_CFG, ctx->cfg);
sound/soc/au1x/i2sc.c:		ctx->cfg &= ~((stype == PCM_TX) ? CFG_TN : CFG_RN);
sound/soc/au1x/i2sc.c:		WR(ctx, I2S_CFG, ctx->cfg);
sound/soc/au1x/i2sc.c:	ctx->cfg &= ~CFG_SZ_MASK;
sound/soc/au1x/i2sc.c:	ctx->cfg |= v;
sound/soc/au1x/i2sc.c:	snd_soc_dai_set_dma_data(dai, substream, &ctx->dmaids[0]);
sound/soc/au1x/i2sc.c:	ctx->mmio = devm_ioremap_nocache(&pdev->dev, iores->start,
sound/soc/au1x/i2sc.c:	if (!ctx->mmio)
sound/soc/au1x/i2sc.c:	ctx->dmaids[SNDRV_PCM_STREAM_PLAYBACK] = dmares->start;
sound/soc/au1x/i2sc.c:	ctx->dmaids[SNDRV_PCM_STREAM_CAPTURE] = dmares->start;
sound/soc/au1x/dma.c:	return &(ctx->stream[ss->stream]);
sound/soc/au1x/dma.c:	ctx->stream[s].dma = request_au1000_dma(dmaids[s], name,
sound/soc/au1x/dma.c:					&ctx->stream[s]);
sound/soc/au1x/dma.c:	set_dma_mode(ctx->stream[s].dma,
sound/soc/au1x/dma.c:		     get_dma_mode(ctx->stream[s].dma) & ~DMA_NC);
sound/soc/au1x/dma.c:	ctx->stream[s].substream = substream;
sound/soc/au1x/dma.c:	ctx->stream[s].buffer = NULL;
sound/soc/au1x/dma.c:	ctx->stream[stype].substream = NULL;
sound/soc/au1x/dma.c:	free_au1000_dma(ctx->stream[stype].dma);
sound/soc/au1x/ac97c.c:	return __raw_readl(ctx->mmio + reg);
sound/soc/au1x/ac97c.c:	__raw_writel(v, ctx->mmio + reg);
sound/soc/au1x/ac97c.c:		mutex_lock(&ctx->lock);
sound/soc/au1x/ac97c.c:		mutex_unlock(&ctx->lock);
sound/soc/au1x/ac97c.c:		mutex_lock(&ctx->lock);
sound/soc/au1x/ac97c.c:		mutex_unlock(&ctx->lock);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg | CFG_SG | CFG_SN);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg | CFG_SG);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg | CFG_RS);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg);
sound/soc/au1x/ac97c.c:	snd_soc_dai_set_dma_data(dai, substream, &ctx->dmaids[0]);
sound/soc/au1x/ac97c.c:	mutex_init(&ctx->lock);
sound/soc/au1x/ac97c.c:	ctx->mmio = devm_ioremap_nocache(&pdev->dev, iores->start,
sound/soc/au1x/ac97c.c:	if (!ctx->mmio)
sound/soc/au1x/ac97c.c:	ctx->dmaids[SNDRV_PCM_STREAM_PLAYBACK] = dmares->start;
sound/soc/au1x/ac97c.c:	ctx->dmaids[SNDRV_PCM_STREAM_CAPTURE] = dmares->start;
sound/soc/au1x/ac97c.c:	ctx->cfg = CFG_RC(3) | CFG_XS(3);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg);
sound/soc/au1x/ac97c.c:	WR(ctx, AC97_CONFIG, ctx->cfg);
sound/soc/intel/common/sst-dsp.c:	dev_dbg(ctx->dev, "FW Poll Status: reg=%#x %s %s\n", reg, operation,
sound/soc/intel/boards/cht_bsw_rt5645.c:		if (ctx->mclk) {
sound/soc/intel/boards/cht_bsw_rt5645.c:			ret = clk_prepare_enable(ctx->mclk);
sound/soc/intel/boards/cht_bsw_rt5645.c:		if (ctx->mclk)
sound/soc/intel/boards/cht_bsw_rt5645.c:			clk_disable_unprepare(ctx->mclk);
sound/soc/intel/boards/cht_bsw_rt5645.c:	if (ctx->acpi_card->codec_type == CODEC_TYPE_RT5650)
sound/soc/intel/boards/cht_bsw_rt5645.c:				    jack_type, &ctx->jack,
sound/soc/intel/boards/cht_bsw_rt5645.c:	rt5645_set_jack_detect(codec, &ctx->jack, &ctx->jack, &ctx->jack);
sound/soc/intel/boards/cht_bsw_rt5645.c:	if (ctx->mclk) {
sound/soc/intel/boards/cht_bsw_rt5645.c:		ret = clk_prepare_enable(ctx->mclk);
sound/soc/intel/boards/cht_bsw_rt5645.c:			clk_disable_unprepare(ctx->mclk);
sound/soc/intel/boards/cht_bsw_rt5645.c:		ret = clk_set_rate(ctx->mclk, CHT_PLAT_CLK_3_HZ);
sound/soc/intel/boards/skl_nau88l25_max98357a.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_max98357a.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_max98357a.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_max98357a.c:	list_for_each_entry(pcm, &ctx->hdmi_pcm_list, head) {
sound/soc/intel/boards/skl_nau88l25_max98357a.c:	INIT_LIST_HEAD(&ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_ssm4567.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_ssm4567.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_ssm4567.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_nau88l25_ssm4567.c:	list_for_each_entry(pcm, &ctx->hdmi_pcm_list, head) {
sound/soc/intel/boards/skl_nau88l25_ssm4567.c:	INIT_LIST_HEAD(&ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_rt286.c:	list_add_tail(&pcm->head, &ctx->hdmi_pcm_list);
sound/soc/intel/boards/skl_rt286.c:	list_for_each_entry(pcm, &ctx->hdmi_pcm_list, head) {
sound/soc/intel/boards/skl_rt286.c:	INIT_LIST_HEAD(&ctx->hdmi_pcm_list);
sound/soc/intel/boards/cht_bsw_max98090_ti.c:	struct snd_soc_jack *jack = &ctx->jack;
sound/soc/intel/boards/cht_bsw_max98090_ti.c:	if (ctx->ts3a227e_present)
sound/soc/intel/boards/cht_bsw_max98090_ti.c:	if (ctx->ts3a227e_present)
sound/soc/intel/boards/cht_bsw_max98090_ti.c:	return ts3a227e_enable_jack_detect(component, &ctx->jack);
sound/soc/intel/boards/mfld_machine.c:	mfld_jack_check(mc_drv_ctx->interrupt_status);
sound/soc/intel/boards/mfld_machine.c:	mc_drv_ctx->int_base = devm_ioremap_nocache(&pdev->dev, irq_mem->start,
sound/soc/intel/boards/mfld_machine.c:	if (!mc_drv_ctx->int_base) {
sound/soc/intel/skylake/skl-sst.c:	ret = ctx->cl_dev.ops.cl_copy_to_dmabuf(ctx, basefw, base_fw_size);
sound/soc/intel/skylake/skl-sst.c:	ctx->cl_dev.ops.cl_stop_dma(ctx);
sound/soc/intel/skylake/skl-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst.c:	if (ctx->fw == NULL) {
sound/soc/intel/skylake/skl-sst.c:		ret = request_firmware(&ctx->fw, ctx->fw_name, ctx->dev);
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "Request firmware failed %d\n", ret);
sound/soc/intel/skylake/skl-sst.c:		ret = snd_skl_parse_uuids(ctx, ctx->fw, SKL_ADSP_FW_BIN_HDR_OFFSET, 0);
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "UUID parsing err: %d\n", ret);
sound/soc/intel/skylake/skl-sst.c:			release_firmware(ctx->fw);
sound/soc/intel/skylake/skl-sst.c:	stripped_fw.data = ctx->fw->data;
sound/soc/intel/skylake/skl-sst.c:	stripped_fw.size = ctx->fw->size;
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Boot dsp core failed ret: %d\n", ret);
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "CL dma prepare failed : %d\n", ret);
sound/soc/intel/skylake/skl-sst.c:			dev_dbg(ctx->dev,
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Transfer firmware failed%d\n", ret);
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "DSP boot failed, FW Ready timed-out\n");
sound/soc/intel/skylake/skl-sst.c:		dev_dbg(ctx->dev, "Download firmware successful%d\n", ret);
sound/soc/intel/skylake/skl-sst.c:	ctx->cl_dev.ops.cl_cleanup_controller(ctx);
sound/soc/intel/skylake/skl-sst.c:	release_firmware(ctx->fw);
sound/soc/intel/skylake/skl-sst.c:	ctx->fw = NULL;
sound/soc/intel/skylake/skl-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "unable to load firmware\n");
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "Failed to set dsp to D0:core id= %d\n",
sound/soc/intel/skylake/skl-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "set Dx core %d fail: %d\n", core_id, ret);
sound/soc/intel/skylake/skl-sst.c:		ctx->cl_dev.ops.cl_cleanup_controller(ctx);
sound/soc/intel/skylake/skl-sst.c:	list_for_each_entry(module, &ctx->module_list, list) {
sound/soc/intel/skylake/skl-sst.c:	list_for_each_entry(module, &ctx->module_list, list) {
sound/soc/intel/skylake/skl-sst.c:	ret = request_firmware(&fw, mod_name, ctx->dev);
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Request Module %s failed :%d\n",
sound/soc/intel/skylake/skl-sst.c:	skl_module = devm_kzalloc(ctx->dev, sizeof(*skl_module), GFP_KERNEL);
sound/soc/intel/skylake/skl-sst.c:	skl_module->mod_info = devm_kzalloc(ctx->dev, size, GFP_KERNEL);
sound/soc/intel/skylake/skl-sst.c:	list_add(&skl_module->list, &ctx->module_list);
sound/soc/intel/skylake/skl-sst.c:	if (list_empty(&ctx->module_list)) {
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Module list is empty\n");
sound/soc/intel/skylake/skl-sst.c:	list_for_each_entry(module, &ctx->module_list, list) {
sound/soc/intel/skylake/skl-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst.c:	ret = ctx->cl_dev.ops.cl_copy_to_dmabuf(ctx, module->fw->data,
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Failed to Load module: %d\n", ret);
sound/soc/intel/skylake/skl-sst.c:	ctx->cl_dev.ops.cl_stop_dma(ctx);
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "Failed to Load module\n");
sound/soc/intel/skylake/skl-sst.c:			dev_err(ctx->dev, "Failed to Load module\n");
sound/soc/intel/skylake/skl-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Module bad usage cnt!:%d\n", usage_cnt);
sound/soc/intel/skylake/skl-sst.c:		dev_err(ctx->dev, "Failed to UnLoad module\n");
sound/soc/intel/skylake/skl-sst.c:	if (list_empty(&ctx->module_list))
sound/soc/intel/skylake/skl-sst.c:	list_for_each_entry(module, &ctx->module_list, list) {
sound/soc/intel/skylake/skl-sst.c:	if (list_empty(&ctx->module_list))
sound/soc/intel/skylake/skl-sst.c:	list_for_each_entry_safe(module, tmp, &ctx->module_list, list) {
sound/soc/intel/skylake/skl-sst.c:	struct sst_dsp *sst = ctx->dsp;
sound/soc/intel/skylake/skl-sst.c:	ctx->is_first_boot = false;
sound/soc/intel/skylake/skl-sst.c:	if (ctx->dsp->fw)
sound/soc/intel/skylake/skl-sst.c:		release_firmware(ctx->dsp->fw);
sound/soc/intel/skylake/skl-sst.c:	skl_clear_module_table(ctx->dsp);
sound/soc/intel/skylake/skl-sst.c:	skl_ipc_free(&ctx->ipc);
sound/soc/intel/skylake/skl-sst.c:	ctx->dsp->ops->free(ctx->dsp);
sound/soc/intel/skylake/skl-sst.c:	if (ctx->boot_complete) {
sound/soc/intel/skylake/skl-sst.c:		ctx->dsp->cl_dev.ops.cl_cleanup_controller(ctx->dsp);
sound/soc/intel/skylake/skl-sst.c:		skl_cldma_int_disable(ctx->dsp);
sound/soc/intel/skylake/skl-sst-dsp.c:	mutex_lock(&ctx->mutex);
sound/soc/intel/skylake/skl-sst-dsp.c:	ctx->sst_state = state;
sound/soc/intel/skylake/skl-sst-dsp.c:	mutex_unlock(&ctx->mutex);
sound/soc/intel/skylake/skl-sst-dsp.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst-dsp.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "DSP enabled cores mask = %x\n", en_cores_mask);
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "Set reset state failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "In %s\n", __func__);
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "Unset reset state failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "DSP core(s) enabled? %d : core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "unstall/run core: core_mask = %x\n", core_mask);
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "DSP start core failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "DSP core power up failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "dsp core power up failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "dsp core reset failed: core_mask %x\n",
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "dsp core power down fail mask %x: %d\n",
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "dsp core disable fail mask %x: %d\n",
sound/soc/intel/skylake/skl-sst-dsp.c:			dev_err(ctx->dev, "dsp core0 reset fail: %d\n", ret);
sound/soc/intel/skylake/skl-sst-dsp.c:			dev_err(ctx->dev, "dsp core0 start fail: %d\n", ret);
sound/soc/intel/skylake/skl-sst-dsp.c:			dev_err(ctx->dev, "dsp core0 disable fail: %d\n", ret);
sound/soc/intel/skylake/skl-sst-dsp.c:	spin_lock(&ctx->spinlock);
sound/soc/intel/skylake/skl-sst-dsp.c:	ctx->intr_status = val;
sound/soc/intel/skylake/skl-sst-dsp.c:		spin_unlock(&ctx->spinlock);
sound/soc/intel/skylake/skl-sst-dsp.c:	spin_unlock(&ctx->spinlock);
sound/soc/intel/skylake/skl-sst-dsp.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "invalid core id: %d\n", core_id);
sound/soc/intel/skylake/skl-sst-dsp.c:		ret = ctx->fw_ops.set_state_D0(ctx, core_id);
sound/soc/intel/skylake/skl-sst-dsp.c:			dev_err(ctx->dev, "unable to get core%d\n", core_id);
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "core id %d state %d usage_count %d\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst-dsp.c:		dev_err(ctx->dev, "invalid core id: %d\n", core_id);
sound/soc/intel/skylake/skl-sst-dsp.c:		ret = ctx->fw_ops.set_state_D3(ctx, core_id);
sound/soc/intel/skylake/skl-sst-dsp.c:			dev_err(ctx->dev, "unable to put core %d: %d\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	dev_dbg(ctx->dev, "core id %d state %d usage_count %d\n",
sound/soc/intel/skylake/skl-sst-dsp.c:	return (ctx->sst_state == SKL_DSP_RUNNING);
sound/soc/intel/skylake/skl-messages.c:	skl_ipc_set_large_config(&ctx->ipc, &msg, (u32 *)&mask);
sound/soc/intel/skylake/skl-messages.c:	if (ctx->dsp->addr.lpe)
sound/soc/intel/skylake/skl-messages.c:		iounmap(ctx->dsp->addr.lpe);
sound/soc/intel/skylake/skl-messages.c:	ret = skl_dsp_sleep(ctx->dsp);
sound/soc/intel/skylake/skl-messages.c:	ret = skl_dsp_wake(ctx->dsp);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "bit_depth=%x valid_bd=%x ch_config=%x\n",
sound/soc/intel/skylake/skl-messages.c:	err = skl_ipc_set_large_config(&ctx->ipc, &msg, (u32 *)dma_ctrl);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "copier out format chan=%d fre=%d bitdepth=%d\n",
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "Module type=%d config size: %d bytes\n",
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: module_id = %d instance=%d\n", __func__,
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Pipe not created state= %d pipe_id= %d\n",
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to set module format ret=%d\n", ret);
sound/soc/intel/skylake/skl-messages.c:	ret = skl_ipc_init_instance(&ctx->ipc, &msg, param_data);
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to init instance ret=%d\n", ret);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: src module_id = %d  src_instance=%d\n",
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: dst_module=%d dst_instacne=%d\n", __func__,
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "src_module state = %d dst module state = %d\n",
sound/soc/intel/skylake/skl-messages.c:	ret = skl_ipc_bind_unbind(&ctx->ipc, &msg);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "src queue = %d dst queue =%d\n",
sound/soc/intel/skylake/skl-messages.c:	ret = skl_ipc_bind_unbind(&ctx->ipc, &msg);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: pipe_satate = %d\n", __func__, state);
sound/soc/intel/skylake/skl-messages.c:	return skl_ipc_set_pipeline_state(&ctx->ipc, pipe->ppl_id, state);
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: pipe_id = %d\n", __func__, pipe->ppl_id);
sound/soc/intel/skylake/skl-messages.c:	ret = skl_ipc_create_pipeline(&ctx->ipc, pipe->memory_pages,
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to create pipeline\n");
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: pipe = %d\n", __func__, pipe->ppl_id);
sound/soc/intel/skylake/skl-messages.c:			dev_err(ctx->dev, "Failed to stop pipeline\n");
sound/soc/intel/skylake/skl-messages.c:	ret = skl_ipc_delete_pipeline(&ctx->ipc, pipe->ppl_id);
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to delete pipeline\n");
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "%s: pipe = %d\n", __func__, pipe->ppl_id);
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to pause pipe\n");
sound/soc/intel/skylake/skl-messages.c:		dev_err(ctx->dev, "Failed to start pipe\n");
sound/soc/intel/skylake/skl-messages.c:	dev_dbg(ctx->dev, "In %s pipe=%d\n", __func__, pipe->ppl_id);
sound/soc/intel/skylake/skl-messages.c:		dev_dbg(ctx->dev, "Failed to stop pipe\n");
sound/soc/intel/skylake/skl-messages.c:		dev_dbg(ctx->dev, "Failed to reset pipe ret=%d\n", ret);
sound/soc/intel/skylake/skl-messages.c:	return skl_ipc_set_large_config(&ctx->ipc, &msg, params);
sound/soc/intel/skylake/skl-messages.c:	return skl_ipc_get_large_config(&ctx->ipc, &msg, params);
sound/soc/intel/skylake/bxt-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/bxt-sst.c:		ret = request_firmware(&fw, minfo->lib[i].name, ctx->dev);
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Request lib %s failed:%d\n",
sound/soc/intel/skylake/bxt-sst.c:		stream_tag = ctx->dsp_ops.prepare(ctx->dev, 0x40,
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Lib prepare DMA err: %x\n",
sound/soc/intel/skylake/bxt-sst.c:		ctx->dsp_ops.trigger(ctx->dev, true, stream_tag);
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "IPC Load Lib for %s fail: %d\n",
sound/soc/intel/skylake/bxt-sst.c:		ctx->dsp_ops.trigger(ctx->dev, false, stream_tag);
sound/soc/intel/skylake/bxt-sst.c:		ctx->dsp_ops.cleanup(ctx->dev, &dmab, stream_tag);
sound/soc/intel/skylake/bxt-sst.c:	stream_tag = ctx->dsp_ops.prepare(ctx->dev, 0x40, fwsize, &ctx->dmab);
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Failed to prepare DMA FW loading err: %x\n",
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp_ops.stream_tag = stream_tag;
sound/soc/intel/skylake/bxt-sst.c:	memcpy(ctx->dmab.area, fwdata, fwsize);
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "dsp core0/1 power up failed\n");
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Start dsp core failed ret: %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:		dev_info(ctx->dev, "Waiting for HIPCIE done, reg: 0x%x\n", reg);
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "dsp core1 power down failed\n");
sound/soc/intel/skylake/bxt-sst.c:			dev_info(ctx->dev, "ROM loaded, continue FW loading\n");
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Timeout for ROM init, HIPCIE: 0x%x\n", reg);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp_ops.cleanup(ctx->dev, &ctx->dmab, stream_tag);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp_ops.trigger(ctx->dev, true, ctx->dsp_ops.stream_tag);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp_ops.trigger(ctx->dev, false, ctx->dsp_ops.stream_tag);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp_ops.cleanup(ctx->dev, &ctx->dmab, ctx->dsp_ops.stream_tag);
sound/soc/intel/skylake/bxt-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/bxt-sst.c:	ret = request_firmware(&ctx->fw, ctx->fw_name, ctx->dev);
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Request firmware failed %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:	if (ctx->fw == NULL)
sound/soc/intel/skylake/bxt-sst.c:		ret = snd_skl_parse_uuids(ctx, ctx->fw, BXT_ADSP_FW_BIN_HDR_OFFSET, 0);
sound/soc/intel/skylake/bxt-sst.c:	stripped_fw.data = ctx->fw->data;
sound/soc/intel/skylake/bxt-sst.c:	stripped_fw.size = ctx->fw->size;
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Error code=0x%x: FW status=0x%x\n",
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Core En/ROM load fail:%d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Transfer firmware failed %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:		dev_info(ctx->dev, "Error code=0x%x: FW status=0x%x\n",
sound/soc/intel/skylake/bxt-sst.c:		dev_dbg(ctx->dev, "Firmware download successful\n");
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "DSP boot fail, FW Ready timeout\n");
sound/soc/intel/skylake/bxt-sst.c:	release_firmware(ctx->fw);
sound/soc/intel/skylake/bxt-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "reload fw failed: %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:				dev_err(ctx->dev, "reload libs failed: %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "%s: DSP boot timeout\n", __func__);
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Error code=0x%x: FW status=0x%x\n",
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "Failed to set core0 to D0 state\n");
sound/soc/intel/skylake/bxt-sst.c:			dev_err(ctx->dev, "IPC set_dx for core %d fail: %d\n",
sound/soc/intel/skylake/bxt-sst.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/bxt-sst.c:	dev_dbg(ctx->dev, "core mask=%x dx_mask=%x\n",
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/bxt-sst.c:		dev_err(ctx->dev, "Failed to disable core %d\n", ret);
sound/soc/intel/skylake/bxt-sst.c:	struct sst_dsp *sst = ctx->dsp;
sound/soc/intel/skylake/bxt-sst.c:	if (ctx->manifest.lib_count > 1) {
sound/soc/intel/skylake/bxt-sst.c:		ret = sst->fw_ops.load_library(sst, &ctx->manifest);
sound/soc/intel/skylake/bxt-sst.c:	ctx->is_first_boot = false;
sound/soc/intel/skylake/bxt-sst.c:	skl_ipc_free(&ctx->ipc);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp->cl_dev.ops.cl_cleanup_controller(ctx->dsp);
sound/soc/intel/skylake/bxt-sst.c:	if (ctx->dsp->addr.lpe)
sound/soc/intel/skylake/bxt-sst.c:		iounmap(ctx->dsp->addr.lpe);
sound/soc/intel/skylake/bxt-sst.c:	ctx->dsp->ops->free(ctx->dsp);
sound/soc/intel/skylake/skl-sst-cldma.c:		dev_err(ctx->dev, "Failed to set Run bit=%d enable=%d\n", val, enable);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.frags = 0;
sound/soc/intel/skylake/skl-sst-cldma.c:				(ctx->cl_dev.frags * ctx->cl_dev.bufsize));
sound/soc/intel/skylake/skl-sst-cldma.c:		bdl[2] = cpu_to_le32(ctx->cl_dev.bufsize);
sound/soc/intel/skylake/skl-sst-cldma.c:		size -= ctx->cl_dev.bufsize;
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.frags++;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_data);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_bdl);
sound/soc/intel/skylake/skl-sst-cldma.c:	if (!wait_event_timeout(ctx->cl_dev.wait_queue,
sound/soc/intel/skylake/skl-sst-cldma.c:				ctx->cl_dev.wait_condition,
sound/soc/intel/skylake/skl-sst-cldma.c:		dev_err(ctx->dev, "%s: Wait timeout\n", __func__);
sound/soc/intel/skylake/skl-sst-cldma.c:	dev_dbg(ctx->dev, "%s: Event wake\n", __func__);
sound/soc/intel/skylake/skl-sst-cldma.c:	if (ctx->cl_dev.wake_status != SKL_CL_DMA_BUF_COMPLETE) {
sound/soc/intel/skylake/skl-sst-cldma.c:		dev_err(ctx->dev, "%s: DMA Error\n", __func__);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.wake_status = SKL_CL_DMA_STATUS_NONE;
sound/soc/intel/skylake/skl-sst-cldma.c:	dev_dbg(ctx->dev, "Size: %x, intr_enable: %d\n", size, intr_enable);
sound/soc/intel/skylake/skl-sst-cldma.c:	dev_dbg(ctx->dev, "buf_pos_index:%d, trigger:%d\n",
sound/soc/intel/skylake/skl-sst-cldma.c:			ctx->cl_dev.dma_buffer_offset, trigger);
sound/soc/intel/skylake/skl-sst-cldma.c:	dev_dbg(ctx->dev, "spib position: %d\n", ctx->cl_dev.curr_spib_pos);
sound/soc/intel/skylake/skl-sst-cldma.c:	if (ctx->cl_dev.dma_buffer_offset + size > ctx->cl_dev.bufsize) {
sound/soc/intel/skylake/skl-sst-cldma.c:		unsigned int size_b = ctx->cl_dev.bufsize -
sound/soc/intel/skylake/skl-sst-cldma.c:					ctx->cl_dev.dma_buffer_offset;
sound/soc/intel/skylake/skl-sst-cldma.c:		memcpy(ctx->cl_dev.dmab_data.area + ctx->cl_dev.dma_buffer_offset,
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.dma_buffer_offset = 0;
sound/soc/intel/skylake/skl-sst-cldma.c:	memcpy(ctx->cl_dev.dmab_data.area + ctx->cl_dev.dma_buffer_offset,
sound/soc/intel/skylake/skl-sst-cldma.c:	if (ctx->cl_dev.curr_spib_pos == ctx->cl_dev.bufsize)
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.dma_buffer_offset = 0;
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.dma_buffer_offset = ctx->cl_dev.curr_spib_pos;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.wait_condition = false;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_spb(ctx, ctx->cl_dev.curr_spib_pos, trigger);
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.ops.cl_trigger(ctx, true);
sound/soc/intel/skylake/skl-sst-cldma.c:	dev_dbg(ctx->dev, "%s: Total binary size: %u\n", __func__, bytes_left);
sound/soc/intel/skylake/skl-sst-cldma.c:		if (bytes_left > ctx->cl_dev.bufsize) {
sound/soc/intel/skylake/skl-sst-cldma.c:			if (ctx->cl_dev.curr_spib_pos == 0)
sound/soc/intel/skylake/skl-sst-cldma.c:				ctx->cl_dev.curr_spib_pos = ctx->cl_dev.bufsize;
sound/soc/intel/skylake/skl-sst-cldma.c:			size = ctx->cl_dev.bufsize;
sound/soc/intel/skylake/skl-sst-cldma.c:			if ((ctx->cl_dev.curr_spib_pos + bytes_left)
sound/soc/intel/skylake/skl-sst-cldma.c:							<= ctx->cl_dev.bufsize) {
sound/soc/intel/skylake/skl-sst-cldma.c:				ctx->cl_dev.curr_spib_pos += bytes_left;
sound/soc/intel/skylake/skl-sst-cldma.c:					(ctx->cl_dev.bufsize -
sound/soc/intel/skylake/skl-sst-cldma.c:					ctx->cl_dev.curr_spib_pos);
sound/soc/intel/skylake/skl-sst-cldma.c:				ctx->cl_dev.curr_spib_pos = excess_bytes;
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.wake_status = SKL_CL_DMA_ERR;
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->cl_dev.wake_status = SKL_CL_DMA_BUF_COMPLETE;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.wait_condition = true;
sound/soc/intel/skylake/skl-sst-cldma.c:	wake_up(&ctx->cl_dev.wait_queue);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.bufsize = SKL_MAX_BUFFER_SIZE;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_bdle = skl_cldma_setup_bdle;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_controller = skl_cldma_setup_controller;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_spb = skl_cldma_setup_spb;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_cleanup_spb = skl_cldma_cleanup_spb;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_trigger = skl_cldma_stream_run;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_cleanup_controller = skl_cldma_cleanup;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_copy_to_dmabuf = skl_cldma_copy_to_buf;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_stop_dma = skl_cldma_stop;
sound/soc/intel/skylake/skl-sst-cldma.c:	ret = ctx->dsp_ops.alloc_dma_buf(ctx->dev,
sound/soc/intel/skylake/skl-sst-cldma.c:			&ctx->cl_dev.dmab_data, ctx->cl_dev.bufsize);
sound/soc/intel/skylake/skl-sst-cldma.c:		dev_err(ctx->dev, "Alloc buffer for base fw failed: %x\n", ret);
sound/soc/intel/skylake/skl-sst-cldma.c:	ret = ctx->dsp_ops.alloc_dma_buf(ctx->dev,
sound/soc/intel/skylake/skl-sst-cldma.c:			&ctx->cl_dev.dmab_bdl, PAGE_SIZE);
sound/soc/intel/skylake/skl-sst-cldma.c:		dev_err(ctx->dev, "Alloc buffer for blde failed: %x\n", ret);
sound/soc/intel/skylake/skl-sst-cldma.c:		ctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_data);
sound/soc/intel/skylake/skl-sst-cldma.c:	bdl = (u32 *)ctx->cl_dev.dmab_bdl.area;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_bdle(ctx, &ctx->cl_dev.dmab_data,
sound/soc/intel/skylake/skl-sst-cldma.c:			&bdl, ctx->cl_dev.bufsize, 1);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.ops.cl_setup_controller(ctx, &ctx->cl_dev.dmab_bdl,
sound/soc/intel/skylake/skl-sst-cldma.c:			ctx->cl_dev.bufsize, ctx->cl_dev.frags);
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.curr_spib_pos = 0;
sound/soc/intel/skylake/skl-sst-cldma.c:	ctx->cl_dev.dma_buffer_offset = 0;
sound/soc/intel/skylake/skl-sst-cldma.c:	init_waitqueue_head(&ctx->cl_dev.wait_queue);
sound/soc/intel/skylake/skl-sst-utils.c:	if (list_empty(&ctx->uuid_list)) {
sound/soc/intel/skylake/skl-sst-utils.c:		dev_err(ctx->dev, "Module list is empty\n");
sound/soc/intel/skylake/skl-sst-utils.c:	list_for_each_entry(module, &ctx->uuid_list, list) {
sound/soc/intel/skylake/skl-sst-utils.c:	list_for_each_entry(module, &ctx->uuid_list, list) {
sound/soc/intel/skylake/skl-sst-utils.c:	list_for_each_entry(module, &ctx->uuid_list, list) {
sound/soc/intel/skylake/skl-sst-utils.c:	list_for_each_entry(module, &ctx->uuid_list, list) {
sound/soc/intel/skylake/skl-sst-utils.c:	struct skl_sst *skl = ctx->thread_context;
sound/soc/intel/skylake/skl-sst-utils.c:		dev_err(ctx->dev, "Small fw file size, No space for hdr\n");
sound/soc/intel/skylake/skl-sst-utils.c:		dev_err(ctx->dev, "Small fw file size, No module entry\n");
sound/soc/intel/skylake/skl-sst-utils.c:		dev_err(ctx->dev, "Small fw file size, No modules\n");
sound/soc/intel/skylake/skl-sst-utils.c:		module->instance_id = devm_kzalloc(ctx->dev, size, GFP_KERNEL);
sound/soc/intel/skylake/skl-sst-utils.c:		dev_dbg(ctx->dev,
sound/soc/intel/skylake/skl-sst-utils.c:	list_for_each_entry_safe(uuid, _uuid, &ctx->uuid_list, list) {
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev,
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Dumping config\n");
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Input Format:\n");
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "channels = %d\n", mcfg->in_fmt[0].channels);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "s_freq = %d\n", mcfg->in_fmt[0].s_freq);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "ch_cfg = %d\n", mcfg->in_fmt[0].ch_cfg);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "valid bit depth = %d\n", mcfg->in_fmt[0].valid_bit_depth);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Output Format:\n");
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "channels = %d\n", mcfg->out_fmt[0].channels);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "s_freq = %d\n", mcfg->out_fmt[0].s_freq);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "valid bit depth = %d\n", mcfg->out_fmt[0].valid_bit_depth);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "ch_cfg = %d\n", mcfg->out_fmt[0].ch_cfg);
sound/soc/intel/skylake/skl-topology.c:	struct skl *skl = get_skl_ctx(ctx->dev);
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Applying default cfg blob\n");
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev, "Blob NULL for id %x type %d dirn %d\n",
sound/soc/intel/skylake/skl-topology.c:		dev_err(ctx->dev, "PCM: ch %d, freq %d, fmt %d\n",
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Mconfig for widget=%s BEFORE updation\n",
sound/soc/intel/skylake/skl-topology.c:	dev_dbg(ctx->dev, "Mconfig for widget=%s AFTER updation\n",
sound/soc/intel/skylake/skl-topology.c:		if (mconfig->is_loadable && ctx->dsp->fw_ops.load_mod) {
sound/soc/intel/skylake/skl-topology.c:			ret = ctx->dsp->fw_ops.load_mod(ctx->dsp,
sound/soc/intel/skylake/skl-topology.c:		if (mconfig->is_loadable && ctx->dsp->fw_ops.unload_mod &&
sound/soc/intel/skylake/skl-topology.c:			ret = ctx->dsp->fw_ops.unload_mod(ctx->dsp,
sound/soc/intel/skylake/skl-topology.c:		dev_dbg(ctx->dev, "%s: src widget=%s\n", __func__, w->name);
sound/soc/intel/skylake/skl-topology.c:		dev_dbg(ctx->dev, "%s: sink widget=%s\n", __func__, p->sink->name);
sound/soc/intel/skylake/skl-topology.c:		dev_dbg(ctx->dev, "sink widget=%s\n", w->name);
sound/soc/intel/skylake/skl-topology.c:		dev_dbg(ctx->dev, "src widget=%s\n", p->source->name);
sound/soc/intel/skylake/skl-topology.c:	skl_clear_module_cnt(ctx->dsp);
sound/soc/intel/atom/sst/sst.c:	ctx->ops->post_message(ctx, NULL, false);
sound/soc/intel/atom/sst/sst.c:	INIT_LIST_HEAD(&ctx->memcpy_list);
sound/soc/intel/atom/sst/sst.c:	INIT_LIST_HEAD(&ctx->rx_list);
sound/soc/intel/atom/sst/sst.c:	INIT_LIST_HEAD(&ctx->ipc_dispatch_list);
sound/soc/intel/atom/sst/sst.c:	INIT_LIST_HEAD(&ctx->block_list);
sound/soc/intel/atom/sst/sst.c:	INIT_WORK(&ctx->ipc_post_msg_wq, sst_process_pending_msg);
sound/soc/intel/atom/sst/sst.c:	init_waitqueue_head(&ctx->wait_queue);
sound/soc/intel/atom/sst/sst.c:	ctx->post_msg_wq =
sound/soc/intel/atom/sst/sst.c:	if (!ctx->post_msg_wq)
sound/soc/intel/atom/sst/sst.c:	mutex_init(&ctx->sst_lock);
sound/soc/intel/atom/sst/sst.c:	spin_lock_init(&ctx->rx_msg_lock);
sound/soc/intel/atom/sst/sst.c:	spin_lock_init(&ctx->ipc_spin_lock);
sound/soc/intel/atom/sst/sst.c:	spin_lock_init(&ctx->block_lock);
sound/soc/intel/atom/sst/sst.c:	if (!ctx->pdata)
sound/soc/intel/atom/sst/sst.c:	if (!ctx->pdata->probe_data)
sound/soc/intel/atom/sst/sst.c:	memcpy(&ctx->info, ctx->pdata->probe_data, sizeof(ctx->info));
sound/soc/intel/atom/sst/sst.c:	ctx->pvt_id = 1;
sound/soc/intel/atom/sst/sst.c:	ctx->stream_cnt = 0;
sound/soc/intel/atom/sst/sst.c:	ctx->fw_in_mem = NULL;
sound/soc/intel/atom/sst/sst.c:	ctx->use_dma = 0;
sound/soc/intel/atom/sst/sst.c:	ctx->use_lli = 0;
sound/soc/intel/atom/sst/sst.c:	ctx->mailbox_recv_offset = ctx->pdata->ipc_info->mbox_recv_off;
sound/soc/intel/atom/sst/sst.c:	ctx->ipc_reg.ipcx = SST_IPCX + ctx->pdata->ipc_info->ipc_offset;
sound/soc/intel/atom/sst/sst.c:	ctx->ipc_reg.ipcd = SST_IPCD + ctx->pdata->ipc_info->ipc_offset;
sound/soc/intel/atom/sst/sst.c:	dev_info(ctx->dev, "Got drv data max stream %d\n",
sound/soc/intel/atom/sst/sst.c:				ctx->info.max_streams);
sound/soc/intel/atom/sst/sst.c:	for (i = 1; i <= ctx->info.max_streams; i++) {
sound/soc/intel/atom/sst/sst.c:		struct stream_info *stream = &ctx->streams[i];
sound/soc/intel/atom/sst/sst.c:	ret = devm_request_threaded_irq(ctx->dev, ctx->irq_num, ctx->ops->interrupt,
sound/soc/intel/atom/sst/sst.c:					ctx->ops->irq_thread, 0, SST_DRV_NAME,
sound/soc/intel/atom/sst/sst.c:	dev_dbg(ctx->dev, "Registered IRQ %#x\n", ctx->irq_num);
sound/soc/intel/atom/sst/sst.c:	sst_shim_write64(ctx->shim, SST_IMRX, 0xFFFF0038);
sound/soc/intel/atom/sst/sst.c:	ctx->qos = devm_kzalloc(ctx->dev,
sound/soc/intel/atom/sst/sst.c:	if (!ctx->qos) {
sound/soc/intel/atom/sst/sst.c:	pm_qos_add_request(ctx->qos, PM_QOS_CPU_DMA_LATENCY,
sound/soc/intel/atom/sst/sst.c:	dev_dbg(ctx->dev, "Requesting FW %s now...\n", ctx->firmware_name);
sound/soc/intel/atom/sst/sst.c:	ret = request_firmware_nowait(THIS_MODULE, true, ctx->firmware_name,
sound/soc/intel/atom/sst/sst.c:				      ctx->dev, GFP_KERNEL, ctx, sst_firmware_load_cb);
sound/soc/intel/atom/sst/sst.c:		dev_err(ctx->dev, "Firmware download failed:%d\n", ret);
sound/soc/intel/atom/sst/sst.c:	sst_register(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	destroy_workqueue(ctx->post_msg_wq);
sound/soc/intel/atom/sst/sst.c:	pm_runtime_get_noresume(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	pm_runtime_disable(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	sst_unregister(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	destroy_workqueue(ctx->post_msg_wq);
sound/soc/intel/atom/sst/sst.c:	pm_qos_remove_request(ctx->qos);
sound/soc/intel/atom/sst/sst.c:	kfree(ctx->fw_sg_list.src);
sound/soc/intel/atom/sst/sst.c:	kfree(ctx->fw_sg_list.dst);
sound/soc/intel/atom/sst/sst.c:	ctx->fw_sg_list.list_len = 0;
sound/soc/intel/atom/sst/sst.c:	kfree(ctx->fw_in_mem);
sound/soc/intel/atom/sst/sst.c:	ctx->fw_in_mem = NULL;
sound/soc/intel/atom/sst/sst.c:	spin_lock_irqsave(&ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst.c:	spin_unlock_irqrestore(&ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst.c:	spin_lock_irqsave(&ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst.c:	spin_unlock_irqrestore(&ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst.c:	pm_runtime_set_autosuspend_delay(ctx->dev, SST_SUSPEND_DELAY);
sound/soc/intel/atom/sst/sst.c:	pm_runtime_use_autosuspend(ctx->dev);
sound/soc/intel/atom/sst/sst.c:		pm_runtime_set_active(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	pm_runtime_enable(ctx->dev);
sound/soc/intel/atom/sst/sst.c:		pm_runtime_set_active(ctx->dev);
sound/soc/intel/atom/sst/sst.c:		pm_runtime_put_noidle(ctx->dev);
sound/soc/intel/atom/sst/sst.c:	sst_save_shim64(ctx, ctx->shim, ctx->shim_regs64);
sound/soc/intel/atom/sst/sst.c:	if (ctx->sst_state == SST_RESET) {
sound/soc/intel/atom/sst/sst.c:	if (ctx->ops->save_dsp_context(ctx))
sound/soc/intel/atom/sst/sst.c:	synchronize_irq(ctx->irq_num);
sound/soc/intel/atom/sst/sst.c:	flush_workqueue(ctx->post_msg_wq);
sound/soc/intel/atom/sst/sst.c:	ctx->ops->reset(ctx);
sound/soc/intel/atom/sst/sst.c:	sst_save_shim64(ctx, ctx->shim, ctx->shim_regs64);
sound/soc/intel/atom/sst/sst.c:	if (ctx->sst_state == SST_RESET)
sound/soc/intel/atom/sst/sst.c:	for (i = 1; i <= ctx->info.max_streams; i++) {
sound/soc/intel/atom/sst/sst.c:		struct stream_info *stream = &ctx->streams[i];
sound/soc/intel/atom/sst/sst.c:	synchronize_irq(ctx->irq_num);
sound/soc/intel/atom/sst/sst.c:	flush_workqueue(ctx->post_msg_wq);
sound/soc/intel/atom/sst/sst.c:	if (ctx->ops->save_dsp_context(ctx))
sound/soc/intel/atom/sst/sst.c:	fw_save->iram = kzalloc(ctx->iram_end - ctx->iram_base, GFP_KERNEL);
sound/soc/intel/atom/sst/sst.c:	fw_save->dram = kzalloc(ctx->dram_end - ctx->dram_base, GFP_KERNEL);
sound/soc/intel/atom/sst/sst.c:	fw_save->ddr = kzalloc(ctx->ddr_end - ctx->ddr_base, GFP_KERNEL);
sound/soc/intel/atom/sst/sst.c:	memcpy32_fromio(fw_save->iram, ctx->iram, ctx->iram_end - ctx->iram_base);
sound/soc/intel/atom/sst/sst.c:	memcpy32_fromio(fw_save->dram, ctx->dram, ctx->dram_end - ctx->dram_base);
sound/soc/intel/atom/sst/sst.c:	memcpy32_fromio(fw_save->sram, ctx->mailbox, SST_MAILBOX_SIZE);
sound/soc/intel/atom/sst/sst.c:	memcpy32_fromio(fw_save->ddr, ctx->ddr, ctx->ddr_end - ctx->ddr_base);
sound/soc/intel/atom/sst/sst.c:	ctx->fw_save = fw_save;
sound/soc/intel/atom/sst/sst.c:	ctx->ops->reset(ctx);
sound/soc/intel/atom/sst/sst.c:	struct sst_fw_save *fw_save = ctx->fw_save;
sound/soc/intel/atom/sst/sst.c:	ctx->ops->reset(ctx);
sound/soc/intel/atom/sst/sst.c:	ctx->fw_save = NULL;
sound/soc/intel/atom/sst/sst.c:	memcpy32_toio(ctx->iram, fw_save->iram, ctx->iram_end - ctx->iram_base);
sound/soc/intel/atom/sst/sst.c:	memcpy32_toio(ctx->dram, fw_save->dram, ctx->dram_end - ctx->dram_base);
sound/soc/intel/atom/sst/sst.c:	memcpy32_toio(ctx->mailbox, fw_save->sram, SST_MAILBOX_SIZE);
sound/soc/intel/atom/sst/sst.c:	memcpy32_toio(ctx->ddr, fw_save->ddr, ctx->ddr_end - ctx->ddr_base);
sound/soc/intel/atom/sst/sst.c:	ctx->ops->start(ctx);
sound/soc/intel/atom/sst/sst.c:		dev_err(ctx->dev, "fw download failed %d\n", ret);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "sst: Resetting the DSP in mrfld\n");
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "value:0x%llx\n", csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	sst_shim_write64(sst_drv_ctx->shim, SST_CSR, csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "value:0x%llx\n", csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	sst_shim_write64(sst_drv_ctx->shim, SST_CSR, csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "value:0x%llx\n", csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "sst: Starting the DSP in mrfld LALALALA\n");
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "value:0x%llx\n", csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	sst_shim_write64(sst_drv_ctx->shim, SST_CSR, csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "value:0x%llx\n", csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	sst_shim_write64(sst_drv_ctx->shim, SST_CSR, csr.full);
sound/soc/intel/atom/sst/sst_loader.c:	csr.full = sst_shim_read64(sst_drv_ctx->shim, SST_CSR);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "sst: Starting the DSP_merrifield:%llx\n",
sound/soc/intel/atom/sst/sst_loader.c:	const void *sst_fw_in_mem = ctx->fw_in_mem;
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(ctx->dev,
sound/soc/intel/atom/sst/sst_loader.c:		dev_err(ctx->dev, "InvalidFW sign/filesize mismatch\n");
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "module sign %s size %x blocks %x type %x\n",
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "module entrypoint 0x%x\n", module->entry_point);
sound/soc/intel/atom/sst/sst_loader.c:			dev_err(sst_drv_ctx->dev, "block size invalid\n");
sound/soc/intel/atom/sst/sst_loader.c:			ram_iomem = sst_drv_ctx->iram;
sound/soc/intel/atom/sst/sst_loader.c:			ram_iomem = sst_drv_ctx->dram;
sound/soc/intel/atom/sst/sst_loader.c:			ram_iomem = sst_drv_ctx->ddr;
sound/soc/intel/atom/sst/sst_loader.c:			dev_err(sst_drv_ctx->dev, "wrong ram type0x%x in block0x%x\n",
sound/soc/intel/atom/sst/sst_loader.c:	if (!list_empty(&sst_drv_ctx->memcpy_list)) {
sound/soc/intel/atom/sst/sst_loader.c:				&sst_drv_ctx->memcpy_list, memcpylist) {
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_loader.c:		dev_err(ctx->dev, "request fw failed\n");
sound/soc/intel/atom/sst/sst_loader.c:	mutex_lock(&ctx->sst_lock);
sound/soc/intel/atom/sst/sst_loader.c:	if (ctx->sst_state != SST_RESET ||
sound/soc/intel/atom/sst/sst_loader.c:			ctx->fw_in_mem != NULL) {
sound/soc/intel/atom/sst/sst_loader.c:		mutex_unlock(&ctx->sst_lock);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(ctx->dev, "Request Fw completed\n");
sound/soc/intel/atom/sst/sst_loader.c:	mutex_unlock(&ctx->sst_lock);
sound/soc/intel/atom/sst/sst_loader.c:	sst_dccm_config_write(ctx->dram, ctx->ddr_base);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(ctx->dev, "config written to DCCM\n");
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "sst_load_fw\n");
sound/soc/intel/atom/sst/sst_loader.c:	if (sst_drv_ctx->sst_state !=  SST_RESET ||
sound/soc/intel/atom/sst/sst_loader.c:			sst_drv_ctx->sst_state == SST_SHUTDOWN)
sound/soc/intel/atom/sst/sst_loader.c:	if (!sst_drv_ctx->fw_in_mem) {
sound/soc/intel/atom/sst/sst_loader.c:		dev_dbg(sst_drv_ctx->dev, "sst: FW not in memory retry to download\n");
sound/soc/intel/atom/sst/sst_loader.c:	BUG_ON(!sst_drv_ctx->fw_in_mem);
sound/soc/intel/atom/sst/sst_loader.c:	pm_qos_update_request(sst_drv_ctx->qos, 0);
sound/soc/intel/atom/sst/sst_loader.c:	sst_drv_ctx->sst_state = SST_FW_LOADING;
sound/soc/intel/atom/sst/sst_loader.c:	ret_val = sst_drv_ctx->ops->reset(sst_drv_ctx);
sound/soc/intel/atom/sst/sst_loader.c:	sst_do_memcpy(&sst_drv_ctx->memcpy_list);
sound/soc/intel/atom/sst/sst_loader.c:	if (sst_drv_ctx->ops->post_download)
sound/soc/intel/atom/sst/sst_loader.c:		sst_drv_ctx->ops->post_download(sst_drv_ctx);
sound/soc/intel/atom/sst/sst_loader.c:	ret_val = sst_drv_ctx->ops->start(sst_drv_ctx);
sound/soc/intel/atom/sst/sst_loader.c:		dev_err(sst_drv_ctx->dev, "fw download failed %d\n" , ret_val);
sound/soc/intel/atom/sst/sst_loader.c:	pm_qos_update_request(sst_drv_ctx->qos, PM_QOS_DEFAULT_VALUE);
sound/soc/intel/atom/sst/sst_loader.c:	dev_dbg(sst_drv_ctx->dev, "fw load successful!!!\n");
sound/soc/intel/atom/sst/sst_loader.c:	if (sst_drv_ctx->ops->restore_dsp_context)
sound/soc/intel/atom/sst/sst_loader.c:		sst_drv_ctx->ops->restore_dsp_context();
sound/soc/intel/atom/sst/sst_loader.c:	sst_drv_ctx->sst_state = SST_FW_RUNNING;
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_stream.c:		dev_err(sst_drv_ctx->dev, "get stream info returned null\n");
sound/soc/intel/atom/sst/sst_stream.c:	sst_drv_ctx->streams[str_id].pipe_id = pipe_id;
sound/soc/intel/atom/sst/sst_stream.c:	sst_drv_ctx->streams[str_id].task_id = task_id;
sound/soc/intel/atom/sst/sst_stream.c:	sst_drv_ctx->streams[str_id].num_ch = num_ch;
sound/soc/intel/atom/sst/sst_stream.c:	if (sst_drv_ctx->info.lpe_viewpt_rqd)
sound/soc/intel/atom/sst/sst_stream.c:		alloc_param.ts = sst_drv_ctx->info.mailbox_start +
sound/soc/intel/atom/sst/sst_stream.c:			sst_drv_ctx->tstamp + (str_id * sizeof(fw_tstamp));
sound/soc/intel/atom/sst/sst_stream.c:		alloc_param.ts = sst_drv_ctx->mailbox_add +
sound/soc/intel/atom/sst/sst_stream.c:			sst_drv_ctx->tstamp + (str_id * sizeof(fw_tstamp));
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "alloc tstamp location = 0x%x\n",
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "assigned pipe id 0x%x to task %d\n",
sound/soc/intel/atom/sst/sst_stream.c:	sst_init_stream(&sst_drv_ctx->streams[str_id], alloc_param.codec_type,
sound/soc/intel/atom/sst/sst_stream.c:	dev_info(sst_drv_ctx->dev, "Alloc for str %d pipe %#x\n",
sound/soc/intel/atom/sst/sst_stream.c:		dev_err(sst_drv_ctx->dev, "FW alloc failed ret %d\n", ret);
sound/soc/intel/atom/sst/sst_stream.c:		dev_err(sst_drv_ctx->dev, "FW alloc failed ret %d\n", ret);
sound/soc/intel/atom/sst/sst_stream.c:			dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "sst_start_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "length is %d\n", length);
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "msg->mrfld_header.p.header_low_payload:%d",
sound/soc/intel/atom/sst/sst_stream.c:			dev_err(sst_drv_ctx->dev, "fw returned err %d\n", ret);
sound/soc/intel/atom/sst/sst_stream.c:			dev_dbg(sst_drv_ctx->dev, "read back %d bytes",
sound/soc/intel/atom/sst/sst_stream.c:	test_and_clear_bit(pvt_id, &sst_drv_ctx->pvt_id);
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "SST DBG:sst_pause_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:			mutex_lock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:			mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:		dev_dbg(sst_drv_ctx->dev, "SST DBG:BADRQC for stream\n ");
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "SST DBG:sst_resume_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:			mutex_lock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:			mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:		dev_err(sst_drv_ctx->dev, "SST ERR: BADQRC for stream\n");
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "SST DBG:sst_drop_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:		dev_dbg(sst_drv_ctx->dev, "BADQRC for stream, state %x\n",
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "SST DBG:sst_drain_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:			dev_err(sst_drv_ctx->dev, "SST ERR: BADQRC for stream = %d\n",
sound/soc/intel/atom/sst/sst_stream.c:	dev_dbg(sst_drv_ctx->dev, "SST DBG:sst_free_stream for %d\n", str_id);
sound/soc/intel/atom/sst/sst_stream.c:	mutex_lock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:	if (sst_drv_ctx->sst_state == SST_RESET) {
sound/soc/intel/atom/sst/sst_stream.c:		mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:	mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:	ops = sst_drv_ctx->ops;
sound/soc/intel/atom/sst/sst_stream.c:		dev_info(sst_drv_ctx->dev, "Free for str %d pipe %#x\n",
sound/soc/intel/atom/sst/sst_stream.c:		dev_dbg(sst_drv_ctx->dev, "sst: wait for free returned %d\n",
sound/soc/intel/atom/sst/sst_stream.c:		mutex_lock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:		mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_stream.c:		dev_dbg(sst_drv_ctx->dev, "SST DBG:Stream freed\n");
sound/soc/intel/atom/sst/sst_stream.c:		dev_dbg(sst_drv_ctx->dev, "SST DBG:BADQRC for stream\n");
sound/soc/intel/atom/sst/sst_pci.c:	struct pci_dev *pci = ctx->pci;
sound/soc/intel/atom/sst/sst_pci.c:	if (ctx->dev_id == SST_MRFLD_PCI_ID) {
sound/soc/intel/atom/sst/sst_pci.c:		ctx->ddr_base = pci_resource_start(pci, 0);
sound/soc/intel/atom/sst/sst_pci.c:		ddr_base = relocate_imr_addr_mrfld(ctx->ddr_base);
sound/soc/intel/atom/sst/sst_pci.c:		if (!ctx->pdata->lib_info) {
sound/soc/intel/atom/sst/sst_pci.c:			dev_err(ctx->dev, "lib_info pointer NULL\n");
sound/soc/intel/atom/sst/sst_pci.c:		if (ddr_base != ctx->pdata->lib_info->mod_base) {
sound/soc/intel/atom/sst/sst_pci.c:			dev_err(ctx->dev,
sound/soc/intel/atom/sst/sst_pci.c:		ctx->ddr_end = pci_resource_end(pci, 0);
sound/soc/intel/atom/sst/sst_pci.c:		ctx->ddr = pcim_iomap(pci, 0,
sound/soc/intel/atom/sst/sst_pci.c:		if (!ctx->ddr) {
sound/soc/intel/atom/sst/sst_pci.c:		dev_dbg(ctx->dev, "sst: DDR Ptr %p\n", ctx->ddr);
sound/soc/intel/atom/sst/sst_pci.c:		ctx->ddr = NULL;
sound/soc/intel/atom/sst/sst_pci.c:	ctx->shim_phy_add = pci_resource_start(pci, 1);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->shim = pcim_iomap(pci, 1, pci_resource_len(pci, 1));
sound/soc/intel/atom/sst/sst_pci.c:	if (!ctx->shim) {
sound/soc/intel/atom/sst/sst_pci.c:	dev_dbg(ctx->dev, "SST Shim Ptr %p\n", ctx->shim);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->mailbox_add = pci_resource_start(pci, 2);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->mailbox = pcim_iomap(pci, 2, pci_resource_len(pci, 2));
sound/soc/intel/atom/sst/sst_pci.c:	if (!ctx->mailbox) {
sound/soc/intel/atom/sst/sst_pci.c:	dev_dbg(ctx->dev, "SRAM Ptr %p\n", ctx->mailbox);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->iram_end = pci_resource_end(pci, 3);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->iram_base = pci_resource_start(pci, 3);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->iram = pcim_iomap(pci, 3, pci_resource_len(pci, 3));
sound/soc/intel/atom/sst/sst_pci.c:	if (!ctx->iram) {
sound/soc/intel/atom/sst/sst_pci.c:	dev_dbg(ctx->dev, "IRAM Ptr %p\n", ctx->iram);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->dram_end = pci_resource_end(pci, 4);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->dram_base = pci_resource_start(pci, 4);
sound/soc/intel/atom/sst/sst_pci.c:	ctx->dram = pcim_iomap(pci, 4, pci_resource_len(pci, 4));
sound/soc/intel/atom/sst/sst_pci.c:	if (!ctx->dram) {
sound/soc/intel/atom/sst/sst_pci.c:	dev_dbg(ctx->dev, "DRAM Ptr %p\n", ctx->dram);
sound/soc/intel/atom/sst/sst_pci.c:	sst_drv_ctx->pdata = sst_pdata;
sound/soc/intel/atom/sst/sst_pci.c:	sst_drv_ctx->irq_num = pci->irq;
sound/soc/intel/atom/sst/sst_pci.c:	snprintf(sst_drv_ctx->firmware_name, sizeof(sst_drv_ctx->firmware_name),
sound/soc/intel/atom/sst/sst_pci.c:			sst_drv_ctx->dev_id, ".bin");
sound/soc/intel/atom/sst/sst_pci.c:		dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_pci.c:	sst_drv_ctx->pci = pci_dev_get(pci);
sound/soc/intel/atom/sst/sst_pci.c:	dev_err(sst_drv_ctx->dev, "Probe failed with %d\n", ret);
sound/soc/intel/atom/sst/sst_pci.c:	pci_dev_put(sst_drv_ctx->pci);
sound/soc/intel/atom/sst/sst_pvt.c:	mutex_lock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_pvt.c:	sst_drv_ctx->sst_state = sst_state;
sound/soc/intel/atom/sst/sst_pvt.c:	mutex_unlock(&sst_drv_ctx->sst_lock);
sound/soc/intel/atom/sst/sst_pvt.c:	if (!wait_event_interruptible(sst_drv_ctx->wait_queue,
sound/soc/intel/atom/sst/sst_pvt.c:			dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_pvt.c:			dev_dbg(sst_drv_ctx->dev, "event up\n");
sound/soc/intel/atom/sst/sst_pvt.c:		dev_err(sst_drv_ctx->dev, "signal interrupted\n");
sound/soc/intel/atom/sst/sst_pvt.c:	dev_dbg(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_pvt.c:	if (wait_event_timeout(sst_drv_ctx->wait_queue,
sound/soc/intel/atom/sst/sst_pvt.c:		dev_dbg(sst_drv_ctx->dev, "Event wake %x\n",
sound/soc/intel/atom/sst/sst_pvt.c:		dev_dbg(sst_drv_ctx->dev, "message ret: %d\n",
sound/soc/intel/atom/sst/sst_pvt.c:		dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_pvt.c:			block->condition, block->msg_id, sst_drv_ctx->sst_state);
sound/soc/intel/atom/sst/sst_pvt.c:		sst_drv_ctx->sst_state = SST_RESET;
sound/soc/intel/atom/sst/sst_pvt.c:	if (str_id <= 0 || str_id > sst_drv_ctx->info.max_streams) {
sound/soc/intel/atom/sst/sst_pvt.c:		dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_pvt.c:			str_id, sst_drv_ctx->info.max_streams);
sound/soc/intel/atom/sst/sst_pvt.c:	return &sst_drv_ctx->streams[str_id];
sound/soc/intel/atom/sst/sst_pvt.c:	for (i = 1; i <= sst_drv_ctx->info.max_streams; i++)
sound/soc/intel/atom/sst/sst_pvt.c:		if (pipe_id == sst_drv_ctx->streams[i].pipe_id)
sound/soc/intel/atom/sst/sst_pvt.c:	dev_dbg(sst_drv_ctx->dev, "no such pipe_id(%u)", pipe_id);
sound/soc/intel/atom/sst/sst_acpi.c:	struct platform_device *pdev = to_platform_device(ctx->dev);
sound/soc/intel/atom/sst/sst_acpi.c:					ctx->pdata->res_info->acpi_lpe_res_index);
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "Invalid SHIM base from IFWI\n");
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "LPE base: %#x size:%#x", (unsigned int) rsrc->start,
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->iram_base = rsrc->start + ctx->pdata->res_info->iram_offset;
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->iram_end =  ctx->iram_base + ctx->pdata->res_info->iram_size - 1;
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "IRAM base: %#x", ctx->iram_base);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->iram = devm_ioremap_nocache(ctx->dev, ctx->iram_base,
sound/soc/intel/atom/sst/sst_acpi.c:					 ctx->pdata->res_info->iram_size);
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->iram) {
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "unable to map IRAM\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->dram_base = rsrc->start + ctx->pdata->res_info->dram_offset;
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->dram_end = ctx->dram_base + ctx->pdata->res_info->dram_size - 1;
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "DRAM base: %#x", ctx->dram_base);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->dram = devm_ioremap_nocache(ctx->dev, ctx->dram_base,
sound/soc/intel/atom/sst/sst_acpi.c:					 ctx->pdata->res_info->dram_size);
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->dram) {
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "unable to map DRAM\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->shim_phy_add = rsrc->start + ctx->pdata->res_info->shim_offset;
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "SHIM base: %#x", ctx->shim_phy_add);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->shim = devm_ioremap_nocache(ctx->dev, ctx->shim_phy_add,
sound/soc/intel/atom/sst/sst_acpi.c:					ctx->pdata->res_info->shim_size);
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->shim) {
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "unable to map SHIM\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->shim_phy_add = ctx->pdata->res_info->shim_phy_addr;
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->mailbox_add = rsrc->start + ctx->pdata->res_info->mbox_offset;
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "Mailbox base: %#x", ctx->mailbox_add);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->mailbox = devm_ioremap_nocache(ctx->dev, ctx->mailbox_add,
sound/soc/intel/atom/sst/sst_acpi.c:					    ctx->pdata->res_info->mbox_size);
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->mailbox) {
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "unable to map mailbox\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->mailbox_add = ctx->info.mailbox_start;
sound/soc/intel/atom/sst/sst_acpi.c:					ctx->pdata->res_info->acpi_ddr_index);
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "Invalid DDR base from IFWI\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->ddr_base = rsrc->start;
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->ddr_end = rsrc->end;
sound/soc/intel/atom/sst/sst_acpi.c:	dev_info(ctx->dev, "DDR base: %#x", ctx->ddr_base);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->ddr = devm_ioremap_nocache(ctx->dev, ctx->ddr_base,
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->ddr) {
sound/soc/intel/atom/sst/sst_acpi.c:		dev_err(ctx->dev, "unable to map DDR\n");
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->irq_num = platform_get_irq(pdev,
sound/soc/intel/atom/sst/sst_acpi.c:				ctx->pdata->res_info->acpi_ipc_irq_index);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->pdata = pdata;
sound/soc/intel/atom/sst/sst_acpi.c:	strcpy(ctx->firmware_name, mach->fw_filename);
sound/soc/intel/atom/sst/sst_acpi.c:	ctx->shim_regs64 = devm_kzalloc(ctx->dev, sizeof(*ctx->shim_regs64),
sound/soc/intel/atom/sst/sst_acpi.c:	if (!ctx->shim_regs64) {
sound/soc/intel/atom/sst/sst_acpi.c:	dev_err(ctx->dev, "failed with %d\n", ret);
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_ipc.c:	spin_lock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	list_add_tail(&msg->node, &ctx->block_list);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_unlock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_ipc.c:	spin_lock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	list_for_each_entry(block, &ctx->block_list, node) {
sound/soc/intel/atom/sst/sst_ipc.c:		dev_dbg(ctx->dev, "Block ipc %d, drv_id %d\n", block->msg_id,
sound/soc/intel/atom/sst/sst_ipc.c:			dev_dbg(ctx->dev, "free up the block\n");
sound/soc/intel/atom/sst/sst_ipc.c:			spin_unlock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:			wake_up(&ctx->wait_queue);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_unlock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(ctx->dev, "Enter\n");
sound/soc/intel/atom/sst/sst_ipc.c:	spin_lock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	list_for_each_entry_safe(block, __block, &ctx->block_list, node) {
sound/soc/intel/atom/sst/sst_ipc.c:			spin_unlock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_unlock_bh(&ctx->block_lock);
sound/soc/intel/atom/sst/sst_ipc.c:	dev_err(ctx->dev, "block is already freed!!!\n");
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(sst_drv_ctx->dev, "Enter: sync: %d\n", sync);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_lock_irqsave(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:	header.full = sst_shim_read64(sst_drv_ctx->shim, SST_IPCX);
sound/soc/intel/atom/sst/sst_ipc.c:				dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:			header.full = sst_shim_read64(sst_drv_ctx->shim, SST_IPCX);
sound/soc/intel/atom/sst/sst_ipc.c:		if (list_empty(&sst_drv_ctx->ipc_dispatch_list)) {
sound/soc/intel/atom/sst/sst_ipc.c:			spin_unlock_irqrestore(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:			dev_dbg(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:			spin_unlock_irqrestore(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:			dev_dbg(sst_drv_ctx->dev, "Busy not free... post later\n");
sound/soc/intel/atom/sst/sst_ipc.c:		msg = list_entry(sst_drv_ctx->ipc_dispatch_list.next,
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(sst_drv_ctx->dev, "sst: Post message: header = %x\n",
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(sst_drv_ctx->dev, "sst: size = 0x%x\n",
sound/soc/intel/atom/sst/sst_ipc.c:		memcpy_toio(sst_drv_ctx->mailbox + SST_MAILBOX_SEND,
sound/soc/intel/atom/sst/sst_ipc.c:	sst_shim_write64(sst_drv_ctx->shim, SST_IPCX, msg->mrfld_header.full);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_unlock_irqrestore(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_lock_irqsave(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:	imr.full = sst_shim_read64(sst_drv_ctx->shim, SST_IMRX);
sound/soc/intel/atom/sst/sst_ipc.c:	isr.full = sst_shim_read64(sst_drv_ctx->shim, SST_ISRX);
sound/soc/intel/atom/sst/sst_ipc.c:	sst_shim_write64(sst_drv_ctx->shim, SST_ISRX, isr.full);
sound/soc/intel/atom/sst/sst_ipc.c:	clear_ipc.full = sst_shim_read64(sst_drv_ctx->shim, SST_IPCD);
sound/soc/intel/atom/sst/sst_ipc.c:	sst_shim_write64(sst_drv_ctx->shim, SST_IPCD, clear_ipc.full);
sound/soc/intel/atom/sst/sst_ipc.c:	sst_shim_write64(sst_drv_ctx->shim, SST_IMRX, imr.full);
sound/soc/intel/atom/sst/sst_ipc.c:	spin_unlock_irqrestore(&sst_drv_ctx->ipc_spin_lock, irq_flags);
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(sst_drv_ctx->dev, "*** FW Init msg came***\n");
sound/soc/intel/atom/sst/sst_ipc.c:		dev_err(sst_drv_ctx->dev, "FW Init failed, Error %x\n",
sound/soc/intel/atom/sst/sst_ipc.c:			dev_dbg(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:			stream = &sst_drv_ctx->streams[str_id];
sound/soc/intel/atom/sst/sst_ipc.c:			stream = &sst_drv_ctx->streams[str_id];
sound/soc/intel/atom/sst/sst_ipc.c:		dev_err(sst_drv_ctx->dev, "FW sent async error msg:\n");
sound/soc/intel/atom/sst/sst_ipc.c:			dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:		dev_err(sst_drv_ctx->dev,
sound/soc/intel/atom/sst/sst_ipc.c:	dev_dbg(sst_drv_ctx->dev, "IPC process message header %x payload %x\n",
sound/soc/intel/atom/sst/sst_ipc.c:		dev_err(sst_drv_ctx->dev, "FW sent error response 0x%x", msg_low);
sound/soc/intel/atom/sst/sst_ipc.c:		dev_dbg(sst_drv_ctx->dev, "cmd_id %d\n", dsp_hdr->cmd_id);
sound/soc/intel/atom/sst/sst_drv_interface.c:			sst_clean_stream(&ctx->streams[str_id]);
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_err(ctx->dev, "we tried to free stream context %d which was freed!!!\n", str_id);
sound/soc/intel/atom/sst/sst_drv_interface.c:	retval = ctx->ops->alloc_stream(ctx, str_param);
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_dbg(ctx->dev, "Stream allocated %d\n", retval);
sound/soc/intel/atom/sst/sst_drv_interface.c:	retval = ctx->ops->alloc_stream(ctx, str_param);
sound/soc/intel/atom/sst/sst_drv_interface.c:	str_info = &ctx->streams[retval];
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_dbg(ctx->dev, "Enable: pm usage count: %d\n", usage_count);
sound/soc/intel/atom/sst/sst_drv_interface.c:			dev_err(ctx->dev, "Runtime get failed with err: %d\n", ret);
sound/soc/intel/atom/sst/sst_drv_interface.c:		if ((ctx->sst_state == SST_RESET) && (usage_count == 1)) {
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_dbg(ctx->dev, "Disable: pm usage count: %d\n", usage_count);
sound/soc/intel/atom/sst/sst_drv_interface.c:		ctx->stream_cnt++;
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_err(ctx->dev, "sst_get_stream returned err %d\n", retval);
sound/soc/intel/atom/sst/sst_drv_interface.c:	retval = pm_runtime_get_sync(ctx->dev);
sound/soc/intel/atom/sst/sst_drv_interface.c:		pm_runtime_put_sync(ctx->dev);
sound/soc/intel/atom/sst/sst_drv_interface.c:		stream = &ctx->streams[str_id];
sound/soc/intel/atom/sst/sst_drv_interface.c:		((void *)(ctx->mailbox + ctx->tstamp)
sound/soc/intel/atom/sst/sst_drv_interface.c:	addr =  ((void *)(ctx->mailbox + ctx->tstamp)) +
sound/soc/intel/atom/sst/sst_drv_interface.c:		((void *)(ctx->mailbox + ctx->tstamp)
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "fragment elapsed from firmware for str_id %d\n",
sound/soc/intel/atom/sst/sst_drv_interface.c:	stream = &ctx->streams[str_id];
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_err(ctx->dev, "stream info is NULL for str %d!!!\n", str_id);
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_dbg(ctx->dev, "stream in reset state...\n");
sound/soc/intel/atom/sst/sst_drv_interface.c:	ctx->stream_cnt--;
sound/soc/intel/atom/sst/sst_drv_interface.c:		dev_err(ctx->dev, "free stream returned err %d\n", retval);
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "Exit\n");
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "mrfld ring_buffer_counter %llu in bytes\n",
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "mrfld hardware_counter %llu in bytes\n",
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "pcm delay %zu in bytes\n", delay_bytes);
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "buffer ptr %llu pcm_delay rep: %llu\n",
sound/soc/intel/atom/sst/sst_drv_interface.c:		((void *)(ctx->mailbox + ctx->tstamp)
sound/soc/intel/atom/sst/sst_drv_interface.c:	if (ctx->sst_state != SST_FW_RUNNING)
sound/soc/intel/atom/sst/sst_drv_interface.c:	if (ctx->sst_state != SST_FW_RUNNING)
sound/soc/intel/atom/sst/sst_drv_interface.c:	if (ctx->sst_state != SST_FW_RUNNING)
sound/soc/intel/atom/sst/sst_drv_interface.c:	if (ctx->sst_state != SST_FW_RUNNING)
sound/soc/intel/atom/sst/sst_drv_interface.c:	if (ctx->sst_state != SST_FW_RUNNING)
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev, "setting the period ptrs\n");
sound/soc/intel/atom/sst/sst_drv_interface.c:	dev_dbg(ctx->dev,
sound/soc/intel/atom/sst/sst_drv_interface.c:	ret_val = pm_runtime_get_sync(ctx->dev);
sound/soc/intel/atom/sst/sst_drv_interface.c:		pm_runtime_put_sync(ctx->dev);
sound/soc/intel/atom/sst-mfld-platform-pcm.c:	map = ctx->pdata->pdev_strm_map;
sound/soc/intel/atom/sst-mfld-platform-pcm.c:	map_size = ctx->pdata->strm_map_size;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.nb_slots = slots;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.active_tx_slot_map = tx_mask;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.active_rx_slot_map = rx_mask;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.nb_bits_per_slots = slot_width;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.ssp_protocol = SSP_MODE_PCM;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.mode = sst_get_ssp_mode(dai, fmt) | (SSP_PCM_MODE_NETWORK << 1);
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.start_delay = 0;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.data_polarity = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.frame_sync_width = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.ssp_protocol = SSP_MODE_PCM;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.mode = sst_get_ssp_mode(dai, fmt) | (SSP_PCM_MODE_NETWORK << 1);
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.start_delay = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.data_polarity = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.frame_sync_width = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.ssp_protocol = SSP_MODE_I2S;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.mode = sst_get_ssp_mode(dai, fmt) | (SSP_PCM_MODE_NORMAL << 1);
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.start_delay = 1;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.data_polarity = 0;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.frame_sync_width = ctx->ssp_cmd.nb_bits_per_slots;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.ssp_protocol = SSP_MODE_I2S;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.mode = sst_get_ssp_mode(dai, fmt) | (SSP_PCM_MODE_NORMAL << 1);
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.start_delay = 0;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.data_polarity = 0;
sound/soc/intel/atom/sst-atom-controls.c:		ctx->ssp_cmd.frame_sync_width = ctx->ssp_cmd.nb_bits_per_slots;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.frame_sync_polarity = fs_polarity;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.selection = config->ssp_id;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.nb_bits_per_slots = config->bits_per_slot;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.nb_slots = config->slots;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.mode = config->ssp_mode | (config->pcm_mode << 1);
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.duplex = config->duplex;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.active_tx_slot_map = config->active_slot_map;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.active_rx_slot_map = config->active_slot_map;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.frame_sync_frequency = config->fs_frequency;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.frame_sync_polarity = config->frame_sync_polarity;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.data_polarity = config->data_polarity;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.frame_sync_width = config->fs_width;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.ssp_protocol = config->ssp_protocol;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.start_delay = config->start_delay;
sound/soc/intel/atom/sst-atom-controls.c:	ctx->ssp_cmd.reserved1 = ctx->ssp_cmd.reserved2 = 0xFF;
sound/ppc/keywest.c:	if (!keywest_ctx->client)
sound/ppc/keywest.c:		keywest_ctx->client = client;
sound/ppc/keywest.c:	info.addr = keywest_ctx->addr;
sound/ppc/keywest.c:	keywest_ctx->client = i2c_new_device(adapter, &info);
sound/ppc/keywest.c:	if (!keywest_ctx->client)
sound/ppc/keywest.c:	if (!keywest_ctx->client->dev.driver) {
sound/ppc/keywest.c:		i2c_unregister_device(keywest_ctx->client);
sound/ppc/keywest.c:		keywest_ctx->client = NULL;
sound/ppc/keywest.c:	list_add_tail(&keywest_ctx->client->detected,
sound/ppc/keywest.c:		      &to_i2c_driver(keywest_ctx->client->dev.driver)->clients);
sound/ppc/keywest.c:	if (client == keywest_ctx->client)
sound/ppc/keywest.c:		keywest_ctx->client = NULL;
sound/ppc/keywest.c:	if (!keywest_ctx || !keywest_ctx->client)
sound/ppc/keywest.c:	if ((err = keywest_ctx->init_client(keywest_ctx)) < 0) {
tools/lib/subcmd/parse-options.c:	ctx->argc = argc - 1;
tools/lib/subcmd/parse-options.c:	ctx->argv = argv + 1;
tools/lib/subcmd/parse-options.c:	ctx->out  = argv;
tools/lib/subcmd/parse-options.c:	ctx->cpidx = ((flags & PARSE_OPT_KEEP_ARGV0) != 0);
tools/lib/subcmd/parse-options.c:	ctx->flags = flags;
tools/lib/subcmd/parse-options.c:	int internal_help = !(ctx->flags & PARSE_OPT_NO_INTERNAL_HELP);
tools/lib/subcmd/parse-options.c:	ctx->opt = NULL;
tools/lib/subcmd/parse-options.c:	for (; ctx->argc; ctx->argc--, ctx->argv++) {
tools/lib/subcmd/parse-options.c:		arg = ctx->argv[0];
tools/lib/subcmd/parse-options.c:			if (ctx->flags & PARSE_OPT_STOP_AT_NON_OPTION)
tools/lib/subcmd/parse-options.c:			ctx->out[ctx->cpidx++] = ctx->argv[0];
tools/lib/subcmd/parse-options.c:			ctx->opt = ++arg;
tools/lib/subcmd/parse-options.c:			if (internal_help && *ctx->opt == 'h') {
tools/lib/subcmd/parse-options.c:			if (ctx->opt)
tools/lib/subcmd/parse-options.c:			while (ctx->opt) {
tools/lib/subcmd/parse-options.c:				if (internal_help && *ctx->opt == 'h')
tools/lib/subcmd/parse-options.c:				arg = ctx->opt;
tools/lib/subcmd/parse-options.c:					ctx->argv[0] = strdup(ctx->opt - 1);
tools/lib/subcmd/parse-options.c:					*(char *)ctx->argv[0] = '-';
tools/lib/subcmd/parse-options.c:			if (!(ctx->flags & PARSE_OPT_KEEP_DASHDASH)) {
tools/lib/subcmd/parse-options.c:				ctx->argc--;
tools/lib/subcmd/parse-options.c:				ctx->argv++;
tools/lib/subcmd/parse-options.c:		if (!(ctx->flags & PARSE_OPT_KEEP_UNKNOWN))
tools/lib/subcmd/parse-options.c:		ctx->out[ctx->cpidx++] = ctx->argv[0];
tools/lib/subcmd/parse-options.c:		ctx->opt = NULL;
tools/lib/subcmd/parse-options.c:	if ((excl_short_opt && ctx->excl_opt->short_name) ||
tools/lib/subcmd/parse-options.c:	    ctx->excl_opt->long_name == NULL) {
tools/lib/subcmd/parse-options.c:		char opt = ctx->excl_opt->short_name;
tools/lib/subcmd/parse-options.c:		parse_options_usage(NULL, options, ctx->excl_opt->long_name, 0);
tools/lib/subcmd/parse-options.c:	memmove(ctx->out + ctx->cpidx, ctx->argv, ctx->argc * sizeof(*ctx->out));
tools/lib/subcmd/parse-options.c:	ctx->out[ctx->cpidx + ctx->argc] = NULL;
tools/lib/subcmd/parse-options.c:	return ctx->cpidx + ctx->argc;
tools/lib/subcmd/parse-options.c:	for (i = 1; i < ctx->argc; ++i) {
tools/lib/subcmd/parse-options.c:		const char *arg = ctx->argv[i];
tools/lib/subcmd/parse-options.c:		if (ctx && ctx->argc > 1 && !option__in_argv(opts, ctx))
tools/perf/ui/gtk/util.c:		ctx->main_window = window;
tools/perf/ui/gtk/util.c:	dialog = gtk_message_dialog_new_with_markup(GTK_WINDOW(pgctx->main_window),
tools/perf/ui/gtk/util.c:	gtk_label_set_text(GTK_LABEL(pgctx->message_label), msg);
tools/perf/ui/gtk/util.c:	gtk_info_bar_set_message_type(GTK_INFO_BAR(pgctx->info_bar),
tools/perf/ui/gtk/util.c:	gtk_widget_show(pgctx->info_bar);
tools/perf/ui/gtk/util.c:	gtk_statusbar_pop(GTK_STATUSBAR(pgctx->statbar),
tools/perf/ui/gtk/util.c:			  pgctx->statbar_ctx_id);
tools/perf/ui/gtk/util.c:	gtk_statusbar_push(GTK_STATUSBAR(pgctx->statbar),
tools/perf/ui/gtk/util.c:			   pgctx->statbar_ctx_id, msg);
tools/perf/ui/gtk/browser.c:	pgctx->info_bar = info_bar;
tools/perf/ui/gtk/browser.c:	pgctx->message_label = label;
tools/perf/ui/gtk/browser.c:	pgctx->statbar = stbar;
tools/perf/ui/gtk/browser.c:	pgctx->statbar_ctx_id = ctxid;
tools/perf/ui/gtk/annotate.c:		window = pgctx->main_window;
tools/perf/ui/gtk/annotate.c:		notebook = pgctx->notebook;
tools/perf/ui/gtk/annotate.c:		pgctx->notebook = notebook;
tools/perf/ui/gtk/annotate.c:	window = pgctx->main_window;
tools/perf/ui/gtk/helpline.c:	gtk_statusbar_pop(GTK_STATUSBAR(pgctx->statbar),
tools/perf/ui/gtk/helpline.c:			  pgctx->statbar_ctx_id);
tools/perf/ui/gtk/helpline.c:	gtk_statusbar_push(GTK_STATUSBAR(pgctx->statbar),
tools/perf/ui/gtk/helpline.c:			   pgctx->statbar_ctx_id, msg);
tools/perf/ui/gtk/gtk.h:	return ctx && ctx->main_window;
tools/perf/bench/sched-messaging.c:	ready(ctx->ready_out, ctx->wakefd);
tools/perf/bench/sched-messaging.c:		for (j = 0; j < ctx->num_fds; j++) {
tools/perf/bench/sched-messaging.c:			ret = write(ctx->out_fds[j], data + done,
tools/perf/bench/sched-messaging.c:		close(ctx->in_fds[1]);
tools/perf/bench/sched-messaging.c:	ready(ctx->ready_out, ctx->wakefd);
tools/perf/bench/sched-messaging.c:	for (i = 0; i < ctx->num_packets; i++) {
tools/perf/bench/sched-messaging.c:		ret = read(ctx->in_fds[0], data + done, DATASIZE - done);
tools/perf/bench/sched-messaging.c:		ctx->num_packets = num_fds * nr_loops;
tools/perf/bench/sched-messaging.c:		ctx->in_fds[0] = fds[0];
tools/perf/bench/sched-messaging.c:		ctx->in_fds[1] = fds[1];
tools/perf/bench/sched-messaging.c:		ctx->ready_out = ready_out;
tools/perf/bench/sched-messaging.c:		ctx->wakefd = wakefd;
tools/perf/bench/sched-messaging.c:		snd_ctx->out_fds[i] = fds[1];
tools/perf/bench/sched-messaging.c:		snd_ctx->ready_out = ready_out;
tools/perf/bench/sched-messaging.c:		snd_ctx->wakefd = wakefd;
tools/perf/bench/sched-messaging.c:		snd_ctx->num_fds = num_fds;
tools/perf/bench/sched-messaging.c:			close(snd_ctx->out_fds[i]);
tools/testing/selftests/x86/entry_from_vm86.c:	if (ctx->uc_mcontext.gregs[REG_EFL] & X86_EFLAGS_VM ||
tools/testing/selftests/x86/entry_from_vm86.c:	    (ctx->uc_mcontext.gregs[REG_CS] & 3) != 3) {
tools/testing/selftests/x86/entry_from_vm86.c:	       (unsigned long)ctx->uc_mcontext.gregs[REG_EFL],
tools/testing/selftests/x86/entry_from_vm86.c:	       (unsigned short)ctx->uc_mcontext.gregs[REG_CS]);
tools/testing/selftests/x86/unwind_vdso.c:	unsigned long ip = ctx->uc_mcontext.gregs[REG_EIP];
tools/testing/selftests/x86/unwind_vdso.c:		return_address = *(unsigned long *)(unsigned long)ctx->uc_mcontext.gregs[REG_ESP];
tools/testing/selftests/x86/unwind_vdso.c:		ctx->uc_mcontext.gregs[REG_EFL] &= ~X86_EFLAGS_TF;
tools/testing/selftests/x86/fsgsbase.c:	ctx->uc_mcontext.gregs[REG_RIP] += 4;	/* Skip the faulting mov */
tools/testing/selftests/x86/sigreturn.c:	struct selectors *sels = (void *)&ctx->uc_mcontext.gregs[REG_CSGSFS];
tools/testing/selftests/x86/sigreturn.c:	struct selectors *sels = (void *)&ctx->uc_mcontext.gregs[REG_CSGSFS];
tools/testing/selftests/x86/sigreturn.c:	return &ctx->uc_mcontext.gregs[REG_SS];
tools/testing/selftests/x86/sigreturn.c:	return &ctx->uc_mcontext.gregs[REG_CS];
tools/testing/selftests/x86/sigreturn.c:	if (!(ctx->uc_flags & UC_SIGCONTEXT_SS)) {
tools/testing/selftests/x86/sigreturn.c:	if (!!(ctx->uc_flags & UC_STRICT_RESTORE_SS) != was_64bit) {
tools/testing/selftests/x86/sigreturn.c:	memcpy(&initial_regs, &ctx->uc_mcontext.gregs, sizeof(gregset_t));
tools/testing/selftests/x86/sigreturn.c:	ctx->uc_mcontext.gregs[REG_IP] =
tools/testing/selftests/x86/sigreturn.c:	ctx->uc_mcontext.gregs[REG_SP] = (unsigned long)0x8badf00d5aadc0deULL;
tools/testing/selftests/x86/sigreturn.c:	ctx->uc_mcontext.gregs[REG_CX] = 0;
tools/testing/selftests/x86/sigreturn.c:	memcpy(&requested_regs, &ctx->uc_mcontext.gregs, sizeof(gregset_t));
tools/testing/selftests/x86/sigreturn.c:	sig_err = ctx->uc_mcontext.gregs[REG_ERR];
tools/testing/selftests/x86/sigreturn.c:	sig_trapno = ctx->uc_mcontext.gregs[REG_TRAPNO];
tools/testing/selftests/x86/sigreturn.c:	greg_t asm_ss = ctx->uc_mcontext.gregs[REG_CX];
tools/testing/selftests/x86/sigreturn.c:	memcpy(&resulting_regs, &ctx->uc_mcontext.gregs, sizeof(gregset_t));
tools/testing/selftests/x86/sigreturn.c:	memcpy(&ctx->uc_mcontext.gregs, &initial_regs, sizeof(gregset_t));
tools/testing/selftests/x86/sigreturn.c:		if (ctx->uc_flags & UC_STRICT_RESTORE_SS) {
tools/testing/selftests/x86/sigreturn.c:	if (!(ctx->uc_flags & UC_STRICT_RESTORE_SS)) {
tools/testing/selftests/x86/sigreturn.c:	ctx->uc_flags &= ~UC_STRICT_RESTORE_SS;
tools/testing/selftests/x86/single_step_syscall.c:		       (unsigned long)ctx->uc_mcontext.gregs[REG_IP]);
tools/testing/selftests/x86/syscall_arg_fault.c:	if (ctx->uc_mcontext.gregs[REG_EAX] != -EFAULT) {
tools/testing/selftests/x86/syscall_arg_fault.c:		       ctx->uc_mcontext.gregs[REG_EAX]);
tools/testing/selftests/powerpc/alignment/copy_paste_unaligned_common.c:	unsigned int *pc = (unsigned int *)ctx->uc_mcontext.gp_regs[PT_NIP];
tools/testing/selftests/powerpc/alignment/copy_paste_unaligned_common.c:	unsigned int *pc = (unsigned int *)ctx->uc_mcontext.uc_regs->gregs[PT_NIP];
